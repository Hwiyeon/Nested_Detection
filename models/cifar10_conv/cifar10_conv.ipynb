{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Conv Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current version [1.3.0]\n",
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "import time\n",
    "import cPickle\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  ## just for ignore DeprcationWarning message\n",
    "print(\"Current version [%s]\" %(tf.__version__))\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAGS READY\n"
     ]
    }
   ],
   "source": [
    "# Dataset Configurations\n",
    "tf.app.flags.DEFINE_integer('img_size', 32, \"\"\"Image size of CIFAR-10 dataset\"\"\")\n",
    "tf.app.flags.DEFINE_integer('img_num', 10000, \"\"\"Number of images in one cifar batch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_num', 5, \"\"\"Number of cifar batches in dataset\"\"\")\n",
    "tf.app.flags.DEFINE_string('train_dir', './../../../Dataset/cifar-10-batches-py', \"\"\"Directory which contains the train data\"\"\")\n",
    "tf.app.flags.DEFINE_string('test_dir', './../../../Dataset/cifar-10-batches-py', \"\"\"Directory which contains the test data\"\"\")\n",
    "\n",
    "# Network Configurations\n",
    "tf.app.flags.DEFINE_integer('batch_size', 100, \"\"\"Number of images to process in a batch\"\"\")\n",
    "tf.app.flags.DEFINE_float('l1_ratio', 0.5, \"\"\"Ratio of level1\"\"\")\n",
    "tf.app.flags.DEFINE_float('l2_ratio', 0.5, \"\"\"Ratio of level2\"\"\")\n",
    "\n",
    "# Optimization Configurations\n",
    "tf.app.flags.DEFINE_float('lr', 0.001, \"\"\"Learning rate\"\"\")\n",
    "\n",
    "# Training Configurations\n",
    "tf.app.flags.DEFINE_integer('training_epochs', 500, \"\"\"Number of epochs to run\"\"\")\n",
    "tf.app.flags.DEFINE_integer('display_step', 5, \"\"\"Number of iterations to display training output\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_step', 20, \"\"\"Number of interations to save checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_max', 10, \"\"\"Number of checkpoints to remain\"\"\")\n",
    "\n",
    "\n",
    "# Save Configurations\n",
    "tf.app.flags.DEFINE_string('nets', './nets', \"\"\"Directory where to write the checkpoints\"\"\")\n",
    "tf.app.flags.DEFINE_string('outputs', './outputs', \"\"\"Directory where to save the output images\"\"\")\n",
    "tf.app.flags.DEFINE_string('tboard', './tensorboard', \"\"\"Directory where to save the tensorboard logs\"\"\")\n",
    "\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "print(\"FLAGS READY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with tf.device('/CPU:0'):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = cPickle.load(fo)\n",
    "        return dict\n",
    "\n",
    "def read_cifar(file):\n",
    "    with tf.device('/CPU:0'):\n",
    "        _dic = unpickle(file)\n",
    "        _img = _dic['data']/255.    # float type\n",
    "        _label = _dic['labels']    # (10000, )\n",
    "\n",
    "#         _img_shape = np.shape(_img)\n",
    "#         _img = np.reshape(np.transpose(np.reshape(_img, (-1, 3, 32, 32)), (0,2,3,1)), _img_shape) # (10000, 3072)\n",
    "\n",
    "        _img = np.transpose(np.reshape(_img, (-1, 3, 32, 32)), (0,2,3,1))\n",
    "    \n",
    "        return _img   # (10000, 32, 32, 3)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random noise mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_mask(prob=0.5):\n",
    "    mask = np.zeros([FLAGS.img_size, FLAGS.img_size, 3])\n",
    "    rd = np.random.random()\n",
    "    if rd > prob:\n",
    "        # threshold of the size of masks\n",
    "        uthd = FLAGS.img_size    \n",
    "        lthd = 0     \n",
    "        # mask size should be beween 14x14, 5x5\n",
    "        while(uthd>14 or lthd<5):\n",
    "            ver1 = np.random.random_integers(0, FLAGS.img_size-1, size= 2)   # vertex1\n",
    "            ver2 = np.random.random_integers(0, FLAGS.img_size-1, size= 2)    # vertex2\n",
    "            uthd = np.maximum(np.abs(ver1[0]-ver2[0]), np.abs(ver1[1]-ver2[1]))    # upperbound\n",
    "            lthd = np.minimum(np.abs(ver1[0]-ver2[0]), np.abs(ver1[1]-ver2[1]))    # lowerbound\n",
    "        xmin = np.minimum(ver1[0], ver2[0])    # left x value\n",
    "        xmax = np.maximum(ver1[0], ver2[0])    # right x value\n",
    "        ymin = np.minimum(ver1[1], ver2[1])    # top y value\n",
    "        ymax = np.maximum(ver1[1], ver2[1])    # bottom y value\n",
    "        noise = np.random.random((xmax-xmin+1, ymax-ymin+1, 3))    # random sample in [0,1]\n",
    "        mask[xmin:xmax+1, ymin:ymax+1, :] = noise    # noise mask with location\n",
    "        mask_meta = [xmin, xmax, ymin, ymax, noise, mask]\n",
    "#         mask = np.reshape(mask, [-1])\n",
    "    return mask\n",
    "\n",
    "def noise_batch(batch_num):\n",
    "    # make random noise batch\n",
    "    mask_batch = np.zeros([batch_num, FLAGS.img_size, FLAGS.img_size, 3])\n",
    "    for i in range(batch_num):\n",
    "        mask_batch[i] = noise_mask()\n",
    "    return mask_batch\n",
    "\n",
    "\n",
    "def occl(target, disturb):\n",
    "    # Occlusion generation\n",
    "    mask = (disturb==0).astype(float)\n",
    "    masked_target = np.multiply(target, mask)\n",
    "    crpt = np.add(masked_target, disturb)\n",
    "    return crpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Convolutional Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nested_enc(l1, l2_s, l2, out_channel, name, filter_size=3, std=[1,2,2,1],pad='SAME', stddev=0.1):\n",
    "    l1_shape = l1.get_shape()\n",
    "    l2_shape = l2.get_shape()\n",
    "    l2_s_shape = l2_s.get_shape()\n",
    "                                   \n",
    "    #with tf.device('/CPU:0'):\n",
    "    with tf.variable_scope('level1'):\n",
    "        with tf.variable_scope(name):\n",
    "            l1_weights = tf.get_variable('weights', \n",
    "                                         [filter_size, filter_size, l1_shape[3], out_channel*FLAGS.l1_ratio], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l1_biases = tf.get_variable('biases', \n",
    "                                        [out_channel*FLAGS.l1_ratio],\n",
    "                                        tf.float32, \n",
    "                                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "    with tf.variable_scope('level2'):\n",
    "        with tf.variable_scope(name):\n",
    "            l2_s_weights = tf.get_variable('weights_shell', \n",
    "                                           [filter_size, filter_size, l2_s_shape[3], out_channel*FLAGS.l2_ratio], \n",
    "                                           tf.float32, \n",
    "                                           initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l2_s_biases = tf.get_variable('biases_shell', \n",
    "                                          [out_channel*FLAGS.l2_ratio],\n",
    "                                          tf.float32, \n",
    "                                          initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l2_weights_1to2 = tf.get_variable('weights_1to2', \n",
    "                                           [filter_size, filter_size, l1_shape[3], out_channel*FLAGS.l2_ratio], \n",
    "                                           tf.float32, \n",
    "                                           initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l2_weights_2to1 = tf.get_variable('weights_2to1', \n",
    "                                           [filter_size, filter_size, l2_s_shape[3], out_channel*FLAGS.l1_ratio], \n",
    "                                           tf.float32, \n",
    "                                           initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "    l1_conv = tf.nn.conv2d(l1, l1_weights, strides=std, padding=pad)\n",
    "    l1_act = tf.nn.sigmoid(tf.add(l1_conv, l1_biases))\n",
    "\n",
    "    l2_s_conv = tf.nn.conv2d(l2_s, l2_s_weights, strides=std, padding=pad)\n",
    "    l2_s_act = tf.nn.sigmoid(tf.add(l2_s_conv, l2_s_biases))\n",
    "\n",
    "    l2_conv_1to1 = tf.nn.conv2d(l2[:,:,:,:l1_shape[3]], l1_weights, strides=std, padding=pad)\n",
    "    l2_conv_2to1 = tf.nn.conv2d(l2[:,:,:,l1_shape[3]:l2_shape[3]], l2_weights_2to1, strides=std, padding=pad)\n",
    "    l2_act_1 = tf.nn.sigmoid(tf.add(tf.add(l2_conv_1to1, l2_conv_2to1), l1_biases))\n",
    "    l2_conv_1to2 = tf.nn.conv2d(l2[:,:,:,:l1_shape[3]], l2_weights_1to2, strides=std, padding=pad)\n",
    "    l2_conv_2to2 = tf.nn.conv2d(l2[:,:,:,l1_shape[3]:l2_shape[3]], l2_s_weights, strides=std, padding=pad)\n",
    "    l2_act_2 = tf.nn.sigmoid(tf.add(tf.add(l2_conv_1to2, l2_conv_2to2), l2_s_biases))\n",
    "    l2_act = tf.concat((l2_act_1, l2_act_2), 3)\n",
    "        \n",
    "        \n",
    "    return l1_act, l2_s_act, l2_act\n",
    "\n",
    "def _nested_enc_init(_img, out_channel, name, filter_size=3, std=[1,2,2,1],pad='SAME', stddev=0.1):\n",
    "    # input is the input image \n",
    "    \n",
    "    #with tf.device('/CPU:0'):\n",
    "    with tf.variable_scope('level1'):\n",
    "        with tf.variable_scope(name):\n",
    "            l1_weights = tf.get_variable('weights', \n",
    "                                         [filter_size, filter_size, 3, out_channel*FLAGS.l1_ratio], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l1_biases = tf.get_variable('biases', \n",
    "                                        [out_channel*FLAGS.l1_ratio],\n",
    "                                        tf.float32, \n",
    "                                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "    with tf.variable_scope('level2'):\n",
    "        with tf.variable_scope(name):\n",
    "            l2_s_weights = tf.get_variable('weights_shell', \n",
    "                                         [filter_size, filter_size, 3, out_channel*FLAGS.l2_ratio], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l2_s_biases = tf.get_variable('biases_shell', \n",
    "                                        [out_channel*FLAGS.l2_ratio],\n",
    "                                        tf.float32, \n",
    "                                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "#     _input_img = tf.reshape(_img, [-1, FLAGS.img_size, FLAGS.img_size, 3])\n",
    "    l1_conv = tf.nn.conv2d(_img, l1_weights, strides=std, padding=pad)\n",
    "    l1_act = tf.nn.sigmoid(tf.add(l1_conv, l1_biases))\n",
    "    l2_s_conv = tf.nn.conv2d(_img, l2_s_weights, strides=std, padding=pad)\n",
    "    l2_s_act = tf.nn.sigmoid(tf.add(l2_s_conv, l2_s_biases))\n",
    "    l2_act = tf.concat((l1_act, l2_s_act), 3)\n",
    "    \n",
    "    return l1_act, l2_s_act, l2_act\n",
    "\n",
    "def _nested_enc_last(l1, l2_s, l2, out_channel, name, pad='VALID', stddev=0.1):\n",
    "    # output is an encoded vector -> Fully convolutioanl layer\n",
    "    l1_shape = l1.get_shape()    \n",
    "    l2_shape = l2.get_shape()\n",
    "    l2_s_shape = l2_s.get_shape()  \n",
    "    #l1_size = [l1_shape[1], l2_shape[2]]    # l1_shape[1], l1_shape[2] will be used in conv_transpose shape\n",
    "\n",
    "    #with tf.device('/CPU:0'):\n",
    "    with tf.variable_scope('level1'):\n",
    "        with tf.variable_scope(name):\n",
    "            l1_weights = tf.get_variable('weights', \n",
    "                                         [l1_shape[1],l1_shape[2],l1_shape[3], out_channel*FLAGS.l1_ratio], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l1_biases = tf.get_variable('biases', \n",
    "                                        [out_channel*FLAGS.l1_ratio],\n",
    "                                        tf.float32, \n",
    "                                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "    with tf.variable_scope('level2'):\n",
    "        with tf.variable_scope(name):\n",
    "            l2_s_weights = tf.get_variable('weights_shell', \n",
    "                                         [l2_s_shape[1],l2_s_shape[2],l2_s_shape[3], out_channel*FLAGS.l2_ratio], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l2_s_biases = tf.get_variable('biases_shell', \n",
    "                                        [out_channel*FLAGS.l2_ratio],\n",
    "                                        tf.float32, \n",
    "                                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "    l1_conv = tf.nn.conv2d(l1, l1_weights, strides=[1,1,1,1], padding=pad)\n",
    "    l1_act = tf.nn.sigmoid(tf.add(l1_conv, l1_biases))\n",
    "    l2_s_conv = tf.nn.conv2d(l2_s, l2_s_weights, strides=[1,1,1,1], padding=pad)\n",
    "    l2_s_act = tf.nn.sigmoid(tf.add(l2_s_conv, l2_s_biases))\n",
    "    l2_act = tf.concat((l1_act, l2_s_act), 3)\n",
    "        \n",
    "    return l1_act, l2_s_act, l2_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Convolutional Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nested_dec(l1, l2_s, l2, out_size, out_channel, name, filter_size=3, std=[1,2,2,1], pad='SAME', stddev=0.1):\n",
    "    l1_shape = l1.get_shape()\n",
    "    l2_shape = l2.get_shape()\n",
    "    l2_s_shape = l2_s.get_shape()\n",
    "    \n",
    "    \n",
    "    l1_out_shape = [tf.shape(l1)[0],out_size[0],out_size[1],int(out_channel*FLAGS.l1_ratio)]\n",
    "    l2_s_out_shape = [tf.shape(l2_s)[0],out_size[0],out_size[1],int(out_channel*FLAGS.l2_ratio)]\n",
    "    \n",
    "    #with tf.device('/CPU:0'):\n",
    "    with tf.variable_scope('level1'):\n",
    "        with tf.variable_scope(name):\n",
    "            l1_weights = tf.get_variable('weights', \n",
    "                                         [filter_size, filter_size, out_channel*FLAGS.l1_ratio, l1_shape[3]], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l1_biases = tf.get_variable('biases', \n",
    "                                        [out_channel*FLAGS.l1_ratio],\n",
    "                                        tf.float32, \n",
    "                                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "    with tf.variable_scope('level2'):\n",
    "        with tf.variable_scope(name):\n",
    "            l2_s_weights = tf.get_variable('weights_shell', \n",
    "                                           [filter_size, filter_size, out_channel*FLAGS.l2_ratio, l2_s_shape[3]], \n",
    "                                           tf.float32, \n",
    "                                           initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l2_s_biases = tf.get_variable('biases_shell', \n",
    "                                          [out_channel*FLAGS.l2_ratio],\n",
    "                                          tf.float32, \n",
    "                                          initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l2_weights_1to2 = tf.get_variable('weights_1to2', \n",
    "                                           [filter_size, filter_size, out_channel*FLAGS.l2_ratio, l1_shape[3]], \n",
    "                                           tf.float32, \n",
    "                                           initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l2_weights_2to1 = tf.get_variable('weights_2to1', \n",
    "                                           [filter_size, filter_size, out_channel*FLAGS.l1_ratio, l2_s_shape[3]], \n",
    "                                           tf.float32, \n",
    "                                           initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "    l1_dec = tf.nn.conv2d_transpose(l1, l1_weights, \n",
    "                                    output_shape=l1_out_shape, strides=std, padding=pad)\n",
    "    l1_act = tf.nn.sigmoid(tf.add(l1_dec, l1_biases))\n",
    "\n",
    "    l2_s_dec = tf.nn.conv2d_transpose(l1, l1_weights,\n",
    "                                       output_shape=l2_s_out_shape, strides=std, padding=pad)\n",
    "    l2_s_act = tf.nn.sigmoid(tf.add(l2_s_dec, l2_s_biases))\n",
    "\n",
    "    l2_dec_1to1 = tf.nn.conv2d_transpose(l2[:,:,:,:l1_shape[3]], l1_weights, \n",
    "                                          output_shape=l1_out_shape, strides=std, padding=pad)\n",
    "    l2_dec_2to1 = tf.nn.conv2d_transpose(l2[:,:,:,l1_shape[3]:l2_shape[3]], l2_weights_2to1,\n",
    "                                          output_shape=l1_out_shape, strides=std, padding=pad)\n",
    "    l2_act_1 = tf.nn.sigmoid(tf.add(tf.add(l2_dec_1to1, l2_dec_2to1), l1_biases))\n",
    "    l2_dec_1to2 = tf.nn.conv2d_transpose(l2[:,:,:,:l1_shape[3]], l2_weights_1to2, \n",
    "                                          output_shape=l2_s_out_shape, strides=std, padding=pad)\n",
    "    l2_dec_2to2 = tf.nn.conv2d_transpose(l2[:,:,:,l1_shape[3]:l2_shape[3]], l2_s_weights, \n",
    "                                          output_shape=l2_s_out_shape, strides=std, padding=pad)\n",
    "    l2_act_2 = tf.nn.sigmoid(tf.add(tf.add(l2_dec_1to2, l2_dec_2to2), l2_s_biases))\n",
    "    l2_act = tf.concat((l2_act_1, l2_act_2), 3)\n",
    "        \n",
    "    return l1_act, l2_s_act, l2_act\n",
    "\n",
    "    \n",
    "def _nested_dec_init(_l1, _l2_s, out_size, out_channel, name, pad='VALID', stddev=0.1):\n",
    "    # input is an encoded vector\n",
    "    # out_size is the shape for conv_transpose \n",
    "    l1_shape = _l1.get_shape()\n",
    "    l2_s_shape = _l2_s.get_shape()\n",
    "    l1_out_shape = [tf.shape(_l1)[0],out_size[0],out_size[1],int(out_channel*FLAGS.l1_ratio)]\n",
    "    l2_s_out_shape = [tf.shape(_l2_s)[0],out_size[0],out_size[1],int(out_channel*FLAGS.l2_ratio)]\n",
    "    \n",
    "    #with tf.device('/CPU:0'):\n",
    "    with tf.variable_scope('level1'):\n",
    "        with tf.variable_scope(name):\n",
    "            l1_weights = tf.get_variable('weights', \n",
    "                                         [out_size[0], out_size[1], out_channel*FLAGS.l1_ratio, l1_shape[3]], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l1_biases = tf.get_variable('biases', \n",
    "                                        [out_channel*FLAGS.l1_ratio],\n",
    "                                        tf.float32, \n",
    "                                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "    with tf.variable_scope('level2'):\n",
    "        with tf.variable_scope(name):\n",
    "            l2_s_weights = tf.get_variable('weights_shell', \n",
    "                                         [out_size[0], out_size[1], out_channel*FLAGS.l2_ratio, l2_s_shape[3]], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            l2_s_biases = tf.get_variable('biases_shell', \n",
    "                                        [out_channel*FLAGS.l2_ratio],\n",
    "                                        tf.float32, \n",
    "                                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "#     l1 = tf.reshape(_l1, [-1, 1, 1, l1_shape[1]])\n",
    "#     l2_s = tf.reshape(_l2_s, [-1, 1, 1, l2_s_shape[1]])\n",
    "    l1_dec = tf.nn.conv2d_transpose(_l1, l1_weights, \n",
    "                                    output_shape=l1_out_shape, strides=[1,1,1,1], padding=pad)\n",
    "    l1_act = tf.nn.sigmoid(tf.add(l1_dec, l1_biases))\n",
    "    l2_s_dec = tf.nn.conv2d_transpose(_l2_s, l2_s_weights, \n",
    "                                    output_shape=l2_s_out_shape, strides=[1,1,1,1], padding=pad)\n",
    "    l2_s_act = tf.nn.sigmoid(tf.add(l2_s_dec, l2_s_biases))\n",
    "    l2_act = tf.concat((l1_act, l2_s_act), 3)\n",
    "    \n",
    "    return l1_act, l2_s_act, l2_act\n",
    " \n",
    "    \n",
    "def _nested_dec_last(l1, l2_s, l2, name, filter_size=3, std=[1,2,2,1], pad='SAME', stddev=0.1):\n",
    "    # output is original size image\n",
    "    l1_shape = l1.get_shape()\n",
    "    l2_shape = l2.get_shape()\n",
    "    l2_s_shape = l2_s.get_shape()\n",
    "    \n",
    "    _out_shape = [tf.shape(l1)[0],FLAGS.img_size,FLAGS.img_size,3]\n",
    "\n",
    "    #with tf.device('/CPU:0'):\n",
    "    with tf.variable_scope('level1'):\n",
    "        with tf.variable_scope(name):\n",
    "            l1_weights = tf.get_variable('weights', \n",
    "                                         [filter_size, filter_size, 3, l1_shape[3]], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            out_biases = tf.get_variable('biases', \n",
    "                                        [3],\n",
    "                                        tf.float32, \n",
    "                                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "    with tf.variable_scope('level2'):\n",
    "        with tf.variable_scope(name):\n",
    "            l2_s_weights = tf.get_variable('weights_shell', \n",
    "                                         [filter_size, filter_size, 3, l2_s_shape[3]], \n",
    "                                         tf.float32, \n",
    "                                         initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "    l1_dec = tf.nn.conv2d_transpose(l1, l1_weights, \n",
    "                                  output_shape=_out_shape, strides=std, padding=pad)\n",
    "    l1_act = tf.nn.sigmoid(tf.add(l1_dec, out_biases))\n",
    "    l2_s_dec = tf.nn.conv2d_transpose(l2_s, l2_s_weights, \n",
    "                                    output_shape=_out_shape, strides=std, padding=pad)\n",
    "    l2_s_act = tf.nn.sigmoid(tf.add(l2_s_dec, out_biases))\n",
    "    l2_act = tf.nn.sigmoid(tf.add(tf.add(l1_dec, l2_s_dec), out_biases))\n",
    "    \n",
    "    return l1_act, l2_s_act, l2_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs Ready\n"
     ]
    }
   ],
   "source": [
    "# Network Topology\n",
    "# n_input = FLAGS.img_size*FLAGS.img_size*3\n",
    "n_enc1 = 64\n",
    "n_enc2 = 128\n",
    "n_enc3 = 256\n",
    "n_dec1 = 128\n",
    "n_dec2 = 64\n",
    "\n",
    "# Inputs and Outputs\n",
    "ph_pure = tf.placeholder(\"float\", [None, FLAGS.img_size, FLAGS.img_size, 3])    # pure image --- core\n",
    "ph_noise= tf.placeholder(\"float\", [None, FLAGS.img_size, FLAGS.img_size, 3])    # noise --- shell1\n",
    "ph_crpt = tf.placeholder(\"float\", [None, FLAGS.img_size, FLAGS.img_size, 3])    # corrupted image   --- level2\n",
    "\n",
    "\n",
    "# Model\n",
    "def nested_ae_conv(_X):\n",
    "    l1_enc1, l2_s_enc1, l2_enc1 = _nested_enc_init(_X, n_enc1, name='enc1')    # 32->16\n",
    "    l1_enc2, l2_s_enc2, l2_enc2 = _nested_enc(l1_enc1, l2_s_enc1, l2_enc1, n_enc2, name='enc2')    # 16->8\n",
    "    l1_enc3, l2_s_enc3, l2_enc3 = _nested_enc_last(l1_enc2, l2_s_enc2, l2_enc2, n_enc3, name='enc3')    # 8->4\n",
    "#     print(l1_enc3.get_shape(), l2_s_enc3.get_shape(), l2_enc3.get_shape())\n",
    "    l1_dec1, l2_s_dec1, l2_dec1 = _nested_dec_init(l1_enc3, l2_s_enc3, [8,8], n_dec1, name='dec1')    # 4->8\n",
    "    l1_dec2, l2_s_dec2, l2_dec2 = _nested_dec(l1_dec1, l2_s_dec1, l2_dec1, [16,16], n_dec2, name='dec2')    # 8->16\n",
    "    l1_out, l2_s_out, l2_out = _nested_dec_last(l1_dec2, l2_s_dec2, l2_dec2, name='out')    #16->32\n",
    "    return l1_out, l2_s_out, l2_out\n",
    "\n",
    "# Generation\n",
    "core_gen, shell2_gen, full_gen = nested_ae_conv(ph_crpt)   # [None, n_input]\n",
    "\n",
    "# Loss & Optimizer\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "#     loss = tf.reduce_mean(tf.nn.l2_loss(full_gen-ph_crpt)) + tf.reduce_mean(tf.nn.l2_loss(core_gen-ph_pure))\\\n",
    "#             + tf.reduce_mean(tf.nn.l2_loss(shell2_gen-ph_noise))\n",
    "    loss = tf.reduce_mean(tf.abs(full_gen-ph_crpt)) + tf.reduce_mean(tf.abs(core_gen-ph_pure))\\\n",
    "            + tf.reduce_mean(tf.abs(shell2_gen-ph_noise))\n",
    "    _train_loss = tf.summary.scalar(\"train_loss\", loss)\n",
    "    _test_loss = tf.summary.scalar(\"test_loss\", loss)\n",
    "\n",
    "optm = tf.train.AdamOptimizer(learning_rate=FLAGS.lr).minimize(loss)\n",
    "\n",
    "\n",
    "print(\"Graphs Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Ready\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "tensorboard_path = FLAGS.tboard\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)\n",
    "writer = tf.summary.FileWriter(tensorboard_path)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "print(\"Initialize Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saver ready\n"
     ]
    }
   ],
   "source": [
    "outputdir = FLAGS.outputs\n",
    "if not os.path.exists(outputdir+'/train'):\n",
    "    os.makedirs(outputdir+'/train')\n",
    "\n",
    "if not os.path.exists(outputdir+'/test'):\n",
    "    os.makedirs(outputdir+'/test')\n",
    "    \n",
    "savedir = FLAGS.nets\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "    \n",
    "saver = tf.train.Saver(max_to_keep=FLAGS.save_max)\n",
    "print(\"Saver ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 001/500 data_batch_1,  Train_loss : 0.6781  Test_loss : 0.6907, Time/batch_file : 9.5198, Training time: 9.5212\n",
      "Epoch : 001/500 data_batch_2,  Train_loss : 0.6648  Test_loss : 0.6640, Time/batch_file : 8.9101, Training time: 18.4319\n",
      "Epoch : 001/500 data_batch_3,  Train_loss : 0.6623  Test_loss : 0.6680, Time/batch_file : 9.3125, Training time: 27.7447\n",
      "Epoch : 001/500 data_batch_4,  Train_loss : 0.6718  Test_loss : 0.6390, Time/batch_file : 9.3174, Training time: 37.0623\n",
      "Epoch : 001/500 data_batch_5,  Train_loss : 0.6394  Test_loss : 0.6339, Time/batch_file : 9.6141, Training time: 46.6767\n",
      "Epoch : 002/500 data_batch_1,  Train_loss : 0.5105  Test_loss : 0.5114, Time/batch_file : 9.3429, Training time: 56.0199\n",
      "Epoch : 002/500 data_batch_2,  Train_loss : 0.4774  Test_loss : 0.4706, Time/batch_file : 9.2066, Training time: 65.2268\n",
      "Epoch : 002/500 data_batch_3,  Train_loss : 0.4458  Test_loss : 0.4422, Time/batch_file : 9.0762, Training time: 74.3033\n",
      "Epoch : 002/500 data_batch_4,  Train_loss : 0.4318  Test_loss : 0.4276, Time/batch_file : 9.2733, Training time: 83.5769\n",
      "Epoch : 002/500 data_batch_5,  Train_loss : 0.4082  Test_loss : 0.4155, Time/batch_file : 8.9170, Training time: 92.4942\n",
      "Epoch : 003/500 data_batch_1,  Train_loss : 0.3917  Test_loss : 0.3957, Time/batch_file : 8.7901, Training time: 101.2846\n",
      "Epoch : 003/500 data_batch_2,  Train_loss : 0.3813  Test_loss : 0.3915, Time/batch_file : 8.8312, Training time: 110.1160\n",
      "Epoch : 003/500 data_batch_3,  Train_loss : 0.3691  Test_loss : 0.3694, Time/batch_file : 8.9642, Training time: 119.0804\n",
      "Epoch : 003/500 data_batch_4,  Train_loss : 0.3484  Test_loss : 0.3682, Time/batch_file : 8.9320, Training time: 128.0126\n",
      "Epoch : 003/500 data_batch_5,  Train_loss : 0.3444  Test_loss : 0.3508, Time/batch_file : 9.2332, Training time: 137.2468\n",
      "Epoch : 004/500 data_batch_1,  Train_loss : 0.3430  Test_loss : 0.3460, Time/batch_file : 9.0257, Training time: 146.2727\n",
      "Epoch : 004/500 data_batch_2,  Train_loss : 0.3427  Test_loss : 0.3200, Time/batch_file : 9.2597, Training time: 155.5327\n",
      "Epoch : 004/500 data_batch_3,  Train_loss : 0.3305  Test_loss : 0.3224, Time/batch_file : 9.4002, Training time: 164.9332\n",
      "Epoch : 004/500 data_batch_4,  Train_loss : 0.3282  Test_loss : 0.3202, Time/batch_file : 9.0619, Training time: 173.9954\n",
      "Epoch : 004/500 data_batch_5,  Train_loss : 0.3141  Test_loss : 0.3040, Time/batch_file : 9.2611, Training time: 183.2568\n",
      "Epoch : 005/500 data_batch_1,  Train_loss : 0.3026  Test_loss : 0.2923, Time/batch_file : 9.0204, Training time: 192.2774\n",
      "Epoch : 005/500 data_batch_2,  Train_loss : 0.2922  Test_loss : 0.2848, Time/batch_file : 9.0740, Training time: 201.3517\n",
      "Epoch : 005/500 data_batch_3,  Train_loss : 0.2810  Test_loss : 0.2836, Time/batch_file : 9.5731, Training time: 210.9251\n",
      "Epoch : 005/500 data_batch_4,  Train_loss : 0.2762  Test_loss : 0.2765, Time/batch_file : 9.2138, Training time: 220.1392\n",
      "Epoch : 005/500 data_batch_5,  Train_loss : 0.2653  Test_loss : 0.2613, Time/batch_file : 9.0907, Training time: 229.2302\n",
      "Epoch : 006/500 data_batch_1,  Train_loss : 0.2656  Test_loss : 0.2720, Time/batch_file : 9.1612, Training time: 240.3118\n",
      "Epoch : 006/500 data_batch_2,  Train_loss : 0.2605  Test_loss : 0.2634, Time/batch_file : 9.3128, Training time: 249.6250\n",
      "Epoch : 006/500 data_batch_3,  Train_loss : 0.2591  Test_loss : 0.2679, Time/batch_file : 9.1759, Training time: 258.8013\n",
      "Epoch : 006/500 data_batch_4,  Train_loss : 0.2506  Test_loss : 0.2548, Time/batch_file : 9.0871, Training time: 267.8887\n",
      "Epoch : 006/500 data_batch_5,  Train_loss : 0.2430  Test_loss : 0.2531, Time/batch_file : 9.4274, Training time: 277.3164\n",
      "Epoch : 007/500 data_batch_1,  Train_loss : 0.2432  Test_loss : 0.2453, Time/batch_file : 9.1192, Training time: 286.4361\n",
      "Epoch : 007/500 data_batch_2,  Train_loss : 0.2525  Test_loss : 0.2468, Time/batch_file : 9.2385, Training time: 295.6750\n",
      "Epoch : 007/500 data_batch_3,  Train_loss : 0.2395  Test_loss : 0.2327, Time/batch_file : 9.3733, Training time: 305.0485\n",
      "Epoch : 007/500 data_batch_4,  Train_loss : 0.2343  Test_loss : 0.2372, Time/batch_file : 9.1825, Training time: 314.2313\n",
      "Epoch : 007/500 data_batch_5,  Train_loss : 0.2351  Test_loss : 0.2258, Time/batch_file : 9.0800, Training time: 323.3116\n",
      "Epoch : 008/500 data_batch_1,  Train_loss : 0.2304  Test_loss : 0.2199, Time/batch_file : 9.1715, Training time: 332.4834\n",
      "Epoch : 008/500 data_batch_2,  Train_loss : 0.2272  Test_loss : 0.2169, Time/batch_file : 9.1953, Training time: 341.6790\n",
      "Epoch : 008/500 data_batch_3,  Train_loss : 0.2173  Test_loss : 0.2180, Time/batch_file : 9.0330, Training time: 350.7122\n",
      "Epoch : 008/500 data_batch_4,  Train_loss : 0.2115  Test_loss : 0.2099, Time/batch_file : 9.0822, Training time: 359.7948\n",
      "Epoch : 008/500 data_batch_5,  Train_loss : 0.2210  Test_loss : 0.2083, Time/batch_file : 9.0607, Training time: 368.8559\n",
      "Epoch : 009/500 data_batch_1,  Train_loss : 0.2083  Test_loss : 0.2093, Time/batch_file : 9.1708, Training time: 378.0271\n",
      "Epoch : 009/500 data_batch_2,  Train_loss : 0.2087  Test_loss : 0.2030, Time/batch_file : 9.3259, Training time: 387.3532\n",
      "Epoch : 009/500 data_batch_3,  Train_loss : 0.1966  Test_loss : 0.2051, Time/batch_file : 9.0574, Training time: 396.4109\n",
      "Epoch : 009/500 data_batch_4,  Train_loss : 0.2047  Test_loss : 0.1969, Time/batch_file : 9.1291, Training time: 405.5402\n",
      "Epoch : 009/500 data_batch_5,  Train_loss : 0.1939  Test_loss : 0.2033, Time/batch_file : 9.1297, Training time: 414.6703\n",
      "Epoch : 010/500 data_batch_1,  Train_loss : 0.2013  Test_loss : 0.2080, Time/batch_file : 9.1351, Training time: 423.8057\n",
      "Epoch : 010/500 data_batch_2,  Train_loss : 0.1956  Test_loss : 0.2085, Time/batch_file : 9.2648, Training time: 433.0707\n",
      "Epoch : 010/500 data_batch_3,  Train_loss : 0.1928  Test_loss : 0.2061, Time/batch_file : 9.0275, Training time: 442.0985\n",
      "Epoch : 010/500 data_batch_4,  Train_loss : 0.1975  Test_loss : 0.2055, Time/batch_file : 9.2584, Training time: 451.3572\n",
      "Epoch : 010/500 data_batch_5,  Train_loss : 0.1847  Test_loss : 0.2037, Time/batch_file : 9.1730, Training time: 460.5306\n",
      "Epoch : 011/500 data_batch_1,  Train_loss : 0.2010  Test_loss : 0.2003, Time/batch_file : 9.3804, Training time: 472.0073\n",
      "Epoch : 011/500 data_batch_2,  Train_loss : 0.2023  Test_loss : 0.1987, Time/batch_file : 9.0621, Training time: 481.0697\n",
      "Epoch : 011/500 data_batch_3,  Train_loss : 0.1968  Test_loss : 0.1942, Time/batch_file : 9.0246, Training time: 490.0947\n",
      "Epoch : 011/500 data_batch_4,  Train_loss : 0.2001  Test_loss : 0.1935, Time/batch_file : 9.2000, Training time: 499.2950\n",
      "Epoch : 011/500 data_batch_5,  Train_loss : 0.1913  Test_loss : 0.2041, Time/batch_file : 9.1427, Training time: 508.4380\n",
      "Epoch : 012/500 data_batch_1,  Train_loss : 0.1882  Test_loss : 0.1830, Time/batch_file : 9.0879, Training time: 517.5262\n",
      "Epoch : 012/500 data_batch_2,  Train_loss : 0.1856  Test_loss : 0.1894, Time/batch_file : 9.0494, Training time: 526.5758\n",
      "Epoch : 012/500 data_batch_3,  Train_loss : 0.1913  Test_loss : 0.1882, Time/batch_file : 9.3416, Training time: 535.9178\n",
      "Epoch : 012/500 data_batch_4,  Train_loss : 0.1870  Test_loss : 0.1844, Time/batch_file : 9.2413, Training time: 545.1594\n",
      "Epoch : 012/500 data_batch_5,  Train_loss : 0.1826  Test_loss : 0.1838, Time/batch_file : 9.3167, Training time: 554.4764\n",
      "Epoch : 013/500 data_batch_1,  Train_loss : 0.2008  Test_loss : 0.1933, Time/batch_file : 9.3528, Training time: 563.8295\n",
      "Epoch : 013/500 data_batch_2,  Train_loss : 0.1917  Test_loss : 0.1924, Time/batch_file : 9.2545, Training time: 573.0844\n",
      "Epoch : 013/500 data_batch_3,  Train_loss : 0.1954  Test_loss : 0.1903, Time/batch_file : 9.0114, Training time: 582.0961\n",
      "Epoch : 013/500 data_batch_4,  Train_loss : 0.1923  Test_loss : 0.1819, Time/batch_file : 9.1743, Training time: 591.2706\n",
      "Epoch : 013/500 data_batch_5,  Train_loss : 0.1881  Test_loss : 0.1863, Time/batch_file : 9.3922, Training time: 600.6632\n",
      "Epoch : 014/500 data_batch_1,  Train_loss : 0.1828  Test_loss : 0.1847, Time/batch_file : 9.3517, Training time: 610.0153\n",
      "Epoch : 014/500 data_batch_2,  Train_loss : 0.1846  Test_loss : 0.1858, Time/batch_file : 9.3610, Training time: 619.3766\n",
      "Epoch : 014/500 data_batch_3,  Train_loss : 0.1939  Test_loss : 0.1849, Time/batch_file : 9.0892, Training time: 628.4660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 014/500 data_batch_4,  Train_loss : 0.1874  Test_loss : 0.1816, Time/batch_file : 9.1898, Training time: 637.6562\n",
      "Epoch : 014/500 data_batch_5,  Train_loss : 0.1822  Test_loss : 0.1794, Time/batch_file : 9.0385, Training time: 646.6949\n",
      "Epoch : 015/500 data_batch_1,  Train_loss : 0.1811  Test_loss : 0.1772, Time/batch_file : 9.2365, Training time: 655.9317\n",
      "Epoch : 015/500 data_batch_2,  Train_loss : 0.1774  Test_loss : 0.1703, Time/batch_file : 8.9825, Training time: 664.9144\n",
      "Epoch : 015/500 data_batch_3,  Train_loss : 0.1768  Test_loss : 0.1738, Time/batch_file : 9.1044, Training time: 674.0190\n",
      "Epoch : 015/500 data_batch_4,  Train_loss : 0.1736  Test_loss : 0.1742, Time/batch_file : 9.2630, Training time: 683.2824\n",
      "Epoch : 015/500 data_batch_5,  Train_loss : 0.1695  Test_loss : 0.1792, Time/batch_file : 9.2649, Training time: 692.5476\n",
      "Epoch : 016/500 data_batch_1,  Train_loss : 0.1814  Test_loss : 0.1820, Time/batch_file : 9.3885, Training time: 703.8280\n",
      "Epoch : 016/500 data_batch_2,  Train_loss : 0.1882  Test_loss : 0.1894, Time/batch_file : 9.0570, Training time: 712.8853\n",
      "Epoch : 016/500 data_batch_3,  Train_loss : 0.1825  Test_loss : 0.1829, Time/batch_file : 9.0199, Training time: 721.9055\n",
      "Epoch : 016/500 data_batch_4,  Train_loss : 0.1776  Test_loss : 0.1820, Time/batch_file : 9.3597, Training time: 731.2653\n",
      "Epoch : 016/500 data_batch_5,  Train_loss : 0.1766  Test_loss : 0.1850, Time/batch_file : 9.1152, Training time: 740.3807\n",
      "Epoch : 017/500 data_batch_1,  Train_loss : 0.1790  Test_loss : 0.1888, Time/batch_file : 9.2479, Training time: 749.6289\n",
      "Epoch : 017/500 data_batch_2,  Train_loss : 0.1811  Test_loss : 0.1795, Time/batch_file : 9.1073, Training time: 758.7365\n",
      "Epoch : 017/500 data_batch_3,  Train_loss : 0.1749  Test_loss : 0.1835, Time/batch_file : 9.3351, Training time: 768.0718\n",
      "Epoch : 017/500 data_batch_4,  Train_loss : 0.1795  Test_loss : 0.1829, Time/batch_file : 9.2139, Training time: 777.2861\n",
      "Epoch : 017/500 data_batch_5,  Train_loss : 0.1775  Test_loss : 0.1818, Time/batch_file : 9.2964, Training time: 786.5827\n",
      "Epoch : 018/500 data_batch_1,  Train_loss : 0.1674  Test_loss : 0.1781, Time/batch_file : 9.0839, Training time: 795.6671\n",
      "Epoch : 018/500 data_batch_2,  Train_loss : 0.1647  Test_loss : 0.1762, Time/batch_file : 9.1209, Training time: 804.7882\n",
      "Epoch : 018/500 data_batch_3,  Train_loss : 0.1716  Test_loss : 0.1799, Time/batch_file : 9.2338, Training time: 814.0223\n",
      "Epoch : 018/500 data_batch_4,  Train_loss : 0.1668  Test_loss : 0.1759, Time/batch_file : 9.1417, Training time: 823.1644\n",
      "Epoch : 018/500 data_batch_5,  Train_loss : 0.1732  Test_loss : 0.1760, Time/batch_file : 9.2147, Training time: 832.3794\n",
      "Epoch : 019/500 data_batch_1,  Train_loss : 0.1749  Test_loss : 0.1720, Time/batch_file : 9.5175, Training time: 841.8974\n",
      "Epoch : 019/500 data_batch_2,  Train_loss : 0.1785  Test_loss : 0.1692, Time/batch_file : 9.0017, Training time: 850.8993\n",
      "Epoch : 019/500 data_batch_3,  Train_loss : 0.1813  Test_loss : 0.1673, Time/batch_file : 9.1530, Training time: 860.0526\n",
      "Epoch : 019/500 data_batch_4,  Train_loss : 0.1799  Test_loss : 0.1622, Time/batch_file : 9.6651, Training time: 869.7180\n",
      "Epoch : 019/500 data_batch_5,  Train_loss : 0.1719  Test_loss : 0.1714, Time/batch_file : 9.0134, Training time: 878.7318\n",
      "Epoch : 020/500 data_batch_1,  Train_loss : 0.1591  Test_loss : 0.1720, Time/batch_file : 9.0274, Training time: 887.7595\n",
      "Epoch : 020/500 data_batch_2,  Train_loss : 0.1681  Test_loss : 0.1796, Time/batch_file : 9.4420, Training time: 897.2019\n",
      "Epoch : 020/500 data_batch_3,  Train_loss : 0.1592  Test_loss : 0.1773, Time/batch_file : 9.2007, Training time: 906.4028\n",
      "Epoch : 020/500 data_batch_4,  Train_loss : 0.1552  Test_loss : 0.1766, Time/batch_file : 9.1855, Training time: 915.5886\n",
      "Epoch : 020/500 data_batch_5,  Train_loss : 0.1599  Test_loss : 0.1759, Time/batch_file : 9.4596, Training time: 925.0484\n",
      "[./nets/net-20.ckpt] SAVED\n",
      "Epoch : 021/500 data_batch_1,  Train_loss : 0.1695  Test_loss : 0.1675, Time/batch_file : 9.0839, Training time: 935.8458\n",
      "Epoch : 021/500 data_batch_2,  Train_loss : 0.1658  Test_loss : 0.1689, Time/batch_file : 9.1873, Training time: 945.0334\n",
      "Epoch : 021/500 data_batch_3,  Train_loss : 0.1625  Test_loss : 0.1727, Time/batch_file : 9.0817, Training time: 954.1155\n",
      "Epoch : 021/500 data_batch_4,  Train_loss : 0.1720  Test_loss : 0.1632, Time/batch_file : 9.1475, Training time: 963.2633\n",
      "Epoch : 021/500 data_batch_5,  Train_loss : 0.1701  Test_loss : 0.1715, Time/batch_file : 9.4067, Training time: 972.6704\n",
      "Epoch : 022/500 data_batch_1,  Train_loss : 0.1729  Test_loss : 0.1692, Time/batch_file : 9.3908, Training time: 982.0615\n",
      "Epoch : 022/500 data_batch_2,  Train_loss : 0.1716  Test_loss : 0.1673, Time/batch_file : 9.3855, Training time: 991.4472\n",
      "Epoch : 022/500 data_batch_3,  Train_loss : 0.1674  Test_loss : 0.1713, Time/batch_file : 9.1258, Training time: 1000.5734\n",
      "Epoch : 022/500 data_batch_4,  Train_loss : 0.1632  Test_loss : 0.1691, Time/batch_file : 9.0452, Training time: 1009.6188\n",
      "Epoch : 022/500 data_batch_5,  Train_loss : 0.1740  Test_loss : 0.1734, Time/batch_file : 9.3380, Training time: 1018.9570\n",
      "Epoch : 023/500 data_batch_1,  Train_loss : 0.1682  Test_loss : 0.1615, Time/batch_file : 9.0464, Training time: 1028.0037\n",
      "Epoch : 023/500 data_batch_2,  Train_loss : 0.1598  Test_loss : 0.1600, Time/batch_file : 9.1724, Training time: 1037.1764\n",
      "Epoch : 023/500 data_batch_3,  Train_loss : 0.1638  Test_loss : 0.1622, Time/batch_file : 9.1718, Training time: 1046.3486\n",
      "Epoch : 023/500 data_batch_4,  Train_loss : 0.1674  Test_loss : 0.1603, Time/batch_file : 9.1827, Training time: 1055.5314\n",
      "Epoch : 023/500 data_batch_5,  Train_loss : 0.1647  Test_loss : 0.1598, Time/batch_file : 9.0781, Training time: 1064.6098\n",
      "Epoch : 024/500 data_batch_1,  Train_loss : 0.1717  Test_loss : 0.1609, Time/batch_file : 9.0370, Training time: 1073.6470\n",
      "Epoch : 024/500 data_batch_2,  Train_loss : 0.1668  Test_loss : 0.1600, Time/batch_file : 9.4285, Training time: 1083.0758\n",
      "Epoch : 024/500 data_batch_3,  Train_loss : 0.1627  Test_loss : 0.1570, Time/batch_file : 9.1731, Training time: 1092.2493\n",
      "Epoch : 024/500 data_batch_4,  Train_loss : 0.1646  Test_loss : 0.1602, Time/batch_file : 9.1202, Training time: 1101.3697\n",
      "Epoch : 024/500 data_batch_5,  Train_loss : 0.1648  Test_loss : 0.1669, Time/batch_file : 9.3024, Training time: 1110.6724\n",
      "Epoch : 025/500 data_batch_1,  Train_loss : 0.1602  Test_loss : 0.1539, Time/batch_file : 9.2996, Training time: 1119.9723\n",
      "Epoch : 025/500 data_batch_2,  Train_loss : 0.1570  Test_loss : 0.1550, Time/batch_file : 9.1028, Training time: 1129.0755\n",
      "Epoch : 025/500 data_batch_3,  Train_loss : 0.1558  Test_loss : 0.1577, Time/batch_file : 9.1772, Training time: 1138.2531\n",
      "Epoch : 025/500 data_batch_4,  Train_loss : 0.1576  Test_loss : 0.1493, Time/batch_file : 9.2462, Training time: 1147.4996\n",
      "Epoch : 025/500 data_batch_5,  Train_loss : 0.1629  Test_loss : 0.1545, Time/batch_file : 8.9997, Training time: 1156.4996\n",
      "Epoch : 026/500 data_batch_1,  Train_loss : 0.1714  Test_loss : 0.1591, Time/batch_file : 9.1847, Training time: 1167.6874\n",
      "Epoch : 026/500 data_batch_2,  Train_loss : 0.1710  Test_loss : 0.1610, Time/batch_file : 9.4590, Training time: 1177.1469\n",
      "Epoch : 026/500 data_batch_3,  Train_loss : 0.1701  Test_loss : 0.1547, Time/batch_file : 9.2294, Training time: 1186.3765\n",
      "Epoch : 026/500 data_batch_4,  Train_loss : 0.1684  Test_loss : 0.1622, Time/batch_file : 9.2024, Training time: 1195.5793\n",
      "Epoch : 026/500 data_batch_5,  Train_loss : 0.1697  Test_loss : 0.1589, Time/batch_file : 9.0661, Training time: 1204.6457\n",
      "Epoch : 027/500 data_batch_1,  Train_loss : 0.1649  Test_loss : 0.1485, Time/batch_file : 8.9608, Training time: 1213.6067\n",
      "Epoch : 027/500 data_batch_2,  Train_loss : 0.1607  Test_loss : 0.1527, Time/batch_file : 9.0992, Training time: 1222.7062\n",
      "Epoch : 027/500 data_batch_3,  Train_loss : 0.1569  Test_loss : 0.1501, Time/batch_file : 9.2924, Training time: 1231.9989\n",
      "Epoch : 027/500 data_batch_4,  Train_loss : 0.1561  Test_loss : 0.1488, Time/batch_file : 9.2972, Training time: 1241.2964\n",
      "Epoch : 027/500 data_batch_5,  Train_loss : 0.1508  Test_loss : 0.1515, Time/batch_file : 9.0457, Training time: 1250.3425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 028/500 data_batch_1,  Train_loss : 0.1591  Test_loss : 0.1571, Time/batch_file : 9.2277, Training time: 1259.5705\n",
      "Epoch : 028/500 data_batch_2,  Train_loss : 0.1584  Test_loss : 0.1532, Time/batch_file : 9.2210, Training time: 1268.7917\n",
      "Epoch : 028/500 data_batch_3,  Train_loss : 0.1595  Test_loss : 0.1510, Time/batch_file : 9.1378, Training time: 1277.9298\n",
      "Epoch : 028/500 data_batch_4,  Train_loss : 0.1539  Test_loss : 0.1596, Time/batch_file : 9.0308, Training time: 1286.9609\n",
      "Epoch : 028/500 data_batch_5,  Train_loss : 0.1542  Test_loss : 0.1537, Time/batch_file : 9.1232, Training time: 1296.0843\n",
      "Epoch : 029/500 data_batch_1,  Train_loss : 0.1527  Test_loss : 0.1587, Time/batch_file : 9.2093, Training time: 1305.2939\n",
      "Epoch : 029/500 data_batch_2,  Train_loss : 0.1582  Test_loss : 0.1595, Time/batch_file : 9.0896, Training time: 1314.3837\n",
      "Epoch : 029/500 data_batch_3,  Train_loss : 0.1536  Test_loss : 0.1586, Time/batch_file : 8.9937, Training time: 1323.3776\n",
      "Epoch : 029/500 data_batch_4,  Train_loss : 0.1489  Test_loss : 0.1621, Time/batch_file : 8.9873, Training time: 1332.3652\n",
      "Epoch : 029/500 data_batch_5,  Train_loss : 0.1599  Test_loss : 0.1595, Time/batch_file : 9.3924, Training time: 1341.7578\n",
      "Epoch : 030/500 data_batch_1,  Train_loss : 0.1592  Test_loss : 0.1643, Time/batch_file : 9.3048, Training time: 1351.0628\n",
      "Epoch : 030/500 data_batch_2,  Train_loss : 0.1627  Test_loss : 0.1557, Time/batch_file : 8.9596, Training time: 1360.0227\n",
      "Epoch : 030/500 data_batch_3,  Train_loss : 0.1563  Test_loss : 0.1559, Time/batch_file : 9.3445, Training time: 1369.3675\n",
      "Epoch : 030/500 data_batch_4,  Train_loss : 0.1605  Test_loss : 0.1513, Time/batch_file : 8.9964, Training time: 1378.3641\n",
      "Epoch : 030/500 data_batch_5,  Train_loss : 0.1561  Test_loss : 0.1534, Time/batch_file : 9.1516, Training time: 1387.5160\n",
      "Epoch : 031/500 data_batch_1,  Train_loss : 0.1510  Test_loss : 0.1506, Time/batch_file : 9.1557, Training time: 1398.7162\n",
      "Epoch : 031/500 data_batch_2,  Train_loss : 0.1535  Test_loss : 0.1597, Time/batch_file : 9.2041, Training time: 1407.9206\n",
      "Epoch : 031/500 data_batch_3,  Train_loss : 0.1548  Test_loss : 0.1504, Time/batch_file : 8.9778, Training time: 1416.8986\n",
      "Epoch : 031/500 data_batch_4,  Train_loss : 0.1566  Test_loss : 0.1521, Time/batch_file : 9.1272, Training time: 1426.0262\n",
      "Epoch : 031/500 data_batch_5,  Train_loss : 0.1489  Test_loss : 0.1509, Time/batch_file : 9.1502, Training time: 1435.1767\n",
      "Epoch : 032/500 data_batch_1,  Train_loss : 0.1624  Test_loss : 0.1621, Time/batch_file : 9.2284, Training time: 1444.4054\n",
      "Epoch : 032/500 data_batch_2,  Train_loss : 0.1599  Test_loss : 0.1671, Time/batch_file : 9.0818, Training time: 1453.4875\n",
      "Epoch : 032/500 data_batch_3,  Train_loss : 0.1626  Test_loss : 0.1649, Time/batch_file : 9.4036, Training time: 1462.8915\n",
      "Epoch : 032/500 data_batch_4,  Train_loss : 0.1646  Test_loss : 0.1599, Time/batch_file : 9.1718, Training time: 1472.0635\n",
      "Epoch : 032/500 data_batch_5,  Train_loss : 0.1627  Test_loss : 0.1539, Time/batch_file : 9.0579, Training time: 1481.1217\n",
      "Epoch : 033/500 data_batch_1,  Train_loss : 0.1572  Test_loss : 0.1576, Time/batch_file : 9.2399, Training time: 1490.3620\n",
      "Epoch : 033/500 data_batch_2,  Train_loss : 0.1516  Test_loss : 0.1610, Time/batch_file : 9.1033, Training time: 1499.4655\n",
      "Epoch : 033/500 data_batch_3,  Train_loss : 0.1555  Test_loss : 0.1541, Time/batch_file : 9.3397, Training time: 1508.8055\n",
      "Epoch : 033/500 data_batch_4,  Train_loss : 0.1499  Test_loss : 0.1501, Time/batch_file : 9.1905, Training time: 1517.9963\n",
      "Epoch : 033/500 data_batch_5,  Train_loss : 0.1565  Test_loss : 0.1530, Time/batch_file : 8.8437, Training time: 1526.8403\n",
      "Epoch : 034/500 data_batch_1,  Train_loss : 0.1593  Test_loss : 0.1561, Time/batch_file : 9.2616, Training time: 1536.1023\n",
      "Epoch : 034/500 data_batch_2,  Train_loss : 0.1560  Test_loss : 0.1493, Time/batch_file : 9.0685, Training time: 1545.1712\n",
      "Epoch : 034/500 data_batch_3,  Train_loss : 0.1591  Test_loss : 0.1473, Time/batch_file : 9.2596, Training time: 1554.4312\n",
      "Epoch : 034/500 data_batch_4,  Train_loss : 0.1548  Test_loss : 0.1496, Time/batch_file : 9.0826, Training time: 1563.5141\n",
      "Epoch : 034/500 data_batch_5,  Train_loss : 0.1556  Test_loss : 0.1476, Time/batch_file : 9.2721, Training time: 1572.7865\n",
      "Epoch : 035/500 data_batch_1,  Train_loss : 0.1543  Test_loss : 0.1459, Time/batch_file : 8.9022, Training time: 1581.6889\n",
      "Epoch : 035/500 data_batch_2,  Train_loss : 0.1552  Test_loss : 0.1510, Time/batch_file : 8.9677, Training time: 1590.6569\n",
      "Epoch : 035/500 data_batch_3,  Train_loss : 0.1544  Test_loss : 0.1501, Time/batch_file : 9.0196, Training time: 1599.6768\n",
      "Epoch : 035/500 data_batch_4,  Train_loss : 0.1545  Test_loss : 0.1530, Time/batch_file : 9.2155, Training time: 1608.8925\n",
      "Epoch : 035/500 data_batch_5,  Train_loss : 0.1565  Test_loss : 0.1515, Time/batch_file : 9.1239, Training time: 1618.0166\n",
      "Epoch : 036/500 data_batch_1,  Train_loss : 0.1497  Test_loss : 0.1479, Time/batch_file : 9.1629, Training time: 1628.8083\n",
      "Epoch : 036/500 data_batch_2,  Train_loss : 0.1494  Test_loss : 0.1528, Time/batch_file : 9.2358, Training time: 1638.0444\n",
      "Epoch : 036/500 data_batch_3,  Train_loss : 0.1498  Test_loss : 0.1516, Time/batch_file : 9.4496, Training time: 1647.4946\n",
      "Epoch : 036/500 data_batch_4,  Train_loss : 0.1472  Test_loss : 0.1503, Time/batch_file : 9.0341, Training time: 1656.5289\n",
      "Epoch : 036/500 data_batch_5,  Train_loss : 0.1540  Test_loss : 0.1499, Time/batch_file : 9.2681, Training time: 1665.7974\n",
      "Epoch : 037/500 data_batch_1,  Train_loss : 0.1535  Test_loss : 0.1619, Time/batch_file : 9.1116, Training time: 1674.9093\n",
      "Epoch : 037/500 data_batch_2,  Train_loss : 0.1537  Test_loss : 0.1638, Time/batch_file : 9.1753, Training time: 1684.0848\n",
      "Epoch : 037/500 data_batch_3,  Train_loss : 0.1529  Test_loss : 0.1633, Time/batch_file : 9.0666, Training time: 1693.1517\n",
      "Epoch : 037/500 data_batch_4,  Train_loss : 0.1485  Test_loss : 0.1571, Time/batch_file : 9.5173, Training time: 1702.6694\n",
      "Epoch : 037/500 data_batch_5,  Train_loss : 0.1584  Test_loss : 0.1565, Time/batch_file : 9.2921, Training time: 1711.9619\n",
      "Epoch : 038/500 data_batch_1,  Train_loss : 0.1515  Test_loss : 0.1541, Time/batch_file : 9.2775, Training time: 1721.2398\n",
      "Epoch : 038/500 data_batch_2,  Train_loss : 0.1487  Test_loss : 0.1598, Time/batch_file : 9.1092, Training time: 1730.3494\n",
      "Epoch : 038/500 data_batch_3,  Train_loss : 0.1462  Test_loss : 0.1597, Time/batch_file : 9.3489, Training time: 1739.6987\n",
      "Epoch : 038/500 data_batch_4,  Train_loss : 0.1428  Test_loss : 0.1599, Time/batch_file : 9.2598, Training time: 1748.9588\n",
      "Epoch : 038/500 data_batch_5,  Train_loss : 0.1497  Test_loss : 0.1514, Time/batch_file : 9.1728, Training time: 1758.1319\n",
      "Epoch : 039/500 data_batch_1,  Train_loss : 0.1514  Test_loss : 0.1477, Time/batch_file : 9.0557, Training time: 1767.1879\n",
      "Epoch : 039/500 data_batch_2,  Train_loss : 0.1520  Test_loss : 0.1522, Time/batch_file : 9.0514, Training time: 1776.2396\n",
      "Epoch : 039/500 data_batch_3,  Train_loss : 0.1533  Test_loss : 0.1489, Time/batch_file : 9.0679, Training time: 1785.3077\n",
      "Epoch : 039/500 data_batch_4,  Train_loss : 0.1541  Test_loss : 0.1485, Time/batch_file : 9.2036, Training time: 1794.5115\n",
      "Epoch : 039/500 data_batch_5,  Train_loss : 0.1505  Test_loss : 0.1471, Time/batch_file : 9.1788, Training time: 1803.6908\n",
      "Epoch : 040/500 data_batch_1,  Train_loss : 0.1472  Test_loss : 0.1590, Time/batch_file : 9.2036, Training time: 1812.8946\n",
      "Epoch : 040/500 data_batch_2,  Train_loss : 0.1444  Test_loss : 0.1586, Time/batch_file : 9.2208, Training time: 1822.1157\n",
      "Epoch : 040/500 data_batch_3,  Train_loss : 0.1419  Test_loss : 0.1526, Time/batch_file : 9.3276, Training time: 1831.4435\n",
      "Epoch : 040/500 data_batch_4,  Train_loss : 0.1437  Test_loss : 0.1635, Time/batch_file : 9.3248, Training time: 1840.7686\n",
      "Epoch : 040/500 data_batch_5,  Train_loss : 0.1475  Test_loss : 0.1576, Time/batch_file : 9.5444, Training time: 1850.3133\n",
      "[./nets/net-40.ckpt] SAVED\n",
      "Epoch : 041/500 data_batch_1,  Train_loss : 0.1530  Test_loss : 0.1476, Time/batch_file : 9.2664, Training time: 1861.9546\n",
      "Epoch : 041/500 data_batch_2,  Train_loss : 0.1517  Test_loss : 0.1481, Time/batch_file : 9.1275, Training time: 1871.0824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 041/500 data_batch_3,  Train_loss : 0.1462  Test_loss : 0.1463, Time/batch_file : 9.3931, Training time: 1880.4758\n",
      "Epoch : 041/500 data_batch_4,  Train_loss : 0.1510  Test_loss : 0.1458, Time/batch_file : 9.2751, Training time: 1889.7512\n",
      "Epoch : 041/500 data_batch_5,  Train_loss : 0.1507  Test_loss : 0.1511, Time/batch_file : 9.0362, Training time: 1898.7877\n",
      "Epoch : 042/500 data_batch_1,  Train_loss : 0.1440  Test_loss : 0.1474, Time/batch_file : 9.0350, Training time: 1907.8232\n",
      "Epoch : 042/500 data_batch_2,  Train_loss : 0.1447  Test_loss : 0.1503, Time/batch_file : 8.9907, Training time: 1916.8142\n",
      "Epoch : 042/500 data_batch_3,  Train_loss : 0.1430  Test_loss : 0.1549, Time/batch_file : 9.1800, Training time: 1925.9945\n",
      "Epoch : 042/500 data_batch_4,  Train_loss : 0.1398  Test_loss : 0.1447, Time/batch_file : 9.0287, Training time: 1935.0234\n",
      "Epoch : 042/500 data_batch_5,  Train_loss : 0.1415  Test_loss : 0.1434, Time/batch_file : 9.1295, Training time: 1944.1533\n",
      "Epoch : 043/500 data_batch_1,  Train_loss : 0.1589  Test_loss : 0.1547, Time/batch_file : 9.0862, Training time: 1953.2398\n",
      "Epoch : 043/500 data_batch_2,  Train_loss : 0.1569  Test_loss : 0.1513, Time/batch_file : 9.0764, Training time: 1962.3165\n",
      "Epoch : 043/500 data_batch_3,  Train_loss : 0.1583  Test_loss : 0.1511, Time/batch_file : 9.0932, Training time: 1971.4100\n",
      "Epoch : 043/500 data_batch_4,  Train_loss : 0.1535  Test_loss : 0.1528, Time/batch_file : 9.2332, Training time: 1980.6435\n",
      "Epoch : 043/500 data_batch_5,  Train_loss : 0.1545  Test_loss : 0.1459, Time/batch_file : 9.1605, Training time: 1989.8042\n",
      "Epoch : 044/500 data_batch_1,  Train_loss : 0.1538  Test_loss : 0.1538, Time/batch_file : 9.2054, Training time: 1999.0100\n",
      "Epoch : 044/500 data_batch_2,  Train_loss : 0.1575  Test_loss : 0.1536, Time/batch_file : 9.0893, Training time: 2008.0997\n",
      "Epoch : 044/500 data_batch_3,  Train_loss : 0.1561  Test_loss : 0.1469, Time/batch_file : 9.1899, Training time: 2017.2898\n",
      "Epoch : 044/500 data_batch_4,  Train_loss : 0.1600  Test_loss : 0.1493, Time/batch_file : 9.1005, Training time: 2026.3906\n",
      "Epoch : 044/500 data_batch_5,  Train_loss : 0.1592  Test_loss : 0.1503, Time/batch_file : 9.5155, Training time: 2035.9062\n",
      "Epoch : 045/500 data_batch_1,  Train_loss : 0.1579  Test_loss : 0.1475, Time/batch_file : 9.0484, Training time: 2044.9549\n",
      "Epoch : 045/500 data_batch_2,  Train_loss : 0.1543  Test_loss : 0.1546, Time/batch_file : 9.2844, Training time: 2054.2397\n",
      "Epoch : 045/500 data_batch_3,  Train_loss : 0.1521  Test_loss : 0.1487, Time/batch_file : 9.1789, Training time: 2063.4189\n",
      "Epoch : 045/500 data_batch_4,  Train_loss : 0.1534  Test_loss : 0.1503, Time/batch_file : 9.1763, Training time: 2072.5956\n",
      "Epoch : 045/500 data_batch_5,  Train_loss : 0.1514  Test_loss : 0.1427, Time/batch_file : 9.1185, Training time: 2081.7144\n",
      "Epoch : 046/500 data_batch_1,  Train_loss : 0.1502  Test_loss : 0.1515, Time/batch_file : 9.2224, Training time: 2092.5754\n",
      "Epoch : 046/500 data_batch_2,  Train_loss : 0.1516  Test_loss : 0.1448, Time/batch_file : 9.2160, Training time: 2101.7918\n",
      "Epoch : 046/500 data_batch_3,  Train_loss : 0.1560  Test_loss : 0.1449, Time/batch_file : 9.4645, Training time: 2111.2565\n",
      "Epoch : 046/500 data_batch_4,  Train_loss : 0.1536  Test_loss : 0.1475, Time/batch_file : 9.3342, Training time: 2120.5910\n",
      "Epoch : 046/500 data_batch_5,  Train_loss : 0.1519  Test_loss : 0.1436, Time/batch_file : 9.3407, Training time: 2129.9321\n",
      "Epoch : 047/500 data_batch_1,  Train_loss : 0.1585  Test_loss : 0.1456, Time/batch_file : 9.0802, Training time: 2139.0125\n",
      "Epoch : 047/500 data_batch_2,  Train_loss : 0.1567  Test_loss : 0.1465, Time/batch_file : 9.1855, Training time: 2148.1983\n",
      "Epoch : 047/500 data_batch_3,  Train_loss : 0.1569  Test_loss : 0.1437, Time/batch_file : 9.3505, Training time: 2157.5490\n",
      "Epoch : 047/500 data_batch_4,  Train_loss : 0.1554  Test_loss : 0.1478, Time/batch_file : 9.2215, Training time: 2166.7708\n",
      "Epoch : 047/500 data_batch_5,  Train_loss : 0.1589  Test_loss : 0.1541, Time/batch_file : 9.0496, Training time: 2175.8206\n",
      "Epoch : 048/500 data_batch_1,  Train_loss : 0.1472  Test_loss : 0.1567, Time/batch_file : 8.9898, Training time: 2184.8108\n",
      "Epoch : 048/500 data_batch_2,  Train_loss : 0.1529  Test_loss : 0.1626, Time/batch_file : 8.9606, Training time: 2193.7718\n",
      "Epoch : 048/500 data_batch_3,  Train_loss : 0.1564  Test_loss : 0.1567, Time/batch_file : 9.1031, Training time: 2202.8752\n",
      "Epoch : 048/500 data_batch_4,  Train_loss : 0.1498  Test_loss : 0.1521, Time/batch_file : 8.9945, Training time: 2211.8700\n",
      "Epoch : 048/500 data_batch_5,  Train_loss : 0.1481  Test_loss : 0.1519, Time/batch_file : 9.0876, Training time: 2220.9578\n",
      "Epoch : 049/500 data_batch_1,  Train_loss : 0.1467  Test_loss : 0.1448, Time/batch_file : 9.1952, Training time: 2230.1533\n",
      "Epoch : 049/500 data_batch_2,  Train_loss : 0.1471  Test_loss : 0.1456, Time/batch_file : 9.4022, Training time: 2239.5558\n",
      "Epoch : 049/500 data_batch_3,  Train_loss : 0.1499  Test_loss : 0.1478, Time/batch_file : 9.0505, Training time: 2248.6066\n",
      "Epoch : 049/500 data_batch_4,  Train_loss : 0.1501  Test_loss : 0.1508, Time/batch_file : 9.0594, Training time: 2257.6663\n",
      "Epoch : 049/500 data_batch_5,  Train_loss : 0.1417  Test_loss : 0.1463, Time/batch_file : 9.2361, Training time: 2266.9026\n",
      "Epoch : 050/500 data_batch_1,  Train_loss : 0.1498  Test_loss : 0.1598, Time/batch_file : 8.9780, Training time: 2275.8809\n",
      "Epoch : 050/500 data_batch_2,  Train_loss : 0.1499  Test_loss : 0.1596, Time/batch_file : 9.2524, Training time: 2285.1337\n",
      "Epoch : 050/500 data_batch_3,  Train_loss : 0.1507  Test_loss : 0.1534, Time/batch_file : 9.1171, Training time: 2294.2510\n",
      "Epoch : 050/500 data_batch_4,  Train_loss : 0.1514  Test_loss : 0.1584, Time/batch_file : 9.1602, Training time: 2303.4115\n",
      "Epoch : 050/500 data_batch_5,  Train_loss : 0.1567  Test_loss : 0.1569, Time/batch_file : 9.5838, Training time: 2312.9956\n",
      "Epoch : 051/500 data_batch_1,  Train_loss : 0.1464  Test_loss : 0.1499, Time/batch_file : 9.4514, Training time: 2324.3305\n",
      "Epoch : 051/500 data_batch_2,  Train_loss : 0.1430  Test_loss : 0.1517, Time/batch_file : 9.1887, Training time: 2333.5196\n",
      "Epoch : 051/500 data_batch_3,  Train_loss : 0.1415  Test_loss : 0.1484, Time/batch_file : 9.5049, Training time: 2343.0248\n",
      "Epoch : 051/500 data_batch_4,  Train_loss : 0.1485  Test_loss : 0.1457, Time/batch_file : 9.3557, Training time: 2352.3808\n",
      "Epoch : 051/500 data_batch_5,  Train_loss : 0.1461  Test_loss : 0.1486, Time/batch_file : 9.0821, Training time: 2361.4632\n",
      "Epoch : 052/500 data_batch_1,  Train_loss : 0.1452  Test_loss : 0.1425, Time/batch_file : 9.2272, Training time: 2370.6908\n",
      "Epoch : 052/500 data_batch_2,  Train_loss : 0.1454  Test_loss : 0.1418, Time/batch_file : 9.1419, Training time: 2379.8331\n",
      "Epoch : 052/500 data_batch_3,  Train_loss : 0.1452  Test_loss : 0.1445, Time/batch_file : 9.5522, Training time: 2389.3855\n",
      "Epoch : 052/500 data_batch_4,  Train_loss : 0.1433  Test_loss : 0.1443, Time/batch_file : 8.9101, Training time: 2398.2958\n",
      "Epoch : 052/500 data_batch_5,  Train_loss : 0.1447  Test_loss : 0.1436, Time/batch_file : 9.4176, Training time: 2407.7137\n",
      "Epoch : 053/500 data_batch_1,  Train_loss : 0.1521  Test_loss : 0.1484, Time/batch_file : 9.3345, Training time: 2417.0485\n",
      "Epoch : 053/500 data_batch_2,  Train_loss : 0.1517  Test_loss : 0.1543, Time/batch_file : 9.0218, Training time: 2426.0707\n",
      "Epoch : 053/500 data_batch_3,  Train_loss : 0.1536  Test_loss : 0.1487, Time/batch_file : 9.1186, Training time: 2435.1896\n",
      "Epoch : 053/500 data_batch_4,  Train_loss : 0.1525  Test_loss : 0.1475, Time/batch_file : 9.2686, Training time: 2444.4585\n",
      "Epoch : 053/500 data_batch_5,  Train_loss : 0.1559  Test_loss : 0.1470, Time/batch_file : 9.0210, Training time: 2453.4797\n",
      "Epoch : 054/500 data_batch_1,  Train_loss : 0.1405  Test_loss : 0.1583, Time/batch_file : 9.0811, Training time: 2462.5611\n",
      "Epoch : 054/500 data_batch_2,  Train_loss : 0.1428  Test_loss : 0.1591, Time/batch_file : 9.3332, Training time: 2471.8947\n",
      "Epoch : 054/500 data_batch_3,  Train_loss : 0.1446  Test_loss : 0.1628, Time/batch_file : 9.0899, Training time: 2480.9848\n",
      "Epoch : 054/500 data_batch_4,  Train_loss : 0.1484  Test_loss : 0.1573, Time/batch_file : 9.0579, Training time: 2490.0430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 054/500 data_batch_5,  Train_loss : 0.1458  Test_loss : 0.1552, Time/batch_file : 9.3385, Training time: 2499.3818\n",
      "Epoch : 055/500 data_batch_1,  Train_loss : 0.1501  Test_loss : 0.1630, Time/batch_file : 9.0434, Training time: 2508.4255\n",
      "Epoch : 055/500 data_batch_2,  Train_loss : 0.1517  Test_loss : 0.1637, Time/batch_file : 9.4403, Training time: 2517.8660\n",
      "Epoch : 055/500 data_batch_3,  Train_loss : 0.1513  Test_loss : 0.1629, Time/batch_file : 9.4672, Training time: 2527.3334\n",
      "Epoch : 055/500 data_batch_4,  Train_loss : 0.1498  Test_loss : 0.1613, Time/batch_file : 9.3124, Training time: 2536.6461\n",
      "Epoch : 055/500 data_batch_5,  Train_loss : 0.1525  Test_loss : 0.1660, Time/batch_file : 9.0991, Training time: 2545.7454\n",
      "Epoch : 056/500 data_batch_1,  Train_loss : 0.1503  Test_loss : 0.1433, Time/batch_file : 9.2237, Training time: 2557.2739\n",
      "Epoch : 056/500 data_batch_2,  Train_loss : 0.1513  Test_loss : 0.1525, Time/batch_file : 8.9527, Training time: 2566.2269\n",
      "Epoch : 056/500 data_batch_3,  Train_loss : 0.1474  Test_loss : 0.1424, Time/batch_file : 9.0133, Training time: 2575.2405\n",
      "Epoch : 056/500 data_batch_4,  Train_loss : 0.1501  Test_loss : 0.1510, Time/batch_file : 9.4248, Training time: 2584.6655\n",
      "Epoch : 056/500 data_batch_5,  Train_loss : 0.1546  Test_loss : 0.1458, Time/batch_file : 9.0594, Training time: 2593.7251\n",
      "Epoch : 057/500 data_batch_1,  Train_loss : 0.1489  Test_loss : 0.1494, Time/batch_file : 9.1775, Training time: 2602.9029\n",
      "Epoch : 057/500 data_batch_2,  Train_loss : 0.1469  Test_loss : 0.1469, Time/batch_file : 9.1494, Training time: 2612.0526\n",
      "Epoch : 057/500 data_batch_3,  Train_loss : 0.1504  Test_loss : 0.1498, Time/batch_file : 9.2875, Training time: 2621.3405\n",
      "Epoch : 057/500 data_batch_4,  Train_loss : 0.1480  Test_loss : 0.1432, Time/batch_file : 9.1038, Training time: 2630.4446\n",
      "Epoch : 057/500 data_batch_5,  Train_loss : 0.1489  Test_loss : 0.1489, Time/batch_file : 9.0910, Training time: 2639.5359\n",
      "Epoch : 058/500 data_batch_1,  Train_loss : 0.1579  Test_loss : 0.1420, Time/batch_file : 9.1792, Training time: 2648.7154\n",
      "Epoch : 058/500 data_batch_2,  Train_loss : 0.1605  Test_loss : 0.1473, Time/batch_file : 9.2351, Training time: 2657.9508\n",
      "Epoch : 058/500 data_batch_3,  Train_loss : 0.1543  Test_loss : 0.1433, Time/batch_file : 9.0769, Training time: 2667.0280\n",
      "Epoch : 058/500 data_batch_4,  Train_loss : 0.1599  Test_loss : 0.1469, Time/batch_file : 9.1718, Training time: 2676.2002\n",
      "Epoch : 058/500 data_batch_5,  Train_loss : 0.1513  Test_loss : 0.1382, Time/batch_file : 9.3355, Training time: 2685.5361\n",
      "Epoch : 059/500 data_batch_1,  Train_loss : 0.1443  Test_loss : 0.1539, Time/batch_file : 9.0779, Training time: 2694.6143\n",
      "Epoch : 059/500 data_batch_2,  Train_loss : 0.1368  Test_loss : 0.1488, Time/batch_file : 9.1110, Training time: 2703.7256\n",
      "Epoch : 059/500 data_batch_3,  Train_loss : 0.1426  Test_loss : 0.1467, Time/batch_file : 8.9678, Training time: 2712.6937\n",
      "Epoch : 059/500 data_batch_4,  Train_loss : 0.1403  Test_loss : 0.1457, Time/batch_file : 9.1849, Training time: 2721.8788\n",
      "Epoch : 059/500 data_batch_5,  Train_loss : 0.1399  Test_loss : 0.1470, Time/batch_file : 9.2208, Training time: 2731.1000\n",
      "Epoch : 060/500 data_batch_1,  Train_loss : 0.1474  Test_loss : 0.1506, Time/batch_file : 9.3571, Training time: 2740.4573\n",
      "Epoch : 060/500 data_batch_2,  Train_loss : 0.1493  Test_loss : 0.1483, Time/batch_file : 9.2505, Training time: 2749.7082\n",
      "Epoch : 060/500 data_batch_3,  Train_loss : 0.1437  Test_loss : 0.1470, Time/batch_file : 9.1388, Training time: 2758.8472\n",
      "Epoch : 060/500 data_batch_4,  Train_loss : 0.1497  Test_loss : 0.1490, Time/batch_file : 9.0039, Training time: 2767.8515\n",
      "Epoch : 060/500 data_batch_5,  Train_loss : 0.1486  Test_loss : 0.1497, Time/batch_file : 9.1672, Training time: 2777.0190\n",
      "[./nets/net-60.ckpt] SAVED\n",
      "Epoch : 061/500 data_batch_1,  Train_loss : 0.1444  Test_loss : 0.1558, Time/batch_file : 8.9987, Training time: 2787.7727\n",
      "Epoch : 061/500 data_batch_2,  Train_loss : 0.1409  Test_loss : 0.1521, Time/batch_file : 9.3894, Training time: 2797.1623\n",
      "Epoch : 061/500 data_batch_3,  Train_loss : 0.1431  Test_loss : 0.1448, Time/batch_file : 9.2789, Training time: 2806.4417\n",
      "Epoch : 061/500 data_batch_4,  Train_loss : 0.1476  Test_loss : 0.1533, Time/batch_file : 9.2947, Training time: 2815.7367\n",
      "Epoch : 061/500 data_batch_5,  Train_loss : 0.1474  Test_loss : 0.1469, Time/batch_file : 9.1162, Training time: 2824.8532\n",
      "Epoch : 062/500 data_batch_1,  Train_loss : 0.1559  Test_loss : 0.1391, Time/batch_file : 9.3298, Training time: 2834.1832\n",
      "Epoch : 062/500 data_batch_2,  Train_loss : 0.1551  Test_loss : 0.1409, Time/batch_file : 9.1309, Training time: 2843.3143\n",
      "Epoch : 062/500 data_batch_3,  Train_loss : 0.1528  Test_loss : 0.1392, Time/batch_file : 9.2603, Training time: 2852.5750\n",
      "Epoch : 062/500 data_batch_4,  Train_loss : 0.1549  Test_loss : 0.1376, Time/batch_file : 9.2522, Training time: 2861.8275\n",
      "Epoch : 062/500 data_batch_5,  Train_loss : 0.1482  Test_loss : 0.1413, Time/batch_file : 9.2495, Training time: 2871.0775\n",
      "Epoch : 063/500 data_batch_1,  Train_loss : 0.1448  Test_loss : 0.1447, Time/batch_file : 9.1501, Training time: 2880.2280\n",
      "Epoch : 063/500 data_batch_2,  Train_loss : 0.1513  Test_loss : 0.1482, Time/batch_file : 9.0805, Training time: 2889.3089\n",
      "Epoch : 063/500 data_batch_3,  Train_loss : 0.1426  Test_loss : 0.1433, Time/batch_file : 9.0319, Training time: 2898.3410\n",
      "Epoch : 063/500 data_batch_4,  Train_loss : 0.1493  Test_loss : 0.1477, Time/batch_file : 9.1333, Training time: 2907.4746\n",
      "Epoch : 063/500 data_batch_5,  Train_loss : 0.1474  Test_loss : 0.1480, Time/batch_file : 9.3635, Training time: 2916.8383\n",
      "Epoch : 064/500 data_batch_1,  Train_loss : 0.1517  Test_loss : 0.1464, Time/batch_file : 8.9877, Training time: 2925.8263\n",
      "Epoch : 064/500 data_batch_2,  Train_loss : 0.1476  Test_loss : 0.1486, Time/batch_file : 9.1441, Training time: 2934.9706\n",
      "Epoch : 064/500 data_batch_3,  Train_loss : 0.1468  Test_loss : 0.1515, Time/batch_file : 9.0871, Training time: 2944.0580\n",
      "Epoch : 064/500 data_batch_4,  Train_loss : 0.1452  Test_loss : 0.1534, Time/batch_file : 9.3314, Training time: 2953.3898\n",
      "Epoch : 064/500 data_batch_5,  Train_loss : 0.1418  Test_loss : 0.1468, Time/batch_file : 9.2537, Training time: 2962.6438\n",
      "Epoch : 065/500 data_batch_1,  Train_loss : 0.1509  Test_loss : 0.1501, Time/batch_file : 9.1020, Training time: 2971.7460\n",
      "Epoch : 065/500 data_batch_2,  Train_loss : 0.1551  Test_loss : 0.1535, Time/batch_file : 9.2689, Training time: 2981.0152\n",
      "Epoch : 065/500 data_batch_3,  Train_loss : 0.1562  Test_loss : 0.1434, Time/batch_file : 9.0553, Training time: 2990.0709\n",
      "Epoch : 065/500 data_batch_4,  Train_loss : 0.1551  Test_loss : 0.1455, Time/batch_file : 9.1616, Training time: 2999.2328\n",
      "Epoch : 065/500 data_batch_5,  Train_loss : 0.1514  Test_loss : 0.1530, Time/batch_file : 9.0429, Training time: 3008.2759\n",
      "Epoch : 066/500 data_batch_1,  Train_loss : 0.1420  Test_loss : 0.1458, Time/batch_file : 9.3601, Training time: 3019.3129\n",
      "Epoch : 066/500 data_batch_2,  Train_loss : 0.1406  Test_loss : 0.1483, Time/batch_file : 9.1331, Training time: 3028.4463\n",
      "Epoch : 066/500 data_batch_3,  Train_loss : 0.1389  Test_loss : 0.1525, Time/batch_file : 9.2517, Training time: 3037.6982\n",
      "Epoch : 066/500 data_batch_4,  Train_loss : 0.1411  Test_loss : 0.1464, Time/batch_file : 8.9175, Training time: 3046.6160\n",
      "Epoch : 066/500 data_batch_5,  Train_loss : 0.1380  Test_loss : 0.1518, Time/batch_file : 9.1645, Training time: 3055.7808\n",
      "Epoch : 067/500 data_batch_1,  Train_loss : 0.1472  Test_loss : 0.1468, Time/batch_file : 9.2619, Training time: 3065.0430\n",
      "Epoch : 067/500 data_batch_2,  Train_loss : 0.1488  Test_loss : 0.1544, Time/batch_file : 9.1421, Training time: 3074.1853\n",
      "Epoch : 067/500 data_batch_3,  Train_loss : 0.1448  Test_loss : 0.1562, Time/batch_file : 9.3183, Training time: 3083.5039\n",
      "Epoch : 067/500 data_batch_4,  Train_loss : 0.1471  Test_loss : 0.1522, Time/batch_file : 9.4442, Training time: 3092.9484\n",
      "Epoch : 067/500 data_batch_5,  Train_loss : 0.1480  Test_loss : 0.1559, Time/batch_file : 9.3594, Training time: 3102.3080\n",
      "Epoch : 068/500 data_batch_1,  Train_loss : 0.1437  Test_loss : 0.1529, Time/batch_file : 9.3063, Training time: 3111.6146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 068/500 data_batch_2,  Train_loss : 0.1419  Test_loss : 0.1507, Time/batch_file : 9.5591, Training time: 3121.1740\n",
      "Epoch : 068/500 data_batch_3,  Train_loss : 0.1381  Test_loss : 0.1535, Time/batch_file : 9.2507, Training time: 3130.4250\n",
      "Epoch : 068/500 data_batch_4,  Train_loss : 0.1426  Test_loss : 0.1576, Time/batch_file : 8.8983, Training time: 3139.3236\n",
      "Epoch : 068/500 data_batch_5,  Train_loss : 0.1457  Test_loss : 0.1491, Time/batch_file : 9.1902, Training time: 3148.5141\n",
      "Epoch : 069/500 data_batch_1,  Train_loss : 0.1462  Test_loss : 0.1466, Time/batch_file : 9.0593, Training time: 3157.5737\n",
      "Epoch : 069/500 data_batch_2,  Train_loss : 0.1443  Test_loss : 0.1508, Time/batch_file : 9.2653, Training time: 3166.8392\n",
      "Epoch : 069/500 data_batch_3,  Train_loss : 0.1426  Test_loss : 0.1442, Time/batch_file : 9.4507, Training time: 3176.2903\n",
      "Epoch : 069/500 data_batch_4,  Train_loss : 0.1449  Test_loss : 0.1433, Time/batch_file : 9.1152, Training time: 3185.4057\n",
      "Epoch : 069/500 data_batch_5,  Train_loss : 0.1454  Test_loss : 0.1508, Time/batch_file : 9.1498, Training time: 3194.5558\n",
      "Epoch : 070/500 data_batch_1,  Train_loss : 0.1456  Test_loss : 0.1409, Time/batch_file : 8.9292, Training time: 3203.4852\n",
      "Epoch : 070/500 data_batch_2,  Train_loss : 0.1395  Test_loss : 0.1442, Time/batch_file : 9.2039, Training time: 3212.6894\n",
      "Epoch : 070/500 data_batch_3,  Train_loss : 0.1429  Test_loss : 0.1436, Time/batch_file : 8.9278, Training time: 3221.6175\n",
      "Epoch : 070/500 data_batch_4,  Train_loss : 0.1499  Test_loss : 0.1394, Time/batch_file : 8.9871, Training time: 3230.6048\n",
      "Epoch : 070/500 data_batch_5,  Train_loss : 0.1475  Test_loss : 0.1452, Time/batch_file : 8.9621, Training time: 3239.5673\n",
      "Epoch : 071/500 data_batch_1,  Train_loss : 0.1399  Test_loss : 0.1519, Time/batch_file : 9.1080, Training time: 3251.0046\n",
      "Epoch : 071/500 data_batch_2,  Train_loss : 0.1375  Test_loss : 0.1538, Time/batch_file : 9.2146, Training time: 3260.2194\n",
      "Epoch : 071/500 data_batch_3,  Train_loss : 0.1363  Test_loss : 0.1503, Time/batch_file : 9.0965, Training time: 3269.3162\n",
      "Epoch : 071/500 data_batch_4,  Train_loss : 0.1375  Test_loss : 0.1494, Time/batch_file : 8.9420, Training time: 3278.2586\n",
      "Epoch : 071/500 data_batch_5,  Train_loss : 0.1398  Test_loss : 0.1493, Time/batch_file : 9.0847, Training time: 3287.3435\n",
      "Epoch : 072/500 data_batch_1,  Train_loss : 0.1449  Test_loss : 0.1445, Time/batch_file : 8.9937, Training time: 3296.3375\n",
      "Epoch : 072/500 data_batch_2,  Train_loss : 0.1440  Test_loss : 0.1450, Time/batch_file : 9.0780, Training time: 3305.4159\n",
      "Epoch : 072/500 data_batch_3,  Train_loss : 0.1418  Test_loss : 0.1416, Time/batch_file : 9.1879, Training time: 3314.6041\n",
      "Epoch : 072/500 data_batch_4,  Train_loss : 0.1432  Test_loss : 0.1433, Time/batch_file : 9.1366, Training time: 3323.7410\n",
      "Epoch : 072/500 data_batch_5,  Train_loss : 0.1404  Test_loss : 0.1497, Time/batch_file : 8.9969, Training time: 3332.7382\n",
      "Epoch : 073/500 data_batch_1,  Train_loss : 0.1396  Test_loss : 0.1390, Time/batch_file : 9.0643, Training time: 3341.8027\n",
      "Epoch : 073/500 data_batch_2,  Train_loss : 0.1438  Test_loss : 0.1393, Time/batch_file : 8.9788, Training time: 3350.7818\n",
      "Epoch : 073/500 data_batch_3,  Train_loss : 0.1407  Test_loss : 0.1415, Time/batch_file : 9.2893, Training time: 3360.0715\n",
      "Epoch : 073/500 data_batch_4,  Train_loss : 0.1409  Test_loss : 0.1389, Time/batch_file : 9.1327, Training time: 3369.2045\n",
      "Epoch : 073/500 data_batch_5,  Train_loss : 0.1403  Test_loss : 0.1427, Time/batch_file : 9.3624, Training time: 3378.5672\n",
      "Epoch : 074/500 data_batch_1,  Train_loss : 0.1435  Test_loss : 0.1393, Time/batch_file : 9.1278, Training time: 3387.6953\n",
      "Epoch : 074/500 data_batch_2,  Train_loss : 0.1430  Test_loss : 0.1443, Time/batch_file : 8.9553, Training time: 3396.6508\n",
      "Epoch : 074/500 data_batch_3,  Train_loss : 0.1444  Test_loss : 0.1424, Time/batch_file : 9.2015, Training time: 3405.8526\n",
      "Epoch : 074/500 data_batch_4,  Train_loss : 0.1498  Test_loss : 0.1422, Time/batch_file : 9.1264, Training time: 3414.9792\n",
      "Epoch : 074/500 data_batch_5,  Train_loss : 0.1466  Test_loss : 0.1445, Time/batch_file : 9.1232, Training time: 3424.1028\n",
      "Epoch : 075/500 data_batch_1,  Train_loss : 0.1387  Test_loss : 0.1465, Time/batch_file : 9.1388, Training time: 3433.2419\n",
      "Epoch : 075/500 data_batch_2,  Train_loss : 0.1385  Test_loss : 0.1540, Time/batch_file : 9.0936, Training time: 3442.3358\n",
      "Epoch : 075/500 data_batch_3,  Train_loss : 0.1414  Test_loss : 0.1518, Time/batch_file : 9.1918, Training time: 3451.5278\n",
      "Epoch : 075/500 data_batch_4,  Train_loss : 0.1444  Test_loss : 0.1493, Time/batch_file : 9.2636, Training time: 3460.7916\n",
      "Epoch : 075/500 data_batch_5,  Train_loss : 0.1374  Test_loss : 0.1474, Time/batch_file : 9.0419, Training time: 3469.8337\n",
      "Epoch : 076/500 data_batch_1,  Train_loss : 0.1467  Test_loss : 0.1515, Time/batch_file : 8.9876, Training time: 3480.3713\n",
      "Epoch : 076/500 data_batch_2,  Train_loss : 0.1450  Test_loss : 0.1547, Time/batch_file : 9.2671, Training time: 3489.6387\n",
      "Epoch : 076/500 data_batch_3,  Train_loss : 0.1446  Test_loss : 0.1494, Time/batch_file : 9.2847, Training time: 3498.9237\n",
      "Epoch : 076/500 data_batch_4,  Train_loss : 0.1414  Test_loss : 0.1525, Time/batch_file : 9.1048, Training time: 3508.0288\n",
      "Epoch : 076/500 data_batch_5,  Train_loss : 0.1464  Test_loss : 0.1503, Time/batch_file : 9.0180, Training time: 3517.0473\n",
      "Epoch : 077/500 data_batch_1,  Train_loss : 0.1467  Test_loss : 0.1480, Time/batch_file : 8.9771, Training time: 3526.0247\n",
      "Epoch : 077/500 data_batch_2,  Train_loss : 0.1544  Test_loss : 0.1519, Time/batch_file : 9.2777, Training time: 3535.3026\n",
      "Epoch : 077/500 data_batch_3,  Train_loss : 0.1486  Test_loss : 0.1441, Time/batch_file : 9.1460, Training time: 3544.4489\n",
      "Epoch : 077/500 data_batch_4,  Train_loss : 0.1518  Test_loss : 0.1516, Time/batch_file : 9.3826, Training time: 3553.8319\n",
      "Epoch : 077/500 data_batch_5,  Train_loss : 0.1494  Test_loss : 0.1527, Time/batch_file : 9.2485, Training time: 3563.0806\n",
      "Epoch : 078/500 data_batch_1,  Train_loss : 0.1497  Test_loss : 0.1571, Time/batch_file : 9.2770, Training time: 3572.3580\n",
      "Epoch : 078/500 data_batch_2,  Train_loss : 0.1524  Test_loss : 0.1582, Time/batch_file : 9.1591, Training time: 3581.5173\n",
      "Epoch : 078/500 data_batch_3,  Train_loss : 0.1520  Test_loss : 0.1537, Time/batch_file : 9.3157, Training time: 3590.8334\n",
      "Epoch : 078/500 data_batch_4,  Train_loss : 0.1542  Test_loss : 0.1570, Time/batch_file : 9.0078, Training time: 3599.8414\n",
      "Epoch : 078/500 data_batch_5,  Train_loss : 0.1490  Test_loss : 0.1545, Time/batch_file : 9.4514, Training time: 3609.2931\n",
      "Epoch : 079/500 data_batch_1,  Train_loss : 0.1449  Test_loss : 0.1375, Time/batch_file : 9.0061, Training time: 3618.2995\n",
      "Epoch : 079/500 data_batch_2,  Train_loss : 0.1470  Test_loss : 0.1482, Time/batch_file : 9.3331, Training time: 3627.6329\n",
      "Epoch : 079/500 data_batch_3,  Train_loss : 0.1480  Test_loss : 0.1454, Time/batch_file : 9.1107, Training time: 3636.7438\n",
      "Epoch : 079/500 data_batch_4,  Train_loss : 0.1428  Test_loss : 0.1421, Time/batch_file : 9.1882, Training time: 3645.9325\n",
      "Epoch : 079/500 data_batch_5,  Train_loss : 0.1392  Test_loss : 0.1488, Time/batch_file : 9.1945, Training time: 3655.1272\n",
      "Epoch : 080/500 data_batch_1,  Train_loss : 0.1422  Test_loss : 0.1428, Time/batch_file : 9.2352, Training time: 3664.3627\n",
      "Epoch : 080/500 data_batch_2,  Train_loss : 0.1464  Test_loss : 0.1441, Time/batch_file : 9.3186, Training time: 3673.6815\n",
      "Epoch : 080/500 data_batch_3,  Train_loss : 0.1427  Test_loss : 0.1431, Time/batch_file : 9.3445, Training time: 3683.0263\n",
      "Epoch : 080/500 data_batch_4,  Train_loss : 0.1449  Test_loss : 0.1423, Time/batch_file : 9.2689, Training time: 3692.2955\n",
      "Epoch : 080/500 data_batch_5,  Train_loss : 0.1436  Test_loss : 0.1393, Time/batch_file : 9.2016, Training time: 3701.4974\n",
      "[./nets/net-80.ckpt] SAVED\n",
      "Epoch : 081/500 data_batch_1,  Train_loss : 0.1470  Test_loss : 0.1576, Time/batch_file : 9.0899, Training time: 3712.3950\n",
      "Epoch : 081/500 data_batch_2,  Train_loss : 0.1448  Test_loss : 0.1493, Time/batch_file : 9.2130, Training time: 3721.6083\n",
      "Epoch : 081/500 data_batch_3,  Train_loss : 0.1528  Test_loss : 0.1533, Time/batch_file : 9.1066, Training time: 3730.7153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 081/500 data_batch_4,  Train_loss : 0.1430  Test_loss : 0.1554, Time/batch_file : 9.1692, Training time: 3739.8848\n",
      "Epoch : 081/500 data_batch_5,  Train_loss : 0.1431  Test_loss : 0.1532, Time/batch_file : 8.9232, Training time: 3748.8082\n",
      "Epoch : 082/500 data_batch_1,  Train_loss : 0.1370  Test_loss : 0.1401, Time/batch_file : 9.3293, Training time: 3758.1378\n",
      "Epoch : 082/500 data_batch_2,  Train_loss : 0.1322  Test_loss : 0.1415, Time/batch_file : 9.1343, Training time: 3767.2725\n",
      "Epoch : 082/500 data_batch_3,  Train_loss : 0.1419  Test_loss : 0.1429, Time/batch_file : 9.1689, Training time: 3776.4416\n",
      "Epoch : 082/500 data_batch_4,  Train_loss : 0.1389  Test_loss : 0.1440, Time/batch_file : 9.2810, Training time: 3785.7229\n",
      "Epoch : 082/500 data_batch_5,  Train_loss : 0.1404  Test_loss : 0.1408, Time/batch_file : 9.2454, Training time: 3794.9687\n",
      "Epoch : 083/500 data_batch_1,  Train_loss : 0.1451  Test_loss : 0.1526, Time/batch_file : 9.2057, Training time: 3804.1748\n",
      "Epoch : 083/500 data_batch_2,  Train_loss : 0.1457  Test_loss : 0.1513, Time/batch_file : 9.4669, Training time: 3813.6419\n",
      "Epoch : 083/500 data_batch_3,  Train_loss : 0.1444  Test_loss : 0.1503, Time/batch_file : 8.9892, Training time: 3822.6315\n",
      "Epoch : 083/500 data_batch_4,  Train_loss : 0.1460  Test_loss : 0.1504, Time/batch_file : 9.3656, Training time: 3831.9974\n",
      "Epoch : 083/500 data_batch_5,  Train_loss : 0.1457  Test_loss : 0.1513, Time/batch_file : 9.2769, Training time: 3841.2746\n",
      "Epoch : 084/500 data_batch_1,  Train_loss : 0.1437  Test_loss : 0.1449, Time/batch_file : 8.9279, Training time: 3850.2028\n",
      "Epoch : 084/500 data_batch_2,  Train_loss : 0.1461  Test_loss : 0.1396, Time/batch_file : 9.2542, Training time: 3859.4572\n",
      "Epoch : 084/500 data_batch_3,  Train_loss : 0.1459  Test_loss : 0.1441, Time/batch_file : 9.3548, Training time: 3868.8123\n",
      "Epoch : 084/500 data_batch_4,  Train_loss : 0.1424  Test_loss : 0.1413, Time/batch_file : 9.0471, Training time: 3877.8597\n",
      "Epoch : 084/500 data_batch_5,  Train_loss : 0.1451  Test_loss : 0.1424, Time/batch_file : 9.2868, Training time: 3887.1469\n",
      "Epoch : 085/500 data_batch_1,  Train_loss : 0.1442  Test_loss : 0.1390, Time/batch_file : 9.1192, Training time: 3896.2664\n",
      "Epoch : 085/500 data_batch_2,  Train_loss : 0.1431  Test_loss : 0.1399, Time/batch_file : 9.5276, Training time: 3905.7944\n",
      "Epoch : 085/500 data_batch_3,  Train_loss : 0.1482  Test_loss : 0.1345, Time/batch_file : 9.3629, Training time: 3915.1577\n",
      "Epoch : 085/500 data_batch_4,  Train_loss : 0.1451  Test_loss : 0.1395, Time/batch_file : 9.0037, Training time: 3924.1616\n",
      "Epoch : 085/500 data_batch_5,  Train_loss : 0.1498  Test_loss : 0.1398, Time/batch_file : 9.2869, Training time: 3933.4488\n",
      "Epoch : 086/500 data_batch_1,  Train_loss : 0.1572  Test_loss : 0.1512, Time/batch_file : 9.2196, Training time: 3944.2096\n",
      "Epoch : 086/500 data_batch_2,  Train_loss : 0.1552  Test_loss : 0.1477, Time/batch_file : 9.2218, Training time: 3953.4317\n",
      "Epoch : 086/500 data_batch_3,  Train_loss : 0.1545  Test_loss : 0.1455, Time/batch_file : 9.3165, Training time: 3962.7485\n",
      "Epoch : 086/500 data_batch_4,  Train_loss : 0.1596  Test_loss : 0.1505, Time/batch_file : 9.1024, Training time: 3971.8511\n",
      "Epoch : 086/500 data_batch_5,  Train_loss : 0.1570  Test_loss : 0.1477, Time/batch_file : 9.1964, Training time: 3981.0478\n",
      "Epoch : 087/500 data_batch_1,  Train_loss : 0.1455  Test_loss : 0.1439, Time/batch_file : 9.3786, Training time: 3990.4269\n",
      "Epoch : 087/500 data_batch_2,  Train_loss : 0.1541  Test_loss : 0.1411, Time/batch_file : 8.9573, Training time: 3999.3845\n",
      "Epoch : 087/500 data_batch_3,  Train_loss : 0.1489  Test_loss : 0.1471, Time/batch_file : 9.3085, Training time: 4008.6933\n",
      "Epoch : 087/500 data_batch_4,  Train_loss : 0.1550  Test_loss : 0.1426, Time/batch_file : 9.0856, Training time: 4017.7791\n",
      "Epoch : 087/500 data_batch_5,  Train_loss : 0.1510  Test_loss : 0.1508, Time/batch_file : 9.1714, Training time: 4026.9509\n",
      "Epoch : 088/500 data_batch_1,  Train_loss : 0.1485  Test_loss : 0.1448, Time/batch_file : 9.6529, Training time: 4036.6041\n",
      "Epoch : 088/500 data_batch_2,  Train_loss : 0.1418  Test_loss : 0.1449, Time/batch_file : 9.1435, Training time: 4045.7478\n",
      "Epoch : 088/500 data_batch_3,  Train_loss : 0.1465  Test_loss : 0.1467, Time/batch_file : 9.2109, Training time: 4054.9592\n",
      "Epoch : 088/500 data_batch_4,  Train_loss : 0.1420  Test_loss : 0.1473, Time/batch_file : 9.2008, Training time: 4064.1603\n",
      "Epoch : 088/500 data_batch_5,  Train_loss : 0.1432  Test_loss : 0.1453, Time/batch_file : 9.3791, Training time: 4073.5397\n",
      "Epoch : 089/500 data_batch_1,  Train_loss : 0.1576  Test_loss : 0.1449, Time/batch_file : 9.0778, Training time: 4082.6177\n",
      "Epoch : 089/500 data_batch_2,  Train_loss : 0.1510  Test_loss : 0.1488, Time/batch_file : 9.2563, Training time: 4091.8743\n",
      "Epoch : 089/500 data_batch_3,  Train_loss : 0.1532  Test_loss : 0.1428, Time/batch_file : 9.3268, Training time: 4101.2013\n",
      "Epoch : 089/500 data_batch_4,  Train_loss : 0.1479  Test_loss : 0.1425, Time/batch_file : 9.0542, Training time: 4110.2558\n",
      "Epoch : 089/500 data_batch_5,  Train_loss : 0.1449  Test_loss : 0.1458, Time/batch_file : 9.1627, Training time: 4119.4188\n",
      "Epoch : 090/500 data_batch_1,  Train_loss : 0.1544  Test_loss : 0.1566, Time/batch_file : 9.2038, Training time: 4128.6228\n",
      "Epoch : 090/500 data_batch_2,  Train_loss : 0.1522  Test_loss : 0.1511, Time/batch_file : 9.3467, Training time: 4137.9699\n",
      "Epoch : 090/500 data_batch_3,  Train_loss : 0.1533  Test_loss : 0.1580, Time/batch_file : 9.5326, Training time: 4147.5028\n",
      "Epoch : 090/500 data_batch_4,  Train_loss : 0.1529  Test_loss : 0.1516, Time/batch_file : 9.5570, Training time: 4157.0601\n",
      "Epoch : 090/500 data_batch_5,  Train_loss : 0.1525  Test_loss : 0.1561, Time/batch_file : 9.4079, Training time: 4166.4683\n",
      "Epoch : 091/500 data_batch_1,  Train_loss : 0.1429  Test_loss : 0.1436, Time/batch_file : 9.1455, Training time: 4178.1408\n",
      "Epoch : 091/500 data_batch_2,  Train_loss : 0.1353  Test_loss : 0.1433, Time/batch_file : 8.9297, Training time: 4187.0707\n",
      "Epoch : 091/500 data_batch_3,  Train_loss : 0.1378  Test_loss : 0.1407, Time/batch_file : 9.1072, Training time: 4196.1782\n",
      "Epoch : 091/500 data_batch_4,  Train_loss : 0.1337  Test_loss : 0.1470, Time/batch_file : 9.3426, Training time: 4205.5211\n",
      "Epoch : 091/500 data_batch_5,  Train_loss : 0.1388  Test_loss : 0.1449, Time/batch_file : 9.1310, Training time: 4214.6524\n",
      "Epoch : 092/500 data_batch_1,  Train_loss : 0.1537  Test_loss : 0.1491, Time/batch_file : 9.0299, Training time: 4223.6825\n",
      "Epoch : 092/500 data_batch_2,  Train_loss : 0.1558  Test_loss : 0.1525, Time/batch_file : 9.3958, Training time: 4233.0786\n",
      "Epoch : 092/500 data_batch_3,  Train_loss : 0.1497  Test_loss : 0.1553, Time/batch_file : 8.9297, Training time: 4242.0086\n",
      "Epoch : 092/500 data_batch_4,  Train_loss : 0.1538  Test_loss : 0.1558, Time/batch_file : 9.1234, Training time: 4251.1322\n",
      "Epoch : 092/500 data_batch_5,  Train_loss : 0.1558  Test_loss : 0.1519, Time/batch_file : 9.2735, Training time: 4260.4060\n",
      "Epoch : 093/500 data_batch_1,  Train_loss : 0.1437  Test_loss : 0.1443, Time/batch_file : 9.0771, Training time: 4269.4836\n",
      "Epoch : 093/500 data_batch_2,  Train_loss : 0.1440  Test_loss : 0.1437, Time/batch_file : 9.1311, Training time: 4278.6150\n",
      "Epoch : 093/500 data_batch_3,  Train_loss : 0.1435  Test_loss : 0.1431, Time/batch_file : 8.9368, Training time: 4287.5520\n",
      "Epoch : 093/500 data_batch_4,  Train_loss : 0.1458  Test_loss : 0.1391, Time/batch_file : 9.1513, Training time: 4296.7036\n",
      "Epoch : 093/500 data_batch_5,  Train_loss : 0.1400  Test_loss : 0.1454, Time/batch_file : 9.2529, Training time: 4305.9569\n",
      "Epoch : 094/500 data_batch_1,  Train_loss : 0.1491  Test_loss : 0.1588, Time/batch_file : 9.0751, Training time: 4315.0322\n",
      "Epoch : 094/500 data_batch_2,  Train_loss : 0.1496  Test_loss : 0.1549, Time/batch_file : 9.2683, Training time: 4324.3008\n",
      "Epoch : 094/500 data_batch_3,  Train_loss : 0.1439  Test_loss : 0.1560, Time/batch_file : 9.4917, Training time: 4333.7929\n",
      "Epoch : 094/500 data_batch_4,  Train_loss : 0.1448  Test_loss : 0.1534, Time/batch_file : 9.0750, Training time: 4342.8682\n",
      "Epoch : 094/500 data_batch_5,  Train_loss : 0.1404  Test_loss : 0.1579, Time/batch_file : 9.1359, Training time: 4352.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 095/500 data_batch_1,  Train_loss : 0.1539  Test_loss : 0.1450, Time/batch_file : 9.2744, Training time: 4361.2792\n",
      "Epoch : 095/500 data_batch_2,  Train_loss : 0.1489  Test_loss : 0.1475, Time/batch_file : 9.1441, Training time: 4370.4235\n",
      "Epoch : 095/500 data_batch_3,  Train_loss : 0.1458  Test_loss : 0.1492, Time/batch_file : 9.0911, Training time: 4379.5148\n",
      "Epoch : 095/500 data_batch_4,  Train_loss : 0.1524  Test_loss : 0.1498, Time/batch_file : 9.3022, Training time: 4388.8171\n",
      "Epoch : 095/500 data_batch_5,  Train_loss : 0.1465  Test_loss : 0.1457, Time/batch_file : 9.0853, Training time: 4397.9026\n",
      "Epoch : 096/500 data_batch_1,  Train_loss : 0.1439  Test_loss : 0.1523, Time/batch_file : 9.1898, Training time: 4408.8232\n",
      "Epoch : 096/500 data_batch_2,  Train_loss : 0.1415  Test_loss : 0.1439, Time/batch_file : 9.1635, Training time: 4417.9871\n",
      "Epoch : 096/500 data_batch_3,  Train_loss : 0.1402  Test_loss : 0.1451, Time/batch_file : 9.2669, Training time: 4427.2543\n",
      "Epoch : 096/500 data_batch_4,  Train_loss : 0.1414  Test_loss : 0.1466, Time/batch_file : 9.0409, Training time: 4436.2955\n",
      "Epoch : 096/500 data_batch_5,  Train_loss : 0.1380  Test_loss : 0.1490, Time/batch_file : 9.1893, Training time: 4445.4850\n",
      "Epoch : 097/500 data_batch_1,  Train_loss : 0.1482  Test_loss : 0.1473, Time/batch_file : 9.2403, Training time: 4454.7256\n",
      "Epoch : 097/500 data_batch_2,  Train_loss : 0.1451  Test_loss : 0.1467, Time/batch_file : 9.1597, Training time: 4463.8856\n",
      "Epoch : 097/500 data_batch_3,  Train_loss : 0.1490  Test_loss : 0.1516, Time/batch_file : 9.1195, Training time: 4473.0054\n",
      "Epoch : 097/500 data_batch_4,  Train_loss : 0.1434  Test_loss : 0.1476, Time/batch_file : 9.1169, Training time: 4482.1226\n",
      "Epoch : 097/500 data_batch_5,  Train_loss : 0.1453  Test_loss : 0.1493, Time/batch_file : 9.4321, Training time: 4491.5550\n",
      "Epoch : 098/500 data_batch_1,  Train_loss : 0.1452  Test_loss : 0.1450, Time/batch_file : 9.2808, Training time: 4500.8361\n",
      "Epoch : 098/500 data_batch_2,  Train_loss : 0.1504  Test_loss : 0.1467, Time/batch_file : 9.0628, Training time: 4509.8993\n",
      "Epoch : 098/500 data_batch_3,  Train_loss : 0.1446  Test_loss : 0.1500, Time/batch_file : 9.1595, Training time: 4519.0590\n",
      "Epoch : 098/500 data_batch_4,  Train_loss : 0.1437  Test_loss : 0.1462, Time/batch_file : 9.1887, Training time: 4528.2479\n",
      "Epoch : 098/500 data_batch_5,  Train_loss : 0.1468  Test_loss : 0.1466, Time/batch_file : 9.1187, Training time: 4537.3669\n",
      "Epoch : 099/500 data_batch_1,  Train_loss : 0.1507  Test_loss : 0.1448, Time/batch_file : 8.9601, Training time: 4546.3274\n",
      "Epoch : 099/500 data_batch_2,  Train_loss : 0.1433  Test_loss : 0.1489, Time/batch_file : 9.4450, Training time: 4555.7726\n",
      "Epoch : 099/500 data_batch_3,  Train_loss : 0.1468  Test_loss : 0.1498, Time/batch_file : 9.1197, Training time: 4564.8926\n",
      "Epoch : 099/500 data_batch_4,  Train_loss : 0.1449  Test_loss : 0.1482, Time/batch_file : 9.3054, Training time: 4574.1981\n",
      "Epoch : 099/500 data_batch_5,  Train_loss : 0.1460  Test_loss : 0.1444, Time/batch_file : 9.0136, Training time: 4583.2121\n",
      "Epoch : 100/500 data_batch_1,  Train_loss : 0.1470  Test_loss : 0.1356, Time/batch_file : 9.0924, Training time: 4592.3048\n",
      "Epoch : 100/500 data_batch_2,  Train_loss : 0.1447  Test_loss : 0.1361, Time/batch_file : 9.2224, Training time: 4601.5274\n",
      "Epoch : 100/500 data_batch_3,  Train_loss : 0.1491  Test_loss : 0.1354, Time/batch_file : 9.2412, Training time: 4610.7689\n",
      "Epoch : 100/500 data_batch_4,  Train_loss : 0.1502  Test_loss : 0.1369, Time/batch_file : 8.9813, Training time: 4619.7504\n",
      "Epoch : 100/500 data_batch_5,  Train_loss : 0.1458  Test_loss : 0.1311, Time/batch_file : 9.3220, Training time: 4629.0726\n",
      "[./nets/net-100.ckpt] SAVED\n",
      "Epoch : 101/500 data_batch_1,  Train_loss : 0.1485  Test_loss : 0.1464, Time/batch_file : 9.2341, Training time: 4640.0620\n",
      "Epoch : 101/500 data_batch_2,  Train_loss : 0.1483  Test_loss : 0.1454, Time/batch_file : 8.9778, Training time: 4649.0401\n",
      "Epoch : 101/500 data_batch_3,  Train_loss : 0.1454  Test_loss : 0.1488, Time/batch_file : 9.0641, Training time: 4658.1045\n",
      "Epoch : 101/500 data_batch_4,  Train_loss : 0.1431  Test_loss : 0.1474, Time/batch_file : 9.1275, Training time: 4667.2322\n",
      "Epoch : 101/500 data_batch_5,  Train_loss : 0.1459  Test_loss : 0.1463, Time/batch_file : 9.0208, Training time: 4676.2533\n",
      "Epoch : 102/500 data_batch_1,  Train_loss : 0.1471  Test_loss : 0.1402, Time/batch_file : 9.0718, Training time: 4685.3254\n",
      "Epoch : 102/500 data_batch_2,  Train_loss : 0.1398  Test_loss : 0.1448, Time/batch_file : 9.0567, Training time: 4694.3823\n",
      "Epoch : 102/500 data_batch_3,  Train_loss : 0.1431  Test_loss : 0.1442, Time/batch_file : 9.3315, Training time: 4703.7143\n",
      "Epoch : 102/500 data_batch_4,  Train_loss : 0.1453  Test_loss : 0.1467, Time/batch_file : 9.0252, Training time: 4712.7397\n",
      "Epoch : 102/500 data_batch_5,  Train_loss : 0.1435  Test_loss : 0.1391, Time/batch_file : 9.1844, Training time: 4721.9243\n",
      "Epoch : 103/500 data_batch_1,  Train_loss : 0.1400  Test_loss : 0.1524, Time/batch_file : 9.3585, Training time: 4731.2830\n",
      "Epoch : 103/500 data_batch_2,  Train_loss : 0.1457  Test_loss : 0.1460, Time/batch_file : 9.0284, Training time: 4740.3117\n",
      "Epoch : 103/500 data_batch_3,  Train_loss : 0.1469  Test_loss : 0.1543, Time/batch_file : 9.4852, Training time: 4749.7972\n",
      "Epoch : 103/500 data_batch_4,  Train_loss : 0.1416  Test_loss : 0.1544, Time/batch_file : 9.2185, Training time: 4759.0159\n",
      "Epoch : 103/500 data_batch_5,  Train_loss : 0.1440  Test_loss : 0.1583, Time/batch_file : 9.1878, Training time: 4768.2039\n",
      "Epoch : 104/500 data_batch_1,  Train_loss : 0.1471  Test_loss : 0.1466, Time/batch_file : 8.9659, Training time: 4777.1702\n",
      "Epoch : 104/500 data_batch_2,  Train_loss : 0.1421  Test_loss : 0.1433, Time/batch_file : 9.3102, Training time: 4786.4807\n",
      "Epoch : 104/500 data_batch_3,  Train_loss : 0.1464  Test_loss : 0.1442, Time/batch_file : 9.1379, Training time: 4795.6189\n",
      "Epoch : 104/500 data_batch_4,  Train_loss : 0.1524  Test_loss : 0.1409, Time/batch_file : 8.8979, Training time: 4804.5171\n",
      "Epoch : 104/500 data_batch_5,  Train_loss : 0.1442  Test_loss : 0.1441, Time/batch_file : 9.1177, Training time: 4813.6351\n",
      "Epoch : 105/500 data_batch_1,  Train_loss : 0.1384  Test_loss : 0.1519, Time/batch_file : 9.2722, Training time: 4822.9075\n",
      "Epoch : 105/500 data_batch_2,  Train_loss : 0.1367  Test_loss : 0.1555, Time/batch_file : 9.0621, Training time: 4831.9701\n",
      "Epoch : 105/500 data_batch_3,  Train_loss : 0.1397  Test_loss : 0.1521, Time/batch_file : 9.3019, Training time: 4841.2722\n",
      "Epoch : 105/500 data_batch_4,  Train_loss : 0.1416  Test_loss : 0.1556, Time/batch_file : 9.2516, Training time: 4850.5240\n",
      "Epoch : 105/500 data_batch_5,  Train_loss : 0.1368  Test_loss : 0.1471, Time/batch_file : 8.9948, Training time: 4859.5192\n",
      "Epoch : 106/500 data_batch_1,  Train_loss : 0.1339  Test_loss : 0.1497, Time/batch_file : 9.4707, Training time: 4870.5576\n",
      "Epoch : 106/500 data_batch_2,  Train_loss : 0.1406  Test_loss : 0.1561, Time/batch_file : 9.0405, Training time: 4879.5984\n",
      "Epoch : 106/500 data_batch_3,  Train_loss : 0.1302  Test_loss : 0.1500, Time/batch_file : 8.9958, Training time: 4888.5945\n",
      "Epoch : 106/500 data_batch_4,  Train_loss : 0.1337  Test_loss : 0.1471, Time/batch_file : 9.2901, Training time: 4897.8849\n",
      "Epoch : 106/500 data_batch_5,  Train_loss : 0.1357  Test_loss : 0.1520, Time/batch_file : 9.1984, Training time: 4907.0835\n",
      "Epoch : 107/500 data_batch_1,  Train_loss : 0.1439  Test_loss : 0.1474, Time/batch_file : 9.0418, Training time: 4916.1256\n",
      "Epoch : 107/500 data_batch_2,  Train_loss : 0.1385  Test_loss : 0.1454, Time/batch_file : 9.1707, Training time: 4925.2966\n",
      "Epoch : 107/500 data_batch_3,  Train_loss : 0.1405  Test_loss : 0.1438, Time/batch_file : 9.2879, Training time: 4934.5849\n",
      "Epoch : 107/500 data_batch_4,  Train_loss : 0.1388  Test_loss : 0.1454, Time/batch_file : 9.0954, Training time: 4943.6805\n",
      "Epoch : 107/500 data_batch_5,  Train_loss : 0.1413  Test_loss : 0.1481, Time/batch_file : 9.4501, Training time: 4953.1309\n",
      "Epoch : 108/500 data_batch_1,  Train_loss : 0.1399  Test_loss : 0.1399, Time/batch_file : 9.0192, Training time: 4962.1505\n",
      "Epoch : 108/500 data_batch_2,  Train_loss : 0.1338  Test_loss : 0.1514, Time/batch_file : 9.1469, Training time: 4971.2976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 108/500 data_batch_3,  Train_loss : 0.1391  Test_loss : 0.1497, Time/batch_file : 9.2541, Training time: 4980.5520\n",
      "Epoch : 108/500 data_batch_4,  Train_loss : 0.1368  Test_loss : 0.1509, Time/batch_file : 8.9974, Training time: 4989.5499\n",
      "Epoch : 108/500 data_batch_5,  Train_loss : 0.1341  Test_loss : 0.1467, Time/batch_file : 9.4618, Training time: 4999.0119\n",
      "Epoch : 109/500 data_batch_1,  Train_loss : 0.1356  Test_loss : 0.1443, Time/batch_file : 9.4190, Training time: 5008.4313\n",
      "Epoch : 109/500 data_batch_2,  Train_loss : 0.1331  Test_loss : 0.1480, Time/batch_file : 9.0556, Training time: 5017.4872\n",
      "Epoch : 109/500 data_batch_3,  Train_loss : 0.1355  Test_loss : 0.1459, Time/batch_file : 9.1270, Training time: 5026.6145\n",
      "Epoch : 109/500 data_batch_4,  Train_loss : 0.1352  Test_loss : 0.1471, Time/batch_file : 9.1248, Training time: 5035.7395\n",
      "Epoch : 109/500 data_batch_5,  Train_loss : 0.1373  Test_loss : 0.1459, Time/batch_file : 9.1865, Training time: 5044.9262\n",
      "Epoch : 110/500 data_batch_1,  Train_loss : 0.1481  Test_loss : 0.1500, Time/batch_file : 9.0244, Training time: 5053.9509\n",
      "Epoch : 110/500 data_batch_2,  Train_loss : 0.1487  Test_loss : 0.1556, Time/batch_file : 9.0413, Training time: 5062.9925\n",
      "Epoch : 110/500 data_batch_3,  Train_loss : 0.1441  Test_loss : 0.1493, Time/batch_file : 9.0603, Training time: 5072.0531\n",
      "Epoch : 110/500 data_batch_4,  Train_loss : 0.1493  Test_loss : 0.1552, Time/batch_file : 9.1065, Training time: 5081.1599\n",
      "Epoch : 110/500 data_batch_5,  Train_loss : 0.1462  Test_loss : 0.1454, Time/batch_file : 9.1412, Training time: 5090.3014\n",
      "Epoch : 111/500 data_batch_1,  Train_loss : 0.1461  Test_loss : 0.1495, Time/batch_file : 9.0466, Training time: 5102.1989\n",
      "Epoch : 111/500 data_batch_2,  Train_loss : 0.1458  Test_loss : 0.1488, Time/batch_file : 9.4015, Training time: 5111.6007\n",
      "Epoch : 111/500 data_batch_3,  Train_loss : 0.1484  Test_loss : 0.1432, Time/batch_file : 9.1593, Training time: 5120.7603\n",
      "Epoch : 111/500 data_batch_4,  Train_loss : 0.1471  Test_loss : 0.1503, Time/batch_file : 9.1671, Training time: 5129.9276\n",
      "Epoch : 111/500 data_batch_5,  Train_loss : 0.1412  Test_loss : 0.1503, Time/batch_file : 9.0040, Training time: 5138.9318\n",
      "Epoch : 112/500 data_batch_1,  Train_loss : 0.1502  Test_loss : 0.1348, Time/batch_file : 9.1437, Training time: 5148.0759\n",
      "Epoch : 112/500 data_batch_2,  Train_loss : 0.1471  Test_loss : 0.1371, Time/batch_file : 9.3403, Training time: 5157.4164\n",
      "Epoch : 112/500 data_batch_3,  Train_loss : 0.1481  Test_loss : 0.1400, Time/batch_file : 9.3234, Training time: 5166.7400\n",
      "Epoch : 112/500 data_batch_4,  Train_loss : 0.1529  Test_loss : 0.1390, Time/batch_file : 9.0574, Training time: 5175.7978\n",
      "Epoch : 112/500 data_batch_5,  Train_loss : 0.1529  Test_loss : 0.1374, Time/batch_file : 9.2411, Training time: 5185.0392\n",
      "Epoch : 113/500 data_batch_1,  Train_loss : 0.1366  Test_loss : 0.1508, Time/batch_file : 9.1040, Training time: 5194.1434\n",
      "Epoch : 113/500 data_batch_2,  Train_loss : 0.1457  Test_loss : 0.1509, Time/batch_file : 9.0764, Training time: 5203.2200\n",
      "Epoch : 113/500 data_batch_3,  Train_loss : 0.1451  Test_loss : 0.1493, Time/batch_file : 9.0874, Training time: 5212.3077\n",
      "Epoch : 113/500 data_batch_4,  Train_loss : 0.1404  Test_loss : 0.1511, Time/batch_file : 9.2517, Training time: 5221.5597\n",
      "Epoch : 113/500 data_batch_5,  Train_loss : 0.1381  Test_loss : 0.1453, Time/batch_file : 9.3115, Training time: 5230.8714\n",
      "Epoch : 114/500 data_batch_1,  Train_loss : 0.1399  Test_loss : 0.1513, Time/batch_file : 9.4621, Training time: 5240.3338\n",
      "Epoch : 114/500 data_batch_2,  Train_loss : 0.1441  Test_loss : 0.1499, Time/batch_file : 8.9648, Training time: 5249.2989\n",
      "Epoch : 114/500 data_batch_3,  Train_loss : 0.1370  Test_loss : 0.1544, Time/batch_file : 9.1810, Training time: 5258.4802\n",
      "Epoch : 114/500 data_batch_4,  Train_loss : 0.1371  Test_loss : 0.1532, Time/batch_file : 9.1731, Training time: 5267.6537\n",
      "Epoch : 114/500 data_batch_5,  Train_loss : 0.1400  Test_loss : 0.1504, Time/batch_file : 9.0825, Training time: 5276.7364\n",
      "Epoch : 115/500 data_batch_1,  Train_loss : 0.1527  Test_loss : 0.1384, Time/batch_file : 8.9491, Training time: 5285.6858\n",
      "Epoch : 115/500 data_batch_2,  Train_loss : 0.1438  Test_loss : 0.1450, Time/batch_file : 9.2586, Training time: 5294.9447\n",
      "Epoch : 115/500 data_batch_3,  Train_loss : 0.1441  Test_loss : 0.1432, Time/batch_file : 9.0391, Training time: 5303.9840\n",
      "Epoch : 115/500 data_batch_4,  Train_loss : 0.1422  Test_loss : 0.1481, Time/batch_file : 9.5345, Training time: 5313.5189\n",
      "Epoch : 115/500 data_batch_5,  Train_loss : 0.1435  Test_loss : 0.1467, Time/batch_file : 9.2318, Training time: 5322.7509\n",
      "Epoch : 116/500 data_batch_1,  Train_loss : 0.1481  Test_loss : 0.1454, Time/batch_file : 9.2851, Training time: 5333.8075\n",
      "Epoch : 116/500 data_batch_2,  Train_loss : 0.1474  Test_loss : 0.1443, Time/batch_file : 9.1710, Training time: 5342.9787\n",
      "Epoch : 116/500 data_batch_3,  Train_loss : 0.1457  Test_loss : 0.1444, Time/batch_file : 9.4266, Training time: 5352.4056\n",
      "Epoch : 116/500 data_batch_4,  Train_loss : 0.1450  Test_loss : 0.1470, Time/batch_file : 9.0367, Training time: 5361.4425\n",
      "Epoch : 116/500 data_batch_5,  Train_loss : 0.1492  Test_loss : 0.1481, Time/batch_file : 9.3297, Training time: 5370.7725\n",
      "Epoch : 117/500 data_batch_1,  Train_loss : 0.1291  Test_loss : 0.1409, Time/batch_file : 9.0802, Training time: 5379.8529\n",
      "Epoch : 117/500 data_batch_2,  Train_loss : 0.1295  Test_loss : 0.1396, Time/batch_file : 9.2730, Training time: 5389.1261\n",
      "Epoch : 117/500 data_batch_3,  Train_loss : 0.1229  Test_loss : 0.1415, Time/batch_file : 9.0276, Training time: 5398.1542\n",
      "Epoch : 117/500 data_batch_4,  Train_loss : 0.1284  Test_loss : 0.1426, Time/batch_file : 9.3099, Training time: 5407.4644\n",
      "Epoch : 117/500 data_batch_5,  Train_loss : 0.1268  Test_loss : 0.1417, Time/batch_file : 9.1780, Training time: 5416.6425\n",
      "Epoch : 118/500 data_batch_1,  Train_loss : 0.1462  Test_loss : 0.1384, Time/batch_file : 9.5002, Training time: 5426.1430\n",
      "Epoch : 118/500 data_batch_2,  Train_loss : 0.1521  Test_loss : 0.1434, Time/batch_file : 8.9918, Training time: 5435.1351\n",
      "Epoch : 118/500 data_batch_3,  Train_loss : 0.1489  Test_loss : 0.1373, Time/batch_file : 8.9515, Training time: 5444.0870\n",
      "Epoch : 118/500 data_batch_4,  Train_loss : 0.1455  Test_loss : 0.1479, Time/batch_file : 9.1142, Training time: 5453.2016\n",
      "Epoch : 118/500 data_batch_5,  Train_loss : 0.1489  Test_loss : 0.1385, Time/batch_file : 8.9041, Training time: 5462.1061\n",
      "Epoch : 119/500 data_batch_1,  Train_loss : 0.1478  Test_loss : 0.1421, Time/batch_file : 9.0176, Training time: 5471.1240\n",
      "Epoch : 119/500 data_batch_2,  Train_loss : 0.1490  Test_loss : 0.1450, Time/batch_file : 9.1806, Training time: 5480.3048\n",
      "Epoch : 119/500 data_batch_3,  Train_loss : 0.1450  Test_loss : 0.1469, Time/batch_file : 9.1082, Training time: 5489.4134\n",
      "Epoch : 119/500 data_batch_4,  Train_loss : 0.1430  Test_loss : 0.1411, Time/batch_file : 9.2695, Training time: 5498.6832\n",
      "Epoch : 119/500 data_batch_5,  Train_loss : 0.1461  Test_loss : 0.1436, Time/batch_file : 8.9770, Training time: 5507.6604\n",
      "Epoch : 120/500 data_batch_1,  Train_loss : 0.1479  Test_loss : 0.1496, Time/batch_file : 9.2131, Training time: 5516.8738\n",
      "Epoch : 120/500 data_batch_2,  Train_loss : 0.1488  Test_loss : 0.1462, Time/batch_file : 9.1898, Training time: 5526.0638\n",
      "Epoch : 120/500 data_batch_3,  Train_loss : 0.1496  Test_loss : 0.1445, Time/batch_file : 9.1402, Training time: 5535.2043\n",
      "Epoch : 120/500 data_batch_4,  Train_loss : 0.1549  Test_loss : 0.1408, Time/batch_file : 9.4346, Training time: 5544.6393\n",
      "Epoch : 120/500 data_batch_5,  Train_loss : 0.1474  Test_loss : 0.1412, Time/batch_file : 9.3460, Training time: 5553.9855\n",
      "[./nets/net-120.ckpt] SAVED\n",
      "Epoch : 121/500 data_batch_1,  Train_loss : 0.1572  Test_loss : 0.1321, Time/batch_file : 9.2188, Training time: 5565.1491\n",
      "Epoch : 121/500 data_batch_2,  Train_loss : 0.1566  Test_loss : 0.1327, Time/batch_file : 9.0971, Training time: 5574.2465\n",
      "Epoch : 121/500 data_batch_3,  Train_loss : 0.1575  Test_loss : 0.1319, Time/batch_file : 9.0335, Training time: 5583.2804\n",
      "Epoch : 121/500 data_batch_4,  Train_loss : 0.1572  Test_loss : 0.1359, Time/batch_file : 9.4312, Training time: 5592.7118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 121/500 data_batch_5,  Train_loss : 0.1558  Test_loss : 0.1357, Time/batch_file : 9.2270, Training time: 5601.9390\n",
      "Epoch : 122/500 data_batch_1,  Train_loss : 0.1431  Test_loss : 0.1392, Time/batch_file : 9.4834, Training time: 5611.4228\n",
      "Epoch : 122/500 data_batch_2,  Train_loss : 0.1398  Test_loss : 0.1443, Time/batch_file : 9.3094, Training time: 5620.7324\n",
      "Epoch : 122/500 data_batch_3,  Train_loss : 0.1342  Test_loss : 0.1454, Time/batch_file : 9.2233, Training time: 5629.9559\n",
      "Epoch : 122/500 data_batch_4,  Train_loss : 0.1377  Test_loss : 0.1445, Time/batch_file : 9.4308, Training time: 5639.3871\n",
      "Epoch : 122/500 data_batch_5,  Train_loss : 0.1376  Test_loss : 0.1419, Time/batch_file : 9.1728, Training time: 5648.5602\n",
      "Epoch : 123/500 data_batch_1,  Train_loss : 0.1394  Test_loss : 0.1398, Time/batch_file : 9.1727, Training time: 5657.7332\n",
      "Epoch : 123/500 data_batch_2,  Train_loss : 0.1493  Test_loss : 0.1383, Time/batch_file : 9.2929, Training time: 5667.0266\n",
      "Epoch : 123/500 data_batch_3,  Train_loss : 0.1518  Test_loss : 0.1418, Time/batch_file : 9.1062, Training time: 5676.1332\n",
      "Epoch : 123/500 data_batch_4,  Train_loss : 0.1510  Test_loss : 0.1445, Time/batch_file : 9.1990, Training time: 5685.3324\n",
      "Epoch : 123/500 data_batch_5,  Train_loss : 0.1481  Test_loss : 0.1402, Time/batch_file : 9.5414, Training time: 5694.8740\n",
      "Epoch : 124/500 data_batch_1,  Train_loss : 0.1427  Test_loss : 0.1405, Time/batch_file : 9.3842, Training time: 5704.2586\n",
      "Epoch : 124/500 data_batch_2,  Train_loss : 0.1519  Test_loss : 0.1407, Time/batch_file : 9.1500, Training time: 5713.4088\n",
      "Epoch : 124/500 data_batch_3,  Train_loss : 0.1466  Test_loss : 0.1418, Time/batch_file : 9.0922, Training time: 5722.5012\n",
      "Epoch : 124/500 data_batch_4,  Train_loss : 0.1486  Test_loss : 0.1443, Time/batch_file : 9.2939, Training time: 5731.7954\n",
      "Epoch : 124/500 data_batch_5,  Train_loss : 0.1422  Test_loss : 0.1425, Time/batch_file : 9.1852, Training time: 5740.9808\n",
      "Epoch : 125/500 data_batch_1,  Train_loss : 0.1567  Test_loss : 0.1506, Time/batch_file : 9.2586, Training time: 5750.2398\n",
      "Epoch : 125/500 data_batch_2,  Train_loss : 0.1513  Test_loss : 0.1541, Time/batch_file : 9.1152, Training time: 5759.3552\n",
      "Epoch : 125/500 data_batch_3,  Train_loss : 0.1544  Test_loss : 0.1527, Time/batch_file : 9.1752, Training time: 5768.5306\n",
      "Epoch : 125/500 data_batch_4,  Train_loss : 0.1507  Test_loss : 0.1523, Time/batch_file : 9.1848, Training time: 5777.7156\n",
      "Epoch : 125/500 data_batch_5,  Train_loss : 0.1516  Test_loss : 0.1500, Time/batch_file : 9.2391, Training time: 5786.9550\n",
      "Epoch : 126/500 data_batch_1,  Train_loss : 0.1452  Test_loss : 0.1404, Time/batch_file : 9.2049, Training time: 5797.8025\n",
      "Epoch : 126/500 data_batch_2,  Train_loss : 0.1423  Test_loss : 0.1501, Time/batch_file : 9.2374, Training time: 5807.0401\n",
      "Epoch : 126/500 data_batch_3,  Train_loss : 0.1369  Test_loss : 0.1469, Time/batch_file : 9.3163, Training time: 5816.3567\n",
      "Epoch : 126/500 data_batch_4,  Train_loss : 0.1419  Test_loss : 0.1502, Time/batch_file : 9.4495, Training time: 5825.8065\n",
      "Epoch : 126/500 data_batch_5,  Train_loss : 0.1389  Test_loss : 0.1473, Time/batch_file : 9.0939, Training time: 5834.9008\n",
      "Epoch : 127/500 data_batch_1,  Train_loss : 0.1375  Test_loss : 0.1475, Time/batch_file : 9.4846, Training time: 5844.3857\n",
      "Epoch : 127/500 data_batch_2,  Train_loss : 0.1430  Test_loss : 0.1507, Time/batch_file : 9.0809, Training time: 5853.4669\n",
      "Epoch : 127/500 data_batch_3,  Train_loss : 0.1366  Test_loss : 0.1462, Time/batch_file : 9.0583, Training time: 5862.5255\n",
      "Epoch : 127/500 data_batch_4,  Train_loss : 0.1391  Test_loss : 0.1495, Time/batch_file : 9.0890, Training time: 5871.6147\n",
      "Epoch : 127/500 data_batch_5,  Train_loss : 0.1393  Test_loss : 0.1482, Time/batch_file : 9.1407, Training time: 5880.7559\n",
      "Epoch : 128/500 data_batch_1,  Train_loss : 0.1488  Test_loss : 0.1446, Time/batch_file : 9.1943, Training time: 5889.9506\n",
      "Epoch : 128/500 data_batch_2,  Train_loss : 0.1518  Test_loss : 0.1444, Time/batch_file : 8.9947, Training time: 5898.9455\n",
      "Epoch : 128/500 data_batch_3,  Train_loss : 0.1439  Test_loss : 0.1482, Time/batch_file : 9.2736, Training time: 5908.2194\n",
      "Epoch : 128/500 data_batch_4,  Train_loss : 0.1481  Test_loss : 0.1461, Time/batch_file : 9.6362, Training time: 5917.8560\n",
      "Epoch : 128/500 data_batch_5,  Train_loss : 0.1450  Test_loss : 0.1408, Time/batch_file : 9.1901, Training time: 5927.0463\n",
      "Epoch : 129/500 data_batch_1,  Train_loss : 0.1460  Test_loss : 0.1410, Time/batch_file : 8.9856, Training time: 5936.0323\n",
      "Epoch : 129/500 data_batch_2,  Train_loss : 0.1454  Test_loss : 0.1424, Time/batch_file : 9.5565, Training time: 5945.5890\n",
      "Epoch : 129/500 data_batch_3,  Train_loss : 0.1452  Test_loss : 0.1421, Time/batch_file : 9.3627, Training time: 5954.9521\n",
      "Epoch : 129/500 data_batch_4,  Train_loss : 0.1424  Test_loss : 0.1401, Time/batch_file : 9.2591, Training time: 5964.2115\n",
      "Epoch : 129/500 data_batch_5,  Train_loss : 0.1460  Test_loss : 0.1451, Time/batch_file : 9.2915, Training time: 5973.5034\n",
      "Epoch : 130/500 data_batch_1,  Train_loss : 0.1477  Test_loss : 0.1444, Time/batch_file : 9.6699, Training time: 5983.1736\n",
      "Epoch : 130/500 data_batch_2,  Train_loss : 0.1452  Test_loss : 0.1471, Time/batch_file : 9.0674, Training time: 5992.2414\n",
      "Epoch : 130/500 data_batch_3,  Train_loss : 0.1433  Test_loss : 0.1472, Time/batch_file : 9.1713, Training time: 6001.4130\n",
      "Epoch : 130/500 data_batch_4,  Train_loss : 0.1467  Test_loss : 0.1442, Time/batch_file : 9.1920, Training time: 6010.6052\n",
      "Epoch : 130/500 data_batch_5,  Train_loss : 0.1434  Test_loss : 0.1422, Time/batch_file : 9.1735, Training time: 6019.7790\n",
      "Epoch : 131/500 data_batch_1,  Train_loss : 0.1429  Test_loss : 0.1452, Time/batch_file : 9.1550, Training time: 6030.6392\n",
      "Epoch : 131/500 data_batch_2,  Train_loss : 0.1408  Test_loss : 0.1429, Time/batch_file : 9.0950, Training time: 6039.7348\n",
      "Epoch : 131/500 data_batch_3,  Train_loss : 0.1426  Test_loss : 0.1383, Time/batch_file : 9.1106, Training time: 6048.8457\n",
      "Epoch : 131/500 data_batch_4,  Train_loss : 0.1409  Test_loss : 0.1382, Time/batch_file : 9.0892, Training time: 6057.9352\n",
      "Epoch : 131/500 data_batch_5,  Train_loss : 0.1432  Test_loss : 0.1446, Time/batch_file : 8.9674, Training time: 6066.9030\n",
      "Epoch : 132/500 data_batch_1,  Train_loss : 0.1399  Test_loss : 0.1502, Time/batch_file : 9.1790, Training time: 6076.0823\n",
      "Epoch : 132/500 data_batch_2,  Train_loss : 0.1383  Test_loss : 0.1440, Time/batch_file : 9.1411, Training time: 6085.2236\n",
      "Epoch : 132/500 data_batch_3,  Train_loss : 0.1387  Test_loss : 0.1419, Time/batch_file : 9.3398, Training time: 6094.5637\n",
      "Epoch : 132/500 data_batch_4,  Train_loss : 0.1367  Test_loss : 0.1491, Time/batch_file : 9.2241, Training time: 6103.7882\n",
      "Epoch : 132/500 data_batch_5,  Train_loss : 0.1384  Test_loss : 0.1476, Time/batch_file : 9.1770, Training time: 6112.9655\n",
      "Epoch : 133/500 data_batch_1,  Train_loss : 0.1404  Test_loss : 0.1426, Time/batch_file : 9.1797, Training time: 6122.1454\n",
      "Epoch : 133/500 data_batch_2,  Train_loss : 0.1373  Test_loss : 0.1407, Time/batch_file : 9.2658, Training time: 6131.4115\n",
      "Epoch : 133/500 data_batch_3,  Train_loss : 0.1406  Test_loss : 0.1414, Time/batch_file : 9.1449, Training time: 6140.5569\n",
      "Epoch : 133/500 data_batch_4,  Train_loss : 0.1440  Test_loss : 0.1437, Time/batch_file : 9.1552, Training time: 6149.7123\n",
      "Epoch : 133/500 data_batch_5,  Train_loss : 0.1420  Test_loss : 0.1379, Time/batch_file : 8.9724, Training time: 6158.6850\n",
      "Epoch : 134/500 data_batch_1,  Train_loss : 0.1422  Test_loss : 0.1424, Time/batch_file : 9.1608, Training time: 6167.8461\n",
      "Epoch : 134/500 data_batch_2,  Train_loss : 0.1350  Test_loss : 0.1400, Time/batch_file : 9.1252, Training time: 6176.9716\n",
      "Epoch : 134/500 data_batch_3,  Train_loss : 0.1427  Test_loss : 0.1377, Time/batch_file : 9.2767, Training time: 6186.2485\n",
      "Epoch : 134/500 data_batch_4,  Train_loss : 0.1398  Test_loss : 0.1366, Time/batch_file : 9.0341, Training time: 6195.2828\n",
      "Epoch : 134/500 data_batch_5,  Train_loss : 0.1409  Test_loss : 0.1393, Time/batch_file : 9.2898, Training time: 6204.5728\n",
      "Epoch : 135/500 data_batch_1,  Train_loss : 0.1445  Test_loss : 0.1462, Time/batch_file : 9.2866, Training time: 6213.8598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 135/500 data_batch_2,  Train_loss : 0.1447  Test_loss : 0.1462, Time/batch_file : 9.4208, Training time: 6223.2809\n",
      "Epoch : 135/500 data_batch_3,  Train_loss : 0.1458  Test_loss : 0.1422, Time/batch_file : 9.1017, Training time: 6232.3830\n",
      "Epoch : 135/500 data_batch_4,  Train_loss : 0.1447  Test_loss : 0.1467, Time/batch_file : 9.1605, Training time: 6241.5437\n",
      "Epoch : 135/500 data_batch_5,  Train_loss : 0.1360  Test_loss : 0.1451, Time/batch_file : 9.1708, Training time: 6250.7148\n",
      "Epoch : 136/500 data_batch_1,  Train_loss : 0.1392  Test_loss : 0.1332, Time/batch_file : 9.0594, Training time: 6261.4123\n",
      "Epoch : 136/500 data_batch_2,  Train_loss : 0.1397  Test_loss : 0.1390, Time/batch_file : 9.1483, Training time: 6270.5608\n",
      "Epoch : 136/500 data_batch_3,  Train_loss : 0.1392  Test_loss : 0.1414, Time/batch_file : 9.3707, Training time: 6279.9320\n",
      "Epoch : 136/500 data_batch_4,  Train_loss : 0.1356  Test_loss : 0.1322, Time/batch_file : 9.3270, Training time: 6289.2594\n",
      "Epoch : 136/500 data_batch_5,  Train_loss : 0.1380  Test_loss : 0.1372, Time/batch_file : 9.3005, Training time: 6298.5601\n",
      "Epoch : 137/500 data_batch_1,  Train_loss : 0.1437  Test_loss : 0.1483, Time/batch_file : 9.1385, Training time: 6307.6989\n",
      "Epoch : 137/500 data_batch_2,  Train_loss : 0.1412  Test_loss : 0.1444, Time/batch_file : 9.1710, Training time: 6316.8702\n",
      "Epoch : 137/500 data_batch_3,  Train_loss : 0.1377  Test_loss : 0.1425, Time/batch_file : 9.1686, Training time: 6326.0391\n",
      "Epoch : 137/500 data_batch_4,  Train_loss : 0.1478  Test_loss : 0.1444, Time/batch_file : 9.0799, Training time: 6335.1193\n",
      "Epoch : 137/500 data_batch_5,  Train_loss : 0.1458  Test_loss : 0.1431, Time/batch_file : 9.0869, Training time: 6344.2065\n",
      "Epoch : 138/500 data_batch_1,  Train_loss : 0.1358  Test_loss : 0.1447, Time/batch_file : 9.3317, Training time: 6353.5386\n",
      "Epoch : 138/500 data_batch_2,  Train_loss : 0.1455  Test_loss : 0.1440, Time/batch_file : 9.1306, Training time: 6362.6696\n",
      "Epoch : 138/500 data_batch_3,  Train_loss : 0.1420  Test_loss : 0.1454, Time/batch_file : 8.9772, Training time: 6371.6470\n",
      "Epoch : 138/500 data_batch_4,  Train_loss : 0.1406  Test_loss : 0.1431, Time/batch_file : 8.9780, Training time: 6380.6253\n",
      "Epoch : 138/500 data_batch_5,  Train_loss : 0.1425  Test_loss : 0.1528, Time/batch_file : 9.3009, Training time: 6389.9265\n",
      "Epoch : 139/500 data_batch_1,  Train_loss : 0.1414  Test_loss : 0.1351, Time/batch_file : 9.2681, Training time: 6399.1948\n",
      "Epoch : 139/500 data_batch_2,  Train_loss : 0.1460  Test_loss : 0.1382, Time/batch_file : 9.0831, Training time: 6408.2783\n",
      "Epoch : 139/500 data_batch_3,  Train_loss : 0.1479  Test_loss : 0.1379, Time/batch_file : 9.0329, Training time: 6417.3114\n",
      "Epoch : 139/500 data_batch_4,  Train_loss : 0.1468  Test_loss : 0.1422, Time/batch_file : 9.0099, Training time: 6426.3216\n",
      "Epoch : 139/500 data_batch_5,  Train_loss : 0.1431  Test_loss : 0.1365, Time/batch_file : 9.2972, Training time: 6435.6189\n",
      "Epoch : 140/500 data_batch_1,  Train_loss : 0.1480  Test_loss : 0.1427, Time/batch_file : 9.1241, Training time: 6444.7435\n",
      "Epoch : 140/500 data_batch_2,  Train_loss : 0.1472  Test_loss : 0.1393, Time/batch_file : 9.2948, Training time: 6454.0385\n",
      "Epoch : 140/500 data_batch_3,  Train_loss : 0.1432  Test_loss : 0.1413, Time/batch_file : 9.3851, Training time: 6463.4238\n",
      "Epoch : 140/500 data_batch_4,  Train_loss : 0.1471  Test_loss : 0.1422, Time/batch_file : 9.1399, Training time: 6472.5640\n",
      "Epoch : 140/500 data_batch_5,  Train_loss : 0.1504  Test_loss : 0.1410, Time/batch_file : 9.0255, Training time: 6481.5899\n",
      "[./nets/net-140.ckpt] SAVED\n",
      "Epoch : 141/500 data_batch_1,  Train_loss : 0.1401  Test_loss : 0.1483, Time/batch_file : 9.0759, Training time: 6493.9131\n",
      "Epoch : 141/500 data_batch_2,  Train_loss : 0.1351  Test_loss : 0.1436, Time/batch_file : 9.3896, Training time: 6503.3030\n",
      "Epoch : 141/500 data_batch_3,  Train_loss : 0.1354  Test_loss : 0.1455, Time/batch_file : 8.8633, Training time: 6512.1666\n",
      "Epoch : 141/500 data_batch_4,  Train_loss : 0.1352  Test_loss : 0.1411, Time/batch_file : 9.1912, Training time: 6521.3587\n",
      "Epoch : 141/500 data_batch_5,  Train_loss : 0.1367  Test_loss : 0.1385, Time/batch_file : 8.9449, Training time: 6530.3038\n",
      "Epoch : 142/500 data_batch_1,  Train_loss : 0.1429  Test_loss : 0.1406, Time/batch_file : 9.2859, Training time: 6539.5901\n",
      "Epoch : 142/500 data_batch_2,  Train_loss : 0.1397  Test_loss : 0.1404, Time/batch_file : 9.1561, Training time: 6548.7465\n",
      "Epoch : 142/500 data_batch_3,  Train_loss : 0.1397  Test_loss : 0.1377, Time/batch_file : 9.3350, Training time: 6558.0817\n",
      "Epoch : 142/500 data_batch_4,  Train_loss : 0.1393  Test_loss : 0.1353, Time/batch_file : 9.1926, Training time: 6567.2745\n",
      "Epoch : 142/500 data_batch_5,  Train_loss : 0.1385  Test_loss : 0.1351, Time/batch_file : 9.0644, Training time: 6576.3392\n",
      "Epoch : 143/500 data_batch_1,  Train_loss : 0.1417  Test_loss : 0.1391, Time/batch_file : 9.0537, Training time: 6585.3932\n",
      "Epoch : 143/500 data_batch_2,  Train_loss : 0.1507  Test_loss : 0.1393, Time/batch_file : 9.2601, Training time: 6594.6536\n",
      "Epoch : 143/500 data_batch_3,  Train_loss : 0.1461  Test_loss : 0.1377, Time/batch_file : 9.4007, Training time: 6604.0547\n",
      "Epoch : 143/500 data_batch_4,  Train_loss : 0.1532  Test_loss : 0.1379, Time/batch_file : 9.1313, Training time: 6613.1863\n",
      "Epoch : 143/500 data_batch_5,  Train_loss : 0.1462  Test_loss : 0.1346, Time/batch_file : 9.3284, Training time: 6622.5151\n",
      "Epoch : 144/500 data_batch_1,  Train_loss : 0.1462  Test_loss : 0.1525, Time/batch_file : 9.3564, Training time: 6631.8718\n",
      "Epoch : 144/500 data_batch_2,  Train_loss : 0.1474  Test_loss : 0.1497, Time/batch_file : 9.3077, Training time: 6641.1798\n",
      "Epoch : 144/500 data_batch_3,  Train_loss : 0.1518  Test_loss : 0.1448, Time/batch_file : 9.2153, Training time: 6650.3953\n",
      "Epoch : 144/500 data_batch_4,  Train_loss : 0.1482  Test_loss : 0.1453, Time/batch_file : 9.2851, Training time: 6659.6808\n",
      "Epoch : 144/500 data_batch_5,  Train_loss : 0.1482  Test_loss : 0.1463, Time/batch_file : 9.4711, Training time: 6669.1521\n",
      "Epoch : 145/500 data_batch_1,  Train_loss : 0.1399  Test_loss : 0.1488, Time/batch_file : 9.1626, Training time: 6678.3159\n",
      "Epoch : 145/500 data_batch_2,  Train_loss : 0.1421  Test_loss : 0.1471, Time/batch_file : 9.2257, Training time: 6687.5420\n",
      "Epoch : 145/500 data_batch_3,  Train_loss : 0.1454  Test_loss : 0.1524, Time/batch_file : 9.1352, Training time: 6696.6775\n",
      "Epoch : 145/500 data_batch_4,  Train_loss : 0.1372  Test_loss : 0.1440, Time/batch_file : 9.2608, Training time: 6705.9385\n",
      "Epoch : 145/500 data_batch_5,  Train_loss : 0.1367  Test_loss : 0.1566, Time/batch_file : 9.0749, Training time: 6715.0136\n",
      "Epoch : 146/500 data_batch_1,  Train_loss : 0.1435  Test_loss : 0.1373, Time/batch_file : 9.1747, Training time: 6725.8561\n",
      "Epoch : 146/500 data_batch_2,  Train_loss : 0.1383  Test_loss : 0.1369, Time/batch_file : 9.1974, Training time: 6735.0538\n",
      "Epoch : 146/500 data_batch_3,  Train_loss : 0.1377  Test_loss : 0.1320, Time/batch_file : 9.1501, Training time: 6744.2041\n",
      "Epoch : 146/500 data_batch_4,  Train_loss : 0.1380  Test_loss : 0.1347, Time/batch_file : 9.2234, Training time: 6753.4279\n",
      "Epoch : 146/500 data_batch_5,  Train_loss : 0.1384  Test_loss : 0.1312, Time/batch_file : 9.3992, Training time: 6762.8273\n",
      "Epoch : 147/500 data_batch_1,  Train_loss : 0.1412  Test_loss : 0.1425, Time/batch_file : 9.4653, Training time: 6772.2930\n",
      "Epoch : 147/500 data_batch_2,  Train_loss : 0.1380  Test_loss : 0.1513, Time/batch_file : 9.3418, Training time: 6781.6351\n",
      "Epoch : 147/500 data_batch_3,  Train_loss : 0.1394  Test_loss : 0.1444, Time/batch_file : 9.3311, Training time: 6790.9665\n",
      "Epoch : 147/500 data_batch_4,  Train_loss : 0.1417  Test_loss : 0.1483, Time/batch_file : 9.3640, Training time: 6800.3308\n",
      "Epoch : 147/500 data_batch_5,  Train_loss : 0.1453  Test_loss : 0.1522, Time/batch_file : 9.5130, Training time: 6809.8441\n",
      "Epoch : 148/500 data_batch_1,  Train_loss : 0.1424  Test_loss : 0.1478, Time/batch_file : 9.1668, Training time: 6819.0112\n",
      "Epoch : 148/500 data_batch_2,  Train_loss : 0.1471  Test_loss : 0.1434, Time/batch_file : 9.1387, Training time: 6828.1501\n",
      "Epoch : 148/500 data_batch_3,  Train_loss : 0.1463  Test_loss : 0.1417, Time/batch_file : 9.2323, Training time: 6837.3828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 148/500 data_batch_4,  Train_loss : 0.1444  Test_loss : 0.1476, Time/batch_file : 9.3180, Training time: 6846.7011\n",
      "Epoch : 148/500 data_batch_5,  Train_loss : 0.1416  Test_loss : 0.1431, Time/batch_file : 9.0393, Training time: 6855.7406\n",
      "Epoch : 149/500 data_batch_1,  Train_loss : 0.1390  Test_loss : 0.1444, Time/batch_file : 9.2885, Training time: 6865.0295\n",
      "Epoch : 149/500 data_batch_2,  Train_loss : 0.1383  Test_loss : 0.1450, Time/batch_file : 9.2389, Training time: 6874.2686\n",
      "Epoch : 149/500 data_batch_3,  Train_loss : 0.1406  Test_loss : 0.1414, Time/batch_file : 9.1079, Training time: 6883.3769\n",
      "Epoch : 149/500 data_batch_4,  Train_loss : 0.1409  Test_loss : 0.1501, Time/batch_file : 9.1036, Training time: 6892.4807\n",
      "Epoch : 149/500 data_batch_5,  Train_loss : 0.1396  Test_loss : 0.1468, Time/batch_file : 9.2329, Training time: 6901.7139\n",
      "Epoch : 150/500 data_batch_1,  Train_loss : 0.1394  Test_loss : 0.1480, Time/batch_file : 9.0547, Training time: 6910.7689\n",
      "Epoch : 150/500 data_batch_2,  Train_loss : 0.1448  Test_loss : 0.1410, Time/batch_file : 9.0882, Training time: 6919.8573\n",
      "Epoch : 150/500 data_batch_3,  Train_loss : 0.1454  Test_loss : 0.1467, Time/batch_file : 9.1469, Training time: 6929.0045\n",
      "Epoch : 150/500 data_batch_4,  Train_loss : 0.1369  Test_loss : 0.1451, Time/batch_file : 9.1232, Training time: 6938.1279\n",
      "Epoch : 150/500 data_batch_5,  Train_loss : 0.1397  Test_loss : 0.1435, Time/batch_file : 9.1484, Training time: 6947.2765\n",
      "Epoch : 151/500 data_batch_1,  Train_loss : 0.1353  Test_loss : 0.1571, Time/batch_file : 9.0985, Training time: 6958.0240\n",
      "Epoch : 151/500 data_batch_2,  Train_loss : 0.1340  Test_loss : 0.1586, Time/batch_file : 9.1314, Training time: 6967.1557\n",
      "Epoch : 151/500 data_batch_3,  Train_loss : 0.1334  Test_loss : 0.1505, Time/batch_file : 9.1613, Training time: 6976.3173\n",
      "Epoch : 151/500 data_batch_4,  Train_loss : 0.1395  Test_loss : 0.1479, Time/batch_file : 9.1542, Training time: 6985.4718\n",
      "Epoch : 151/500 data_batch_5,  Train_loss : 0.1319  Test_loss : 0.1583, Time/batch_file : 9.1233, Training time: 6994.5955\n",
      "Epoch : 152/500 data_batch_1,  Train_loss : 0.1346  Test_loss : 0.1501, Time/batch_file : 8.9974, Training time: 7003.5932\n",
      "Epoch : 152/500 data_batch_2,  Train_loss : 0.1473  Test_loss : 0.1532, Time/batch_file : 9.2499, Training time: 7012.8434\n",
      "Epoch : 152/500 data_batch_3,  Train_loss : 0.1439  Test_loss : 0.1414, Time/batch_file : 9.3141, Training time: 7022.1577\n",
      "Epoch : 152/500 data_batch_4,  Train_loss : 0.1427  Test_loss : 0.1508, Time/batch_file : 9.0895, Training time: 7031.2474\n",
      "Epoch : 152/500 data_batch_5,  Train_loss : 0.1401  Test_loss : 0.1503, Time/batch_file : 9.1513, Training time: 7040.3991\n",
      "Epoch : 153/500 data_batch_1,  Train_loss : 0.1415  Test_loss : 0.1547, Time/batch_file : 9.2135, Training time: 7049.6129\n",
      "Epoch : 153/500 data_batch_2,  Train_loss : 0.1434  Test_loss : 0.1530, Time/batch_file : 9.2021, Training time: 7058.8152\n",
      "Epoch : 153/500 data_batch_3,  Train_loss : 0.1437  Test_loss : 0.1532, Time/batch_file : 9.3308, Training time: 7068.1462\n",
      "Epoch : 153/500 data_batch_4,  Train_loss : 0.1434  Test_loss : 0.1523, Time/batch_file : 9.3751, Training time: 7077.5216\n",
      "Epoch : 153/500 data_batch_5,  Train_loss : 0.1475  Test_loss : 0.1496, Time/batch_file : 9.1702, Training time: 7086.6921\n",
      "Epoch : 154/500 data_batch_1,  Train_loss : 0.1427  Test_loss : 0.1431, Time/batch_file : 9.0102, Training time: 7095.7028\n",
      "Epoch : 154/500 data_batch_2,  Train_loss : 0.1468  Test_loss : 0.1431, Time/batch_file : 9.1509, Training time: 7104.8539\n",
      "Epoch : 154/500 data_batch_3,  Train_loss : 0.1466  Test_loss : 0.1420, Time/batch_file : 9.1496, Training time: 7114.0038\n",
      "Epoch : 154/500 data_batch_4,  Train_loss : 0.1413  Test_loss : 0.1416, Time/batch_file : 9.0579, Training time: 7123.0618\n",
      "Epoch : 154/500 data_batch_5,  Train_loss : 0.1404  Test_loss : 0.1418, Time/batch_file : 9.2702, Training time: 7132.3323\n",
      "Epoch : 155/500 data_batch_1,  Train_loss : 0.1461  Test_loss : 0.1458, Time/batch_file : 9.2503, Training time: 7141.5829\n",
      "Epoch : 155/500 data_batch_2,  Train_loss : 0.1424  Test_loss : 0.1412, Time/batch_file : 9.1655, Training time: 7150.7486\n",
      "Epoch : 155/500 data_batch_3,  Train_loss : 0.1469  Test_loss : 0.1465, Time/batch_file : 9.1255, Training time: 7159.8745\n",
      "Epoch : 155/500 data_batch_4,  Train_loss : 0.1460  Test_loss : 0.1406, Time/batch_file : 9.3783, Training time: 7169.2530\n",
      "Epoch : 155/500 data_batch_5,  Train_loss : 0.1477  Test_loss : 0.1415, Time/batch_file : 9.0754, Training time: 7178.3286\n",
      "Epoch : 156/500 data_batch_1,  Train_loss : 0.1401  Test_loss : 0.1411, Time/batch_file : 9.2805, Training time: 7189.1403\n",
      "Epoch : 156/500 data_batch_2,  Train_loss : 0.1475  Test_loss : 0.1379, Time/batch_file : 9.1004, Training time: 7198.2411\n",
      "Epoch : 156/500 data_batch_3,  Train_loss : 0.1508  Test_loss : 0.1384, Time/batch_file : 9.4313, Training time: 7207.6727\n",
      "Epoch : 156/500 data_batch_4,  Train_loss : 0.1401  Test_loss : 0.1357, Time/batch_file : 9.0059, Training time: 7216.6789\n",
      "Epoch : 156/500 data_batch_5,  Train_loss : 0.1473  Test_loss : 0.1437, Time/batch_file : 9.2230, Training time: 7225.9023\n",
      "Epoch : 157/500 data_batch_1,  Train_loss : 0.1430  Test_loss : 0.1457, Time/batch_file : 9.2799, Training time: 7235.1825\n",
      "Epoch : 157/500 data_batch_2,  Train_loss : 0.1399  Test_loss : 0.1388, Time/batch_file : 9.3042, Training time: 7244.4870\n",
      "Epoch : 157/500 data_batch_3,  Train_loss : 0.1322  Test_loss : 0.1435, Time/batch_file : 9.0551, Training time: 7253.5423\n",
      "Epoch : 157/500 data_batch_4,  Train_loss : 0.1349  Test_loss : 0.1397, Time/batch_file : 9.3614, Training time: 7262.9040\n",
      "Epoch : 157/500 data_batch_5,  Train_loss : 0.1342  Test_loss : 0.1369, Time/batch_file : 8.9706, Training time: 7271.8749\n",
      "Epoch : 158/500 data_batch_1,  Train_loss : 0.1436  Test_loss : 0.1398, Time/batch_file : 9.3484, Training time: 7281.2235\n",
      "Epoch : 158/500 data_batch_2,  Train_loss : 0.1442  Test_loss : 0.1425, Time/batch_file : 9.2240, Training time: 7290.4479\n",
      "Epoch : 158/500 data_batch_3,  Train_loss : 0.1434  Test_loss : 0.1358, Time/batch_file : 9.2449, Training time: 7299.6931\n",
      "Epoch : 158/500 data_batch_4,  Train_loss : 0.1456  Test_loss : 0.1425, Time/batch_file : 9.2860, Training time: 7308.9795\n",
      "Epoch : 158/500 data_batch_5,  Train_loss : 0.1435  Test_loss : 0.1398, Time/batch_file : 9.2450, Training time: 7318.2249\n",
      "Epoch : 159/500 data_batch_1,  Train_loss : 0.1478  Test_loss : 0.1483, Time/batch_file : 9.3577, Training time: 7327.5828\n",
      "Epoch : 159/500 data_batch_2,  Train_loss : 0.1457  Test_loss : 0.1494, Time/batch_file : 9.1200, Training time: 7336.7032\n",
      "Epoch : 159/500 data_batch_3,  Train_loss : 0.1486  Test_loss : 0.1468, Time/batch_file : 9.1839, Training time: 7345.8874\n",
      "Epoch : 159/500 data_batch_4,  Train_loss : 0.1471  Test_loss : 0.1419, Time/batch_file : 9.1322, Training time: 7355.0199\n",
      "Epoch : 159/500 data_batch_5,  Train_loss : 0.1502  Test_loss : 0.1412, Time/batch_file : 9.3561, Training time: 7364.3763\n",
      "Epoch : 160/500 data_batch_1,  Train_loss : 0.1342  Test_loss : 0.1432, Time/batch_file : 9.1029, Training time: 7373.4795\n",
      "Epoch : 160/500 data_batch_2,  Train_loss : 0.1478  Test_loss : 0.1430, Time/batch_file : 9.1206, Training time: 7382.6003\n",
      "Epoch : 160/500 data_batch_3,  Train_loss : 0.1419  Test_loss : 0.1431, Time/batch_file : 9.3257, Training time: 7391.9262\n",
      "Epoch : 160/500 data_batch_4,  Train_loss : 0.1403  Test_loss : 0.1376, Time/batch_file : 9.1782, Training time: 7401.1046\n",
      "Epoch : 160/500 data_batch_5,  Train_loss : 0.1434  Test_loss : 0.1385, Time/batch_file : 9.1045, Training time: 7410.2094\n",
      "[./nets/net-160.ckpt] SAVED\n",
      "Epoch : 161/500 data_batch_1,  Train_loss : 0.1447  Test_loss : 0.1535, Time/batch_file : 9.0882, Training time: 7421.1040\n",
      "Epoch : 161/500 data_batch_2,  Train_loss : 0.1510  Test_loss : 0.1541, Time/batch_file : 9.0421, Training time: 7430.1464\n",
      "Epoch : 161/500 data_batch_3,  Train_loss : 0.1493  Test_loss : 0.1536, Time/batch_file : 9.2647, Training time: 7439.4115\n",
      "Epoch : 161/500 data_batch_4,  Train_loss : 0.1450  Test_loss : 0.1576, Time/batch_file : 9.0637, Training time: 7448.4755\n",
      "Epoch : 161/500 data_batch_5,  Train_loss : 0.1486  Test_loss : 0.1536, Time/batch_file : 8.9380, Training time: 7457.4139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 162/500 data_batch_1,  Train_loss : 0.1431  Test_loss : 0.1429, Time/batch_file : 9.4413, Training time: 7466.8555\n",
      "Epoch : 162/500 data_batch_2,  Train_loss : 0.1435  Test_loss : 0.1420, Time/batch_file : 9.2053, Training time: 7476.0610\n",
      "Epoch : 162/500 data_batch_3,  Train_loss : 0.1371  Test_loss : 0.1415, Time/batch_file : 9.0914, Training time: 7485.1526\n",
      "Epoch : 162/500 data_batch_4,  Train_loss : 0.1448  Test_loss : 0.1423, Time/batch_file : 8.9967, Training time: 7494.1496\n",
      "Epoch : 162/500 data_batch_5,  Train_loss : 0.1417  Test_loss : 0.1435, Time/batch_file : 9.2642, Training time: 7503.4140\n",
      "Epoch : 163/500 data_batch_1,  Train_loss : 0.1328  Test_loss : 0.1438, Time/batch_file : 9.4374, Training time: 7512.8517\n",
      "Epoch : 163/500 data_batch_2,  Train_loss : 0.1339  Test_loss : 0.1500, Time/batch_file : 9.1609, Training time: 7522.0129\n",
      "Epoch : 163/500 data_batch_3,  Train_loss : 0.1370  Test_loss : 0.1494, Time/batch_file : 8.9222, Training time: 7530.9353\n",
      "Epoch : 163/500 data_batch_4,  Train_loss : 0.1327  Test_loss : 0.1508, Time/batch_file : 9.4242, Training time: 7540.3598\n",
      "Epoch : 163/500 data_batch_5,  Train_loss : 0.1337  Test_loss : 0.1486, Time/batch_file : 9.0891, Training time: 7549.4491\n",
      "Epoch : 164/500 data_batch_1,  Train_loss : 0.1325  Test_loss : 0.1318, Time/batch_file : 9.0450, Training time: 7558.4943\n",
      "Epoch : 164/500 data_batch_2,  Train_loss : 0.1350  Test_loss : 0.1331, Time/batch_file : 9.1824, Training time: 7567.6769\n",
      "Epoch : 164/500 data_batch_3,  Train_loss : 0.1352  Test_loss : 0.1410, Time/batch_file : 9.0098, Training time: 7576.6870\n",
      "Epoch : 164/500 data_batch_4,  Train_loss : 0.1366  Test_loss : 0.1404, Time/batch_file : 9.0361, Training time: 7585.7235\n",
      "Epoch : 164/500 data_batch_5,  Train_loss : 0.1356  Test_loss : 0.1353, Time/batch_file : 9.1035, Training time: 7594.8273\n",
      "Epoch : 165/500 data_batch_1,  Train_loss : 0.1399  Test_loss : 0.1425, Time/batch_file : 9.0480, Training time: 7603.8755\n",
      "Epoch : 165/500 data_batch_2,  Train_loss : 0.1384  Test_loss : 0.1410, Time/batch_file : 9.2498, Training time: 7613.1256\n",
      "Epoch : 165/500 data_batch_3,  Train_loss : 0.1495  Test_loss : 0.1414, Time/batch_file : 9.1947, Training time: 7622.3206\n",
      "Epoch : 165/500 data_batch_4,  Train_loss : 0.1453  Test_loss : 0.1437, Time/batch_file : 9.0388, Training time: 7631.3598\n",
      "Epoch : 165/500 data_batch_5,  Train_loss : 0.1403  Test_loss : 0.1446, Time/batch_file : 9.2938, Training time: 7640.6538\n",
      "Epoch : 166/500 data_batch_1,  Train_loss : 0.1351  Test_loss : 0.1396, Time/batch_file : 9.1642, Training time: 7651.7137\n",
      "Epoch : 166/500 data_batch_2,  Train_loss : 0.1409  Test_loss : 0.1422, Time/batch_file : 9.2284, Training time: 7660.9423\n",
      "Epoch : 166/500 data_batch_3,  Train_loss : 0.1339  Test_loss : 0.1426, Time/batch_file : 8.9433, Training time: 7669.8859\n",
      "Epoch : 166/500 data_batch_4,  Train_loss : 0.1356  Test_loss : 0.1500, Time/batch_file : 9.3581, Training time: 7679.2443\n",
      "Epoch : 166/500 data_batch_5,  Train_loss : 0.1348  Test_loss : 0.1443, Time/batch_file : 9.1428, Training time: 7688.3873\n",
      "Epoch : 167/500 data_batch_1,  Train_loss : 0.1413  Test_loss : 0.1382, Time/batch_file : 9.2442, Training time: 7697.6317\n",
      "Epoch : 167/500 data_batch_2,  Train_loss : 0.1427  Test_loss : 0.1417, Time/batch_file : 9.2197, Training time: 7706.8518\n",
      "Epoch : 167/500 data_batch_3,  Train_loss : 0.1333  Test_loss : 0.1413, Time/batch_file : 9.1272, Training time: 7715.9793\n",
      "Epoch : 167/500 data_batch_4,  Train_loss : 0.1420  Test_loss : 0.1459, Time/batch_file : 9.1199, Training time: 7725.0995\n",
      "Epoch : 167/500 data_batch_5,  Train_loss : 0.1391  Test_loss : 0.1456, Time/batch_file : 9.1017, Training time: 7734.2013\n",
      "Epoch : 168/500 data_batch_1,  Train_loss : 0.1456  Test_loss : 0.1459, Time/batch_file : 9.1094, Training time: 7743.3110\n",
      "Epoch : 168/500 data_batch_2,  Train_loss : 0.1458  Test_loss : 0.1392, Time/batch_file : 9.2022, Training time: 7752.5136\n",
      "Epoch : 168/500 data_batch_3,  Train_loss : 0.1464  Test_loss : 0.1419, Time/batch_file : 9.0461, Training time: 7761.5599\n",
      "Epoch : 168/500 data_batch_4,  Train_loss : 0.1476  Test_loss : 0.1417, Time/batch_file : 9.1368, Training time: 7770.6970\n",
      "Epoch : 168/500 data_batch_5,  Train_loss : 0.1366  Test_loss : 0.1412, Time/batch_file : 9.2090, Training time: 7779.9063\n",
      "Epoch : 169/500 data_batch_1,  Train_loss : 0.1357  Test_loss : 0.1442, Time/batch_file : 9.2306, Training time: 7789.1371\n",
      "Epoch : 169/500 data_batch_2,  Train_loss : 0.1441  Test_loss : 0.1435, Time/batch_file : 9.3739, Training time: 7798.5114\n",
      "Epoch : 169/500 data_batch_3,  Train_loss : 0.1376  Test_loss : 0.1450, Time/batch_file : 9.0336, Training time: 7807.5453\n",
      "Epoch : 169/500 data_batch_4,  Train_loss : 0.1352  Test_loss : 0.1454, Time/batch_file : 9.4551, Training time: 7817.0007\n",
      "Epoch : 169/500 data_batch_5,  Train_loss : 0.1366  Test_loss : 0.1531, Time/batch_file : 9.1417, Training time: 7826.1428\n",
      "Epoch : 170/500 data_batch_1,  Train_loss : 0.1366  Test_loss : 0.1398, Time/batch_file : 9.1221, Training time: 7835.2651\n",
      "Epoch : 170/500 data_batch_2,  Train_loss : 0.1369  Test_loss : 0.1388, Time/batch_file : 9.1265, Training time: 7844.3919\n",
      "Epoch : 170/500 data_batch_3,  Train_loss : 0.1401  Test_loss : 0.1380, Time/batch_file : 9.0095, Training time: 7853.4018\n",
      "Epoch : 170/500 data_batch_4,  Train_loss : 0.1394  Test_loss : 0.1383, Time/batch_file : 9.0265, Training time: 7862.4285\n",
      "Epoch : 170/500 data_batch_5,  Train_loss : 0.1414  Test_loss : 0.1427, Time/batch_file : 9.3013, Training time: 7871.7302\n",
      "Epoch : 171/500 data_batch_1,  Train_loss : 0.1437  Test_loss : 0.1344, Time/batch_file : 8.9479, Training time: 7882.5219\n",
      "Epoch : 171/500 data_batch_2,  Train_loss : 0.1440  Test_loss : 0.1396, Time/batch_file : 9.1462, Training time: 7891.6684\n",
      "Epoch : 171/500 data_batch_3,  Train_loss : 0.1463  Test_loss : 0.1420, Time/batch_file : 9.4715, Training time: 7901.1401\n",
      "Epoch : 171/500 data_batch_4,  Train_loss : 0.1445  Test_loss : 0.1394, Time/batch_file : 9.0008, Training time: 7910.1414\n",
      "Epoch : 171/500 data_batch_5,  Train_loss : 0.1473  Test_loss : 0.1376, Time/batch_file : 8.9901, Training time: 7919.1317\n",
      "Epoch : 172/500 data_batch_1,  Train_loss : 0.1413  Test_loss : 0.1479, Time/batch_file : 9.1342, Training time: 7928.2662\n",
      "Epoch : 172/500 data_batch_2,  Train_loss : 0.1407  Test_loss : 0.1472, Time/batch_file : 9.1597, Training time: 7937.4262\n",
      "Epoch : 172/500 data_batch_3,  Train_loss : 0.1457  Test_loss : 0.1457, Time/batch_file : 9.0539, Training time: 7946.4803\n",
      "Epoch : 172/500 data_batch_4,  Train_loss : 0.1405  Test_loss : 0.1460, Time/batch_file : 9.3355, Training time: 7955.8160\n",
      "Epoch : 172/500 data_batch_5,  Train_loss : 0.1429  Test_loss : 0.1465, Time/batch_file : 9.3038, Training time: 7965.1202\n",
      "Epoch : 173/500 data_batch_1,  Train_loss : 0.1486  Test_loss : 0.1390, Time/batch_file : 9.0829, Training time: 7974.2033\n",
      "Epoch : 173/500 data_batch_2,  Train_loss : 0.1507  Test_loss : 0.1397, Time/batch_file : 9.4238, Training time: 7983.6274\n",
      "Epoch : 173/500 data_batch_3,  Train_loss : 0.1495  Test_loss : 0.1408, Time/batch_file : 9.1807, Training time: 7992.8086\n",
      "Epoch : 173/500 data_batch_4,  Train_loss : 0.1493  Test_loss : 0.1442, Time/batch_file : 9.0980, Training time: 8001.9068\n",
      "Epoch : 173/500 data_batch_5,  Train_loss : 0.1456  Test_loss : 0.1417, Time/batch_file : 9.0907, Training time: 8010.9979\n",
      "Epoch : 174/500 data_batch_1,  Train_loss : 0.1468  Test_loss : 0.1515, Time/batch_file : 9.2299, Training time: 8020.2282\n",
      "Epoch : 174/500 data_batch_2,  Train_loss : 0.1407  Test_loss : 0.1498, Time/batch_file : 9.2729, Training time: 8029.5013\n",
      "Epoch : 174/500 data_batch_3,  Train_loss : 0.1479  Test_loss : 0.1480, Time/batch_file : 9.3029, Training time: 8038.8044\n",
      "Epoch : 174/500 data_batch_4,  Train_loss : 0.1440  Test_loss : 0.1501, Time/batch_file : 8.8371, Training time: 8047.6419\n",
      "Epoch : 174/500 data_batch_5,  Train_loss : 0.1487  Test_loss : 0.1492, Time/batch_file : 9.3517, Training time: 8056.9939\n",
      "Epoch : 175/500 data_batch_1,  Train_loss : 0.1460  Test_loss : 0.1391, Time/batch_file : 9.2597, Training time: 8066.2539\n",
      "Epoch : 175/500 data_batch_2,  Train_loss : 0.1477  Test_loss : 0.1417, Time/batch_file : 9.2589, Training time: 8075.5131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 175/500 data_batch_3,  Train_loss : 0.1411  Test_loss : 0.1385, Time/batch_file : 9.0453, Training time: 8084.5586\n",
      "Epoch : 175/500 data_batch_4,  Train_loss : 0.1459  Test_loss : 0.1391, Time/batch_file : 9.2758, Training time: 8093.8347\n",
      "Epoch : 175/500 data_batch_5,  Train_loss : 0.1520  Test_loss : 0.1405, Time/batch_file : 8.9490, Training time: 8102.7841\n",
      "Epoch : 176/500 data_batch_1,  Train_loss : 0.1461  Test_loss : 0.1432, Time/batch_file : 9.3622, Training time: 8115.6725\n",
      "Epoch : 176/500 data_batch_2,  Train_loss : 0.1468  Test_loss : 0.1436, Time/batch_file : 8.9651, Training time: 8124.6378\n",
      "Epoch : 176/500 data_batch_3,  Train_loss : 0.1422  Test_loss : 0.1340, Time/batch_file : 8.9853, Training time: 8133.6235\n",
      "Epoch : 176/500 data_batch_4,  Train_loss : 0.1497  Test_loss : 0.1398, Time/batch_file : 8.9392, Training time: 8142.5629\n",
      "Epoch : 176/500 data_batch_5,  Train_loss : 0.1466  Test_loss : 0.1425, Time/batch_file : 9.6406, Training time: 8152.2039\n",
      "Epoch : 177/500 data_batch_1,  Train_loss : 0.1375  Test_loss : 0.1456, Time/batch_file : 9.2408, Training time: 8161.4450\n",
      "Epoch : 177/500 data_batch_2,  Train_loss : 0.1376  Test_loss : 0.1391, Time/batch_file : 9.2803, Training time: 8170.7255\n",
      "Epoch : 177/500 data_batch_3,  Train_loss : 0.1378  Test_loss : 0.1426, Time/batch_file : 9.0349, Training time: 8179.7606\n",
      "Epoch : 177/500 data_batch_4,  Train_loss : 0.1417  Test_loss : 0.1442, Time/batch_file : 9.0157, Training time: 8188.7766\n",
      "Epoch : 177/500 data_batch_5,  Train_loss : 0.1331  Test_loss : 0.1432, Time/batch_file : 9.3215, Training time: 8198.0984\n",
      "Epoch : 178/500 data_batch_1,  Train_loss : 0.1458  Test_loss : 0.1386, Time/batch_file : 9.2010, Training time: 8207.2996\n",
      "Epoch : 178/500 data_batch_2,  Train_loss : 0.1407  Test_loss : 0.1465, Time/batch_file : 9.0765, Training time: 8216.3767\n",
      "Epoch : 178/500 data_batch_3,  Train_loss : 0.1429  Test_loss : 0.1388, Time/batch_file : 9.0354, Training time: 8225.4124\n",
      "Epoch : 178/500 data_batch_4,  Train_loss : 0.1477  Test_loss : 0.1440, Time/batch_file : 9.0115, Training time: 8234.4241\n",
      "Epoch : 178/500 data_batch_5,  Train_loss : 0.1406  Test_loss : 0.1451, Time/batch_file : 8.9637, Training time: 8243.3881\n",
      "Epoch : 179/500 data_batch_1,  Train_loss : 0.1391  Test_loss : 0.1461, Time/batch_file : 9.2343, Training time: 8252.6257\n",
      "Epoch : 179/500 data_batch_2,  Train_loss : 0.1423  Test_loss : 0.1426, Time/batch_file : 9.3334, Training time: 8261.9594\n",
      "Epoch : 179/500 data_batch_3,  Train_loss : 0.1472  Test_loss : 0.1430, Time/batch_file : 9.0176, Training time: 8270.9772\n",
      "Epoch : 179/500 data_batch_4,  Train_loss : 0.1386  Test_loss : 0.1443, Time/batch_file : 9.1500, Training time: 8280.1274\n",
      "Epoch : 179/500 data_batch_5,  Train_loss : 0.1427  Test_loss : 0.1472, Time/batch_file : 9.3907, Training time: 8289.5184\n",
      "Epoch : 180/500 data_batch_1,  Train_loss : 0.1525  Test_loss : 0.1511, Time/batch_file : 9.3369, Training time: 8298.8555\n",
      "Epoch : 180/500 data_batch_2,  Train_loss : 0.1545  Test_loss : 0.1500, Time/batch_file : 9.1887, Training time: 8308.0446\n",
      "Epoch : 180/500 data_batch_3,  Train_loss : 0.1552  Test_loss : 0.1537, Time/batch_file : 9.2896, Training time: 8317.3344\n",
      "Epoch : 180/500 data_batch_4,  Train_loss : 0.1511  Test_loss : 0.1577, Time/batch_file : 9.0329, Training time: 8326.3677\n",
      "Epoch : 180/500 data_batch_5,  Train_loss : 0.1521  Test_loss : 0.1544, Time/batch_file : 9.2875, Training time: 8335.6555\n",
      "[./nets/net-180.ckpt] SAVED\n",
      "Epoch : 181/500 data_batch_1,  Train_loss : 0.1520  Test_loss : 0.1356, Time/batch_file : 9.2439, Training time: 8346.9201\n",
      "Epoch : 181/500 data_batch_2,  Train_loss : 0.1471  Test_loss : 0.1364, Time/batch_file : 9.2470, Training time: 8356.1675\n",
      "Epoch : 181/500 data_batch_3,  Train_loss : 0.1491  Test_loss : 0.1390, Time/batch_file : 9.1158, Training time: 8365.2835\n",
      "Epoch : 181/500 data_batch_4,  Train_loss : 0.1473  Test_loss : 0.1414, Time/batch_file : 9.3908, Training time: 8374.6746\n",
      "Epoch : 181/500 data_batch_5,  Train_loss : 0.1480  Test_loss : 0.1404, Time/batch_file : 9.2095, Training time: 8383.8843\n",
      "Epoch : 182/500 data_batch_1,  Train_loss : 0.1381  Test_loss : 0.1405, Time/batch_file : 9.2217, Training time: 8393.1062\n",
      "Epoch : 182/500 data_batch_2,  Train_loss : 0.1350  Test_loss : 0.1398, Time/batch_file : 9.1018, Training time: 8402.2083\n",
      "Epoch : 182/500 data_batch_3,  Train_loss : 0.1359  Test_loss : 0.1394, Time/batch_file : 9.1348, Training time: 8411.3434\n",
      "Epoch : 182/500 data_batch_4,  Train_loss : 0.1341  Test_loss : 0.1380, Time/batch_file : 9.4167, Training time: 8420.7604\n",
      "Epoch : 182/500 data_batch_5,  Train_loss : 0.1353  Test_loss : 0.1380, Time/batch_file : 9.1388, Training time: 8429.8995\n",
      "Epoch : 183/500 data_batch_1,  Train_loss : 0.1455  Test_loss : 0.1358, Time/batch_file : 9.2863, Training time: 8439.1862\n",
      "Epoch : 183/500 data_batch_2,  Train_loss : 0.1380  Test_loss : 0.1345, Time/batch_file : 9.2704, Training time: 8448.4568\n",
      "Epoch : 183/500 data_batch_3,  Train_loss : 0.1433  Test_loss : 0.1379, Time/batch_file : 9.1152, Training time: 8457.5723\n",
      "Epoch : 183/500 data_batch_4,  Train_loss : 0.1416  Test_loss : 0.1325, Time/batch_file : 9.4012, Training time: 8466.9739\n",
      "Epoch : 183/500 data_batch_5,  Train_loss : 0.1368  Test_loss : 0.1362, Time/batch_file : 9.1803, Training time: 8476.1545\n",
      "Epoch : 184/500 data_batch_1,  Train_loss : 0.1459  Test_loss : 0.1444, Time/batch_file : 9.4313, Training time: 8485.5860\n",
      "Epoch : 184/500 data_batch_2,  Train_loss : 0.1442  Test_loss : 0.1458, Time/batch_file : 9.1782, Training time: 8494.7645\n",
      "Epoch : 184/500 data_batch_3,  Train_loss : 0.1447  Test_loss : 0.1387, Time/batch_file : 9.4877, Training time: 8504.2524\n",
      "Epoch : 184/500 data_batch_4,  Train_loss : 0.1430  Test_loss : 0.1400, Time/batch_file : 9.2089, Training time: 8513.4617\n",
      "Epoch : 184/500 data_batch_5,  Train_loss : 0.1453  Test_loss : 0.1413, Time/batch_file : 9.4171, Training time: 8522.8790\n",
      "Epoch : 185/500 data_batch_1,  Train_loss : 0.1390  Test_loss : 0.1427, Time/batch_file : 9.0490, Training time: 8531.9283\n",
      "Epoch : 185/500 data_batch_2,  Train_loss : 0.1394  Test_loss : 0.1448, Time/batch_file : 9.1574, Training time: 8541.0860\n",
      "Epoch : 185/500 data_batch_3,  Train_loss : 0.1434  Test_loss : 0.1391, Time/batch_file : 9.1386, Training time: 8550.2248\n",
      "Epoch : 185/500 data_batch_4,  Train_loss : 0.1368  Test_loss : 0.1422, Time/batch_file : 9.0624, Training time: 8559.2876\n",
      "Epoch : 185/500 data_batch_5,  Train_loss : 0.1418  Test_loss : 0.1364, Time/batch_file : 9.1012, Training time: 8568.3891\n",
      "Epoch : 186/500 data_batch_1,  Train_loss : 0.1339  Test_loss : 0.1472, Time/batch_file : 9.1154, Training time: 8579.1543\n",
      "Epoch : 186/500 data_batch_2,  Train_loss : 0.1349  Test_loss : 0.1499, Time/batch_file : 9.4034, Training time: 8588.5580\n",
      "Epoch : 186/500 data_batch_3,  Train_loss : 0.1363  Test_loss : 0.1457, Time/batch_file : 9.2731, Training time: 8597.8313\n",
      "Epoch : 186/500 data_batch_4,  Train_loss : 0.1360  Test_loss : 0.1415, Time/batch_file : 9.5719, Training time: 8607.4036\n",
      "Epoch : 186/500 data_batch_5,  Train_loss : 0.1351  Test_loss : 0.1475, Time/batch_file : 9.2818, Training time: 8616.6856\n",
      "Epoch : 187/500 data_batch_1,  Train_loss : 0.1289  Test_loss : 0.1470, Time/batch_file : 9.2420, Training time: 8625.9279\n",
      "Epoch : 187/500 data_batch_2,  Train_loss : 0.1337  Test_loss : 0.1435, Time/batch_file : 9.0145, Training time: 8634.9427\n",
      "Epoch : 187/500 data_batch_3,  Train_loss : 0.1306  Test_loss : 0.1443, Time/batch_file : 9.2665, Training time: 8644.2095\n",
      "Epoch : 187/500 data_batch_4,  Train_loss : 0.1298  Test_loss : 0.1446, Time/batch_file : 9.1267, Training time: 8653.3367\n",
      "Epoch : 187/500 data_batch_5,  Train_loss : 0.1308  Test_loss : 0.1490, Time/batch_file : 9.4916, Training time: 8662.8285\n",
      "Epoch : 188/500 data_batch_1,  Train_loss : 0.1367  Test_loss : 0.1421, Time/batch_file : 9.6054, Training time: 8672.4341\n",
      "Epoch : 188/500 data_batch_2,  Train_loss : 0.1331  Test_loss : 0.1402, Time/batch_file : 9.0160, Training time: 8681.4504\n",
      "Epoch : 188/500 data_batch_3,  Train_loss : 0.1357  Test_loss : 0.1475, Time/batch_file : 9.1621, Training time: 8690.6127\n",
      "Epoch : 188/500 data_batch_4,  Train_loss : 0.1395  Test_loss : 0.1387, Time/batch_file : 9.0171, Training time: 8699.6301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 188/500 data_batch_5,  Train_loss : 0.1336  Test_loss : 0.1421, Time/batch_file : 9.3803, Training time: 8709.0107\n",
      "Epoch : 189/500 data_batch_1,  Train_loss : 0.1387  Test_loss : 0.1499, Time/batch_file : 9.1730, Training time: 8718.1839\n",
      "Epoch : 189/500 data_batch_2,  Train_loss : 0.1389  Test_loss : 0.1477, Time/batch_file : 9.1285, Training time: 8727.3128\n",
      "Epoch : 189/500 data_batch_3,  Train_loss : 0.1383  Test_loss : 0.1500, Time/batch_file : 9.2344, Training time: 8736.5474\n",
      "Epoch : 189/500 data_batch_4,  Train_loss : 0.1406  Test_loss : 0.1529, Time/batch_file : 9.3168, Training time: 8745.8644\n",
      "Epoch : 189/500 data_batch_5,  Train_loss : 0.1411  Test_loss : 0.1584, Time/batch_file : 9.3361, Training time: 8755.2008\n",
      "Epoch : 190/500 data_batch_1,  Train_loss : 0.1388  Test_loss : 0.1455, Time/batch_file : 9.3801, Training time: 8764.5813\n",
      "Epoch : 190/500 data_batch_2,  Train_loss : 0.1467  Test_loss : 0.1427, Time/batch_file : 9.1115, Training time: 8773.6931\n",
      "Epoch : 190/500 data_batch_3,  Train_loss : 0.1437  Test_loss : 0.1461, Time/batch_file : 9.5033, Training time: 8783.1967\n",
      "Epoch : 190/500 data_batch_4,  Train_loss : 0.1388  Test_loss : 0.1388, Time/batch_file : 9.3221, Training time: 8792.5190\n",
      "Epoch : 190/500 data_batch_5,  Train_loss : 0.1416  Test_loss : 0.1445, Time/batch_file : 9.2344, Training time: 8801.7537\n",
      "Epoch : 191/500 data_batch_1,  Train_loss : 0.1438  Test_loss : 0.1428, Time/batch_file : 9.0270, Training time: 8812.3776\n",
      "Epoch : 191/500 data_batch_2,  Train_loss : 0.1444  Test_loss : 0.1418, Time/batch_file : 9.2464, Training time: 8821.6245\n",
      "Epoch : 191/500 data_batch_3,  Train_loss : 0.1462  Test_loss : 0.1414, Time/batch_file : 9.0155, Training time: 8830.6403\n",
      "Epoch : 191/500 data_batch_4,  Train_loss : 0.1450  Test_loss : 0.1436, Time/batch_file : 9.3670, Training time: 8840.0075\n",
      "Epoch : 191/500 data_batch_5,  Train_loss : 0.1457  Test_loss : 0.1424, Time/batch_file : 9.3097, Training time: 8849.3175\n",
      "Epoch : 192/500 data_batch_1,  Train_loss : 0.1378  Test_loss : 0.1367, Time/batch_file : 9.2127, Training time: 8858.5305\n",
      "Epoch : 192/500 data_batch_2,  Train_loss : 0.1415  Test_loss : 0.1324, Time/batch_file : 9.3379, Training time: 8867.8687\n",
      "Epoch : 192/500 data_batch_3,  Train_loss : 0.1402  Test_loss : 0.1352, Time/batch_file : 9.2437, Training time: 8877.1128\n",
      "Epoch : 192/500 data_batch_4,  Train_loss : 0.1372  Test_loss : 0.1368, Time/batch_file : 9.2456, Training time: 8886.3587\n",
      "Epoch : 192/500 data_batch_5,  Train_loss : 0.1422  Test_loss : 0.1338, Time/batch_file : 9.2866, Training time: 8895.6456\n",
      "Epoch : 193/500 data_batch_1,  Train_loss : 0.1347  Test_loss : 0.1392, Time/batch_file : 9.2397, Training time: 8904.8856\n",
      "Epoch : 193/500 data_batch_2,  Train_loss : 0.1402  Test_loss : 0.1446, Time/batch_file : 8.9397, Training time: 8913.8257\n",
      "Epoch : 193/500 data_batch_3,  Train_loss : 0.1341  Test_loss : 0.1410, Time/batch_file : 9.6720, Training time: 8923.4981\n",
      "Epoch : 193/500 data_batch_4,  Train_loss : 0.1345  Test_loss : 0.1373, Time/batch_file : 9.2865, Training time: 8932.7848\n",
      "Epoch : 193/500 data_batch_5,  Train_loss : 0.1342  Test_loss : 0.1405, Time/batch_file : 9.3758, Training time: 8942.1609\n",
      "Epoch : 194/500 data_batch_1,  Train_loss : 0.1462  Test_loss : 0.1494, Time/batch_file : 9.2145, Training time: 8951.3757\n",
      "Epoch : 194/500 data_batch_2,  Train_loss : 0.1468  Test_loss : 0.1496, Time/batch_file : 9.0357, Training time: 8960.4116\n",
      "Epoch : 194/500 data_batch_3,  Train_loss : 0.1474  Test_loss : 0.1491, Time/batch_file : 9.2086, Training time: 8969.6205\n",
      "Epoch : 194/500 data_batch_4,  Train_loss : 0.1476  Test_loss : 0.1510, Time/batch_file : 9.3014, Training time: 8978.9222\n",
      "Epoch : 194/500 data_batch_5,  Train_loss : 0.1509  Test_loss : 0.1535, Time/batch_file : 9.0894, Training time: 8988.0120\n",
      "Epoch : 195/500 data_batch_1,  Train_loss : 0.1418  Test_loss : 0.1493, Time/batch_file : 9.1795, Training time: 8997.1918\n",
      "Epoch : 195/500 data_batch_2,  Train_loss : 0.1395  Test_loss : 0.1524, Time/batch_file : 9.0052, Training time: 9006.1975\n",
      "Epoch : 195/500 data_batch_3,  Train_loss : 0.1398  Test_loss : 0.1451, Time/batch_file : 9.0521, Training time: 9015.2498\n",
      "Epoch : 195/500 data_batch_4,  Train_loss : 0.1385  Test_loss : 0.1489, Time/batch_file : 9.2116, Training time: 9024.4616\n",
      "Epoch : 195/500 data_batch_5,  Train_loss : 0.1402  Test_loss : 0.1499, Time/batch_file : 9.1893, Training time: 9033.6512\n",
      "Epoch : 196/500 data_batch_1,  Train_loss : 0.1407  Test_loss : 0.1416, Time/batch_file : 9.0722, Training time: 9044.2742\n",
      "Epoch : 196/500 data_batch_2,  Train_loss : 0.1417  Test_loss : 0.1416, Time/batch_file : 9.0237, Training time: 9053.2981\n",
      "Epoch : 196/500 data_batch_3,  Train_loss : 0.1374  Test_loss : 0.1443, Time/batch_file : 9.0528, Training time: 9062.3512\n",
      "Epoch : 196/500 data_batch_4,  Train_loss : 0.1390  Test_loss : 0.1424, Time/batch_file : 9.1715, Training time: 9071.5230\n",
      "Epoch : 196/500 data_batch_5,  Train_loss : 0.1406  Test_loss : 0.1452, Time/batch_file : 9.1567, Training time: 9080.6799\n",
      "Epoch : 197/500 data_batch_1,  Train_loss : 0.1469  Test_loss : 0.1427, Time/batch_file : 9.1540, Training time: 9089.8342\n",
      "Epoch : 197/500 data_batch_2,  Train_loss : 0.1463  Test_loss : 0.1422, Time/batch_file : 9.1109, Training time: 9098.9454\n",
      "Epoch : 197/500 data_batch_3,  Train_loss : 0.1457  Test_loss : 0.1430, Time/batch_file : 9.1565, Training time: 9108.1021\n",
      "Epoch : 197/500 data_batch_4,  Train_loss : 0.1437  Test_loss : 0.1385, Time/batch_file : 9.2585, Training time: 9117.3608\n",
      "Epoch : 197/500 data_batch_5,  Train_loss : 0.1453  Test_loss : 0.1466, Time/batch_file : 9.0809, Training time: 9126.4421\n",
      "Epoch : 198/500 data_batch_1,  Train_loss : 0.1471  Test_loss : 0.1489, Time/batch_file : 9.4901, Training time: 9135.9325\n",
      "Epoch : 198/500 data_batch_2,  Train_loss : 0.1416  Test_loss : 0.1526, Time/batch_file : 9.0600, Training time: 9144.9927\n",
      "Epoch : 198/500 data_batch_3,  Train_loss : 0.1429  Test_loss : 0.1479, Time/batch_file : 8.9875, Training time: 9153.9804\n",
      "Epoch : 198/500 data_batch_4,  Train_loss : 0.1474  Test_loss : 0.1493, Time/batch_file : 9.4912, Training time: 9163.4719\n",
      "Epoch : 198/500 data_batch_5,  Train_loss : 0.1513  Test_loss : 0.1502, Time/batch_file : 9.3566, Training time: 9172.8287\n",
      "Epoch : 199/500 data_batch_1,  Train_loss : 0.1423  Test_loss : 0.1389, Time/batch_file : 9.2125, Training time: 9182.0415\n",
      "Epoch : 199/500 data_batch_2,  Train_loss : 0.1394  Test_loss : 0.1405, Time/batch_file : 9.2488, Training time: 9191.2906\n",
      "Epoch : 199/500 data_batch_3,  Train_loss : 0.1404  Test_loss : 0.1393, Time/batch_file : 9.2677, Training time: 9200.5587\n",
      "Epoch : 199/500 data_batch_4,  Train_loss : 0.1401  Test_loss : 0.1408, Time/batch_file : 9.2143, Training time: 9209.7733\n",
      "Epoch : 199/500 data_batch_5,  Train_loss : 0.1393  Test_loss : 0.1408, Time/batch_file : 9.0142, Training time: 9218.7878\n",
      "Epoch : 200/500 data_batch_1,  Train_loss : 0.1414  Test_loss : 0.1453, Time/batch_file : 9.2737, Training time: 9228.0619\n",
      "Epoch : 200/500 data_batch_2,  Train_loss : 0.1390  Test_loss : 0.1413, Time/batch_file : 9.2028, Training time: 9237.2650\n",
      "Epoch : 200/500 data_batch_3,  Train_loss : 0.1411  Test_loss : 0.1478, Time/batch_file : 9.0281, Training time: 9246.2934\n",
      "Epoch : 200/500 data_batch_4,  Train_loss : 0.1422  Test_loss : 0.1406, Time/batch_file : 9.1591, Training time: 9255.4528\n",
      "Epoch : 200/500 data_batch_5,  Train_loss : 0.1373  Test_loss : 0.1446, Time/batch_file : 9.3792, Training time: 9264.8322\n",
      "[./nets/net-200.ckpt] SAVED\n",
      "Epoch : 201/500 data_batch_1,  Train_loss : 0.1491  Test_loss : 0.1461, Time/batch_file : 9.2750, Training time: 9275.9319\n",
      "Epoch : 201/500 data_batch_2,  Train_loss : 0.1501  Test_loss : 0.1457, Time/batch_file : 9.3710, Training time: 9285.3033\n",
      "Epoch : 201/500 data_batch_3,  Train_loss : 0.1438  Test_loss : 0.1462, Time/batch_file : 9.2566, Training time: 9294.5602\n",
      "Epoch : 201/500 data_batch_4,  Train_loss : 0.1507  Test_loss : 0.1415, Time/batch_file : 9.0745, Training time: 9303.6350\n",
      "Epoch : 201/500 data_batch_5,  Train_loss : 0.1501  Test_loss : 0.1420, Time/batch_file : 9.4571, Training time: 9313.0923\n",
      "Epoch : 202/500 data_batch_1,  Train_loss : 0.1386  Test_loss : 0.1443, Time/batch_file : 9.1175, Training time: 9322.2103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 202/500 data_batch_2,  Train_loss : 0.1374  Test_loss : 0.1451, Time/batch_file : 9.1254, Training time: 9331.3360\n",
      "Epoch : 202/500 data_batch_3,  Train_loss : 0.1366  Test_loss : 0.1495, Time/batch_file : 9.2435, Training time: 9340.5798\n",
      "Epoch : 202/500 data_batch_4,  Train_loss : 0.1381  Test_loss : 0.1488, Time/batch_file : 8.9467, Training time: 9349.5269\n",
      "Epoch : 202/500 data_batch_5,  Train_loss : 0.1430  Test_loss : 0.1467, Time/batch_file : 9.2680, Training time: 9358.7951\n",
      "Epoch : 203/500 data_batch_1,  Train_loss : 0.1381  Test_loss : 0.1422, Time/batch_file : 9.1429, Training time: 9367.9384\n",
      "Epoch : 203/500 data_batch_2,  Train_loss : 0.1344  Test_loss : 0.1449, Time/batch_file : 9.1837, Training time: 9377.1224\n",
      "Epoch : 203/500 data_batch_3,  Train_loss : 0.1373  Test_loss : 0.1436, Time/batch_file : 9.3104, Training time: 9386.4331\n",
      "Epoch : 203/500 data_batch_4,  Train_loss : 0.1395  Test_loss : 0.1446, Time/batch_file : 9.3084, Training time: 9395.7425\n",
      "Epoch : 203/500 data_batch_5,  Train_loss : 0.1337  Test_loss : 0.1457, Time/batch_file : 9.1870, Training time: 9404.9299\n",
      "Epoch : 204/500 data_batch_1,  Train_loss : 0.1450  Test_loss : 0.1473, Time/batch_file : 9.1599, Training time: 9414.0900\n",
      "Epoch : 204/500 data_batch_2,  Train_loss : 0.1425  Test_loss : 0.1460, Time/batch_file : 9.1047, Training time: 9423.1950\n",
      "Epoch : 204/500 data_batch_3,  Train_loss : 0.1431  Test_loss : 0.1411, Time/batch_file : 9.0427, Training time: 9432.2382\n",
      "Epoch : 204/500 data_batch_4,  Train_loss : 0.1490  Test_loss : 0.1447, Time/batch_file : 9.8098, Training time: 9442.0482\n",
      "Epoch : 204/500 data_batch_5,  Train_loss : 0.1425  Test_loss : 0.1448, Time/batch_file : 9.2907, Training time: 9451.3391\n",
      "Epoch : 205/500 data_batch_1,  Train_loss : 0.1435  Test_loss : 0.1411, Time/batch_file : 9.5341, Training time: 9460.8735\n",
      "Epoch : 205/500 data_batch_2,  Train_loss : 0.1458  Test_loss : 0.1461, Time/batch_file : 9.2772, Training time: 9470.1512\n",
      "Epoch : 205/500 data_batch_3,  Train_loss : 0.1504  Test_loss : 0.1507, Time/batch_file : 9.1940, Training time: 9479.3456\n",
      "Epoch : 205/500 data_batch_4,  Train_loss : 0.1463  Test_loss : 0.1530, Time/batch_file : 9.1903, Training time: 9488.5363\n",
      "Epoch : 205/500 data_batch_5,  Train_loss : 0.1490  Test_loss : 0.1469, Time/batch_file : 9.3038, Training time: 9497.8403\n",
      "Epoch : 206/500 data_batch_1,  Train_loss : 0.1483  Test_loss : 0.1364, Time/batch_file : 9.2729, Training time: 9508.8075\n",
      "Epoch : 206/500 data_batch_2,  Train_loss : 0.1499  Test_loss : 0.1393, Time/batch_file : 9.4794, Training time: 9518.2872\n",
      "Epoch : 206/500 data_batch_3,  Train_loss : 0.1454  Test_loss : 0.1387, Time/batch_file : 9.0898, Training time: 9527.3773\n",
      "Epoch : 206/500 data_batch_4,  Train_loss : 0.1472  Test_loss : 0.1379, Time/batch_file : 9.3608, Training time: 9536.7387\n",
      "Epoch : 206/500 data_batch_5,  Train_loss : 0.1453  Test_loss : 0.1344, Time/batch_file : 9.2420, Training time: 9545.9810\n",
      "Epoch : 207/500 data_batch_1,  Train_loss : 0.1442  Test_loss : 0.1354, Time/batch_file : 8.9660, Training time: 9554.9472\n",
      "Epoch : 207/500 data_batch_2,  Train_loss : 0.1507  Test_loss : 0.1387, Time/batch_file : 9.1420, Training time: 9564.0895\n",
      "Epoch : 207/500 data_batch_3,  Train_loss : 0.1457  Test_loss : 0.1394, Time/batch_file : 9.0925, Training time: 9573.1824\n",
      "Epoch : 207/500 data_batch_4,  Train_loss : 0.1444  Test_loss : 0.1418, Time/batch_file : 9.1753, Training time: 9582.3580\n",
      "Epoch : 207/500 data_batch_5,  Train_loss : 0.1438  Test_loss : 0.1448, Time/batch_file : 9.1432, Training time: 9591.5016\n",
      "Epoch : 208/500 data_batch_1,  Train_loss : 0.1442  Test_loss : 0.1473, Time/batch_file : 10.0155, Training time: 9601.5175\n",
      "Epoch : 208/500 data_batch_2,  Train_loss : 0.1437  Test_loss : 0.1428, Time/batch_file : 9.2539, Training time: 9610.7717\n",
      "Epoch : 208/500 data_batch_3,  Train_loss : 0.1458  Test_loss : 0.1466, Time/batch_file : 9.2432, Training time: 9620.0151\n",
      "Epoch : 208/500 data_batch_4,  Train_loss : 0.1412  Test_loss : 0.1503, Time/batch_file : 9.1242, Training time: 9629.1395\n",
      "Epoch : 208/500 data_batch_5,  Train_loss : 0.1417  Test_loss : 0.1462, Time/batch_file : 9.3167, Training time: 9638.4564\n",
      "Epoch : 209/500 data_batch_1,  Train_loss : 0.1422  Test_loss : 0.1366, Time/batch_file : 9.2399, Training time: 9647.6967\n",
      "Epoch : 209/500 data_batch_2,  Train_loss : 0.1443  Test_loss : 0.1314, Time/batch_file : 9.1538, Training time: 9656.8507\n",
      "Epoch : 209/500 data_batch_3,  Train_loss : 0.1477  Test_loss : 0.1345, Time/batch_file : 9.0855, Training time: 9665.9365\n",
      "Epoch : 209/500 data_batch_4,  Train_loss : 0.1392  Test_loss : 0.1338, Time/batch_file : 9.0757, Training time: 9675.0125\n",
      "Epoch : 209/500 data_batch_5,  Train_loss : 0.1442  Test_loss : 0.1367, Time/batch_file : 9.1174, Training time: 9684.1302\n",
      "Epoch : 210/500 data_batch_1,  Train_loss : 0.1470  Test_loss : 0.1373, Time/batch_file : 9.2287, Training time: 9693.3591\n",
      "Epoch : 210/500 data_batch_2,  Train_loss : 0.1443  Test_loss : 0.1315, Time/batch_file : 9.2144, Training time: 9702.5739\n",
      "Epoch : 210/500 data_batch_3,  Train_loss : 0.1421  Test_loss : 0.1289, Time/batch_file : 9.3391, Training time: 9711.9132\n",
      "Epoch : 210/500 data_batch_4,  Train_loss : 0.1440  Test_loss : 0.1311, Time/batch_file : 9.1386, Training time: 9721.0521\n",
      "Epoch : 210/500 data_batch_5,  Train_loss : 0.1423  Test_loss : 0.1321, Time/batch_file : 9.2834, Training time: 9730.3360\n",
      "Epoch : 211/500 data_batch_1,  Train_loss : 0.1401  Test_loss : 0.1462, Time/batch_file : 9.2082, Training time: 9741.1350\n",
      "Epoch : 211/500 data_batch_2,  Train_loss : 0.1440  Test_loss : 0.1437, Time/batch_file : 9.2006, Training time: 9750.3359\n",
      "Epoch : 211/500 data_batch_3,  Train_loss : 0.1388  Test_loss : 0.1433, Time/batch_file : 9.3497, Training time: 9759.6859\n",
      "Epoch : 211/500 data_batch_4,  Train_loss : 0.1385  Test_loss : 0.1419, Time/batch_file : 9.2803, Training time: 9768.9664\n",
      "Epoch : 211/500 data_batch_5,  Train_loss : 0.1381  Test_loss : 0.1430, Time/batch_file : 9.1279, Training time: 9778.0946\n",
      "Epoch : 212/500 data_batch_1,  Train_loss : 0.1435  Test_loss : 0.1467, Time/batch_file : 9.3298, Training time: 9787.4247\n",
      "Epoch : 212/500 data_batch_2,  Train_loss : 0.1428  Test_loss : 0.1498, Time/batch_file : 9.3500, Training time: 9796.7748\n",
      "Epoch : 212/500 data_batch_3,  Train_loss : 0.1442  Test_loss : 0.1473, Time/batch_file : 9.2017, Training time: 9805.9769\n",
      "Epoch : 212/500 data_batch_4,  Train_loss : 0.1433  Test_loss : 0.1415, Time/batch_file : 9.0903, Training time: 9815.0674\n",
      "Epoch : 212/500 data_batch_5,  Train_loss : 0.1396  Test_loss : 0.1473, Time/batch_file : 9.4475, Training time: 9824.5151\n",
      "Epoch : 213/500 data_batch_1,  Train_loss : 0.1513  Test_loss : 0.1337, Time/batch_file : 9.1127, Training time: 9833.6281\n",
      "Epoch : 213/500 data_batch_2,  Train_loss : 0.1516  Test_loss : 0.1443, Time/batch_file : 9.1055, Training time: 9842.7339\n",
      "Epoch : 213/500 data_batch_3,  Train_loss : 0.1516  Test_loss : 0.1385, Time/batch_file : 9.1032, Training time: 9851.8374\n",
      "Epoch : 213/500 data_batch_4,  Train_loss : 0.1487  Test_loss : 0.1404, Time/batch_file : 9.2642, Training time: 9861.1019\n",
      "Epoch : 213/500 data_batch_5,  Train_loss : 0.1466  Test_loss : 0.1405, Time/batch_file : 9.1535, Training time: 9870.2556\n",
      "Epoch : 214/500 data_batch_1,  Train_loss : 0.1473  Test_loss : 0.1452, Time/batch_file : 9.2227, Training time: 9879.4786\n",
      "Epoch : 214/500 data_batch_2,  Train_loss : 0.1450  Test_loss : 0.1426, Time/batch_file : 9.3454, Training time: 9888.8242\n",
      "Epoch : 214/500 data_batch_3,  Train_loss : 0.1435  Test_loss : 0.1415, Time/batch_file : 9.0596, Training time: 9897.8842\n",
      "Epoch : 214/500 data_batch_4,  Train_loss : 0.1447  Test_loss : 0.1445, Time/batch_file : 9.0481, Training time: 9906.9326\n",
      "Epoch : 214/500 data_batch_5,  Train_loss : 0.1425  Test_loss : 0.1483, Time/batch_file : 9.1438, Training time: 9916.0766\n",
      "Epoch : 215/500 data_batch_1,  Train_loss : 0.1448  Test_loss : 0.1411, Time/batch_file : 9.0824, Training time: 9925.1593\n",
      "Epoch : 215/500 data_batch_2,  Train_loss : 0.1488  Test_loss : 0.1373, Time/batch_file : 9.2665, Training time: 9934.4261\n",
      "Epoch : 215/500 data_batch_3,  Train_loss : 0.1462  Test_loss : 0.1363, Time/batch_file : 9.5384, Training time: 9943.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 215/500 data_batch_4,  Train_loss : 0.1503  Test_loss : 0.1427, Time/batch_file : 9.0992, Training time: 9953.0642\n",
      "Epoch : 215/500 data_batch_5,  Train_loss : 0.1441  Test_loss : 0.1441, Time/batch_file : 9.1145, Training time: 9962.1791\n",
      "Epoch : 216/500 data_batch_1,  Train_loss : 0.1470  Test_loss : 0.1481, Time/batch_file : 9.0805, Training time: 9975.1571\n",
      "Epoch : 216/500 data_batch_2,  Train_loss : 0.1482  Test_loss : 0.1485, Time/batch_file : 9.0718, Training time: 9984.2293\n",
      "Epoch : 216/500 data_batch_3,  Train_loss : 0.1469  Test_loss : 0.1457, Time/batch_file : 9.0839, Training time: 9993.3134\n",
      "Epoch : 216/500 data_batch_4,  Train_loss : 0.1483  Test_loss : 0.1409, Time/batch_file : 9.2238, Training time: 10002.5375\n",
      "Epoch : 216/500 data_batch_5,  Train_loss : 0.1484  Test_loss : 0.1449, Time/batch_file : 9.3884, Training time: 10011.9261\n",
      "Epoch : 217/500 data_batch_1,  Train_loss : 0.1426  Test_loss : 0.1376, Time/batch_file : 9.1413, Training time: 10021.0677\n",
      "Epoch : 217/500 data_batch_2,  Train_loss : 0.1436  Test_loss : 0.1398, Time/batch_file : 9.1392, Training time: 10030.2072\n",
      "Epoch : 217/500 data_batch_3,  Train_loss : 0.1472  Test_loss : 0.1376, Time/batch_file : 8.9652, Training time: 10039.1727\n",
      "Epoch : 217/500 data_batch_4,  Train_loss : 0.1421  Test_loss : 0.1361, Time/batch_file : 9.0233, Training time: 10048.1963\n",
      "Epoch : 217/500 data_batch_5,  Train_loss : 0.1450  Test_loss : 0.1308, Time/batch_file : 9.1597, Training time: 10057.3563\n",
      "Epoch : 218/500 data_batch_1,  Train_loss : 0.1417  Test_loss : 0.1409, Time/batch_file : 9.1950, Training time: 10066.5515\n",
      "Epoch : 218/500 data_batch_2,  Train_loss : 0.1385  Test_loss : 0.1383, Time/batch_file : 9.2573, Training time: 10075.8091\n",
      "Epoch : 218/500 data_batch_3,  Train_loss : 0.1410  Test_loss : 0.1448, Time/batch_file : 9.0540, Training time: 10084.8635\n",
      "Epoch : 218/500 data_batch_4,  Train_loss : 0.1371  Test_loss : 0.1358, Time/batch_file : 9.0962, Training time: 10093.9600\n",
      "Epoch : 218/500 data_batch_5,  Train_loss : 0.1427  Test_loss : 0.1378, Time/batch_file : 9.4345, Training time: 10103.3948\n",
      "Epoch : 219/500 data_batch_1,  Train_loss : 0.1378  Test_loss : 0.1345, Time/batch_file : 9.1880, Training time: 10112.5832\n",
      "Epoch : 219/500 data_batch_2,  Train_loss : 0.1354  Test_loss : 0.1402, Time/batch_file : 9.1925, Training time: 10121.7759\n",
      "Epoch : 219/500 data_batch_3,  Train_loss : 0.1352  Test_loss : 0.1398, Time/batch_file : 8.8915, Training time: 10130.6678\n",
      "Epoch : 219/500 data_batch_4,  Train_loss : 0.1342  Test_loss : 0.1359, Time/batch_file : 9.0089, Training time: 10139.6769\n",
      "Epoch : 219/500 data_batch_5,  Train_loss : 0.1411  Test_loss : 0.1478, Time/batch_file : 9.2032, Training time: 10148.8803\n",
      "Epoch : 220/500 data_batch_1,  Train_loss : 0.1353  Test_loss : 0.1481, Time/batch_file : 9.1784, Training time: 10158.0589\n",
      "Epoch : 220/500 data_batch_2,  Train_loss : 0.1397  Test_loss : 0.1423, Time/batch_file : 9.1687, Training time: 10167.2282\n",
      "Epoch : 220/500 data_batch_3,  Train_loss : 0.1370  Test_loss : 0.1405, Time/batch_file : 9.2251, Training time: 10176.4535\n",
      "Epoch : 220/500 data_batch_4,  Train_loss : 0.1391  Test_loss : 0.1460, Time/batch_file : 9.3429, Training time: 10185.7967\n",
      "Epoch : 220/500 data_batch_5,  Train_loss : 0.1378  Test_loss : 0.1411, Time/batch_file : 9.3353, Training time: 10195.1323\n",
      "[./nets/net-220.ckpt] SAVED\n",
      "Epoch : 221/500 data_batch_1,  Train_loss : 0.1339  Test_loss : 0.1442, Time/batch_file : 9.1330, Training time: 10205.9488\n",
      "Epoch : 221/500 data_batch_2,  Train_loss : 0.1325  Test_loss : 0.1394, Time/batch_file : 9.1840, Training time: 10215.1331\n",
      "Epoch : 221/500 data_batch_3,  Train_loss : 0.1375  Test_loss : 0.1425, Time/batch_file : 9.3687, Training time: 10224.5020\n",
      "Epoch : 221/500 data_batch_4,  Train_loss : 0.1375  Test_loss : 0.1374, Time/batch_file : 9.3217, Training time: 10233.8239\n",
      "Epoch : 221/500 data_batch_5,  Train_loss : 0.1330  Test_loss : 0.1403, Time/batch_file : 9.3358, Training time: 10243.1600\n",
      "Epoch : 222/500 data_batch_1,  Train_loss : 0.1493  Test_loss : 0.1347, Time/batch_file : 9.4729, Training time: 10252.6333\n",
      "Epoch : 222/500 data_batch_2,  Train_loss : 0.1526  Test_loss : 0.1349, Time/batch_file : 9.0823, Training time: 10261.7160\n",
      "Epoch : 222/500 data_batch_3,  Train_loss : 0.1538  Test_loss : 0.1301, Time/batch_file : 9.3916, Training time: 10271.1079\n",
      "Epoch : 222/500 data_batch_4,  Train_loss : 0.1534  Test_loss : 0.1352, Time/batch_file : 9.1528, Training time: 10280.2610\n",
      "Epoch : 222/500 data_batch_5,  Train_loss : 0.1492  Test_loss : 0.1345, Time/batch_file : 8.9112, Training time: 10289.1724\n",
      "Epoch : 223/500 data_batch_1,  Train_loss : 0.1480  Test_loss : 0.1430, Time/batch_file : 9.2002, Training time: 10298.3729\n",
      "Epoch : 223/500 data_batch_2,  Train_loss : 0.1452  Test_loss : 0.1413, Time/batch_file : 9.0699, Training time: 10307.4431\n",
      "Epoch : 223/500 data_batch_3,  Train_loss : 0.1414  Test_loss : 0.1436, Time/batch_file : 9.0513, Training time: 10316.4946\n",
      "Epoch : 223/500 data_batch_4,  Train_loss : 0.1462  Test_loss : 0.1401, Time/batch_file : 8.9567, Training time: 10325.4515\n",
      "Epoch : 223/500 data_batch_5,  Train_loss : 0.1455  Test_loss : 0.1399, Time/batch_file : 8.9378, Training time: 10334.3896\n",
      "Epoch : 224/500 data_batch_1,  Train_loss : 0.1301  Test_loss : 0.1406, Time/batch_file : 9.0996, Training time: 10343.4896\n",
      "Epoch : 224/500 data_batch_2,  Train_loss : 0.1334  Test_loss : 0.1408, Time/batch_file : 9.1191, Training time: 10352.6089\n",
      "Epoch : 224/500 data_batch_3,  Train_loss : 0.1309  Test_loss : 0.1436, Time/batch_file : 9.3160, Training time: 10361.9252\n",
      "Epoch : 224/500 data_batch_4,  Train_loss : 0.1295  Test_loss : 0.1453, Time/batch_file : 9.2165, Training time: 10371.1420\n",
      "Epoch : 224/500 data_batch_5,  Train_loss : 0.1324  Test_loss : 0.1368, Time/batch_file : 9.1719, Training time: 10380.3141\n",
      "Epoch : 225/500 data_batch_1,  Train_loss : 0.1354  Test_loss : 0.1450, Time/batch_file : 9.0184, Training time: 10389.3328\n",
      "Epoch : 225/500 data_batch_2,  Train_loss : 0.1440  Test_loss : 0.1406, Time/batch_file : 8.9347, Training time: 10398.2678\n",
      "Epoch : 225/500 data_batch_3,  Train_loss : 0.1370  Test_loss : 0.1504, Time/batch_file : 9.1318, Training time: 10407.3997\n",
      "Epoch : 225/500 data_batch_4,  Train_loss : 0.1370  Test_loss : 0.1424, Time/batch_file : 9.1089, Training time: 10416.5089\n",
      "Epoch : 225/500 data_batch_5,  Train_loss : 0.1429  Test_loss : 0.1459, Time/batch_file : 9.3052, Training time: 10425.8143\n",
      "Epoch : 226/500 data_batch_1,  Train_loss : 0.1411  Test_loss : 0.1319, Time/batch_file : 9.1146, Training time: 10436.6330\n",
      "Epoch : 226/500 data_batch_2,  Train_loss : 0.1363  Test_loss : 0.1293, Time/batch_file : 9.3164, Training time: 10445.9497\n",
      "Epoch : 226/500 data_batch_3,  Train_loss : 0.1320  Test_loss : 0.1331, Time/batch_file : 9.0042, Training time: 10454.9541\n",
      "Epoch : 226/500 data_batch_4,  Train_loss : 0.1354  Test_loss : 0.1335, Time/batch_file : 9.0237, Training time: 10463.9780\n",
      "Epoch : 226/500 data_batch_5,  Train_loss : 0.1382  Test_loss : 0.1298, Time/batch_file : 9.1376, Training time: 10473.1159\n",
      "Epoch : 227/500 data_batch_1,  Train_loss : 0.1494  Test_loss : 0.1422, Time/batch_file : 9.2067, Training time: 10482.3230\n",
      "Epoch : 227/500 data_batch_2,  Train_loss : 0.1484  Test_loss : 0.1386, Time/batch_file : 9.2222, Training time: 10491.5455\n",
      "Epoch : 227/500 data_batch_3,  Train_loss : 0.1466  Test_loss : 0.1431, Time/batch_file : 9.1436, Training time: 10500.6893\n",
      "Epoch : 227/500 data_batch_4,  Train_loss : 0.1456  Test_loss : 0.1464, Time/batch_file : 9.2191, Training time: 10509.9087\n",
      "Epoch : 227/500 data_batch_5,  Train_loss : 0.1502  Test_loss : 0.1427, Time/batch_file : 9.5409, Training time: 10519.4500\n",
      "Epoch : 228/500 data_batch_1,  Train_loss : 0.1306  Test_loss : 0.1472, Time/batch_file : 9.2516, Training time: 10528.7020\n",
      "Epoch : 228/500 data_batch_2,  Train_loss : 0.1334  Test_loss : 0.1484, Time/batch_file : 9.1514, Training time: 10537.8537\n",
      "Epoch : 228/500 data_batch_3,  Train_loss : 0.1352  Test_loss : 0.1485, Time/batch_file : 9.1843, Training time: 10547.0383\n",
      "Epoch : 228/500 data_batch_4,  Train_loss : 0.1357  Test_loss : 0.1502, Time/batch_file : 9.1645, Training time: 10556.2032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 228/500 data_batch_5,  Train_loss : 0.1365  Test_loss : 0.1575, Time/batch_file : 9.1976, Training time: 10565.4010\n",
      "Epoch : 229/500 data_batch_1,  Train_loss : 0.1469  Test_loss : 0.1426, Time/batch_file : 9.1646, Training time: 10574.5659\n",
      "Epoch : 229/500 data_batch_2,  Train_loss : 0.1529  Test_loss : 0.1464, Time/batch_file : 9.1346, Training time: 10583.7009\n",
      "Epoch : 229/500 data_batch_3,  Train_loss : 0.1405  Test_loss : 0.1480, Time/batch_file : 9.3161, Training time: 10593.0172\n",
      "Epoch : 229/500 data_batch_4,  Train_loss : 0.1463  Test_loss : 0.1464, Time/batch_file : 8.9916, Training time: 10602.0091\n",
      "Epoch : 229/500 data_batch_5,  Train_loss : 0.1513  Test_loss : 0.1430, Time/batch_file : 8.9060, Training time: 10610.9154\n",
      "Epoch : 230/500 data_batch_1,  Train_loss : 0.1406  Test_loss : 0.1382, Time/batch_file : 9.1174, Training time: 10620.0330\n",
      "Epoch : 230/500 data_batch_2,  Train_loss : 0.1310  Test_loss : 0.1432, Time/batch_file : 9.4286, Training time: 10629.4618\n",
      "Epoch : 230/500 data_batch_3,  Train_loss : 0.1328  Test_loss : 0.1382, Time/batch_file : 9.5786, Training time: 10639.0408\n",
      "Epoch : 230/500 data_batch_4,  Train_loss : 0.1339  Test_loss : 0.1450, Time/batch_file : 9.1796, Training time: 10648.2207\n",
      "Epoch : 230/500 data_batch_5,  Train_loss : 0.1349  Test_loss : 0.1455, Time/batch_file : 9.1710, Training time: 10657.3919\n",
      "Epoch : 231/500 data_batch_1,  Train_loss : 0.1500  Test_loss : 0.1471, Time/batch_file : 9.0729, Training time: 10668.2395\n",
      "Epoch : 231/500 data_batch_2,  Train_loss : 0.1487  Test_loss : 0.1457, Time/batch_file : 9.1654, Training time: 10677.4053\n",
      "Epoch : 231/500 data_batch_3,  Train_loss : 0.1462  Test_loss : 0.1452, Time/batch_file : 9.2349, Training time: 10686.6405\n",
      "Epoch : 231/500 data_batch_4,  Train_loss : 0.1450  Test_loss : 0.1426, Time/batch_file : 8.9642, Training time: 10695.6051\n",
      "Epoch : 231/500 data_batch_5,  Train_loss : 0.1485  Test_loss : 0.1446, Time/batch_file : 9.1601, Training time: 10704.7655\n",
      "Epoch : 232/500 data_batch_1,  Train_loss : 0.1446  Test_loss : 0.1426, Time/batch_file : 9.1865, Training time: 10713.9522\n",
      "Epoch : 232/500 data_batch_2,  Train_loss : 0.1409  Test_loss : 0.1442, Time/batch_file : 9.2289, Training time: 10723.1813\n",
      "Epoch : 232/500 data_batch_3,  Train_loss : 0.1457  Test_loss : 0.1480, Time/batch_file : 9.3732, Training time: 10732.5548\n",
      "Epoch : 232/500 data_batch_4,  Train_loss : 0.1458  Test_loss : 0.1463, Time/batch_file : 8.9795, Training time: 10741.5346\n",
      "Epoch : 232/500 data_batch_5,  Train_loss : 0.1460  Test_loss : 0.1423, Time/batch_file : 9.1553, Training time: 10750.6902\n",
      "Epoch : 233/500 data_batch_1,  Train_loss : 0.1384  Test_loss : 0.1440, Time/batch_file : 9.2390, Training time: 10759.9294\n",
      "Epoch : 233/500 data_batch_2,  Train_loss : 0.1402  Test_loss : 0.1441, Time/batch_file : 9.2059, Training time: 10769.1356\n",
      "Epoch : 233/500 data_batch_3,  Train_loss : 0.1417  Test_loss : 0.1418, Time/batch_file : 9.2785, Training time: 10778.4144\n",
      "Epoch : 233/500 data_batch_4,  Train_loss : 0.1377  Test_loss : 0.1442, Time/batch_file : 9.1105, Training time: 10787.5253\n",
      "Epoch : 233/500 data_batch_5,  Train_loss : 0.1416  Test_loss : 0.1501, Time/batch_file : 9.2495, Training time: 10796.7750\n",
      "Epoch : 234/500 data_batch_1,  Train_loss : 0.1437  Test_loss : 0.1430, Time/batch_file : 9.1258, Training time: 10805.9010\n",
      "Epoch : 234/500 data_batch_2,  Train_loss : 0.1452  Test_loss : 0.1444, Time/batch_file : 9.0719, Training time: 10814.9732\n",
      "Epoch : 234/500 data_batch_3,  Train_loss : 0.1410  Test_loss : 0.1451, Time/batch_file : 9.1108, Training time: 10824.0843\n",
      "Epoch : 234/500 data_batch_4,  Train_loss : 0.1390  Test_loss : 0.1457, Time/batch_file : 9.5735, Training time: 10833.6581\n",
      "Epoch : 234/500 data_batch_5,  Train_loss : 0.1400  Test_loss : 0.1464, Time/batch_file : 9.3890, Training time: 10843.0474\n",
      "Epoch : 235/500 data_batch_1,  Train_loss : 0.1366  Test_loss : 0.1453, Time/batch_file : 9.2083, Training time: 10852.2560\n",
      "Epoch : 235/500 data_batch_2,  Train_loss : 0.1425  Test_loss : 0.1410, Time/batch_file : 9.1092, Training time: 10861.3656\n",
      "Epoch : 235/500 data_batch_3,  Train_loss : 0.1394  Test_loss : 0.1430, Time/batch_file : 9.2240, Training time: 10870.5899\n",
      "Epoch : 235/500 data_batch_4,  Train_loss : 0.1499  Test_loss : 0.1450, Time/batch_file : 9.2174, Training time: 10879.8076\n",
      "Epoch : 235/500 data_batch_5,  Train_loss : 0.1383  Test_loss : 0.1464, Time/batch_file : 9.1204, Training time: 10888.9284\n",
      "Epoch : 236/500 data_batch_1,  Train_loss : 0.1376  Test_loss : 0.1463, Time/batch_file : 9.1771, Training time: 10899.7986\n",
      "Epoch : 236/500 data_batch_2,  Train_loss : 0.1379  Test_loss : 0.1423, Time/batch_file : 9.4640, Training time: 10909.2628\n",
      "Epoch : 236/500 data_batch_3,  Train_loss : 0.1345  Test_loss : 0.1444, Time/batch_file : 9.2360, Training time: 10918.4990\n",
      "Epoch : 236/500 data_batch_4,  Train_loss : 0.1344  Test_loss : 0.1444, Time/batch_file : 9.2004, Training time: 10927.6999\n",
      "Epoch : 236/500 data_batch_5,  Train_loss : 0.1338  Test_loss : 0.1410, Time/batch_file : 9.2755, Training time: 10936.9756\n",
      "Epoch : 237/500 data_batch_1,  Train_loss : 0.1300  Test_loss : 0.1370, Time/batch_file : 9.3358, Training time: 10946.3116\n",
      "Epoch : 237/500 data_batch_2,  Train_loss : 0.1352  Test_loss : 0.1322, Time/batch_file : 8.8610, Training time: 10955.1729\n",
      "Epoch : 237/500 data_batch_3,  Train_loss : 0.1331  Test_loss : 0.1377, Time/batch_file : 9.0419, Training time: 10964.2150\n",
      "Epoch : 237/500 data_batch_4,  Train_loss : 0.1351  Test_loss : 0.1362, Time/batch_file : 8.9521, Training time: 10973.1674\n",
      "Epoch : 237/500 data_batch_5,  Train_loss : 0.1355  Test_loss : 0.1385, Time/batch_file : 9.3738, Training time: 10982.5415\n",
      "Epoch : 238/500 data_batch_1,  Train_loss : 0.1377  Test_loss : 0.1434, Time/batch_file : 9.0334, Training time: 10991.5752\n",
      "Epoch : 238/500 data_batch_2,  Train_loss : 0.1366  Test_loss : 0.1376, Time/batch_file : 9.1989, Training time: 11000.7743\n",
      "Epoch : 238/500 data_batch_3,  Train_loss : 0.1355  Test_loss : 0.1396, Time/batch_file : 9.1417, Training time: 11009.9162\n",
      "Epoch : 238/500 data_batch_4,  Train_loss : 0.1370  Test_loss : 0.1354, Time/batch_file : 9.3624, Training time: 11019.2790\n",
      "Epoch : 238/500 data_batch_5,  Train_loss : 0.1425  Test_loss : 0.1377, Time/batch_file : 9.2427, Training time: 11028.5219\n",
      "Epoch : 239/500 data_batch_1,  Train_loss : 0.1402  Test_loss : 0.1410, Time/batch_file : 9.4146, Training time: 11037.9368\n",
      "Epoch : 239/500 data_batch_2,  Train_loss : 0.1408  Test_loss : 0.1396, Time/batch_file : 9.1490, Training time: 11047.0861\n",
      "Epoch : 239/500 data_batch_3,  Train_loss : 0.1387  Test_loss : 0.1399, Time/batch_file : 9.1093, Training time: 11056.1958\n",
      "Epoch : 239/500 data_batch_4,  Train_loss : 0.1408  Test_loss : 0.1439, Time/batch_file : 9.1750, Training time: 11065.3711\n",
      "Epoch : 239/500 data_batch_5,  Train_loss : 0.1401  Test_loss : 0.1431, Time/batch_file : 9.3348, Training time: 11074.7062\n",
      "Epoch : 240/500 data_batch_1,  Train_loss : 0.1342  Test_loss : 0.1444, Time/batch_file : 9.3851, Training time: 11084.0916\n",
      "Epoch : 240/500 data_batch_2,  Train_loss : 0.1292  Test_loss : 0.1429, Time/batch_file : 9.0614, Training time: 11093.1533\n",
      "Epoch : 240/500 data_batch_3,  Train_loss : 0.1316  Test_loss : 0.1393, Time/batch_file : 9.0718, Training time: 11102.2254\n",
      "Epoch : 240/500 data_batch_4,  Train_loss : 0.1307  Test_loss : 0.1453, Time/batch_file : 9.2405, Training time: 11111.4661\n",
      "Epoch : 240/500 data_batch_5,  Train_loss : 0.1339  Test_loss : 0.1396, Time/batch_file : 9.2740, Training time: 11120.7404\n",
      "[./nets/net-240.ckpt] SAVED\n",
      "Epoch : 241/500 data_batch_1,  Train_loss : 0.1346  Test_loss : 0.1399, Time/batch_file : 9.1935, Training time: 11131.6263\n",
      "Epoch : 241/500 data_batch_2,  Train_loss : 0.1308  Test_loss : 0.1342, Time/batch_file : 9.1954, Training time: 11140.8220\n",
      "Epoch : 241/500 data_batch_3,  Train_loss : 0.1304  Test_loss : 0.1414, Time/batch_file : 8.9504, Training time: 11149.7726\n",
      "Epoch : 241/500 data_batch_4,  Train_loss : 0.1341  Test_loss : 0.1372, Time/batch_file : 9.1301, Training time: 11158.9031\n",
      "Epoch : 241/500 data_batch_5,  Train_loss : 0.1279  Test_loss : 0.1363, Time/batch_file : 9.2316, Training time: 11168.1349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 242/500 data_batch_1,  Train_loss : 0.1394  Test_loss : 0.1371, Time/batch_file : 9.1976, Training time: 11177.3327\n",
      "Epoch : 242/500 data_batch_2,  Train_loss : 0.1346  Test_loss : 0.1325, Time/batch_file : 9.2908, Training time: 11186.6237\n",
      "Epoch : 242/500 data_batch_3,  Train_loss : 0.1327  Test_loss : 0.1362, Time/batch_file : 9.2983, Training time: 11195.9223\n",
      "Epoch : 242/500 data_batch_4,  Train_loss : 0.1411  Test_loss : 0.1328, Time/batch_file : 9.2805, Training time: 11205.2030\n",
      "Epoch : 242/500 data_batch_5,  Train_loss : 0.1402  Test_loss : 0.1329, Time/batch_file : 9.0252, Training time: 11214.2284\n",
      "Epoch : 243/500 data_batch_1,  Train_loss : 0.1349  Test_loss : 0.1351, Time/batch_file : 9.0745, Training time: 11223.3032\n",
      "Epoch : 243/500 data_batch_2,  Train_loss : 0.1378  Test_loss : 0.1360, Time/batch_file : 9.5159, Training time: 11232.8193\n",
      "Epoch : 243/500 data_batch_3,  Train_loss : 0.1396  Test_loss : 0.1360, Time/batch_file : 9.2138, Training time: 11242.0333\n",
      "Epoch : 243/500 data_batch_4,  Train_loss : 0.1422  Test_loss : 0.1352, Time/batch_file : 9.2161, Training time: 11251.2496\n",
      "Epoch : 243/500 data_batch_5,  Train_loss : 0.1358  Test_loss : 0.1405, Time/batch_file : 9.2052, Training time: 11260.4551\n",
      "Epoch : 244/500 data_batch_1,  Train_loss : 0.1483  Test_loss : 0.1367, Time/batch_file : 9.1871, Training time: 11269.6426\n",
      "Epoch : 244/500 data_batch_2,  Train_loss : 0.1517  Test_loss : 0.1395, Time/batch_file : 9.2487, Training time: 11278.8916\n",
      "Epoch : 244/500 data_batch_3,  Train_loss : 0.1514  Test_loss : 0.1314, Time/batch_file : 9.1753, Training time: 11288.0673\n",
      "Epoch : 244/500 data_batch_4,  Train_loss : 0.1529  Test_loss : 0.1384, Time/batch_file : 9.0934, Training time: 11297.1609\n",
      "Epoch : 244/500 data_batch_5,  Train_loss : 0.1532  Test_loss : 0.1343, Time/batch_file : 9.1044, Training time: 11306.2655\n",
      "Epoch : 245/500 data_batch_1,  Train_loss : 0.1374  Test_loss : 0.1400, Time/batch_file : 9.1372, Training time: 11315.4030\n",
      "Epoch : 245/500 data_batch_2,  Train_loss : 0.1414  Test_loss : 0.1392, Time/batch_file : 9.0166, Training time: 11324.4199\n",
      "Epoch : 245/500 data_batch_3,  Train_loss : 0.1384  Test_loss : 0.1469, Time/batch_file : 9.1409, Training time: 11333.5610\n",
      "Epoch : 245/500 data_batch_4,  Train_loss : 0.1347  Test_loss : 0.1440, Time/batch_file : 9.2273, Training time: 11342.7886\n",
      "Epoch : 245/500 data_batch_5,  Train_loss : 0.1371  Test_loss : 0.1424, Time/batch_file : 9.2171, Training time: 11352.0061\n",
      "Epoch : 246/500 data_batch_1,  Train_loss : 0.1424  Test_loss : 0.1282, Time/batch_file : 9.1022, Training time: 11362.8108\n",
      "Epoch : 246/500 data_batch_2,  Train_loss : 0.1513  Test_loss : 0.1312, Time/batch_file : 9.2085, Training time: 11372.0196\n",
      "Epoch : 246/500 data_batch_3,  Train_loss : 0.1520  Test_loss : 0.1303, Time/batch_file : 9.0165, Training time: 11381.0364\n",
      "Epoch : 246/500 data_batch_4,  Train_loss : 0.1459  Test_loss : 0.1287, Time/batch_file : 8.8794, Training time: 11389.9162\n",
      "Epoch : 246/500 data_batch_5,  Train_loss : 0.1488  Test_loss : 0.1262, Time/batch_file : 9.0923, Training time: 11399.0087\n",
      "Epoch : 247/500 data_batch_1,  Train_loss : 0.1472  Test_loss : 0.1433, Time/batch_file : 9.3455, Training time: 11408.3545\n",
      "Epoch : 247/500 data_batch_2,  Train_loss : 0.1468  Test_loss : 0.1445, Time/batch_file : 8.8635, Training time: 11417.2183\n",
      "Epoch : 247/500 data_batch_3,  Train_loss : 0.1482  Test_loss : 0.1360, Time/batch_file : 9.0120, Training time: 11426.2305\n",
      "Epoch : 247/500 data_batch_4,  Train_loss : 0.1469  Test_loss : 0.1368, Time/batch_file : 9.2070, Training time: 11435.4377\n",
      "Epoch : 247/500 data_batch_5,  Train_loss : 0.1477  Test_loss : 0.1409, Time/batch_file : 9.0464, Training time: 11444.4845\n",
      "Epoch : 248/500 data_batch_1,  Train_loss : 0.1313  Test_loss : 0.1395, Time/batch_file : 9.1346, Training time: 11453.6195\n",
      "Epoch : 248/500 data_batch_2,  Train_loss : 0.1364  Test_loss : 0.1397, Time/batch_file : 8.9439, Training time: 11462.5636\n",
      "Epoch : 248/500 data_batch_3,  Train_loss : 0.1361  Test_loss : 0.1366, Time/batch_file : 9.3439, Training time: 11471.9077\n",
      "Epoch : 248/500 data_batch_4,  Train_loss : 0.1348  Test_loss : 0.1415, Time/batch_file : 9.1765, Training time: 11481.0844\n",
      "Epoch : 248/500 data_batch_5,  Train_loss : 0.1288  Test_loss : 0.1343, Time/batch_file : 9.2141, Training time: 11490.2987\n",
      "Epoch : 249/500 data_batch_1,  Train_loss : 0.1467  Test_loss : 0.1553, Time/batch_file : 9.0880, Training time: 11499.3871\n",
      "Epoch : 249/500 data_batch_2,  Train_loss : 0.1430  Test_loss : 0.1573, Time/batch_file : 8.8755, Training time: 11508.2628\n",
      "Epoch : 249/500 data_batch_3,  Train_loss : 0.1431  Test_loss : 0.1539, Time/batch_file : 9.2302, Training time: 11517.4933\n",
      "Epoch : 249/500 data_batch_4,  Train_loss : 0.1429  Test_loss : 0.1545, Time/batch_file : 9.1961, Training time: 11526.6898\n",
      "Epoch : 249/500 data_batch_5,  Train_loss : 0.1474  Test_loss : 0.1592, Time/batch_file : 9.1827, Training time: 11535.8728\n",
      "Epoch : 250/500 data_batch_1,  Train_loss : 0.1470  Test_loss : 0.1378, Time/batch_file : 8.9538, Training time: 11544.8269\n",
      "Epoch : 250/500 data_batch_2,  Train_loss : 0.1453  Test_loss : 0.1345, Time/batch_file : 9.2590, Training time: 11554.0862\n",
      "Epoch : 250/500 data_batch_3,  Train_loss : 0.1466  Test_loss : 0.1368, Time/batch_file : 8.9153, Training time: 11563.0017\n",
      "Epoch : 250/500 data_batch_4,  Train_loss : 0.1469  Test_loss : 0.1369, Time/batch_file : 9.2778, Training time: 11572.2799\n",
      "Epoch : 250/500 data_batch_5,  Train_loss : 0.1483  Test_loss : 0.1447, Time/batch_file : 9.3024, Training time: 11581.5826\n",
      "Epoch : 251/500 data_batch_1,  Train_loss : 0.1348  Test_loss : 0.1351, Time/batch_file : 9.3863, Training time: 11592.4693\n",
      "Epoch : 251/500 data_batch_2,  Train_loss : 0.1408  Test_loss : 0.1354, Time/batch_file : 9.0356, Training time: 11601.5053\n",
      "Epoch : 251/500 data_batch_3,  Train_loss : 0.1381  Test_loss : 0.1364, Time/batch_file : 9.2223, Training time: 11610.7278\n",
      "Epoch : 251/500 data_batch_4,  Train_loss : 0.1364  Test_loss : 0.1344, Time/batch_file : 9.1711, Training time: 11619.8991\n",
      "Epoch : 251/500 data_batch_5,  Train_loss : 0.1355  Test_loss : 0.1371, Time/batch_file : 9.6286, Training time: 11629.5280\n",
      "Epoch : 252/500 data_batch_1,  Train_loss : 0.1402  Test_loss : 0.1401, Time/batch_file : 9.2160, Training time: 11638.7444\n",
      "Epoch : 252/500 data_batch_2,  Train_loss : 0.1410  Test_loss : 0.1472, Time/batch_file : 9.2821, Training time: 11648.0269\n",
      "Epoch : 252/500 data_batch_3,  Train_loss : 0.1410  Test_loss : 0.1379, Time/batch_file : 9.1223, Training time: 11657.1494\n",
      "Epoch : 252/500 data_batch_4,  Train_loss : 0.1442  Test_loss : 0.1447, Time/batch_file : 9.2171, Training time: 11666.3668\n",
      "Epoch : 252/500 data_batch_5,  Train_loss : 0.1434  Test_loss : 0.1425, Time/batch_file : 9.5209, Training time: 11675.8880\n",
      "Epoch : 253/500 data_batch_1,  Train_loss : 0.1487  Test_loss : 0.1542, Time/batch_file : 9.1879, Training time: 11685.0764\n",
      "Epoch : 253/500 data_batch_2,  Train_loss : 0.1432  Test_loss : 0.1549, Time/batch_file : 9.2265, Training time: 11694.3031\n",
      "Epoch : 253/500 data_batch_3,  Train_loss : 0.1439  Test_loss : 0.1507, Time/batch_file : 9.1769, Training time: 11703.4804\n",
      "Epoch : 253/500 data_batch_4,  Train_loss : 0.1444  Test_loss : 0.1547, Time/batch_file : 9.1822, Training time: 11712.6629\n",
      "Epoch : 253/500 data_batch_5,  Train_loss : 0.1434  Test_loss : 0.1546, Time/batch_file : 9.0758, Training time: 11721.7389\n",
      "Epoch : 254/500 data_batch_1,  Train_loss : 0.1487  Test_loss : 0.1429, Time/batch_file : 9.2821, Training time: 11731.0213\n",
      "Epoch : 254/500 data_batch_2,  Train_loss : 0.1515  Test_loss : 0.1388, Time/batch_file : 9.2115, Training time: 11740.2330\n",
      "Epoch : 254/500 data_batch_3,  Train_loss : 0.1519  Test_loss : 0.1418, Time/batch_file : 9.0229, Training time: 11749.2561\n",
      "Epoch : 254/500 data_batch_4,  Train_loss : 0.1488  Test_loss : 0.1372, Time/batch_file : 9.3250, Training time: 11758.5814\n",
      "Epoch : 254/500 data_batch_5,  Train_loss : 0.1472  Test_loss : 0.1380, Time/batch_file : 9.0258, Training time: 11767.6076\n",
      "Epoch : 255/500 data_batch_1,  Train_loss : 0.1429  Test_loss : 0.1423, Time/batch_file : 9.2420, Training time: 11776.8498\n",
      "Epoch : 255/500 data_batch_2,  Train_loss : 0.1400  Test_loss : 0.1453, Time/batch_file : 9.1460, Training time: 11785.9962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 255/500 data_batch_3,  Train_loss : 0.1434  Test_loss : 0.1453, Time/batch_file : 9.1659, Training time: 11795.1623\n",
      "Epoch : 255/500 data_batch_4,  Train_loss : 0.1423  Test_loss : 0.1408, Time/batch_file : 9.5143, Training time: 11804.6768\n",
      "Epoch : 255/500 data_batch_5,  Train_loss : 0.1400  Test_loss : 0.1434, Time/batch_file : 9.0527, Training time: 11813.7299\n",
      "Epoch : 256/500 data_batch_1,  Train_loss : 0.1365  Test_loss : 0.1454, Time/batch_file : 9.3704, Training time: 11824.7154\n",
      "Epoch : 256/500 data_batch_2,  Train_loss : 0.1404  Test_loss : 0.1455, Time/batch_file : 9.1876, Training time: 11833.9035\n",
      "Epoch : 256/500 data_batch_3,  Train_loss : 0.1424  Test_loss : 0.1481, Time/batch_file : 9.3556, Training time: 11843.2593\n",
      "Epoch : 256/500 data_batch_4,  Train_loss : 0.1387  Test_loss : 0.1453, Time/batch_file : 9.2741, Training time: 11852.5336\n",
      "Epoch : 256/500 data_batch_5,  Train_loss : 0.1337  Test_loss : 0.1441, Time/batch_file : 9.0620, Training time: 11861.5959\n",
      "Epoch : 257/500 data_batch_1,  Train_loss : 0.1467  Test_loss : 0.1310, Time/batch_file : 9.2197, Training time: 11870.8160\n",
      "Epoch : 257/500 data_batch_2,  Train_loss : 0.1406  Test_loss : 0.1387, Time/batch_file : 9.4870, Training time: 11880.3032\n",
      "Epoch : 257/500 data_batch_3,  Train_loss : 0.1464  Test_loss : 0.1353, Time/batch_file : 9.2917, Training time: 11889.5951\n",
      "Epoch : 257/500 data_batch_4,  Train_loss : 0.1432  Test_loss : 0.1353, Time/batch_file : 9.1655, Training time: 11898.7609\n",
      "Epoch : 257/500 data_batch_5,  Train_loss : 0.1349  Test_loss : 0.1422, Time/batch_file : 8.9992, Training time: 11907.7604\n",
      "Epoch : 258/500 data_batch_1,  Train_loss : 0.1350  Test_loss : 0.1390, Time/batch_file : 9.2269, Training time: 11916.9876\n",
      "Epoch : 258/500 data_batch_2,  Train_loss : 0.1394  Test_loss : 0.1390, Time/batch_file : 9.1490, Training time: 11926.1369\n",
      "Epoch : 258/500 data_batch_3,  Train_loss : 0.1426  Test_loss : 0.1405, Time/batch_file : 9.3151, Training time: 11935.4523\n",
      "Epoch : 258/500 data_batch_4,  Train_loss : 0.1417  Test_loss : 0.1401, Time/batch_file : 9.0537, Training time: 11944.5063\n",
      "Epoch : 258/500 data_batch_5,  Train_loss : 0.1393  Test_loss : 0.1410, Time/batch_file : 9.1808, Training time: 11953.6873\n",
      "Epoch : 259/500 data_batch_1,  Train_loss : 0.1406  Test_loss : 0.1500, Time/batch_file : 9.6738, Training time: 11963.3614\n",
      "Epoch : 259/500 data_batch_2,  Train_loss : 0.1436  Test_loss : 0.1389, Time/batch_file : 9.4292, Training time: 11972.7908\n",
      "Epoch : 259/500 data_batch_3,  Train_loss : 0.1386  Test_loss : 0.1421, Time/batch_file : 9.1405, Training time: 11981.9316\n",
      "Epoch : 259/500 data_batch_4,  Train_loss : 0.1378  Test_loss : 0.1416, Time/batch_file : 8.8258, Training time: 11990.7576\n",
      "Epoch : 259/500 data_batch_5,  Train_loss : 0.1390  Test_loss : 0.1406, Time/batch_file : 8.9638, Training time: 11999.7218\n",
      "Epoch : 260/500 data_batch_1,  Train_loss : 0.1448  Test_loss : 0.1480, Time/batch_file : 9.0357, Training time: 12008.7578\n",
      "Epoch : 260/500 data_batch_2,  Train_loss : 0.1437  Test_loss : 0.1461, Time/batch_file : 9.1347, Training time: 12017.8928\n",
      "Epoch : 260/500 data_batch_3,  Train_loss : 0.1420  Test_loss : 0.1436, Time/batch_file : 8.9182, Training time: 12026.8113\n",
      "Epoch : 260/500 data_batch_4,  Train_loss : 0.1403  Test_loss : 0.1450, Time/batch_file : 9.1763, Training time: 12035.9879\n",
      "Epoch : 260/500 data_batch_5,  Train_loss : 0.1395  Test_loss : 0.1468, Time/batch_file : 9.1318, Training time: 12045.1200\n",
      "[./nets/net-260.ckpt] SAVED\n",
      "Epoch : 261/500 data_batch_1,  Train_loss : 0.1300  Test_loss : 0.1310, Time/batch_file : 9.2829, Training time: 12056.0602\n",
      "Epoch : 261/500 data_batch_2,  Train_loss : 0.1327  Test_loss : 0.1341, Time/batch_file : 9.0011, Training time: 12065.0617\n",
      "Epoch : 261/500 data_batch_3,  Train_loss : 0.1326  Test_loss : 0.1314, Time/batch_file : 9.1053, Training time: 12074.1672\n",
      "Epoch : 261/500 data_batch_4,  Train_loss : 0.1327  Test_loss : 0.1319, Time/batch_file : 9.1400, Training time: 12083.3075\n",
      "Epoch : 261/500 data_batch_5,  Train_loss : 0.1311  Test_loss : 0.1310, Time/batch_file : 8.9928, Training time: 12092.3005\n",
      "Epoch : 262/500 data_batch_1,  Train_loss : 0.1363  Test_loss : 0.1582, Time/batch_file : 9.3292, Training time: 12101.6300\n",
      "Epoch : 262/500 data_batch_2,  Train_loss : 0.1366  Test_loss : 0.1592, Time/batch_file : 9.1456, Training time: 12110.7758\n",
      "Epoch : 262/500 data_batch_3,  Train_loss : 0.1414  Test_loss : 0.1582, Time/batch_file : 9.2800, Training time: 12120.0561\n",
      "Epoch : 262/500 data_batch_4,  Train_loss : 0.1397  Test_loss : 0.1555, Time/batch_file : 9.1693, Training time: 12129.2257\n",
      "Epoch : 262/500 data_batch_5,  Train_loss : 0.1393  Test_loss : 0.1555, Time/batch_file : 9.2737, Training time: 12138.4997\n",
      "Epoch : 263/500 data_batch_1,  Train_loss : 0.1426  Test_loss : 0.1378, Time/batch_file : 9.2764, Training time: 12147.7763\n",
      "Epoch : 263/500 data_batch_2,  Train_loss : 0.1478  Test_loss : 0.1343, Time/batch_file : 9.2146, Training time: 12156.9913\n",
      "Epoch : 263/500 data_batch_3,  Train_loss : 0.1443  Test_loss : 0.1395, Time/batch_file : 9.2836, Training time: 12166.2751\n",
      "Epoch : 263/500 data_batch_4,  Train_loss : 0.1452  Test_loss : 0.1388, Time/batch_file : 9.2167, Training time: 12175.4922\n",
      "Epoch : 263/500 data_batch_5,  Train_loss : 0.1469  Test_loss : 0.1361, Time/batch_file : 9.1784, Training time: 12184.6708\n",
      "Epoch : 264/500 data_batch_1,  Train_loss : 0.1368  Test_loss : 0.1382, Time/batch_file : 9.4172, Training time: 12194.0883\n",
      "Epoch : 264/500 data_batch_2,  Train_loss : 0.1356  Test_loss : 0.1437, Time/batch_file : 9.3169, Training time: 12203.4054\n",
      "Epoch : 264/500 data_batch_3,  Train_loss : 0.1384  Test_loss : 0.1421, Time/batch_file : 9.1251, Training time: 12212.5308\n",
      "Epoch : 264/500 data_batch_4,  Train_loss : 0.1370  Test_loss : 0.1465, Time/batch_file : 9.0843, Training time: 12221.6154\n",
      "Epoch : 264/500 data_batch_5,  Train_loss : 0.1371  Test_loss : 0.1460, Time/batch_file : 9.1341, Training time: 12230.7497\n",
      "Epoch : 265/500 data_batch_1,  Train_loss : 0.1432  Test_loss : 0.1369, Time/batch_file : 9.0192, Training time: 12239.7692\n",
      "Epoch : 265/500 data_batch_2,  Train_loss : 0.1459  Test_loss : 0.1368, Time/batch_file : 9.2770, Training time: 12249.0465\n",
      "Epoch : 265/500 data_batch_3,  Train_loss : 0.1426  Test_loss : 0.1387, Time/batch_file : 9.1377, Training time: 12258.1844\n",
      "Epoch : 265/500 data_batch_4,  Train_loss : 0.1478  Test_loss : 0.1353, Time/batch_file : 9.3849, Training time: 12267.5696\n",
      "Epoch : 265/500 data_batch_5,  Train_loss : 0.1448  Test_loss : 0.1393, Time/batch_file : 8.9087, Training time: 12276.4785\n",
      "Epoch : 266/500 data_batch_1,  Train_loss : 0.1422  Test_loss : 0.1393, Time/batch_file : 9.1150, Training time: 12290.1898\n",
      "Epoch : 266/500 data_batch_2,  Train_loss : 0.1400  Test_loss : 0.1409, Time/batch_file : 8.9986, Training time: 12299.1888\n",
      "Epoch : 266/500 data_batch_3,  Train_loss : 0.1415  Test_loss : 0.1442, Time/batch_file : 9.1164, Training time: 12308.3056\n",
      "Epoch : 266/500 data_batch_4,  Train_loss : 0.1426  Test_loss : 0.1368, Time/batch_file : 9.3134, Training time: 12317.6193\n",
      "Epoch : 266/500 data_batch_5,  Train_loss : 0.1424  Test_loss : 0.1394, Time/batch_file : 9.2809, Training time: 12326.9005\n",
      "Epoch : 267/500 data_batch_1,  Train_loss : 0.1461  Test_loss : 0.1377, Time/batch_file : 9.0397, Training time: 12335.9404\n",
      "Epoch : 267/500 data_batch_2,  Train_loss : 0.1472  Test_loss : 0.1386, Time/batch_file : 9.1472, Training time: 12345.0879\n",
      "Epoch : 267/500 data_batch_3,  Train_loss : 0.1477  Test_loss : 0.1382, Time/batch_file : 9.1239, Training time: 12354.2121\n",
      "Epoch : 267/500 data_batch_4,  Train_loss : 0.1452  Test_loss : 0.1367, Time/batch_file : 9.5679, Training time: 12363.7802\n",
      "Epoch : 267/500 data_batch_5,  Train_loss : 0.1451  Test_loss : 0.1362, Time/batch_file : 9.2914, Training time: 12373.0719\n",
      "Epoch : 268/500 data_batch_1,  Train_loss : 0.1463  Test_loss : 0.1355, Time/batch_file : 9.1538, Training time: 12382.2261\n",
      "Epoch : 268/500 data_batch_2,  Train_loss : 0.1433  Test_loss : 0.1343, Time/batch_file : 9.3599, Training time: 12391.5862\n",
      "Epoch : 268/500 data_batch_3,  Train_loss : 0.1461  Test_loss : 0.1382, Time/batch_file : 9.1091, Training time: 12400.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 268/500 data_batch_4,  Train_loss : 0.1409  Test_loss : 0.1354, Time/batch_file : 9.0550, Training time: 12409.7510\n",
      "Epoch : 268/500 data_batch_5,  Train_loss : 0.1438  Test_loss : 0.1352, Time/batch_file : 9.2100, Training time: 12418.9612\n",
      "Epoch : 269/500 data_batch_1,  Train_loss : 0.1393  Test_loss : 0.1376, Time/batch_file : 9.1737, Training time: 12428.1352\n",
      "Epoch : 269/500 data_batch_2,  Train_loss : 0.1441  Test_loss : 0.1332, Time/batch_file : 9.1733, Training time: 12437.3088\n",
      "Epoch : 269/500 data_batch_3,  Train_loss : 0.1402  Test_loss : 0.1396, Time/batch_file : 9.1144, Training time: 12446.4235\n",
      "Epoch : 269/500 data_batch_4,  Train_loss : 0.1439  Test_loss : 0.1386, Time/batch_file : 9.3339, Training time: 12455.7577\n",
      "Epoch : 269/500 data_batch_5,  Train_loss : 0.1465  Test_loss : 0.1339, Time/batch_file : 9.1146, Training time: 12464.8727\n",
      "Epoch : 270/500 data_batch_1,  Train_loss : 0.1385  Test_loss : 0.1328, Time/batch_file : 9.0166, Training time: 12473.8895\n",
      "Epoch : 270/500 data_batch_2,  Train_loss : 0.1333  Test_loss : 0.1359, Time/batch_file : 9.0629, Training time: 12482.9526\n",
      "Epoch : 270/500 data_batch_3,  Train_loss : 0.1321  Test_loss : 0.1393, Time/batch_file : 9.2003, Training time: 12492.1532\n",
      "Epoch : 270/500 data_batch_4,  Train_loss : 0.1356  Test_loss : 0.1329, Time/batch_file : 9.2502, Training time: 12501.4037\n",
      "Epoch : 270/500 data_batch_5,  Train_loss : 0.1332  Test_loss : 0.1330, Time/batch_file : 9.2899, Training time: 12510.6939\n",
      "Epoch : 271/500 data_batch_1,  Train_loss : 0.1431  Test_loss : 0.1365, Time/batch_file : 9.0070, Training time: 12521.3117\n",
      "Epoch : 271/500 data_batch_2,  Train_loss : 0.1484  Test_loss : 0.1378, Time/batch_file : 9.1568, Training time: 12530.4689\n",
      "Epoch : 271/500 data_batch_3,  Train_loss : 0.1446  Test_loss : 0.1394, Time/batch_file : 9.3724, Training time: 12539.8416\n",
      "Epoch : 271/500 data_batch_4,  Train_loss : 0.1426  Test_loss : 0.1411, Time/batch_file : 9.0673, Training time: 12548.9092\n",
      "Epoch : 271/500 data_batch_5,  Train_loss : 0.1447  Test_loss : 0.1364, Time/batch_file : 9.2672, Training time: 12558.1766\n",
      "Epoch : 272/500 data_batch_1,  Train_loss : 0.1452  Test_loss : 0.1419, Time/batch_file : 9.1235, Training time: 12567.3004\n",
      "Epoch : 272/500 data_batch_2,  Train_loss : 0.1446  Test_loss : 0.1378, Time/batch_file : 9.2272, Training time: 12576.5278\n",
      "Epoch : 272/500 data_batch_3,  Train_loss : 0.1425  Test_loss : 0.1387, Time/batch_file : 8.9678, Training time: 12585.4959\n",
      "Epoch : 272/500 data_batch_4,  Train_loss : 0.1429  Test_loss : 0.1375, Time/batch_file : 8.9994, Training time: 12594.4955\n",
      "Epoch : 272/500 data_batch_5,  Train_loss : 0.1444  Test_loss : 0.1402, Time/batch_file : 9.2022, Training time: 12603.6980\n",
      "Epoch : 273/500 data_batch_1,  Train_loss : 0.1314  Test_loss : 0.1414, Time/batch_file : 9.3850, Training time: 12613.0833\n",
      "Epoch : 273/500 data_batch_2,  Train_loss : 0.1308  Test_loss : 0.1426, Time/batch_file : 9.2391, Training time: 12622.3227\n",
      "Epoch : 273/500 data_batch_3,  Train_loss : 0.1321  Test_loss : 0.1420, Time/batch_file : 8.9808, Training time: 12631.3040\n",
      "Epoch : 273/500 data_batch_4,  Train_loss : 0.1314  Test_loss : 0.1397, Time/batch_file : 9.1688, Training time: 12640.4739\n",
      "Epoch : 273/500 data_batch_5,  Train_loss : 0.1286  Test_loss : 0.1400, Time/batch_file : 9.0277, Training time: 12649.5021\n",
      "Epoch : 274/500 data_batch_1,  Train_loss : 0.1440  Test_loss : 0.1391, Time/batch_file : 9.2407, Training time: 12658.7432\n",
      "Epoch : 274/500 data_batch_2,  Train_loss : 0.1405  Test_loss : 0.1397, Time/batch_file : 9.3547, Training time: 12668.0981\n",
      "Epoch : 274/500 data_batch_3,  Train_loss : 0.1441  Test_loss : 0.1383, Time/batch_file : 9.0498, Training time: 12677.1481\n",
      "Epoch : 274/500 data_batch_4,  Train_loss : 0.1410  Test_loss : 0.1400, Time/batch_file : 9.1484, Training time: 12686.2968\n",
      "Epoch : 274/500 data_batch_5,  Train_loss : 0.1413  Test_loss : 0.1395, Time/batch_file : 9.1443, Training time: 12695.4413\n",
      "Epoch : 275/500 data_batch_1,  Train_loss : 0.1414  Test_loss : 0.1426, Time/batch_file : 9.2102, Training time: 12704.6518\n",
      "Epoch : 275/500 data_batch_2,  Train_loss : 0.1454  Test_loss : 0.1469, Time/batch_file : 9.4294, Training time: 12714.0815\n",
      "Epoch : 275/500 data_batch_3,  Train_loss : 0.1415  Test_loss : 0.1477, Time/batch_file : 9.2642, Training time: 12723.3460\n",
      "Epoch : 275/500 data_batch_4,  Train_loss : 0.1423  Test_loss : 0.1449, Time/batch_file : 8.9053, Training time: 12732.2516\n",
      "Epoch : 275/500 data_batch_5,  Train_loss : 0.1428  Test_loss : 0.1471, Time/batch_file : 9.2404, Training time: 12741.4922\n",
      "Epoch : 276/500 data_batch_1,  Train_loss : 0.1363  Test_loss : 0.1433, Time/batch_file : 9.4210, Training time: 12752.7304\n",
      "Epoch : 276/500 data_batch_2,  Train_loss : 0.1309  Test_loss : 0.1402, Time/batch_file : 9.2565, Training time: 12761.9871\n",
      "Epoch : 276/500 data_batch_3,  Train_loss : 0.1408  Test_loss : 0.1454, Time/batch_file : 9.0786, Training time: 12771.0660\n",
      "Epoch : 276/500 data_batch_4,  Train_loss : 0.1300  Test_loss : 0.1476, Time/batch_file : 9.1100, Training time: 12780.1762\n",
      "Epoch : 276/500 data_batch_5,  Train_loss : 0.1377  Test_loss : 0.1423, Time/batch_file : 9.0123, Training time: 12789.1887\n",
      "Epoch : 277/500 data_batch_1,  Train_loss : 0.1516  Test_loss : 0.1443, Time/batch_file : 9.2648, Training time: 12798.4538\n",
      "Epoch : 277/500 data_batch_2,  Train_loss : 0.1446  Test_loss : 0.1455, Time/batch_file : 8.9991, Training time: 12807.4531\n",
      "Epoch : 277/500 data_batch_3,  Train_loss : 0.1433  Test_loss : 0.1448, Time/batch_file : 9.0606, Training time: 12816.5140\n",
      "Epoch : 277/500 data_batch_4,  Train_loss : 0.1488  Test_loss : 0.1373, Time/batch_file : 9.2449, Training time: 12825.7592\n",
      "Epoch : 277/500 data_batch_5,  Train_loss : 0.1463  Test_loss : 0.1423, Time/batch_file : 9.3361, Training time: 12835.0955\n",
      "Epoch : 278/500 data_batch_1,  Train_loss : 0.1463  Test_loss : 0.1413, Time/batch_file : 9.0811, Training time: 12844.1768\n",
      "Epoch : 278/500 data_batch_2,  Train_loss : 0.1454  Test_loss : 0.1430, Time/batch_file : 9.3183, Training time: 12853.4955\n",
      "Epoch : 278/500 data_batch_3,  Train_loss : 0.1480  Test_loss : 0.1392, Time/batch_file : 9.0219, Training time: 12862.5175\n",
      "Epoch : 278/500 data_batch_4,  Train_loss : 0.1429  Test_loss : 0.1455, Time/batch_file : 9.2293, Training time: 12871.7472\n",
      "Epoch : 278/500 data_batch_5,  Train_loss : 0.1482  Test_loss : 0.1385, Time/batch_file : 9.2847, Training time: 12881.0320\n",
      "Epoch : 279/500 data_batch_1,  Train_loss : 0.1429  Test_loss : 0.1432, Time/batch_file : 9.3514, Training time: 12890.3836\n",
      "Epoch : 279/500 data_batch_2,  Train_loss : 0.1420  Test_loss : 0.1440, Time/batch_file : 9.3290, Training time: 12899.7130\n",
      "Epoch : 279/500 data_batch_3,  Train_loss : 0.1385  Test_loss : 0.1455, Time/batch_file : 9.1253, Training time: 12908.8385\n",
      "Epoch : 279/500 data_batch_4,  Train_loss : 0.1467  Test_loss : 0.1444, Time/batch_file : 9.2997, Training time: 12918.1385\n",
      "Epoch : 279/500 data_batch_5,  Train_loss : 0.1460  Test_loss : 0.1388, Time/batch_file : 9.5689, Training time: 12927.7077\n",
      "Epoch : 280/500 data_batch_1,  Train_loss : 0.1450  Test_loss : 0.1419, Time/batch_file : 9.1259, Training time: 12936.8342\n",
      "Epoch : 280/500 data_batch_2,  Train_loss : 0.1421  Test_loss : 0.1447, Time/batch_file : 9.2547, Training time: 12946.0891\n",
      "Epoch : 280/500 data_batch_3,  Train_loss : 0.1446  Test_loss : 0.1434, Time/batch_file : 9.0250, Training time: 12955.1144\n",
      "Epoch : 280/500 data_batch_4,  Train_loss : 0.1422  Test_loss : 0.1441, Time/batch_file : 9.1444, Training time: 12964.2590\n",
      "Epoch : 280/500 data_batch_5,  Train_loss : 0.1395  Test_loss : 0.1426, Time/batch_file : 9.3160, Training time: 12973.5752\n",
      "[./nets/net-280.ckpt] SAVED\n",
      "Epoch : 281/500 data_batch_1,  Train_loss : 0.1327  Test_loss : 0.1441, Time/batch_file : 9.3285, Training time: 12984.7273\n",
      "Epoch : 281/500 data_batch_2,  Train_loss : 0.1338  Test_loss : 0.1408, Time/batch_file : 9.0738, Training time: 12993.8013\n",
      "Epoch : 281/500 data_batch_3,  Train_loss : 0.1277  Test_loss : 0.1443, Time/batch_file : 9.0958, Training time: 13002.8974\n",
      "Epoch : 281/500 data_batch_4,  Train_loss : 0.1319  Test_loss : 0.1440, Time/batch_file : 9.2990, Training time: 13012.1966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 281/500 data_batch_5,  Train_loss : 0.1328  Test_loss : 0.1407, Time/batch_file : 9.1595, Training time: 13021.3565\n",
      "Epoch : 282/500 data_batch_1,  Train_loss : 0.1325  Test_loss : 0.1419, Time/batch_file : 9.0545, Training time: 13030.4113\n",
      "Epoch : 282/500 data_batch_2,  Train_loss : 0.1372  Test_loss : 0.1366, Time/batch_file : 9.3753, Training time: 13039.7868\n",
      "Epoch : 282/500 data_batch_3,  Train_loss : 0.1348  Test_loss : 0.1387, Time/batch_file : 9.1294, Training time: 13048.9165\n",
      "Epoch : 282/500 data_batch_4,  Train_loss : 0.1386  Test_loss : 0.1349, Time/batch_file : 9.0385, Training time: 13057.9554\n",
      "Epoch : 282/500 data_batch_5,  Train_loss : 0.1363  Test_loss : 0.1391, Time/batch_file : 9.0890, Training time: 13067.0447\n",
      "Epoch : 283/500 data_batch_1,  Train_loss : 0.1349  Test_loss : 0.1505, Time/batch_file : 9.2643, Training time: 13076.3095\n",
      "Epoch : 283/500 data_batch_2,  Train_loss : 0.1315  Test_loss : 0.1502, Time/batch_file : 8.9030, Training time: 13085.2127\n",
      "Epoch : 283/500 data_batch_3,  Train_loss : 0.1345  Test_loss : 0.1472, Time/batch_file : 9.2336, Training time: 13094.4465\n",
      "Epoch : 283/500 data_batch_4,  Train_loss : 0.1330  Test_loss : 0.1548, Time/batch_file : 9.1314, Training time: 13103.5783\n",
      "Epoch : 283/500 data_batch_5,  Train_loss : 0.1318  Test_loss : 0.1520, Time/batch_file : 9.0549, Training time: 13112.6334\n",
      "Epoch : 284/500 data_batch_1,  Train_loss : 0.1330  Test_loss : 0.1385, Time/batch_file : 9.2043, Training time: 13121.8380\n",
      "Epoch : 284/500 data_batch_2,  Train_loss : 0.1409  Test_loss : 0.1401, Time/batch_file : 9.1634, Training time: 13131.0017\n",
      "Epoch : 284/500 data_batch_3,  Train_loss : 0.1335  Test_loss : 0.1361, Time/batch_file : 9.1950, Training time: 13140.1969\n",
      "Epoch : 284/500 data_batch_4,  Train_loss : 0.1349  Test_loss : 0.1403, Time/batch_file : 9.3006, Training time: 13149.4978\n",
      "Epoch : 284/500 data_batch_5,  Train_loss : 0.1333  Test_loss : 0.1427, Time/batch_file : 9.4223, Training time: 13158.9204\n",
      "Epoch : 285/500 data_batch_1,  Train_loss : 0.1340  Test_loss : 0.1433, Time/batch_file : 9.0980, Training time: 13168.0187\n",
      "Epoch : 285/500 data_batch_2,  Train_loss : 0.1320  Test_loss : 0.1403, Time/batch_file : 9.2206, Training time: 13177.2396\n",
      "Epoch : 285/500 data_batch_3,  Train_loss : 0.1365  Test_loss : 0.1412, Time/batch_file : 9.1108, Training time: 13186.3508\n",
      "Epoch : 285/500 data_batch_4,  Train_loss : 0.1335  Test_loss : 0.1437, Time/batch_file : 9.1050, Training time: 13195.4561\n",
      "Epoch : 285/500 data_batch_5,  Train_loss : 0.1338  Test_loss : 0.1440, Time/batch_file : 9.1282, Training time: 13204.5846\n",
      "Epoch : 286/500 data_batch_1,  Train_loss : 0.1355  Test_loss : 0.1461, Time/batch_file : 8.9421, Training time: 13215.1821\n",
      "Epoch : 286/500 data_batch_2,  Train_loss : 0.1290  Test_loss : 0.1485, Time/batch_file : 8.9541, Training time: 13224.1365\n",
      "Epoch : 286/500 data_batch_3,  Train_loss : 0.1279  Test_loss : 0.1444, Time/batch_file : 8.9512, Training time: 13233.0879\n",
      "Epoch : 286/500 data_batch_4,  Train_loss : 0.1340  Test_loss : 0.1438, Time/batch_file : 9.2063, Training time: 13242.2946\n",
      "Epoch : 286/500 data_batch_5,  Train_loss : 0.1341  Test_loss : 0.1428, Time/batch_file : 9.1855, Training time: 13251.4804\n",
      "Epoch : 287/500 data_batch_1,  Train_loss : 0.1355  Test_loss : 0.1472, Time/batch_file : 9.0216, Training time: 13260.5024\n",
      "Epoch : 287/500 data_batch_2,  Train_loss : 0.1388  Test_loss : 0.1477, Time/batch_file : 9.1583, Training time: 13269.6610\n",
      "Epoch : 287/500 data_batch_3,  Train_loss : 0.1354  Test_loss : 0.1482, Time/batch_file : 9.0678, Training time: 13278.7291\n",
      "Epoch : 287/500 data_batch_4,  Train_loss : 0.1379  Test_loss : 0.1461, Time/batch_file : 9.1061, Training time: 13287.8355\n",
      "Epoch : 287/500 data_batch_5,  Train_loss : 0.1373  Test_loss : 0.1378, Time/batch_file : 9.2903, Training time: 13297.1260\n",
      "Epoch : 288/500 data_batch_1,  Train_loss : 0.1458  Test_loss : 0.1453, Time/batch_file : 8.9851, Training time: 13306.1115\n",
      "Epoch : 288/500 data_batch_2,  Train_loss : 0.1466  Test_loss : 0.1469, Time/batch_file : 9.1853, Training time: 13315.2975\n",
      "Epoch : 288/500 data_batch_3,  Train_loss : 0.1466  Test_loss : 0.1456, Time/batch_file : 9.3048, Training time: 13324.6027\n",
      "Epoch : 288/500 data_batch_4,  Train_loss : 0.1436  Test_loss : 0.1489, Time/batch_file : 9.0459, Training time: 13333.6488\n",
      "Epoch : 288/500 data_batch_5,  Train_loss : 0.1428  Test_loss : 0.1454, Time/batch_file : 9.1035, Training time: 13342.7525\n",
      "Epoch : 289/500 data_batch_1,  Train_loss : 0.1467  Test_loss : 0.1360, Time/batch_file : 9.2863, Training time: 13352.0390\n",
      "Epoch : 289/500 data_batch_2,  Train_loss : 0.1422  Test_loss : 0.1392, Time/batch_file : 9.2334, Training time: 13361.2729\n",
      "Epoch : 289/500 data_batch_3,  Train_loss : 0.1429  Test_loss : 0.1343, Time/batch_file : 9.3202, Training time: 13370.5933\n",
      "Epoch : 289/500 data_batch_4,  Train_loss : 0.1435  Test_loss : 0.1345, Time/batch_file : 9.3953, Training time: 13379.9888\n",
      "Epoch : 289/500 data_batch_5,  Train_loss : 0.1451  Test_loss : 0.1321, Time/batch_file : 9.6310, Training time: 13389.6202\n",
      "Epoch : 290/500 data_batch_1,  Train_loss : 0.1348  Test_loss : 0.1501, Time/batch_file : 9.0326, Training time: 13398.6531\n",
      "Epoch : 290/500 data_batch_2,  Train_loss : 0.1372  Test_loss : 0.1451, Time/batch_file : 9.0066, Training time: 13407.6599\n",
      "Epoch : 290/500 data_batch_3,  Train_loss : 0.1392  Test_loss : 0.1468, Time/batch_file : 9.1037, Training time: 13416.7639\n",
      "Epoch : 290/500 data_batch_4,  Train_loss : 0.1383  Test_loss : 0.1518, Time/batch_file : 9.1561, Training time: 13425.9203\n",
      "Epoch : 290/500 data_batch_5,  Train_loss : 0.1360  Test_loss : 0.1426, Time/batch_file : 9.2989, Training time: 13435.2195\n",
      "Epoch : 291/500 data_batch_1,  Train_loss : 0.1360  Test_loss : 0.1426, Time/batch_file : 9.1363, Training time: 13446.0475\n",
      "Epoch : 291/500 data_batch_2,  Train_loss : 0.1384  Test_loss : 0.1421, Time/batch_file : 8.9449, Training time: 13454.9927\n",
      "Epoch : 291/500 data_batch_3,  Train_loss : 0.1326  Test_loss : 0.1458, Time/batch_file : 9.1041, Training time: 13464.0971\n",
      "Epoch : 291/500 data_batch_4,  Train_loss : 0.1325  Test_loss : 0.1463, Time/batch_file : 9.1291, Training time: 13473.2266\n",
      "Epoch : 291/500 data_batch_5,  Train_loss : 0.1316  Test_loss : 0.1450, Time/batch_file : 9.0385, Training time: 13482.2654\n",
      "Epoch : 292/500 data_batch_1,  Train_loss : 0.1467  Test_loss : 0.1334, Time/batch_file : 9.0018, Training time: 13491.2675\n",
      "Epoch : 292/500 data_batch_2,  Train_loss : 0.1460  Test_loss : 0.1327, Time/batch_file : 9.3979, Training time: 13500.6657\n",
      "Epoch : 292/500 data_batch_3,  Train_loss : 0.1425  Test_loss : 0.1311, Time/batch_file : 9.3014, Training time: 13509.9673\n",
      "Epoch : 292/500 data_batch_4,  Train_loss : 0.1399  Test_loss : 0.1359, Time/batch_file : 9.2352, Training time: 13519.2028\n",
      "Epoch : 292/500 data_batch_5,  Train_loss : 0.1435  Test_loss : 0.1314, Time/batch_file : 9.0755, Training time: 13528.2787\n",
      "Epoch : 293/500 data_batch_1,  Train_loss : 0.1334  Test_loss : 0.1278, Time/batch_file : 9.3922, Training time: 13537.6712\n",
      "Epoch : 293/500 data_batch_2,  Train_loss : 0.1416  Test_loss : 0.1374, Time/batch_file : 8.9668, Training time: 13546.6382\n",
      "Epoch : 293/500 data_batch_3,  Train_loss : 0.1349  Test_loss : 0.1354, Time/batch_file : 9.3525, Training time: 13555.9911\n",
      "Epoch : 293/500 data_batch_4,  Train_loss : 0.1383  Test_loss : 0.1323, Time/batch_file : 9.2767, Training time: 13565.2683\n",
      "Epoch : 293/500 data_batch_5,  Train_loss : 0.1370  Test_loss : 0.1341, Time/batch_file : 9.3484, Training time: 13574.6171\n",
      "Epoch : 294/500 data_batch_1,  Train_loss : 0.1379  Test_loss : 0.1366, Time/batch_file : 9.0270, Training time: 13583.6444\n",
      "Epoch : 294/500 data_batch_2,  Train_loss : 0.1367  Test_loss : 0.1328, Time/batch_file : 9.2079, Training time: 13592.8524\n",
      "Epoch : 294/500 data_batch_3,  Train_loss : 0.1397  Test_loss : 0.1344, Time/batch_file : 9.1826, Training time: 13602.0354\n",
      "Epoch : 294/500 data_batch_4,  Train_loss : 0.1445  Test_loss : 0.1338, Time/batch_file : 9.0750, Training time: 13611.1106\n",
      "Epoch : 294/500 data_batch_5,  Train_loss : 0.1437  Test_loss : 0.1308, Time/batch_file : 8.9616, Training time: 13620.0724\n",
      "Epoch : 295/500 data_batch_1,  Train_loss : 0.1444  Test_loss : 0.1376, Time/batch_file : 9.2041, Training time: 13629.2769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 295/500 data_batch_2,  Train_loss : 0.1462  Test_loss : 0.1387, Time/batch_file : 8.8784, Training time: 13638.1556\n",
      "Epoch : 295/500 data_batch_3,  Train_loss : 0.1446  Test_loss : 0.1374, Time/batch_file : 9.1857, Training time: 13647.3416\n",
      "Epoch : 295/500 data_batch_4,  Train_loss : 0.1472  Test_loss : 0.1396, Time/batch_file : 9.1955, Training time: 13656.5373\n",
      "Epoch : 295/500 data_batch_5,  Train_loss : 0.1437  Test_loss : 0.1390, Time/batch_file : 9.4184, Training time: 13665.9561\n",
      "Epoch : 296/500 data_batch_1,  Train_loss : 0.1448  Test_loss : 0.1410, Time/batch_file : 9.2966, Training time: 13676.9614\n",
      "Epoch : 296/500 data_batch_2,  Train_loss : 0.1436  Test_loss : 0.1415, Time/batch_file : 9.0276, Training time: 13685.9893\n",
      "Epoch : 296/500 data_batch_3,  Train_loss : 0.1462  Test_loss : 0.1380, Time/batch_file : 9.1140, Training time: 13695.1035\n",
      "Epoch : 296/500 data_batch_4,  Train_loss : 0.1456  Test_loss : 0.1433, Time/batch_file : 9.2868, Training time: 13704.3905\n",
      "Epoch : 296/500 data_batch_5,  Train_loss : 0.1527  Test_loss : 0.1400, Time/batch_file : 9.3729, Training time: 13713.7636\n",
      "Epoch : 297/500 data_batch_1,  Train_loss : 0.1295  Test_loss : 0.1357, Time/batch_file : 9.2840, Training time: 13723.0479\n",
      "Epoch : 297/500 data_batch_2,  Train_loss : 0.1325  Test_loss : 0.1370, Time/batch_file : 9.1614, Training time: 13732.2095\n",
      "Epoch : 297/500 data_batch_3,  Train_loss : 0.1341  Test_loss : 0.1401, Time/batch_file : 9.2708, Training time: 13741.4807\n",
      "Epoch : 297/500 data_batch_4,  Train_loss : 0.1321  Test_loss : 0.1398, Time/batch_file : 9.1064, Training time: 13750.5873\n",
      "Epoch : 297/500 data_batch_5,  Train_loss : 0.1383  Test_loss : 0.1381, Time/batch_file : 9.2599, Training time: 13759.8475\n",
      "Epoch : 298/500 data_batch_1,  Train_loss : 0.1431  Test_loss : 0.1302, Time/batch_file : 9.4375, Training time: 13769.2853\n",
      "Epoch : 298/500 data_batch_2,  Train_loss : 0.1555  Test_loss : 0.1326, Time/batch_file : 9.3698, Training time: 13778.6554\n",
      "Epoch : 298/500 data_batch_3,  Train_loss : 0.1557  Test_loss : 0.1355, Time/batch_file : 9.1231, Training time: 13787.7789\n",
      "Epoch : 298/500 data_batch_4,  Train_loss : 0.1513  Test_loss : 0.1343, Time/batch_file : 9.0163, Training time: 13796.7955\n",
      "Epoch : 298/500 data_batch_5,  Train_loss : 0.1485  Test_loss : 0.1332, Time/batch_file : 9.0256, Training time: 13805.8213\n",
      "Epoch : 299/500 data_batch_1,  Train_loss : 0.1401  Test_loss : 0.1463, Time/batch_file : 9.2055, Training time: 13815.0271\n",
      "Epoch : 299/500 data_batch_2,  Train_loss : 0.1410  Test_loss : 0.1411, Time/batch_file : 9.2310, Training time: 13824.2584\n",
      "Epoch : 299/500 data_batch_3,  Train_loss : 0.1373  Test_loss : 0.1468, Time/batch_file : 9.1411, Training time: 13833.3997\n",
      "Epoch : 299/500 data_batch_4,  Train_loss : 0.1360  Test_loss : 0.1471, Time/batch_file : 9.0611, Training time: 13842.4610\n",
      "Epoch : 299/500 data_batch_5,  Train_loss : 0.1372  Test_loss : 0.1435, Time/batch_file : 9.2872, Training time: 13851.7485\n",
      "Epoch : 300/500 data_batch_1,  Train_loss : 0.1366  Test_loss : 0.1409, Time/batch_file : 9.0143, Training time: 13860.7631\n",
      "Epoch : 300/500 data_batch_2,  Train_loss : 0.1327  Test_loss : 0.1373, Time/batch_file : 8.9833, Training time: 13869.7469\n",
      "Epoch : 300/500 data_batch_3,  Train_loss : 0.1338  Test_loss : 0.1392, Time/batch_file : 9.1746, Training time: 13878.9218\n",
      "Epoch : 300/500 data_batch_4,  Train_loss : 0.1328  Test_loss : 0.1405, Time/batch_file : 9.4486, Training time: 13888.3707\n",
      "Epoch : 300/500 data_batch_5,  Train_loss : 0.1334  Test_loss : 0.1449, Time/batch_file : 9.3625, Training time: 13897.7335\n",
      "[./nets/net-300.ckpt] SAVED\n",
      "Epoch : 301/500 data_batch_1,  Train_loss : 0.1442  Test_loss : 0.1315, Time/batch_file : 9.2510, Training time: 13908.8168\n",
      "Epoch : 301/500 data_batch_2,  Train_loss : 0.1424  Test_loss : 0.1386, Time/batch_file : 9.1145, Training time: 13917.9316\n",
      "Epoch : 301/500 data_batch_3,  Train_loss : 0.1416  Test_loss : 0.1380, Time/batch_file : 9.1729, Training time: 13927.1048\n",
      "Epoch : 301/500 data_batch_4,  Train_loss : 0.1420  Test_loss : 0.1394, Time/batch_file : 9.2692, Training time: 13936.3744\n",
      "Epoch : 301/500 data_batch_5,  Train_loss : 0.1421  Test_loss : 0.1369, Time/batch_file : 9.2601, Training time: 13945.6347\n",
      "Epoch : 302/500 data_batch_1,  Train_loss : 0.1432  Test_loss : 0.1334, Time/batch_file : 9.2691, Training time: 13954.9042\n",
      "Epoch : 302/500 data_batch_2,  Train_loss : 0.1419  Test_loss : 0.1367, Time/batch_file : 9.6673, Training time: 13964.5718\n",
      "Epoch : 302/500 data_batch_3,  Train_loss : 0.1426  Test_loss : 0.1372, Time/batch_file : 9.3493, Training time: 13973.9214\n",
      "Epoch : 302/500 data_batch_4,  Train_loss : 0.1438  Test_loss : 0.1382, Time/batch_file : 9.3787, Training time: 13983.3006\n",
      "Epoch : 302/500 data_batch_5,  Train_loss : 0.1407  Test_loss : 0.1388, Time/batch_file : 8.9322, Training time: 13992.2331\n",
      "Epoch : 303/500 data_batch_1,  Train_loss : 0.1550  Test_loss : 0.1346, Time/batch_file : 9.2699, Training time: 14001.5032\n",
      "Epoch : 303/500 data_batch_2,  Train_loss : 0.1509  Test_loss : 0.1302, Time/batch_file : 9.2984, Training time: 14010.8018\n",
      "Epoch : 303/500 data_batch_3,  Train_loss : 0.1505  Test_loss : 0.1313, Time/batch_file : 9.2265, Training time: 14020.0286\n",
      "Epoch : 303/500 data_batch_4,  Train_loss : 0.1480  Test_loss : 0.1306, Time/batch_file : 9.3034, Training time: 14029.3322\n",
      "Epoch : 303/500 data_batch_5,  Train_loss : 0.1533  Test_loss : 0.1366, Time/batch_file : 9.2529, Training time: 14038.5854\n",
      "Epoch : 304/500 data_batch_1,  Train_loss : 0.1463  Test_loss : 0.1414, Time/batch_file : 9.4012, Training time: 14047.9869\n",
      "Epoch : 304/500 data_batch_2,  Train_loss : 0.1465  Test_loss : 0.1306, Time/batch_file : 8.9852, Training time: 14056.9725\n",
      "Epoch : 304/500 data_batch_3,  Train_loss : 0.1385  Test_loss : 0.1348, Time/batch_file : 9.1852, Training time: 14066.1581\n",
      "Epoch : 304/500 data_batch_4,  Train_loss : 0.1404  Test_loss : 0.1368, Time/batch_file : 9.3000, Training time: 14075.4583\n",
      "Epoch : 304/500 data_batch_5,  Train_loss : 0.1428  Test_loss : 0.1386, Time/batch_file : 9.5123, Training time: 14084.9708\n",
      "Epoch : 305/500 data_batch_1,  Train_loss : 0.1390  Test_loss : 0.1420, Time/batch_file : 9.1857, Training time: 14094.1568\n",
      "Epoch : 305/500 data_batch_2,  Train_loss : 0.1429  Test_loss : 0.1384, Time/batch_file : 9.3522, Training time: 14103.5093\n",
      "Epoch : 305/500 data_batch_3,  Train_loss : 0.1406  Test_loss : 0.1430, Time/batch_file : 9.0138, Training time: 14112.5233\n",
      "Epoch : 305/500 data_batch_4,  Train_loss : 0.1381  Test_loss : 0.1426, Time/batch_file : 9.0922, Training time: 14121.6158\n",
      "Epoch : 305/500 data_batch_5,  Train_loss : 0.1392  Test_loss : 0.1440, Time/batch_file : 8.9889, Training time: 14130.6050\n",
      "Epoch : 306/500 data_batch_1,  Train_loss : 0.1297  Test_loss : 0.1436, Time/batch_file : 9.1467, Training time: 14141.4493\n",
      "Epoch : 306/500 data_batch_2,  Train_loss : 0.1312  Test_loss : 0.1398, Time/batch_file : 9.0981, Training time: 14150.5477\n",
      "Epoch : 306/500 data_batch_3,  Train_loss : 0.1330  Test_loss : 0.1431, Time/batch_file : 9.2384, Training time: 14159.7863\n",
      "Epoch : 306/500 data_batch_4,  Train_loss : 0.1356  Test_loss : 0.1487, Time/batch_file : 9.1150, Training time: 14168.9016\n",
      "Epoch : 306/500 data_batch_5,  Train_loss : 0.1335  Test_loss : 0.1437, Time/batch_file : 9.3335, Training time: 14178.2354\n",
      "Epoch : 307/500 data_batch_1,  Train_loss : 0.1309  Test_loss : 0.1453, Time/batch_file : 8.9477, Training time: 14187.1834\n",
      "Epoch : 307/500 data_batch_2,  Train_loss : 0.1312  Test_loss : 0.1436, Time/batch_file : 8.9795, Training time: 14196.1632\n",
      "Epoch : 307/500 data_batch_3,  Train_loss : 0.1329  Test_loss : 0.1367, Time/batch_file : 9.3798, Training time: 14205.5432\n",
      "Epoch : 307/500 data_batch_4,  Train_loss : 0.1327  Test_loss : 0.1432, Time/batch_file : 8.9473, Training time: 14214.4908\n",
      "Epoch : 307/500 data_batch_5,  Train_loss : 0.1343  Test_loss : 0.1421, Time/batch_file : 9.0977, Training time: 14223.5887\n",
      "Epoch : 308/500 data_batch_1,  Train_loss : 0.1365  Test_loss : 0.1307, Time/batch_file : 9.0522, Training time: 14232.6413\n",
      "Epoch : 308/500 data_batch_2,  Train_loss : 0.1369  Test_loss : 0.1370, Time/batch_file : 9.1477, Training time: 14241.7893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 308/500 data_batch_3,  Train_loss : 0.1384  Test_loss : 0.1299, Time/batch_file : 9.1214, Training time: 14250.9110\n",
      "Epoch : 308/500 data_batch_4,  Train_loss : 0.1415  Test_loss : 0.1320, Time/batch_file : 8.9384, Training time: 14259.8496\n",
      "Epoch : 308/500 data_batch_5,  Train_loss : 0.1392  Test_loss : 0.1358, Time/batch_file : 9.3603, Training time: 14269.2103\n",
      "Epoch : 309/500 data_batch_1,  Train_loss : 0.1423  Test_loss : 0.1435, Time/batch_file : 9.1747, Training time: 14278.3854\n",
      "Epoch : 309/500 data_batch_2,  Train_loss : 0.1438  Test_loss : 0.1434, Time/batch_file : 8.8900, Training time: 14287.2756\n",
      "Epoch : 309/500 data_batch_3,  Train_loss : 0.1450  Test_loss : 0.1447, Time/batch_file : 8.8670, Training time: 14296.1428\n",
      "Epoch : 309/500 data_batch_4,  Train_loss : 0.1400  Test_loss : 0.1448, Time/batch_file : 9.0917, Training time: 14305.2348\n",
      "Epoch : 309/500 data_batch_5,  Train_loss : 0.1406  Test_loss : 0.1471, Time/batch_file : 9.0136, Training time: 14314.2486\n",
      "Epoch : 310/500 data_batch_1,  Train_loss : 0.1359  Test_loss : 0.1412, Time/batch_file : 9.0773, Training time: 14323.3262\n",
      "Epoch : 310/500 data_batch_2,  Train_loss : 0.1431  Test_loss : 0.1439, Time/batch_file : 9.0966, Training time: 14332.4231\n",
      "Epoch : 310/500 data_batch_3,  Train_loss : 0.1432  Test_loss : 0.1396, Time/batch_file : 9.3557, Training time: 14341.7790\n",
      "Epoch : 310/500 data_batch_4,  Train_loss : 0.1456  Test_loss : 0.1407, Time/batch_file : 9.2956, Training time: 14351.0749\n",
      "Epoch : 310/500 data_batch_5,  Train_loss : 0.1381  Test_loss : 0.1436, Time/batch_file : 9.3345, Training time: 14360.4096\n",
      "Epoch : 311/500 data_batch_1,  Train_loss : 0.1295  Test_loss : 0.1374, Time/batch_file : 9.2508, Training time: 14371.3657\n",
      "Epoch : 311/500 data_batch_2,  Train_loss : 0.1281  Test_loss : 0.1363, Time/batch_file : 9.0625, Training time: 14380.4284\n",
      "Epoch : 311/500 data_batch_3,  Train_loss : 0.1291  Test_loss : 0.1361, Time/batch_file : 9.1664, Training time: 14389.5950\n",
      "Epoch : 311/500 data_batch_4,  Train_loss : 0.1315  Test_loss : 0.1426, Time/batch_file : 9.2228, Training time: 14398.8180\n",
      "Epoch : 311/500 data_batch_5,  Train_loss : 0.1309  Test_loss : 0.1424, Time/batch_file : 9.0742, Training time: 14407.8925\n",
      "Epoch : 312/500 data_batch_1,  Train_loss : 0.1337  Test_loss : 0.1349, Time/batch_file : 9.1873, Training time: 14417.0800\n",
      "Epoch : 312/500 data_batch_2,  Train_loss : 0.1374  Test_loss : 0.1345, Time/batch_file : 9.2102, Training time: 14426.2905\n",
      "Epoch : 312/500 data_batch_3,  Train_loss : 0.1350  Test_loss : 0.1335, Time/batch_file : 8.9804, Training time: 14435.2712\n",
      "Epoch : 312/500 data_batch_4,  Train_loss : 0.1337  Test_loss : 0.1397, Time/batch_file : 9.3203, Training time: 14444.5918\n",
      "Epoch : 312/500 data_batch_5,  Train_loss : 0.1353  Test_loss : 0.1395, Time/batch_file : 9.0701, Training time: 14453.6621\n",
      "Epoch : 313/500 data_batch_1,  Train_loss : 0.1449  Test_loss : 0.1404, Time/batch_file : 9.2106, Training time: 14462.8730\n",
      "Epoch : 313/500 data_batch_2,  Train_loss : 0.1430  Test_loss : 0.1355, Time/batch_file : 9.3688, Training time: 14472.2421\n",
      "Epoch : 313/500 data_batch_3,  Train_loss : 0.1410  Test_loss : 0.1389, Time/batch_file : 9.2497, Training time: 14481.4921\n",
      "Epoch : 313/500 data_batch_4,  Train_loss : 0.1457  Test_loss : 0.1356, Time/batch_file : 9.3449, Training time: 14490.8373\n",
      "Epoch : 313/500 data_batch_5,  Train_loss : 0.1479  Test_loss : 0.1351, Time/batch_file : 9.0350, Training time: 14499.8726\n",
      "Epoch : 314/500 data_batch_1,  Train_loss : 0.1352  Test_loss : 0.1381, Time/batch_file : 9.1026, Training time: 14508.9755\n",
      "Epoch : 314/500 data_batch_2,  Train_loss : 0.1363  Test_loss : 0.1360, Time/batch_file : 9.1914, Training time: 14518.1672\n",
      "Epoch : 314/500 data_batch_3,  Train_loss : 0.1290  Test_loss : 0.1412, Time/batch_file : 9.1076, Training time: 14527.2750\n",
      "Epoch : 314/500 data_batch_4,  Train_loss : 0.1337  Test_loss : 0.1410, Time/batch_file : 9.3219, Training time: 14536.5974\n",
      "Epoch : 314/500 data_batch_5,  Train_loss : 0.1353  Test_loss : 0.1378, Time/batch_file : 9.1773, Training time: 14545.7749\n",
      "Epoch : 315/500 data_batch_1,  Train_loss : 0.1351  Test_loss : 0.1423, Time/batch_file : 9.3407, Training time: 14555.1159\n",
      "Epoch : 315/500 data_batch_2,  Train_loss : 0.1313  Test_loss : 0.1367, Time/batch_file : 9.1852, Training time: 14564.3014\n",
      "Epoch : 315/500 data_batch_3,  Train_loss : 0.1282  Test_loss : 0.1405, Time/batch_file : 9.0945, Training time: 14573.3961\n",
      "Epoch : 315/500 data_batch_4,  Train_loss : 0.1326  Test_loss : 0.1413, Time/batch_file : 9.2274, Training time: 14582.6237\n",
      "Epoch : 315/500 data_batch_5,  Train_loss : 0.1293  Test_loss : 0.1455, Time/batch_file : 9.2454, Training time: 14591.8694\n",
      "Epoch : 316/500 data_batch_1,  Train_loss : 0.1405  Test_loss : 0.1378, Time/batch_file : 9.1630, Training time: 14602.5473\n",
      "Epoch : 316/500 data_batch_2,  Train_loss : 0.1451  Test_loss : 0.1384, Time/batch_file : 9.3478, Training time: 14611.8953\n",
      "Epoch : 316/500 data_batch_3,  Train_loss : 0.1466  Test_loss : 0.1366, Time/batch_file : 9.1030, Training time: 14620.9985\n",
      "Epoch : 316/500 data_batch_4,  Train_loss : 0.1436  Test_loss : 0.1361, Time/batch_file : 8.9141, Training time: 14629.9131\n",
      "Epoch : 316/500 data_batch_5,  Train_loss : 0.1426  Test_loss : 0.1427, Time/batch_file : 9.5765, Training time: 14639.4910\n",
      "Epoch : 317/500 data_batch_1,  Train_loss : 0.1499  Test_loss : 0.1397, Time/batch_file : 9.6383, Training time: 14649.1295\n",
      "Epoch : 317/500 data_batch_2,  Train_loss : 0.1503  Test_loss : 0.1410, Time/batch_file : 9.7351, Training time: 14658.8649\n",
      "Epoch : 317/500 data_batch_3,  Train_loss : 0.1510  Test_loss : 0.1425, Time/batch_file : 9.7192, Training time: 14668.5843\n",
      "Epoch : 317/500 data_batch_4,  Train_loss : 0.1543  Test_loss : 0.1396, Time/batch_file : 9.2107, Training time: 14677.7953\n",
      "Epoch : 317/500 data_batch_5,  Train_loss : 0.1488  Test_loss : 0.1407, Time/batch_file : 8.9967, Training time: 14686.7924\n",
      "Epoch : 318/500 data_batch_1,  Train_loss : 0.1255  Test_loss : 0.1438, Time/batch_file : 9.2576, Training time: 14696.0504\n",
      "Epoch : 318/500 data_batch_2,  Train_loss : 0.1280  Test_loss : 0.1368, Time/batch_file : 9.3557, Training time: 14705.4063\n",
      "Epoch : 318/500 data_batch_3,  Train_loss : 0.1280  Test_loss : 0.1438, Time/batch_file : 9.0629, Training time: 14714.4695\n",
      "Epoch : 318/500 data_batch_4,  Train_loss : 0.1262  Test_loss : 0.1494, Time/batch_file : 9.3519, Training time: 14723.8217\n",
      "Epoch : 318/500 data_batch_5,  Train_loss : 0.1260  Test_loss : 0.1378, Time/batch_file : 9.0806, Training time: 14732.9026\n",
      "Epoch : 319/500 data_batch_1,  Train_loss : 0.1291  Test_loss : 0.1398, Time/batch_file : 9.2704, Training time: 14742.1733\n",
      "Epoch : 319/500 data_batch_2,  Train_loss : 0.1295  Test_loss : 0.1407, Time/batch_file : 9.0208, Training time: 14751.1944\n",
      "Epoch : 319/500 data_batch_3,  Train_loss : 0.1338  Test_loss : 0.1378, Time/batch_file : 9.2656, Training time: 14760.4603\n",
      "Epoch : 319/500 data_batch_4,  Train_loss : 0.1322  Test_loss : 0.1392, Time/batch_file : 8.9957, Training time: 14769.4563\n",
      "Epoch : 319/500 data_batch_5,  Train_loss : 0.1338  Test_loss : 0.1392, Time/batch_file : 9.3998, Training time: 14778.8564\n",
      "Epoch : 320/500 data_batch_1,  Train_loss : 0.1404  Test_loss : 0.1433, Time/batch_file : 9.2053, Training time: 14788.0621\n",
      "Epoch : 320/500 data_batch_2,  Train_loss : 0.1443  Test_loss : 0.1437, Time/batch_file : 9.2091, Training time: 14797.2716\n",
      "Epoch : 320/500 data_batch_3,  Train_loss : 0.1398  Test_loss : 0.1467, Time/batch_file : 9.1425, Training time: 14806.4143\n",
      "Epoch : 320/500 data_batch_4,  Train_loss : 0.1411  Test_loss : 0.1448, Time/batch_file : 9.2316, Training time: 14815.6462\n",
      "Epoch : 320/500 data_batch_5,  Train_loss : 0.1345  Test_loss : 0.1432, Time/batch_file : 9.0862, Training time: 14824.7327\n",
      "[./nets/net-320.ckpt] SAVED\n",
      "Epoch : 321/500 data_batch_1,  Train_loss : 0.1413  Test_loss : 0.1352, Time/batch_file : 9.3039, Training time: 14836.0032\n",
      "Epoch : 321/500 data_batch_2,  Train_loss : 0.1433  Test_loss : 0.1382, Time/batch_file : 9.0310, Training time: 14845.0344\n",
      "Epoch : 321/500 data_batch_3,  Train_loss : 0.1396  Test_loss : 0.1293, Time/batch_file : 9.1252, Training time: 14854.1598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 321/500 data_batch_4,  Train_loss : 0.1421  Test_loss : 0.1346, Time/batch_file : 9.1320, Training time: 14863.2921\n",
      "Epoch : 321/500 data_batch_5,  Train_loss : 0.1348  Test_loss : 0.1367, Time/batch_file : 9.2938, Training time: 14872.5861\n",
      "Epoch : 322/500 data_batch_1,  Train_loss : 0.1388  Test_loss : 0.1381, Time/batch_file : 9.0739, Training time: 14881.6602\n",
      "Epoch : 322/500 data_batch_2,  Train_loss : 0.1462  Test_loss : 0.1373, Time/batch_file : 9.0848, Training time: 14890.7454\n",
      "Epoch : 322/500 data_batch_3,  Train_loss : 0.1476  Test_loss : 0.1343, Time/batch_file : 9.4052, Training time: 14900.1509\n",
      "Epoch : 322/500 data_batch_4,  Train_loss : 0.1487  Test_loss : 0.1370, Time/batch_file : 9.4245, Training time: 14909.5757\n",
      "Epoch : 322/500 data_batch_5,  Train_loss : 0.1472  Test_loss : 0.1401, Time/batch_file : 9.4247, Training time: 14919.0008\n",
      "Epoch : 323/500 data_batch_1,  Train_loss : 0.1538  Test_loss : 0.1444, Time/batch_file : 9.0991, Training time: 14928.1003\n",
      "Epoch : 323/500 data_batch_2,  Train_loss : 0.1450  Test_loss : 0.1451, Time/batch_file : 9.1795, Training time: 14937.2801\n",
      "Epoch : 323/500 data_batch_3,  Train_loss : 0.1492  Test_loss : 0.1443, Time/batch_file : 9.2183, Training time: 14946.4987\n",
      "Epoch : 323/500 data_batch_4,  Train_loss : 0.1460  Test_loss : 0.1437, Time/batch_file : 9.1015, Training time: 14955.6005\n",
      "Epoch : 323/500 data_batch_5,  Train_loss : 0.1427  Test_loss : 0.1434, Time/batch_file : 9.1385, Training time: 14964.7392\n",
      "Epoch : 324/500 data_batch_1,  Train_loss : 0.1443  Test_loss : 0.1438, Time/batch_file : 9.3588, Training time: 14974.0982\n",
      "Epoch : 324/500 data_batch_2,  Train_loss : 0.1479  Test_loss : 0.1428, Time/batch_file : 9.1901, Training time: 14983.2885\n",
      "Epoch : 324/500 data_batch_3,  Train_loss : 0.1418  Test_loss : 0.1398, Time/batch_file : 9.3533, Training time: 14992.6422\n",
      "Epoch : 324/500 data_batch_4,  Train_loss : 0.1406  Test_loss : 0.1352, Time/batch_file : 9.3610, Training time: 15002.0035\n",
      "Epoch : 324/500 data_batch_5,  Train_loss : 0.1434  Test_loss : 0.1452, Time/batch_file : 9.1320, Training time: 15011.1358\n",
      "Epoch : 325/500 data_batch_1,  Train_loss : 0.1283  Test_loss : 0.1457, Time/batch_file : 9.2822, Training time: 15020.4183\n",
      "Epoch : 325/500 data_batch_2,  Train_loss : 0.1293  Test_loss : 0.1525, Time/batch_file : 9.3462, Training time: 15029.7647\n",
      "Epoch : 325/500 data_batch_3,  Train_loss : 0.1289  Test_loss : 0.1466, Time/batch_file : 9.2205, Training time: 15038.9855\n",
      "Epoch : 325/500 data_batch_4,  Train_loss : 0.1285  Test_loss : 0.1429, Time/batch_file : 9.0435, Training time: 15048.0292\n",
      "Epoch : 325/500 data_batch_5,  Train_loss : 0.1295  Test_loss : 0.1418, Time/batch_file : 9.3355, Training time: 15057.3650\n",
      "Epoch : 326/500 data_batch_1,  Train_loss : 0.1354  Test_loss : 0.1407, Time/batch_file : 9.0218, Training time: 15067.9662\n",
      "Epoch : 326/500 data_batch_2,  Train_loss : 0.1338  Test_loss : 0.1381, Time/batch_file : 9.2909, Training time: 15077.2574\n",
      "Epoch : 326/500 data_batch_3,  Train_loss : 0.1403  Test_loss : 0.1392, Time/batch_file : 9.1933, Training time: 15086.4512\n",
      "Epoch : 326/500 data_batch_4,  Train_loss : 0.1372  Test_loss : 0.1363, Time/batch_file : 9.3032, Training time: 15095.7549\n",
      "Epoch : 326/500 data_batch_5,  Train_loss : 0.1379  Test_loss : 0.1412, Time/batch_file : 9.0873, Training time: 15104.8424\n",
      "Epoch : 327/500 data_batch_1,  Train_loss : 0.1470  Test_loss : 0.1364, Time/batch_file : 9.0030, Training time: 15113.8457\n",
      "Epoch : 327/500 data_batch_2,  Train_loss : 0.1443  Test_loss : 0.1359, Time/batch_file : 9.0398, Training time: 15122.8857\n",
      "Epoch : 327/500 data_batch_3,  Train_loss : 0.1452  Test_loss : 0.1288, Time/batch_file : 9.1510, Training time: 15132.0371\n",
      "Epoch : 327/500 data_batch_4,  Train_loss : 0.1441  Test_loss : 0.1316, Time/batch_file : 9.2346, Training time: 15141.2719\n",
      "Epoch : 327/500 data_batch_5,  Train_loss : 0.1429  Test_loss : 0.1342, Time/batch_file : 9.0890, Training time: 15150.3613\n",
      "Epoch : 328/500 data_batch_1,  Train_loss : 0.1317  Test_loss : 0.1457, Time/batch_file : 9.2451, Training time: 15159.6068\n",
      "Epoch : 328/500 data_batch_2,  Train_loss : 0.1335  Test_loss : 0.1441, Time/batch_file : 9.3171, Training time: 15168.9241\n",
      "Epoch : 328/500 data_batch_3,  Train_loss : 0.1297  Test_loss : 0.1425, Time/batch_file : 9.3695, Training time: 15178.2941\n",
      "Epoch : 328/500 data_batch_4,  Train_loss : 0.1292  Test_loss : 0.1464, Time/batch_file : 8.9943, Training time: 15187.2887\n",
      "Epoch : 328/500 data_batch_5,  Train_loss : 0.1287  Test_loss : 0.1396, Time/batch_file : 9.2051, Training time: 15196.4941\n",
      "Epoch : 329/500 data_batch_1,  Train_loss : 0.1328  Test_loss : 0.1434, Time/batch_file : 9.1089, Training time: 15205.6032\n",
      "Epoch : 329/500 data_batch_2,  Train_loss : 0.1341  Test_loss : 0.1390, Time/batch_file : 9.5242, Training time: 15215.1277\n",
      "Epoch : 329/500 data_batch_3,  Train_loss : 0.1372  Test_loss : 0.1409, Time/batch_file : 9.3836, Training time: 15224.5115\n",
      "Epoch : 329/500 data_batch_4,  Train_loss : 0.1337  Test_loss : 0.1378, Time/batch_file : 9.1282, Training time: 15233.6400\n",
      "Epoch : 329/500 data_batch_5,  Train_loss : 0.1267  Test_loss : 0.1343, Time/batch_file : 9.2652, Training time: 15242.9056\n",
      "Epoch : 330/500 data_batch_1,  Train_loss : 0.1477  Test_loss : 0.1325, Time/batch_file : 9.2793, Training time: 15252.1852\n",
      "Epoch : 330/500 data_batch_2,  Train_loss : 0.1453  Test_loss : 0.1384, Time/batch_file : 9.0233, Training time: 15261.2089\n",
      "Epoch : 330/500 data_batch_3,  Train_loss : 0.1475  Test_loss : 0.1325, Time/batch_file : 9.3776, Training time: 15270.5868\n",
      "Epoch : 330/500 data_batch_4,  Train_loss : 0.1426  Test_loss : 0.1360, Time/batch_file : 9.3109, Training time: 15279.8979\n",
      "Epoch : 330/500 data_batch_5,  Train_loss : 0.1409  Test_loss : 0.1364, Time/batch_file : 9.0536, Training time: 15288.9517\n",
      "Epoch : 331/500 data_batch_1,  Train_loss : 0.1280  Test_loss : 0.1398, Time/batch_file : 9.2404, Training time: 15303.3531\n",
      "Epoch : 331/500 data_batch_2,  Train_loss : 0.1316  Test_loss : 0.1424, Time/batch_file : 9.2575, Training time: 15312.6109\n",
      "Epoch : 331/500 data_batch_3,  Train_loss : 0.1233  Test_loss : 0.1385, Time/batch_file : 9.2352, Training time: 15321.8465\n",
      "Epoch : 331/500 data_batch_4,  Train_loss : 0.1284  Test_loss : 0.1392, Time/batch_file : 9.0428, Training time: 15330.8896\n",
      "Epoch : 331/500 data_batch_5,  Train_loss : 0.1279  Test_loss : 0.1394, Time/batch_file : 9.0883, Training time: 15339.9782\n",
      "Epoch : 332/500 data_batch_1,  Train_loss : 0.1357  Test_loss : 0.1354, Time/batch_file : 9.4884, Training time: 15349.4669\n",
      "Epoch : 332/500 data_batch_2,  Train_loss : 0.1340  Test_loss : 0.1380, Time/batch_file : 9.2623, Training time: 15358.7296\n",
      "Epoch : 332/500 data_batch_3,  Train_loss : 0.1389  Test_loss : 0.1374, Time/batch_file : 9.2477, Training time: 15367.9776\n",
      "Epoch : 332/500 data_batch_4,  Train_loss : 0.1345  Test_loss : 0.1338, Time/batch_file : 9.2523, Training time: 15377.2302\n",
      "Epoch : 332/500 data_batch_5,  Train_loss : 0.1279  Test_loss : 0.1395, Time/batch_file : 9.1051, Training time: 15386.3354\n",
      "Epoch : 333/500 data_batch_1,  Train_loss : 0.1374  Test_loss : 0.1349, Time/batch_file : 9.4059, Training time: 15395.7418\n",
      "Epoch : 333/500 data_batch_2,  Train_loss : 0.1434  Test_loss : 0.1327, Time/batch_file : 9.2134, Training time: 15404.9555\n",
      "Epoch : 333/500 data_batch_3,  Train_loss : 0.1433  Test_loss : 0.1322, Time/batch_file : 9.0130, Training time: 15413.9687\n",
      "Epoch : 333/500 data_batch_4,  Train_loss : 0.1417  Test_loss : 0.1317, Time/batch_file : 9.1661, Training time: 15423.1352\n",
      "Epoch : 333/500 data_batch_5,  Train_loss : 0.1398  Test_loss : 0.1367, Time/batch_file : 9.3910, Training time: 15432.5264\n",
      "Epoch : 334/500 data_batch_1,  Train_loss : 0.1388  Test_loss : 0.1406, Time/batch_file : 9.4314, Training time: 15441.9581\n",
      "Epoch : 334/500 data_batch_2,  Train_loss : 0.1379  Test_loss : 0.1403, Time/batch_file : 9.1809, Training time: 15451.1393\n",
      "Epoch : 334/500 data_batch_3,  Train_loss : 0.1321  Test_loss : 0.1428, Time/batch_file : 9.0204, Training time: 15460.1600\n",
      "Epoch : 334/500 data_batch_4,  Train_loss : 0.1375  Test_loss : 0.1453, Time/batch_file : 9.2145, Training time: 15469.3748\n",
      "Epoch : 334/500 data_batch_5,  Train_loss : 0.1360  Test_loss : 0.1347, Time/batch_file : 9.2046, Training time: 15478.5798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 335/500 data_batch_1,  Train_loss : 0.1322  Test_loss : 0.1411, Time/batch_file : 9.4684, Training time: 15488.0485\n",
      "Epoch : 335/500 data_batch_2,  Train_loss : 0.1338  Test_loss : 0.1431, Time/batch_file : 9.1496, Training time: 15497.1985\n",
      "Epoch : 335/500 data_batch_3,  Train_loss : 0.1338  Test_loss : 0.1436, Time/batch_file : 9.2639, Training time: 15506.4626\n",
      "Epoch : 335/500 data_batch_4,  Train_loss : 0.1357  Test_loss : 0.1383, Time/batch_file : 9.0657, Training time: 15515.5285\n",
      "Epoch : 335/500 data_batch_5,  Train_loss : 0.1357  Test_loss : 0.1431, Time/batch_file : 9.4021, Training time: 15524.9309\n",
      "Epoch : 336/500 data_batch_1,  Train_loss : 0.1383  Test_loss : 0.1462, Time/batch_file : 9.2778, Training time: 15535.8362\n",
      "Epoch : 336/500 data_batch_2,  Train_loss : 0.1420  Test_loss : 0.1428, Time/batch_file : 9.1290, Training time: 15544.9655\n",
      "Epoch : 336/500 data_batch_3,  Train_loss : 0.1415  Test_loss : 0.1503, Time/batch_file : 9.2374, Training time: 15554.2033\n",
      "Epoch : 336/500 data_batch_4,  Train_loss : 0.1420  Test_loss : 0.1497, Time/batch_file : 9.3820, Training time: 15563.5855\n",
      "Epoch : 336/500 data_batch_5,  Train_loss : 0.1358  Test_loss : 0.1465, Time/batch_file : 8.9036, Training time: 15572.4893\n",
      "Epoch : 337/500 data_batch_1,  Train_loss : 0.1376  Test_loss : 0.1575, Time/batch_file : 9.0985, Training time: 15581.5882\n",
      "Epoch : 337/500 data_batch_2,  Train_loss : 0.1398  Test_loss : 0.1547, Time/batch_file : 9.0509, Training time: 15590.6394\n",
      "Epoch : 337/500 data_batch_3,  Train_loss : 0.1376  Test_loss : 0.1582, Time/batch_file : 9.1740, Training time: 15599.8138\n",
      "Epoch : 337/500 data_batch_4,  Train_loss : 0.1400  Test_loss : 0.1606, Time/batch_file : 9.0849, Training time: 15608.8990\n",
      "Epoch : 337/500 data_batch_5,  Train_loss : 0.1375  Test_loss : 0.1549, Time/batch_file : 9.2344, Training time: 15618.1337\n",
      "Epoch : 338/500 data_batch_1,  Train_loss : 0.1475  Test_loss : 0.1296, Time/batch_file : 9.3301, Training time: 15627.4640\n",
      "Epoch : 338/500 data_batch_2,  Train_loss : 0.1389  Test_loss : 0.1337, Time/batch_file : 9.2302, Training time: 15636.6946\n",
      "Epoch : 338/500 data_batch_3,  Train_loss : 0.1399  Test_loss : 0.1350, Time/batch_file : 9.0619, Training time: 15645.7567\n",
      "Epoch : 338/500 data_batch_4,  Train_loss : 0.1386  Test_loss : 0.1340, Time/batch_file : 9.3418, Training time: 15655.0989\n",
      "Epoch : 338/500 data_batch_5,  Train_loss : 0.1363  Test_loss : 0.1237, Time/batch_file : 9.3063, Training time: 15664.4055\n",
      "Epoch : 339/500 data_batch_1,  Train_loss : 0.1415  Test_loss : 0.1364, Time/batch_file : 9.2185, Training time: 15673.6244\n",
      "Epoch : 339/500 data_batch_2,  Train_loss : 0.1431  Test_loss : 0.1390, Time/batch_file : 9.1543, Training time: 15682.7790\n",
      "Epoch : 339/500 data_batch_3,  Train_loss : 0.1445  Test_loss : 0.1440, Time/batch_file : 9.4570, Training time: 15692.2362\n",
      "Epoch : 339/500 data_batch_4,  Train_loss : 0.1409  Test_loss : 0.1376, Time/batch_file : 9.2574, Training time: 15701.4939\n",
      "Epoch : 339/500 data_batch_5,  Train_loss : 0.1443  Test_loss : 0.1318, Time/batch_file : 9.2743, Training time: 15710.7684\n",
      "Epoch : 340/500 data_batch_1,  Train_loss : 0.1350  Test_loss : 0.1404, Time/batch_file : 8.9887, Training time: 15719.7575\n",
      "Epoch : 340/500 data_batch_2,  Train_loss : 0.1368  Test_loss : 0.1412, Time/batch_file : 9.0116, Training time: 15728.7693\n",
      "Epoch : 340/500 data_batch_3,  Train_loss : 0.1375  Test_loss : 0.1451, Time/batch_file : 9.1375, Training time: 15737.9072\n",
      "Epoch : 340/500 data_batch_4,  Train_loss : 0.1402  Test_loss : 0.1403, Time/batch_file : 9.3441, Training time: 15747.2515\n",
      "Epoch : 340/500 data_batch_5,  Train_loss : 0.1356  Test_loss : 0.1439, Time/batch_file : 9.0010, Training time: 15756.2529\n",
      "[./nets/net-340.ckpt] SAVED\n",
      "Epoch : 341/500 data_batch_1,  Train_loss : 0.1425  Test_loss : 0.1409, Time/batch_file : 9.4806, Training time: 15767.6511\n",
      "Epoch : 341/500 data_batch_2,  Train_loss : 0.1445  Test_loss : 0.1404, Time/batch_file : 9.0453, Training time: 15776.6967\n",
      "Epoch : 341/500 data_batch_3,  Train_loss : 0.1442  Test_loss : 0.1384, Time/batch_file : 9.2699, Training time: 15785.9669\n",
      "Epoch : 341/500 data_batch_4,  Train_loss : 0.1433  Test_loss : 0.1419, Time/batch_file : 9.0900, Training time: 15795.0572\n",
      "Epoch : 341/500 data_batch_5,  Train_loss : 0.1384  Test_loss : 0.1414, Time/batch_file : 9.0922, Training time: 15804.1497\n",
      "Epoch : 342/500 data_batch_1,  Train_loss : 0.1515  Test_loss : 0.1412, Time/batch_file : 9.1420, Training time: 15813.2919\n",
      "Epoch : 342/500 data_batch_2,  Train_loss : 0.1519  Test_loss : 0.1399, Time/batch_file : 9.1374, Training time: 15822.4296\n",
      "Epoch : 342/500 data_batch_3,  Train_loss : 0.1492  Test_loss : 0.1419, Time/batch_file : 9.0359, Training time: 15831.4659\n",
      "Epoch : 342/500 data_batch_4,  Train_loss : 0.1464  Test_loss : 0.1359, Time/batch_file : 9.2723, Training time: 15840.7386\n",
      "Epoch : 342/500 data_batch_5,  Train_loss : 0.1455  Test_loss : 0.1391, Time/batch_file : 9.2707, Training time: 15850.0095\n",
      "Epoch : 343/500 data_batch_1,  Train_loss : 0.1346  Test_loss : 0.1400, Time/batch_file : 9.4947, Training time: 15859.5045\n",
      "Epoch : 343/500 data_batch_2,  Train_loss : 0.1330  Test_loss : 0.1360, Time/batch_file : 8.9529, Training time: 15868.4577\n",
      "Epoch : 343/500 data_batch_3,  Train_loss : 0.1354  Test_loss : 0.1454, Time/batch_file : 9.1190, Training time: 15877.5770\n",
      "Epoch : 343/500 data_batch_4,  Train_loss : 0.1342  Test_loss : 0.1412, Time/batch_file : 9.1546, Training time: 15886.7320\n",
      "Epoch : 343/500 data_batch_5,  Train_loss : 0.1328  Test_loss : 0.1452, Time/batch_file : 9.1349, Training time: 15895.8672\n",
      "Epoch : 344/500 data_batch_1,  Train_loss : 0.1441  Test_loss : 0.1364, Time/batch_file : 9.2849, Training time: 15905.1524\n",
      "Epoch : 344/500 data_batch_2,  Train_loss : 0.1422  Test_loss : 0.1430, Time/batch_file : 9.2436, Training time: 15914.3963\n",
      "Epoch : 344/500 data_batch_3,  Train_loss : 0.1432  Test_loss : 0.1388, Time/batch_file : 9.0864, Training time: 15923.4829\n",
      "Epoch : 344/500 data_batch_4,  Train_loss : 0.1434  Test_loss : 0.1377, Time/batch_file : 9.3382, Training time: 15932.8214\n",
      "Epoch : 344/500 data_batch_5,  Train_loss : 0.1426  Test_loss : 0.1357, Time/batch_file : 9.1051, Training time: 15941.9268\n",
      "Epoch : 345/500 data_batch_1,  Train_loss : 0.1376  Test_loss : 0.1411, Time/batch_file : 9.0566, Training time: 15950.9837\n",
      "Epoch : 345/500 data_batch_2,  Train_loss : 0.1380  Test_loss : 0.1401, Time/batch_file : 9.1262, Training time: 15960.1102\n",
      "Epoch : 345/500 data_batch_3,  Train_loss : 0.1356  Test_loss : 0.1445, Time/batch_file : 9.2391, Training time: 15969.3496\n",
      "Epoch : 345/500 data_batch_4,  Train_loss : 0.1394  Test_loss : 0.1429, Time/batch_file : 9.2107, Training time: 15978.5605\n",
      "Epoch : 345/500 data_batch_5,  Train_loss : 0.1373  Test_loss : 0.1395, Time/batch_file : 9.2492, Training time: 15987.8100\n",
      "Epoch : 346/500 data_batch_1,  Train_loss : 0.1424  Test_loss : 0.1402, Time/batch_file : 9.1292, Training time: 15998.5825\n",
      "Epoch : 346/500 data_batch_2,  Train_loss : 0.1411  Test_loss : 0.1383, Time/batch_file : 9.4623, Training time: 16008.0451\n",
      "Epoch : 346/500 data_batch_3,  Train_loss : 0.1418  Test_loss : 0.1440, Time/batch_file : 9.0594, Training time: 16017.1049\n",
      "Epoch : 346/500 data_batch_4,  Train_loss : 0.1441  Test_loss : 0.1363, Time/batch_file : 9.5627, Training time: 16026.6680\n",
      "Epoch : 346/500 data_batch_5,  Train_loss : 0.1481  Test_loss : 0.1318, Time/batch_file : 8.8595, Training time: 16035.5280\n",
      "Epoch : 347/500 data_batch_1,  Train_loss : 0.1346  Test_loss : 0.1358, Time/batch_file : 9.0702, Training time: 16044.5984\n",
      "Epoch : 347/500 data_batch_2,  Train_loss : 0.1321  Test_loss : 0.1359, Time/batch_file : 9.4126, Training time: 16054.0114\n",
      "Epoch : 347/500 data_batch_3,  Train_loss : 0.1350  Test_loss : 0.1384, Time/batch_file : 9.2652, Training time: 16063.2770\n",
      "Epoch : 347/500 data_batch_4,  Train_loss : 0.1333  Test_loss : 0.1373, Time/batch_file : 9.1629, Training time: 16072.4402\n",
      "Epoch : 347/500 data_batch_5,  Train_loss : 0.1316  Test_loss : 0.1333, Time/batch_file : 9.1961, Training time: 16081.6366\n",
      "Epoch : 348/500 data_batch_1,  Train_loss : 0.1393  Test_loss : 0.1438, Time/batch_file : 9.2217, Training time: 16090.8586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 348/500 data_batch_2,  Train_loss : 0.1401  Test_loss : 0.1424, Time/batch_file : 9.2532, Training time: 16100.1120\n",
      "Epoch : 348/500 data_batch_3,  Train_loss : 0.1446  Test_loss : 0.1406, Time/batch_file : 9.1096, Training time: 16109.2219\n",
      "Epoch : 348/500 data_batch_4,  Train_loss : 0.1423  Test_loss : 0.1440, Time/batch_file : 9.0637, Training time: 16118.2859\n",
      "Epoch : 348/500 data_batch_5,  Train_loss : 0.1463  Test_loss : 0.1432, Time/batch_file : 9.1171, Training time: 16127.4033\n",
      "Epoch : 349/500 data_batch_1,  Train_loss : 0.1408  Test_loss : 0.1341, Time/batch_file : 9.0624, Training time: 16136.4661\n",
      "Epoch : 349/500 data_batch_2,  Train_loss : 0.1370  Test_loss : 0.1326, Time/batch_file : 9.1642, Training time: 16145.6307\n",
      "Epoch : 349/500 data_batch_3,  Train_loss : 0.1386  Test_loss : 0.1253, Time/batch_file : 9.1811, Training time: 16154.8120\n",
      "Epoch : 349/500 data_batch_4,  Train_loss : 0.1360  Test_loss : 0.1239, Time/batch_file : 9.0233, Training time: 16163.8356\n",
      "Epoch : 349/500 data_batch_5,  Train_loss : 0.1376  Test_loss : 0.1348, Time/batch_file : 9.2979, Training time: 16173.1339\n",
      "Epoch : 350/500 data_batch_1,  Train_loss : 0.1447  Test_loss : 0.1299, Time/batch_file : 9.4543, Training time: 16182.5884\n",
      "Epoch : 350/500 data_batch_2,  Train_loss : 0.1447  Test_loss : 0.1273, Time/batch_file : 9.1239, Training time: 16191.7126\n",
      "Epoch : 350/500 data_batch_3,  Train_loss : 0.1475  Test_loss : 0.1327, Time/batch_file : 9.0269, Training time: 16200.7398\n",
      "Epoch : 350/500 data_batch_4,  Train_loss : 0.1447  Test_loss : 0.1345, Time/batch_file : 9.7105, Training time: 16210.4505\n",
      "Epoch : 350/500 data_batch_5,  Train_loss : 0.1450  Test_loss : 0.1291, Time/batch_file : 9.5886, Training time: 16220.0394\n",
      "Epoch : 351/500 data_batch_1,  Train_loss : 0.1301  Test_loss : 0.1362, Time/batch_file : 9.0233, Training time: 16230.6697\n",
      "Epoch : 351/500 data_batch_2,  Train_loss : 0.1362  Test_loss : 0.1375, Time/batch_file : 9.0859, Training time: 16239.7560\n",
      "Epoch : 351/500 data_batch_3,  Train_loss : 0.1337  Test_loss : 0.1427, Time/batch_file : 9.1062, Training time: 16248.8624\n",
      "Epoch : 351/500 data_batch_4,  Train_loss : 0.1416  Test_loss : 0.1416, Time/batch_file : 9.1355, Training time: 16257.9982\n",
      "Epoch : 351/500 data_batch_5,  Train_loss : 0.1379  Test_loss : 0.1391, Time/batch_file : 9.3459, Training time: 16267.3444\n",
      "Epoch : 352/500 data_batch_1,  Train_loss : 0.1376  Test_loss : 0.1418, Time/batch_file : 9.0859, Training time: 16276.4305\n",
      "Epoch : 352/500 data_batch_2,  Train_loss : 0.1472  Test_loss : 0.1410, Time/batch_file : 9.4554, Training time: 16285.8861\n",
      "Epoch : 352/500 data_batch_3,  Train_loss : 0.1480  Test_loss : 0.1392, Time/batch_file : 9.1860, Training time: 16295.0725\n",
      "Epoch : 352/500 data_batch_4,  Train_loss : 0.1417  Test_loss : 0.1406, Time/batch_file : 9.2142, Training time: 16304.2870\n",
      "Epoch : 352/500 data_batch_5,  Train_loss : 0.1467  Test_loss : 0.1426, Time/batch_file : 9.0962, Training time: 16313.3834\n",
      "Epoch : 353/500 data_batch_1,  Train_loss : 0.1402  Test_loss : 0.1378, Time/batch_file : 9.1306, Training time: 16322.5144\n",
      "Epoch : 353/500 data_batch_2,  Train_loss : 0.1427  Test_loss : 0.1441, Time/batch_file : 8.9447, Training time: 16331.4595\n",
      "Epoch : 353/500 data_batch_3,  Train_loss : 0.1328  Test_loss : 0.1418, Time/batch_file : 9.1369, Training time: 16340.5968\n",
      "Epoch : 353/500 data_batch_4,  Train_loss : 0.1352  Test_loss : 0.1481, Time/batch_file : 9.0542, Training time: 16349.6513\n",
      "Epoch : 353/500 data_batch_5,  Train_loss : 0.1334  Test_loss : 0.1434, Time/batch_file : 8.9897, Training time: 16358.6412\n",
      "Epoch : 354/500 data_batch_1,  Train_loss : 0.1401  Test_loss : 0.1347, Time/batch_file : 8.9704, Training time: 16367.6119\n",
      "Epoch : 354/500 data_batch_2,  Train_loss : 0.1532  Test_loss : 0.1297, Time/batch_file : 8.9957, Training time: 16376.6079\n",
      "Epoch : 354/500 data_batch_3,  Train_loss : 0.1476  Test_loss : 0.1263, Time/batch_file : 9.0467, Training time: 16385.6550\n",
      "Epoch : 354/500 data_batch_4,  Train_loss : 0.1450  Test_loss : 0.1322, Time/batch_file : 9.1187, Training time: 16394.7741\n",
      "Epoch : 354/500 data_batch_5,  Train_loss : 0.1417  Test_loss : 0.1344, Time/batch_file : 8.8830, Training time: 16403.6573\n",
      "Epoch : 355/500 data_batch_1,  Train_loss : 0.1368  Test_loss : 0.1385, Time/batch_file : 9.1104, Training time: 16412.7681\n",
      "Epoch : 355/500 data_batch_2,  Train_loss : 0.1400  Test_loss : 0.1389, Time/batch_file : 9.0631, Training time: 16421.8314\n",
      "Epoch : 355/500 data_batch_3,  Train_loss : 0.1419  Test_loss : 0.1413, Time/batch_file : 9.3846, Training time: 16431.2163\n",
      "Epoch : 355/500 data_batch_4,  Train_loss : 0.1446  Test_loss : 0.1419, Time/batch_file : 9.2983, Training time: 16440.5149\n",
      "Epoch : 355/500 data_batch_5,  Train_loss : 0.1406  Test_loss : 0.1392, Time/batch_file : 9.4729, Training time: 16449.9883\n",
      "Epoch : 356/500 data_batch_1,  Train_loss : 0.1522  Test_loss : 0.1512, Time/batch_file : 9.2462, Training time: 16460.9891\n",
      "Epoch : 356/500 data_batch_2,  Train_loss : 0.1487  Test_loss : 0.1456, Time/batch_file : 9.1635, Training time: 16470.1529\n",
      "Epoch : 356/500 data_batch_3,  Train_loss : 0.1504  Test_loss : 0.1534, Time/batch_file : 9.1166, Training time: 16479.2698\n",
      "Epoch : 356/500 data_batch_4,  Train_loss : 0.1538  Test_loss : 0.1497, Time/batch_file : 9.1927, Training time: 16488.4630\n",
      "Epoch : 356/500 data_batch_5,  Train_loss : 0.1481  Test_loss : 0.1474, Time/batch_file : 9.0979, Training time: 16497.5611\n",
      "Epoch : 357/500 data_batch_1,  Train_loss : 0.1473  Test_loss : 0.1544, Time/batch_file : 9.1229, Training time: 16506.6844\n",
      "Epoch : 357/500 data_batch_2,  Train_loss : 0.1432  Test_loss : 0.1456, Time/batch_file : 8.9651, Training time: 16515.6499\n",
      "Epoch : 357/500 data_batch_3,  Train_loss : 0.1464  Test_loss : 0.1479, Time/batch_file : 8.9418, Training time: 16524.5920\n",
      "Epoch : 357/500 data_batch_4,  Train_loss : 0.1375  Test_loss : 0.1510, Time/batch_file : 9.1820, Training time: 16533.7742\n",
      "Epoch : 357/500 data_batch_5,  Train_loss : 0.1442  Test_loss : 0.1488, Time/batch_file : 9.2196, Training time: 16542.9941\n",
      "Epoch : 358/500 data_batch_1,  Train_loss : 0.1460  Test_loss : 0.1408, Time/batch_file : 9.4916, Training time: 16552.4860\n",
      "Epoch : 358/500 data_batch_2,  Train_loss : 0.1409  Test_loss : 0.1406, Time/batch_file : 9.1497, Training time: 16561.6359\n",
      "Epoch : 358/500 data_batch_3,  Train_loss : 0.1427  Test_loss : 0.1443, Time/batch_file : 9.1525, Training time: 16570.7886\n",
      "Epoch : 358/500 data_batch_4,  Train_loss : 0.1401  Test_loss : 0.1414, Time/batch_file : 9.1771, Training time: 16579.9661\n",
      "Epoch : 358/500 data_batch_5,  Train_loss : 0.1445  Test_loss : 0.1394, Time/batch_file : 9.1445, Training time: 16589.1110\n",
      "Epoch : 359/500 data_batch_1,  Train_loss : 0.1455  Test_loss : 0.1486, Time/batch_file : 9.3602, Training time: 16598.4714\n",
      "Epoch : 359/500 data_batch_2,  Train_loss : 0.1442  Test_loss : 0.1433, Time/batch_file : 9.1523, Training time: 16607.6240\n",
      "Epoch : 359/500 data_batch_3,  Train_loss : 0.1461  Test_loss : 0.1388, Time/batch_file : 9.2189, Training time: 16616.8432\n",
      "Epoch : 359/500 data_batch_4,  Train_loss : 0.1519  Test_loss : 0.1434, Time/batch_file : 9.0496, Training time: 16625.8930\n",
      "Epoch : 359/500 data_batch_5,  Train_loss : 0.1459  Test_loss : 0.1447, Time/batch_file : 9.0851, Training time: 16634.9785\n",
      "Epoch : 360/500 data_batch_1,  Train_loss : 0.1360  Test_loss : 0.1431, Time/batch_file : 9.2261, Training time: 16644.2048\n",
      "Epoch : 360/500 data_batch_2,  Train_loss : 0.1355  Test_loss : 0.1422, Time/batch_file : 9.3314, Training time: 16653.5366\n",
      "Epoch : 360/500 data_batch_3,  Train_loss : 0.1420  Test_loss : 0.1439, Time/batch_file : 9.1515, Training time: 16662.6883\n",
      "Epoch : 360/500 data_batch_4,  Train_loss : 0.1393  Test_loss : 0.1443, Time/batch_file : 9.1298, Training time: 16671.8186\n",
      "Epoch : 360/500 data_batch_5,  Train_loss : 0.1407  Test_loss : 0.1409, Time/batch_file : 9.0925, Training time: 16680.9113\n",
      "[./nets/net-360.ckpt] SAVED\n",
      "Epoch : 361/500 data_batch_1,  Train_loss : 0.1356  Test_loss : 0.1455, Time/batch_file : 9.2632, Training time: 16691.8379\n",
      "Epoch : 361/500 data_batch_2,  Train_loss : 0.1348  Test_loss : 0.1431, Time/batch_file : 9.1326, Training time: 16700.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 361/500 data_batch_3,  Train_loss : 0.1375  Test_loss : 0.1489, Time/batch_file : 9.1027, Training time: 16710.0737\n",
      "Epoch : 361/500 data_batch_4,  Train_loss : 0.1322  Test_loss : 0.1464, Time/batch_file : 9.0238, Training time: 16719.0977\n",
      "Epoch : 361/500 data_batch_5,  Train_loss : 0.1363  Test_loss : 0.1553, Time/batch_file : 9.1670, Training time: 16728.2649\n",
      "Epoch : 362/500 data_batch_1,  Train_loss : 0.1318  Test_loss : 0.1377, Time/batch_file : 9.1426, Training time: 16737.4078\n",
      "Epoch : 362/500 data_batch_2,  Train_loss : 0.1337  Test_loss : 0.1296, Time/batch_file : 9.2829, Training time: 16746.6909\n",
      "Epoch : 362/500 data_batch_3,  Train_loss : 0.1339  Test_loss : 0.1404, Time/batch_file : 9.2539, Training time: 16755.9452\n",
      "Epoch : 362/500 data_batch_4,  Train_loss : 0.1358  Test_loss : 0.1395, Time/batch_file : 9.2132, Training time: 16765.1585\n",
      "Epoch : 362/500 data_batch_5,  Train_loss : 0.1376  Test_loss : 0.1367, Time/batch_file : 9.0522, Training time: 16774.2109\n",
      "Epoch : 363/500 data_batch_1,  Train_loss : 0.1361  Test_loss : 0.1375, Time/batch_file : 9.4504, Training time: 16783.6615\n",
      "Epoch : 363/500 data_batch_2,  Train_loss : 0.1329  Test_loss : 0.1398, Time/batch_file : 8.9594, Training time: 16792.6212\n",
      "Epoch : 363/500 data_batch_3,  Train_loss : 0.1396  Test_loss : 0.1413, Time/batch_file : 9.2126, Training time: 16801.8342\n",
      "Epoch : 363/500 data_batch_4,  Train_loss : 0.1312  Test_loss : 0.1424, Time/batch_file : 8.9781, Training time: 16810.8126\n",
      "Epoch : 363/500 data_batch_5,  Train_loss : 0.1362  Test_loss : 0.1363, Time/batch_file : 9.3245, Training time: 16820.1373\n",
      "Epoch : 364/500 data_batch_1,  Train_loss : 0.1475  Test_loss : 0.1372, Time/batch_file : 9.2468, Training time: 16829.3845\n",
      "Epoch : 364/500 data_batch_2,  Train_loss : 0.1541  Test_loss : 0.1389, Time/batch_file : 9.0980, Training time: 16838.4828\n",
      "Epoch : 364/500 data_batch_3,  Train_loss : 0.1453  Test_loss : 0.1357, Time/batch_file : 9.1689, Training time: 16847.6519\n",
      "Epoch : 364/500 data_batch_4,  Train_loss : 0.1517  Test_loss : 0.1386, Time/batch_file : 9.2516, Training time: 16856.9038\n",
      "Epoch : 364/500 data_batch_5,  Train_loss : 0.1453  Test_loss : 0.1362, Time/batch_file : 9.4213, Training time: 16866.3253\n",
      "Epoch : 365/500 data_batch_1,  Train_loss : 0.1400  Test_loss : 0.1434, Time/batch_file : 9.1999, Training time: 16875.5255\n",
      "Epoch : 365/500 data_batch_2,  Train_loss : 0.1418  Test_loss : 0.1367, Time/batch_file : 9.1190, Training time: 16884.6449\n",
      "Epoch : 365/500 data_batch_3,  Train_loss : 0.1437  Test_loss : 0.1371, Time/batch_file : 9.1255, Training time: 16893.7706\n",
      "Epoch : 365/500 data_batch_4,  Train_loss : 0.1402  Test_loss : 0.1368, Time/batch_file : 9.2956, Training time: 16903.0665\n",
      "Epoch : 365/500 data_batch_5,  Train_loss : 0.1434  Test_loss : 0.1380, Time/batch_file : 9.4826, Training time: 16912.5493\n",
      "Epoch : 366/500 data_batch_1,  Train_loss : 0.1370  Test_loss : 0.1266, Time/batch_file : 9.2882, Training time: 16923.3731\n",
      "Epoch : 366/500 data_batch_2,  Train_loss : 0.1360  Test_loss : 0.1301, Time/batch_file : 9.1605, Training time: 16932.5338\n",
      "Epoch : 366/500 data_batch_3,  Train_loss : 0.1394  Test_loss : 0.1293, Time/batch_file : 9.2429, Training time: 16941.7770\n",
      "Epoch : 366/500 data_batch_4,  Train_loss : 0.1356  Test_loss : 0.1295, Time/batch_file : 9.4342, Training time: 16951.2114\n",
      "Epoch : 366/500 data_batch_5,  Train_loss : 0.1345  Test_loss : 0.1303, Time/batch_file : 9.0994, Training time: 16960.3112\n",
      "Epoch : 367/500 data_batch_1,  Train_loss : 0.1332  Test_loss : 0.1446, Time/batch_file : 9.1767, Training time: 16969.4881\n",
      "Epoch : 367/500 data_batch_2,  Train_loss : 0.1336  Test_loss : 0.1414, Time/batch_file : 9.3279, Training time: 16978.8163\n",
      "Epoch : 367/500 data_batch_3,  Train_loss : 0.1337  Test_loss : 0.1384, Time/batch_file : 9.0076, Training time: 16987.8242\n",
      "Epoch : 367/500 data_batch_4,  Train_loss : 0.1320  Test_loss : 0.1457, Time/batch_file : 9.1152, Training time: 16996.9398\n",
      "Epoch : 367/500 data_batch_5,  Train_loss : 0.1325  Test_loss : 0.1445, Time/batch_file : 9.0968, Training time: 17006.0369\n",
      "Epoch : 368/500 data_batch_1,  Train_loss : 0.1441  Test_loss : 0.1428, Time/batch_file : 9.2645, Training time: 17015.3018\n",
      "Epoch : 368/500 data_batch_2,  Train_loss : 0.1441  Test_loss : 0.1437, Time/batch_file : 9.0465, Training time: 17024.3488\n",
      "Epoch : 368/500 data_batch_3,  Train_loss : 0.1422  Test_loss : 0.1384, Time/batch_file : 9.0307, Training time: 17033.3798\n",
      "Epoch : 368/500 data_batch_4,  Train_loss : 0.1438  Test_loss : 0.1430, Time/batch_file : 9.3890, Training time: 17042.7692\n",
      "Epoch : 368/500 data_batch_5,  Train_loss : 0.1430  Test_loss : 0.1444, Time/batch_file : 9.2029, Training time: 17051.9724\n",
      "Epoch : 369/500 data_batch_1,  Train_loss : 0.1402  Test_loss : 0.1355, Time/batch_file : 9.1709, Training time: 17061.1437\n",
      "Epoch : 369/500 data_batch_2,  Train_loss : 0.1342  Test_loss : 0.1379, Time/batch_file : 9.3050, Training time: 17070.4490\n",
      "Epoch : 369/500 data_batch_3,  Train_loss : 0.1399  Test_loss : 0.1368, Time/batch_file : 9.1410, Training time: 17079.5906\n",
      "Epoch : 369/500 data_batch_4,  Train_loss : 0.1354  Test_loss : 0.1364, Time/batch_file : 9.0939, Training time: 17088.6847\n",
      "Epoch : 369/500 data_batch_5,  Train_loss : 0.1318  Test_loss : 0.1404, Time/batch_file : 9.4826, Training time: 17098.1676\n",
      "Epoch : 370/500 data_batch_1,  Train_loss : 0.1343  Test_loss : 0.1494, Time/batch_file : 9.5561, Training time: 17107.7240\n",
      "Epoch : 370/500 data_batch_2,  Train_loss : 0.1375  Test_loss : 0.1480, Time/batch_file : 9.0028, Training time: 17116.7272\n",
      "Epoch : 370/500 data_batch_3,  Train_loss : 0.1383  Test_loss : 0.1482, Time/batch_file : 9.0148, Training time: 17125.7423\n",
      "Epoch : 370/500 data_batch_4,  Train_loss : 0.1357  Test_loss : 0.1433, Time/batch_file : 9.1628, Training time: 17134.9055\n",
      "Epoch : 370/500 data_batch_5,  Train_loss : 0.1327  Test_loss : 0.1405, Time/batch_file : 8.9700, Training time: 17143.8757\n",
      "Epoch : 371/500 data_batch_1,  Train_loss : 0.1366  Test_loss : 0.1377, Time/batch_file : 9.5256, Training time: 17155.0508\n",
      "Epoch : 371/500 data_batch_2,  Train_loss : 0.1377  Test_loss : 0.1395, Time/batch_file : 9.0747, Training time: 17164.1258\n",
      "Epoch : 371/500 data_batch_3,  Train_loss : 0.1400  Test_loss : 0.1398, Time/batch_file : 9.1130, Training time: 17173.2391\n",
      "Epoch : 371/500 data_batch_4,  Train_loss : 0.1404  Test_loss : 0.1354, Time/batch_file : 8.9712, Training time: 17182.2106\n",
      "Epoch : 371/500 data_batch_5,  Train_loss : 0.1401  Test_loss : 0.1347, Time/batch_file : 9.3104, Training time: 17191.5213\n",
      "Epoch : 372/500 data_batch_1,  Train_loss : 0.1330  Test_loss : 0.1424, Time/batch_file : 9.0335, Training time: 17200.5551\n",
      "Epoch : 372/500 data_batch_2,  Train_loss : 0.1374  Test_loss : 0.1436, Time/batch_file : 9.1592, Training time: 17209.7147\n",
      "Epoch : 372/500 data_batch_3,  Train_loss : 0.1349  Test_loss : 0.1450, Time/batch_file : 9.3100, Training time: 17219.0249\n",
      "Epoch : 372/500 data_batch_4,  Train_loss : 0.1346  Test_loss : 0.1398, Time/batch_file : 9.1510, Training time: 17228.1762\n",
      "Epoch : 372/500 data_batch_5,  Train_loss : 0.1352  Test_loss : 0.1447, Time/batch_file : 9.3797, Training time: 17237.5563\n",
      "Epoch : 373/500 data_batch_1,  Train_loss : 0.1339  Test_loss : 0.1397, Time/batch_file : 9.1163, Training time: 17246.6728\n",
      "Epoch : 373/500 data_batch_2,  Train_loss : 0.1370  Test_loss : 0.1439, Time/batch_file : 9.4620, Training time: 17256.1351\n",
      "Epoch : 373/500 data_batch_3,  Train_loss : 0.1334  Test_loss : 0.1435, Time/batch_file : 9.2056, Training time: 17265.3410\n",
      "Epoch : 373/500 data_batch_4,  Train_loss : 0.1338  Test_loss : 0.1441, Time/batch_file : 9.2070, Training time: 17274.5482\n",
      "Epoch : 373/500 data_batch_5,  Train_loss : 0.1330  Test_loss : 0.1375, Time/batch_file : 9.2579, Training time: 17283.8064\n",
      "Epoch : 374/500 data_batch_1,  Train_loss : 0.1322  Test_loss : 0.1436, Time/batch_file : 9.3349, Training time: 17293.1417\n",
      "Epoch : 374/500 data_batch_2,  Train_loss : 0.1371  Test_loss : 0.1434, Time/batch_file : 9.1463, Training time: 17302.2883\n",
      "Epoch : 374/500 data_batch_3,  Train_loss : 0.1320  Test_loss : 0.1393, Time/batch_file : 9.1122, Training time: 17311.4007\n",
      "Epoch : 374/500 data_batch_4,  Train_loss : 0.1331  Test_loss : 0.1411, Time/batch_file : 9.0551, Training time: 17320.4562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 374/500 data_batch_5,  Train_loss : 0.1325  Test_loss : 0.1410, Time/batch_file : 9.1435, Training time: 17329.6000\n",
      "Epoch : 375/500 data_batch_1,  Train_loss : 0.1498  Test_loss : 0.1360, Time/batch_file : 9.3457, Training time: 17338.9460\n",
      "Epoch : 375/500 data_batch_2,  Train_loss : 0.1441  Test_loss : 0.1427, Time/batch_file : 9.3597, Training time: 17348.3061\n",
      "Epoch : 375/500 data_batch_3,  Train_loss : 0.1405  Test_loss : 0.1387, Time/batch_file : 9.2955, Training time: 17357.6019\n",
      "Epoch : 375/500 data_batch_4,  Train_loss : 0.1445  Test_loss : 0.1312, Time/batch_file : 9.1840, Training time: 17366.7861\n",
      "Epoch : 375/500 data_batch_5,  Train_loss : 0.1431  Test_loss : 0.1363, Time/batch_file : 9.0310, Training time: 17375.8174\n",
      "Epoch : 376/500 data_batch_1,  Train_loss : 0.1349  Test_loss : 0.1450, Time/batch_file : 8.9257, Training time: 17386.5231\n",
      "Epoch : 376/500 data_batch_2,  Train_loss : 0.1312  Test_loss : 0.1395, Time/batch_file : 9.1191, Training time: 17395.6425\n",
      "Epoch : 376/500 data_batch_3,  Train_loss : 0.1363  Test_loss : 0.1391, Time/batch_file : 9.1883, Training time: 17404.8310\n",
      "Epoch : 376/500 data_batch_4,  Train_loss : 0.1347  Test_loss : 0.1441, Time/batch_file : 9.1231, Training time: 17413.9544\n",
      "Epoch : 376/500 data_batch_5,  Train_loss : 0.1385  Test_loss : 0.1411, Time/batch_file : 9.6257, Training time: 17423.5804\n",
      "Epoch : 377/500 data_batch_1,  Train_loss : 0.1369  Test_loss : 0.1402, Time/batch_file : 9.2262, Training time: 17432.8068\n",
      "Epoch : 377/500 data_batch_2,  Train_loss : 0.1370  Test_loss : 0.1450, Time/batch_file : 9.1027, Training time: 17441.9098\n",
      "Epoch : 377/500 data_batch_3,  Train_loss : 0.1378  Test_loss : 0.1441, Time/batch_file : 9.1086, Training time: 17451.0187\n",
      "Epoch : 377/500 data_batch_4,  Train_loss : 0.1440  Test_loss : 0.1378, Time/batch_file : 9.2954, Training time: 17460.3144\n",
      "Epoch : 377/500 data_batch_5,  Train_loss : 0.1408  Test_loss : 0.1416, Time/batch_file : 9.0188, Training time: 17469.3336\n",
      "Epoch : 378/500 data_batch_1,  Train_loss : 0.1433  Test_loss : 0.1348, Time/batch_file : 9.2334, Training time: 17478.5673\n",
      "Epoch : 378/500 data_batch_2,  Train_loss : 0.1442  Test_loss : 0.1416, Time/batch_file : 9.2127, Training time: 17487.7802\n",
      "Epoch : 378/500 data_batch_3,  Train_loss : 0.1407  Test_loss : 0.1374, Time/batch_file : 9.0996, Training time: 17496.8800\n",
      "Epoch : 378/500 data_batch_4,  Train_loss : 0.1430  Test_loss : 0.1350, Time/batch_file : 9.1401, Training time: 17506.0204\n",
      "Epoch : 378/500 data_batch_5,  Train_loss : 0.1452  Test_loss : 0.1327, Time/batch_file : 9.1235, Training time: 17515.1442\n",
      "Epoch : 379/500 data_batch_1,  Train_loss : 0.1428  Test_loss : 0.1439, Time/batch_file : 9.1703, Training time: 17524.3149\n",
      "Epoch : 379/500 data_batch_2,  Train_loss : 0.1411  Test_loss : 0.1448, Time/batch_file : 9.2857, Training time: 17533.6007\n",
      "Epoch : 379/500 data_batch_3,  Train_loss : 0.1439  Test_loss : 0.1439, Time/batch_file : 9.3389, Training time: 17542.9399\n",
      "Epoch : 379/500 data_batch_4,  Train_loss : 0.1475  Test_loss : 0.1435, Time/batch_file : 9.2322, Training time: 17552.1725\n",
      "Epoch : 379/500 data_batch_5,  Train_loss : 0.1445  Test_loss : 0.1474, Time/batch_file : 9.0946, Training time: 17561.2675\n",
      "Epoch : 380/500 data_batch_1,  Train_loss : 0.1444  Test_loss : 0.1408, Time/batch_file : 9.0933, Training time: 17570.3610\n",
      "Epoch : 380/500 data_batch_2,  Train_loss : 0.1434  Test_loss : 0.1429, Time/batch_file : 8.9181, Training time: 17579.2794\n",
      "Epoch : 380/500 data_batch_3,  Train_loss : 0.1396  Test_loss : 0.1439, Time/batch_file : 9.2201, Training time: 17588.4998\n",
      "Epoch : 380/500 data_batch_4,  Train_loss : 0.1476  Test_loss : 0.1441, Time/batch_file : 9.2504, Training time: 17597.7504\n",
      "Epoch : 380/500 data_batch_5,  Train_loss : 0.1456  Test_loss : 0.1414, Time/batch_file : 9.2363, Training time: 17606.9870\n",
      "[./nets/net-380.ckpt] SAVED\n",
      "Epoch : 381/500 data_batch_1,  Train_loss : 0.1389  Test_loss : 0.1311, Time/batch_file : 9.4524, Training time: 17618.2255\n",
      "Epoch : 381/500 data_batch_2,  Train_loss : 0.1395  Test_loss : 0.1333, Time/batch_file : 9.3187, Training time: 17627.5445\n",
      "Epoch : 381/500 data_batch_3,  Train_loss : 0.1418  Test_loss : 0.1294, Time/batch_file : 9.1850, Training time: 17636.7297\n",
      "Epoch : 381/500 data_batch_4,  Train_loss : 0.1414  Test_loss : 0.1373, Time/batch_file : 9.0528, Training time: 17645.7827\n",
      "Epoch : 381/500 data_batch_5,  Train_loss : 0.1385  Test_loss : 0.1345, Time/batch_file : 9.2024, Training time: 17654.9853\n",
      "Epoch : 382/500 data_batch_1,  Train_loss : 0.1271  Test_loss : 0.1419, Time/batch_file : 9.0086, Training time: 17663.9943\n",
      "Epoch : 382/500 data_batch_2,  Train_loss : 0.1291  Test_loss : 0.1354, Time/batch_file : 9.2663, Training time: 17673.2608\n",
      "Epoch : 382/500 data_batch_3,  Train_loss : 0.1235  Test_loss : 0.1394, Time/batch_file : 9.2424, Training time: 17682.5035\n",
      "Epoch : 382/500 data_batch_4,  Train_loss : 0.1233  Test_loss : 0.1381, Time/batch_file : 9.2138, Training time: 17691.7177\n",
      "Epoch : 382/500 data_batch_5,  Train_loss : 0.1251  Test_loss : 0.1366, Time/batch_file : 9.0833, Training time: 17700.8013\n",
      "Epoch : 383/500 data_batch_1,  Train_loss : 0.1447  Test_loss : 0.1426, Time/batch_file : 9.3056, Training time: 17710.1073\n",
      "Epoch : 383/500 data_batch_2,  Train_loss : 0.1409  Test_loss : 0.1430, Time/batch_file : 9.2573, Training time: 17719.3648\n",
      "Epoch : 383/500 data_batch_3,  Train_loss : 0.1392  Test_loss : 0.1456, Time/batch_file : 9.2494, Training time: 17728.6145\n",
      "Epoch : 383/500 data_batch_4,  Train_loss : 0.1383  Test_loss : 0.1402, Time/batch_file : 9.2721, Training time: 17737.8867\n",
      "Epoch : 383/500 data_batch_5,  Train_loss : 0.1434  Test_loss : 0.1449, Time/batch_file : 9.0970, Training time: 17746.9840\n",
      "Epoch : 384/500 data_batch_1,  Train_loss : 0.1300  Test_loss : 0.1289, Time/batch_file : 8.9167, Training time: 17755.9011\n",
      "Epoch : 384/500 data_batch_2,  Train_loss : 0.1352  Test_loss : 0.1301, Time/batch_file : 9.5309, Training time: 17765.4323\n",
      "Epoch : 384/500 data_batch_3,  Train_loss : 0.1319  Test_loss : 0.1315, Time/batch_file : 9.0534, Training time: 17774.4861\n",
      "Epoch : 384/500 data_batch_4,  Train_loss : 0.1311  Test_loss : 0.1274, Time/batch_file : 9.0602, Training time: 17783.5466\n",
      "Epoch : 384/500 data_batch_5,  Train_loss : 0.1262  Test_loss : 0.1239, Time/batch_file : 9.1632, Training time: 17792.7101\n",
      "Epoch : 385/500 data_batch_1,  Train_loss : 0.1297  Test_loss : 0.1383, Time/batch_file : 9.0848, Training time: 17801.7953\n",
      "Epoch : 385/500 data_batch_2,  Train_loss : 0.1311  Test_loss : 0.1436, Time/batch_file : 9.2176, Training time: 17811.0131\n",
      "Epoch : 385/500 data_batch_3,  Train_loss : 0.1290  Test_loss : 0.1444, Time/batch_file : 9.1214, Training time: 17820.1348\n",
      "Epoch : 385/500 data_batch_4,  Train_loss : 0.1252  Test_loss : 0.1406, Time/batch_file : 9.1226, Training time: 17829.2578\n",
      "Epoch : 385/500 data_batch_5,  Train_loss : 0.1258  Test_loss : 0.1378, Time/batch_file : 9.0024, Training time: 17838.2609\n",
      "Epoch : 386/500 data_batch_1,  Train_loss : 0.1372  Test_loss : 0.1407, Time/batch_file : 9.0983, Training time: 17848.9768\n",
      "Epoch : 386/500 data_batch_2,  Train_loss : 0.1369  Test_loss : 0.1443, Time/batch_file : 9.3723, Training time: 17858.3494\n",
      "Epoch : 386/500 data_batch_3,  Train_loss : 0.1396  Test_loss : 0.1418, Time/batch_file : 9.1688, Training time: 17867.5186\n",
      "Epoch : 386/500 data_batch_4,  Train_loss : 0.1421  Test_loss : 0.1382, Time/batch_file : 8.9149, Training time: 17876.4338\n",
      "Epoch : 386/500 data_batch_5,  Train_loss : 0.1398  Test_loss : 0.1365, Time/batch_file : 9.1464, Training time: 17885.5804\n",
      "Epoch : 387/500 data_batch_1,  Train_loss : 0.1380  Test_loss : 0.1365, Time/batch_file : 8.9610, Training time: 17894.5416\n",
      "Epoch : 387/500 data_batch_2,  Train_loss : 0.1392  Test_loss : 0.1402, Time/batch_file : 9.1534, Training time: 17903.6953\n",
      "Epoch : 387/500 data_batch_3,  Train_loss : 0.1422  Test_loss : 0.1368, Time/batch_file : 9.3580, Training time: 17913.0536\n",
      "Epoch : 387/500 data_batch_4,  Train_loss : 0.1379  Test_loss : 0.1355, Time/batch_file : 9.0986, Training time: 17922.1525\n",
      "Epoch : 387/500 data_batch_5,  Train_loss : 0.1422  Test_loss : 0.1372, Time/batch_file : 9.4471, Training time: 17931.5998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 388/500 data_batch_1,  Train_loss : 0.1333  Test_loss : 0.1376, Time/batch_file : 9.0972, Training time: 17940.6975\n",
      "Epoch : 388/500 data_batch_2,  Train_loss : 0.1315  Test_loss : 0.1374, Time/batch_file : 9.0962, Training time: 17949.7941\n",
      "Epoch : 388/500 data_batch_3,  Train_loss : 0.1352  Test_loss : 0.1405, Time/batch_file : 9.1395, Training time: 17958.9339\n",
      "Epoch : 388/500 data_batch_4,  Train_loss : 0.1352  Test_loss : 0.1400, Time/batch_file : 9.1087, Training time: 17968.0429\n",
      "Epoch : 388/500 data_batch_5,  Train_loss : 0.1348  Test_loss : 0.1331, Time/batch_file : 9.2749, Training time: 17977.3182\n",
      "Epoch : 389/500 data_batch_1,  Train_loss : 0.1426  Test_loss : 0.1333, Time/batch_file : 9.1004, Training time: 17986.4188\n",
      "Epoch : 389/500 data_batch_2,  Train_loss : 0.1424  Test_loss : 0.1336, Time/batch_file : 9.2127, Training time: 17995.6318\n",
      "Epoch : 389/500 data_batch_3,  Train_loss : 0.1398  Test_loss : 0.1299, Time/batch_file : 9.0304, Training time: 18004.6625\n",
      "Epoch : 389/500 data_batch_4,  Train_loss : 0.1419  Test_loss : 0.1361, Time/batch_file : 9.1726, Training time: 18013.8353\n",
      "Epoch : 389/500 data_batch_5,  Train_loss : 0.1350  Test_loss : 0.1331, Time/batch_file : 9.1468, Training time: 18022.9824\n",
      "Epoch : 390/500 data_batch_1,  Train_loss : 0.1277  Test_loss : 0.1498, Time/batch_file : 9.1878, Training time: 18032.1704\n",
      "Epoch : 390/500 data_batch_2,  Train_loss : 0.1333  Test_loss : 0.1532, Time/batch_file : 9.1805, Training time: 18041.3513\n",
      "Epoch : 390/500 data_batch_3,  Train_loss : 0.1270  Test_loss : 0.1548, Time/batch_file : 9.1839, Training time: 18050.5354\n",
      "Epoch : 390/500 data_batch_4,  Train_loss : 0.1301  Test_loss : 0.1489, Time/batch_file : 9.0994, Training time: 18059.6351\n",
      "Epoch : 390/500 data_batch_5,  Train_loss : 0.1346  Test_loss : 0.1585, Time/batch_file : 9.0005, Training time: 18068.6358\n",
      "Epoch : 391/500 data_batch_1,  Train_loss : 0.1398  Test_loss : 0.1365, Time/batch_file : 9.1775, Training time: 18079.6432\n",
      "Epoch : 391/500 data_batch_2,  Train_loss : 0.1454  Test_loss : 0.1377, Time/batch_file : 9.0584, Training time: 18088.7019\n",
      "Epoch : 391/500 data_batch_3,  Train_loss : 0.1420  Test_loss : 0.1348, Time/batch_file : 9.1191, Training time: 18097.8212\n",
      "Epoch : 391/500 data_batch_4,  Train_loss : 0.1394  Test_loss : 0.1426, Time/batch_file : 9.2247, Training time: 18107.0462\n",
      "Epoch : 391/500 data_batch_5,  Train_loss : 0.1448  Test_loss : 0.1385, Time/batch_file : 9.0840, Training time: 18116.1306\n",
      "Epoch : 392/500 data_batch_1,  Train_loss : 0.1454  Test_loss : 0.1377, Time/batch_file : 9.1687, Training time: 18125.2996\n",
      "Epoch : 392/500 data_batch_2,  Train_loss : 0.1464  Test_loss : 0.1365, Time/batch_file : 9.3899, Training time: 18134.6897\n",
      "Epoch : 392/500 data_batch_3,  Train_loss : 0.1389  Test_loss : 0.1393, Time/batch_file : 9.0869, Training time: 18143.7769\n",
      "Epoch : 392/500 data_batch_4,  Train_loss : 0.1397  Test_loss : 0.1359, Time/batch_file : 9.2149, Training time: 18152.9921\n",
      "Epoch : 392/500 data_batch_5,  Train_loss : 0.1417  Test_loss : 0.1365, Time/batch_file : 9.1699, Training time: 18162.1624\n",
      "Epoch : 393/500 data_batch_1,  Train_loss : 0.1514  Test_loss : 0.1447, Time/batch_file : 9.0635, Training time: 18171.2261\n",
      "Epoch : 393/500 data_batch_2,  Train_loss : 0.1482  Test_loss : 0.1432, Time/batch_file : 9.4770, Training time: 18180.7034\n",
      "Epoch : 393/500 data_batch_3,  Train_loss : 0.1503  Test_loss : 0.1450, Time/batch_file : 9.6361, Training time: 18190.3397\n",
      "Epoch : 393/500 data_batch_4,  Train_loss : 0.1495  Test_loss : 0.1462, Time/batch_file : 9.2003, Training time: 18199.5403\n",
      "Epoch : 393/500 data_batch_5,  Train_loss : 0.1511  Test_loss : 0.1455, Time/batch_file : 9.1338, Training time: 18208.6743\n",
      "Epoch : 394/500 data_batch_1,  Train_loss : 0.1444  Test_loss : 0.1410, Time/batch_file : 8.9940, Training time: 18217.6685\n",
      "Epoch : 394/500 data_batch_2,  Train_loss : 0.1440  Test_loss : 0.1400, Time/batch_file : 9.2587, Training time: 18226.9275\n",
      "Epoch : 394/500 data_batch_3,  Train_loss : 0.1430  Test_loss : 0.1363, Time/batch_file : 9.1302, Training time: 18236.0579\n",
      "Epoch : 394/500 data_batch_4,  Train_loss : 0.1438  Test_loss : 0.1413, Time/batch_file : 9.3253, Training time: 18245.3835\n",
      "Epoch : 394/500 data_batch_5,  Train_loss : 0.1402  Test_loss : 0.1371, Time/batch_file : 9.2474, Training time: 18254.6312\n",
      "Epoch : 395/500 data_batch_1,  Train_loss : 0.1392  Test_loss : 0.1345, Time/batch_file : 9.3389, Training time: 18263.9704\n",
      "Epoch : 395/500 data_batch_2,  Train_loss : 0.1423  Test_loss : 0.1423, Time/batch_file : 9.0288, Training time: 18272.9997\n",
      "Epoch : 395/500 data_batch_3,  Train_loss : 0.1380  Test_loss : 0.1420, Time/batch_file : 9.0413, Training time: 18282.0411\n",
      "Epoch : 395/500 data_batch_4,  Train_loss : 0.1384  Test_loss : 0.1428, Time/batch_file : 9.0946, Training time: 18291.1359\n",
      "Epoch : 395/500 data_batch_5,  Train_loss : 0.1383  Test_loss : 0.1374, Time/batch_file : 9.3306, Training time: 18300.4667\n",
      "Epoch : 396/500 data_batch_1,  Train_loss : 0.1348  Test_loss : 0.1376, Time/batch_file : 9.2007, Training time: 18311.2577\n",
      "Epoch : 396/500 data_batch_2,  Train_loss : 0.1296  Test_loss : 0.1434, Time/batch_file : 9.2708, Training time: 18320.5286\n",
      "Epoch : 396/500 data_batch_3,  Train_loss : 0.1300  Test_loss : 0.1347, Time/batch_file : 9.5574, Training time: 18330.0862\n",
      "Epoch : 396/500 data_batch_4,  Train_loss : 0.1329  Test_loss : 0.1409, Time/batch_file : 9.1900, Training time: 18339.2765\n",
      "Epoch : 396/500 data_batch_5,  Train_loss : 0.1302  Test_loss : 0.1417, Time/batch_file : 9.1633, Training time: 18348.4401\n",
      "Epoch : 397/500 data_batch_1,  Train_loss : 0.1308  Test_loss : 0.1370, Time/batch_file : 9.4084, Training time: 18357.8488\n",
      "Epoch : 397/500 data_batch_2,  Train_loss : 0.1368  Test_loss : 0.1372, Time/batch_file : 9.0873, Training time: 18366.9364\n",
      "Epoch : 397/500 data_batch_3,  Train_loss : 0.1360  Test_loss : 0.1409, Time/batch_file : 9.1220, Training time: 18376.0585\n",
      "Epoch : 397/500 data_batch_4,  Train_loss : 0.1400  Test_loss : 0.1391, Time/batch_file : 9.1645, Training time: 18385.2233\n",
      "Epoch : 397/500 data_batch_5,  Train_loss : 0.1382  Test_loss : 0.1409, Time/batch_file : 9.1462, Training time: 18394.3697\n",
      "Epoch : 398/500 data_batch_1,  Train_loss : 0.1387  Test_loss : 0.1368, Time/batch_file : 9.1278, Training time: 18403.4978\n",
      "Epoch : 398/500 data_batch_2,  Train_loss : 0.1450  Test_loss : 0.1307, Time/batch_file : 9.2198, Training time: 18412.7179\n",
      "Epoch : 398/500 data_batch_3,  Train_loss : 0.1409  Test_loss : 0.1392, Time/batch_file : 9.2770, Training time: 18421.9952\n",
      "Epoch : 398/500 data_batch_4,  Train_loss : 0.1458  Test_loss : 0.1444, Time/batch_file : 9.1698, Training time: 18431.1652\n",
      "Epoch : 398/500 data_batch_5,  Train_loss : 0.1412  Test_loss : 0.1344, Time/batch_file : 9.1593, Training time: 18440.3248\n",
      "Epoch : 399/500 data_batch_1,  Train_loss : 0.1407  Test_loss : 0.1304, Time/batch_file : 9.4337, Training time: 18449.7587\n",
      "Epoch : 399/500 data_batch_2,  Train_loss : 0.1339  Test_loss : 0.1316, Time/batch_file : 9.1693, Training time: 18458.9282\n",
      "Epoch : 399/500 data_batch_3,  Train_loss : 0.1404  Test_loss : 0.1351, Time/batch_file : 9.0174, Training time: 18467.9459\n",
      "Epoch : 399/500 data_batch_4,  Train_loss : 0.1427  Test_loss : 0.1311, Time/batch_file : 8.9805, Training time: 18476.9267\n",
      "Epoch : 399/500 data_batch_5,  Train_loss : 0.1436  Test_loss : 0.1342, Time/batch_file : 9.3220, Training time: 18486.2489\n",
      "Epoch : 400/500 data_batch_1,  Train_loss : 0.1328  Test_loss : 0.1508, Time/batch_file : 9.3328, Training time: 18495.5821\n",
      "Epoch : 400/500 data_batch_2,  Train_loss : 0.1313  Test_loss : 0.1532, Time/batch_file : 9.1866, Training time: 18504.7692\n",
      "Epoch : 400/500 data_batch_3,  Train_loss : 0.1305  Test_loss : 0.1471, Time/batch_file : 9.3232, Training time: 18514.0926\n",
      "Epoch : 400/500 data_batch_4,  Train_loss : 0.1315  Test_loss : 0.1496, Time/batch_file : 9.1309, Training time: 18523.2237\n",
      "Epoch : 400/500 data_batch_5,  Train_loss : 0.1344  Test_loss : 0.1503, Time/batch_file : 9.4928, Training time: 18532.7169\n",
      "[./nets/net-400.ckpt] SAVED\n",
      "Epoch : 401/500 data_batch_1,  Train_loss : 0.1348  Test_loss : 0.1384, Time/batch_file : 9.1355, Training time: 18543.6423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 401/500 data_batch_2,  Train_loss : 0.1371  Test_loss : 0.1440, Time/batch_file : 9.1518, Training time: 18552.7943\n",
      "Epoch : 401/500 data_batch_3,  Train_loss : 0.1392  Test_loss : 0.1416, Time/batch_file : 9.3942, Training time: 18562.1887\n",
      "Epoch : 401/500 data_batch_4,  Train_loss : 0.1394  Test_loss : 0.1407, Time/batch_file : 9.3570, Training time: 18571.5460\n",
      "Epoch : 401/500 data_batch_5,  Train_loss : 0.1415  Test_loss : 0.1391, Time/batch_file : 9.0694, Training time: 18580.6157\n",
      "Epoch : 402/500 data_batch_1,  Train_loss : 0.1495  Test_loss : 0.1392, Time/batch_file : 9.1773, Training time: 18589.7933\n",
      "Epoch : 402/500 data_batch_2,  Train_loss : 0.1500  Test_loss : 0.1418, Time/batch_file : 9.0014, Training time: 18598.7949\n",
      "Epoch : 402/500 data_batch_3,  Train_loss : 0.1460  Test_loss : 0.1400, Time/batch_file : 9.3083, Training time: 18608.1035\n",
      "Epoch : 402/500 data_batch_4,  Train_loss : 0.1462  Test_loss : 0.1381, Time/batch_file : 9.2373, Training time: 18617.3411\n",
      "Epoch : 402/500 data_batch_5,  Train_loss : 0.1469  Test_loss : 0.1387, Time/batch_file : 9.2216, Training time: 18626.5630\n",
      "Epoch : 403/500 data_batch_1,  Train_loss : 0.1287  Test_loss : 0.1458, Time/batch_file : 9.3443, Training time: 18635.9075\n",
      "Epoch : 403/500 data_batch_2,  Train_loss : 0.1280  Test_loss : 0.1444, Time/batch_file : 9.4505, Training time: 18645.3583\n",
      "Epoch : 403/500 data_batch_3,  Train_loss : 0.1257  Test_loss : 0.1435, Time/batch_file : 9.0934, Training time: 18654.4521\n",
      "Epoch : 403/500 data_batch_4,  Train_loss : 0.1243  Test_loss : 0.1420, Time/batch_file : 9.4577, Training time: 18663.9100\n",
      "Epoch : 403/500 data_batch_5,  Train_loss : 0.1259  Test_loss : 0.1451, Time/batch_file : 9.1302, Training time: 18673.0404\n",
      "Epoch : 404/500 data_batch_1,  Train_loss : 0.1453  Test_loss : 0.1443, Time/batch_file : 8.9763, Training time: 18682.0169\n",
      "Epoch : 404/500 data_batch_2,  Train_loss : 0.1445  Test_loss : 0.1401, Time/batch_file : 9.1066, Training time: 18691.1239\n",
      "Epoch : 404/500 data_batch_3,  Train_loss : 0.1424  Test_loss : 0.1375, Time/batch_file : 9.0748, Training time: 18700.1990\n",
      "Epoch : 404/500 data_batch_4,  Train_loss : 0.1438  Test_loss : 0.1412, Time/batch_file : 9.1626, Training time: 18709.3618\n",
      "Epoch : 404/500 data_batch_5,  Train_loss : 0.1479  Test_loss : 0.1407, Time/batch_file : 9.4787, Training time: 18718.8408\n",
      "Epoch : 405/500 data_batch_1,  Train_loss : 0.1471  Test_loss : 0.1330, Time/batch_file : 9.1107, Training time: 18727.9519\n",
      "Epoch : 405/500 data_batch_2,  Train_loss : 0.1508  Test_loss : 0.1395, Time/batch_file : 9.5123, Training time: 18737.4644\n",
      "Epoch : 405/500 data_batch_3,  Train_loss : 0.1524  Test_loss : 0.1399, Time/batch_file : 9.3460, Training time: 18746.8107\n",
      "Epoch : 405/500 data_batch_4,  Train_loss : 0.1485  Test_loss : 0.1439, Time/batch_file : 9.3895, Training time: 18756.2005\n",
      "Epoch : 405/500 data_batch_5,  Train_loss : 0.1478  Test_loss : 0.1382, Time/batch_file : 9.2946, Training time: 18765.4954\n",
      "Epoch : 406/500 data_batch_1,  Train_loss : 0.1390  Test_loss : 0.1368, Time/batch_file : 9.6119, Training time: 18780.8754\n",
      "Epoch : 406/500 data_batch_2,  Train_loss : 0.1407  Test_loss : 0.1355, Time/batch_file : 9.3075, Training time: 18790.1832\n",
      "Epoch : 406/500 data_batch_3,  Train_loss : 0.1420  Test_loss : 0.1399, Time/batch_file : 9.3741, Training time: 18799.5576\n",
      "Epoch : 406/500 data_batch_4,  Train_loss : 0.1406  Test_loss : 0.1335, Time/batch_file : 9.0945, Training time: 18808.6523\n",
      "Epoch : 406/500 data_batch_5,  Train_loss : 0.1401  Test_loss : 0.1388, Time/batch_file : 9.4147, Training time: 18818.0673\n",
      "Epoch : 407/500 data_batch_1,  Train_loss : 0.1465  Test_loss : 0.1484, Time/batch_file : 9.3947, Training time: 18827.4623\n",
      "Epoch : 407/500 data_batch_2,  Train_loss : 0.1444  Test_loss : 0.1472, Time/batch_file : 9.1939, Training time: 18836.6565\n",
      "Epoch : 407/500 data_batch_3,  Train_loss : 0.1415  Test_loss : 0.1483, Time/batch_file : 9.3020, Training time: 18845.9588\n",
      "Epoch : 407/500 data_batch_4,  Train_loss : 0.1457  Test_loss : 0.1412, Time/batch_file : 9.3180, Training time: 18855.2770\n",
      "Epoch : 407/500 data_batch_5,  Train_loss : 0.1412  Test_loss : 0.1446, Time/batch_file : 9.2613, Training time: 18864.5386\n",
      "Epoch : 408/500 data_batch_1,  Train_loss : 0.1347  Test_loss : 0.1432, Time/batch_file : 9.1545, Training time: 18873.6935\n",
      "Epoch : 408/500 data_batch_2,  Train_loss : 0.1313  Test_loss : 0.1394, Time/batch_file : 9.3794, Training time: 18883.0732\n",
      "Epoch : 408/500 data_batch_3,  Train_loss : 0.1303  Test_loss : 0.1459, Time/batch_file : 9.0808, Training time: 18892.1542\n",
      "Epoch : 408/500 data_batch_4,  Train_loss : 0.1286  Test_loss : 0.1414, Time/batch_file : 9.1110, Training time: 18901.2655\n",
      "Epoch : 408/500 data_batch_5,  Train_loss : 0.1301  Test_loss : 0.1422, Time/batch_file : 9.2722, Training time: 18910.5380\n",
      "Epoch : 409/500 data_batch_1,  Train_loss : 0.1440  Test_loss : 0.1421, Time/batch_file : 9.4373, Training time: 18919.9755\n",
      "Epoch : 409/500 data_batch_2,  Train_loss : 0.1438  Test_loss : 0.1414, Time/batch_file : 9.2045, Training time: 18929.1803\n",
      "Epoch : 409/500 data_batch_3,  Train_loss : 0.1410  Test_loss : 0.1410, Time/batch_file : 8.9623, Training time: 18938.1429\n",
      "Epoch : 409/500 data_batch_4,  Train_loss : 0.1386  Test_loss : 0.1454, Time/batch_file : 9.1748, Training time: 18947.3180\n",
      "Epoch : 409/500 data_batch_5,  Train_loss : 0.1419  Test_loss : 0.1424, Time/batch_file : 9.1466, Training time: 18956.4650\n",
      "Epoch : 410/500 data_batch_1,  Train_loss : 0.1295  Test_loss : 0.1445, Time/batch_file : 9.2635, Training time: 18965.7288\n",
      "Epoch : 410/500 data_batch_2,  Train_loss : 0.1294  Test_loss : 0.1449, Time/batch_file : 9.0663, Training time: 18974.7954\n",
      "Epoch : 410/500 data_batch_3,  Train_loss : 0.1342  Test_loss : 0.1367, Time/batch_file : 9.0884, Training time: 18983.8841\n",
      "Epoch : 410/500 data_batch_4,  Train_loss : 0.1278  Test_loss : 0.1390, Time/batch_file : 9.0921, Training time: 18992.9764\n",
      "Epoch : 410/500 data_batch_5,  Train_loss : 0.1320  Test_loss : 0.1394, Time/batch_file : 9.0735, Training time: 19002.0501\n",
      "Epoch : 411/500 data_batch_1,  Train_loss : 0.1426  Test_loss : 0.1357, Time/batch_file : 9.1390, Training time: 19012.8861\n",
      "Epoch : 411/500 data_batch_2,  Train_loss : 0.1452  Test_loss : 0.1370, Time/batch_file : 9.6192, Training time: 19022.5056\n",
      "Epoch : 411/500 data_batch_3,  Train_loss : 0.1432  Test_loss : 0.1349, Time/batch_file : 9.3728, Training time: 19031.8787\n",
      "Epoch : 411/500 data_batch_4,  Train_loss : 0.1440  Test_loss : 0.1351, Time/batch_file : 9.0935, Training time: 19040.9725\n",
      "Epoch : 411/500 data_batch_5,  Train_loss : 0.1453  Test_loss : 0.1331, Time/batch_file : 9.1456, Training time: 19050.1183\n",
      "Epoch : 412/500 data_batch_1,  Train_loss : 0.1390  Test_loss : 0.1425, Time/batch_file : 9.0589, Training time: 19059.1775\n",
      "Epoch : 412/500 data_batch_2,  Train_loss : 0.1349  Test_loss : 0.1361, Time/batch_file : 9.2306, Training time: 19068.4084\n",
      "Epoch : 412/500 data_batch_3,  Train_loss : 0.1380  Test_loss : 0.1432, Time/batch_file : 9.1102, Training time: 19077.5189\n",
      "Epoch : 412/500 data_batch_4,  Train_loss : 0.1444  Test_loss : 0.1366, Time/batch_file : 9.1598, Training time: 19086.6790\n",
      "Epoch : 412/500 data_batch_5,  Train_loss : 0.1332  Test_loss : 0.1377, Time/batch_file : 9.2973, Training time: 19095.9765\n",
      "Epoch : 413/500 data_batch_1,  Train_loss : 0.1350  Test_loss : 0.1452, Time/batch_file : 9.6908, Training time: 19105.6676\n",
      "Epoch : 413/500 data_batch_2,  Train_loss : 0.1368  Test_loss : 0.1450, Time/batch_file : 9.1277, Training time: 19114.7955\n",
      "Epoch : 413/500 data_batch_3,  Train_loss : 0.1364  Test_loss : 0.1458, Time/batch_file : 9.2201, Training time: 19124.0159\n",
      "Epoch : 413/500 data_batch_4,  Train_loss : 0.1358  Test_loss : 0.1385, Time/batch_file : 9.1486, Training time: 19133.1648\n",
      "Epoch : 413/500 data_batch_5,  Train_loss : 0.1372  Test_loss : 0.1392, Time/batch_file : 9.0621, Training time: 19142.2272\n",
      "Epoch : 414/500 data_batch_1,  Train_loss : 0.1383  Test_loss : 0.1307, Time/batch_file : 9.0567, Training time: 19151.2841\n",
      "Epoch : 414/500 data_batch_2,  Train_loss : 0.1410  Test_loss : 0.1379, Time/batch_file : 9.0310, Training time: 19160.3154\n",
      "Epoch : 414/500 data_batch_3,  Train_loss : 0.1386  Test_loss : 0.1353, Time/batch_file : 9.0400, Training time: 19169.3557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 414/500 data_batch_4,  Train_loss : 0.1405  Test_loss : 0.1358, Time/batch_file : 9.3626, Training time: 19178.7186\n",
      "Epoch : 414/500 data_batch_5,  Train_loss : 0.1406  Test_loss : 0.1358, Time/batch_file : 9.2256, Training time: 19187.9444\n",
      "Epoch : 415/500 data_batch_1,  Train_loss : 0.1261  Test_loss : 0.1350, Time/batch_file : 9.1709, Training time: 19197.1156\n",
      "Epoch : 415/500 data_batch_2,  Train_loss : 0.1300  Test_loss : 0.1345, Time/batch_file : 9.0291, Training time: 19206.1449\n",
      "Epoch : 415/500 data_batch_3,  Train_loss : 0.1312  Test_loss : 0.1408, Time/batch_file : 8.9098, Training time: 19215.0549\n",
      "Epoch : 415/500 data_batch_4,  Train_loss : 0.1295  Test_loss : 0.1405, Time/batch_file : 9.2738, Training time: 19224.3289\n",
      "Epoch : 415/500 data_batch_5,  Train_loss : 0.1290  Test_loss : 0.1371, Time/batch_file : 9.1683, Training time: 19233.4975\n",
      "Epoch : 416/500 data_batch_1,  Train_loss : 0.1355  Test_loss : 0.1346, Time/batch_file : 9.2351, Training time: 19244.5646\n",
      "Epoch : 416/500 data_batch_2,  Train_loss : 0.1351  Test_loss : 0.1367, Time/batch_file : 9.0771, Training time: 19253.6421\n",
      "Epoch : 416/500 data_batch_3,  Train_loss : 0.1345  Test_loss : 0.1367, Time/batch_file : 9.1471, Training time: 19262.7896\n",
      "Epoch : 416/500 data_batch_4,  Train_loss : 0.1314  Test_loss : 0.1401, Time/batch_file : 9.5612, Training time: 19272.3510\n",
      "Epoch : 416/500 data_batch_5,  Train_loss : 0.1317  Test_loss : 0.1392, Time/batch_file : 9.0766, Training time: 19281.4279\n",
      "Epoch : 417/500 data_batch_1,  Train_loss : 0.1258  Test_loss : 0.1414, Time/batch_file : 9.4443, Training time: 19290.8728\n",
      "Epoch : 417/500 data_batch_2,  Train_loss : 0.1315  Test_loss : 0.1427, Time/batch_file : 9.3903, Training time: 19300.2635\n",
      "Epoch : 417/500 data_batch_3,  Train_loss : 0.1297  Test_loss : 0.1414, Time/batch_file : 9.3075, Training time: 19309.5713\n",
      "Epoch : 417/500 data_batch_4,  Train_loss : 0.1263  Test_loss : 0.1398, Time/batch_file : 9.3007, Training time: 19318.8724\n",
      "Epoch : 417/500 data_batch_5,  Train_loss : 0.1269  Test_loss : 0.1418, Time/batch_file : 9.2894, Training time: 19328.1620\n",
      "Epoch : 418/500 data_batch_1,  Train_loss : 0.1445  Test_loss : 0.1449, Time/batch_file : 9.2257, Training time: 19337.3880\n",
      "Epoch : 418/500 data_batch_2,  Train_loss : 0.1474  Test_loss : 0.1409, Time/batch_file : 9.3083, Training time: 19346.6966\n",
      "Epoch : 418/500 data_batch_3,  Train_loss : 0.1500  Test_loss : 0.1458, Time/batch_file : 9.3104, Training time: 19356.0075\n",
      "Epoch : 418/500 data_batch_4,  Train_loss : 0.1473  Test_loss : 0.1428, Time/batch_file : 9.3036, Training time: 19365.3114\n",
      "Epoch : 418/500 data_batch_5,  Train_loss : 0.1418  Test_loss : 0.1443, Time/batch_file : 9.5126, Training time: 19374.8244\n",
      "Epoch : 419/500 data_batch_1,  Train_loss : 0.1404  Test_loss : 0.1348, Time/batch_file : 9.4667, Training time: 19384.2915\n",
      "Epoch : 419/500 data_batch_2,  Train_loss : 0.1355  Test_loss : 0.1409, Time/batch_file : 9.2959, Training time: 19393.5877\n",
      "Epoch : 419/500 data_batch_3,  Train_loss : 0.1413  Test_loss : 0.1371, Time/batch_file : 9.3295, Training time: 19402.9174\n",
      "Epoch : 419/500 data_batch_4,  Train_loss : 0.1407  Test_loss : 0.1352, Time/batch_file : 9.0485, Training time: 19411.9663\n",
      "Epoch : 419/500 data_batch_5,  Train_loss : 0.1375  Test_loss : 0.1336, Time/batch_file : 9.1421, Training time: 19421.1086\n",
      "Epoch : 420/500 data_batch_1,  Train_loss : 0.1373  Test_loss : 0.1403, Time/batch_file : 8.9333, Training time: 19430.0421\n",
      "Epoch : 420/500 data_batch_2,  Train_loss : 0.1407  Test_loss : 0.1384, Time/batch_file : 9.2492, Training time: 19439.2917\n",
      "Epoch : 420/500 data_batch_3,  Train_loss : 0.1392  Test_loss : 0.1479, Time/batch_file : 9.3325, Training time: 19448.6245\n",
      "Epoch : 420/500 data_batch_4,  Train_loss : 0.1359  Test_loss : 0.1403, Time/batch_file : 9.1894, Training time: 19457.8141\n",
      "Epoch : 420/500 data_batch_5,  Train_loss : 0.1389  Test_loss : 0.1432, Time/batch_file : 9.2486, Training time: 19467.0631\n",
      "[./nets/net-420.ckpt] SAVED\n",
      "Epoch : 421/500 data_batch_1,  Train_loss : 0.1442  Test_loss : 0.1411, Time/batch_file : 9.3278, Training time: 19478.1771\n",
      "Epoch : 421/500 data_batch_2,  Train_loss : 0.1402  Test_loss : 0.1367, Time/batch_file : 9.3869, Training time: 19487.5643\n",
      "Epoch : 421/500 data_batch_3,  Train_loss : 0.1471  Test_loss : 0.1396, Time/batch_file : 9.1051, Training time: 19496.6698\n",
      "Epoch : 421/500 data_batch_4,  Train_loss : 0.1406  Test_loss : 0.1365, Time/batch_file : 9.0664, Training time: 19505.7365\n",
      "Epoch : 421/500 data_batch_5,  Train_loss : 0.1423  Test_loss : 0.1418, Time/batch_file : 8.9740, Training time: 19514.7107\n",
      "Epoch : 422/500 data_batch_1,  Train_loss : 0.1360  Test_loss : 0.1371, Time/batch_file : 8.8914, Training time: 19523.6023\n",
      "Epoch : 422/500 data_batch_2,  Train_loss : 0.1384  Test_loss : 0.1386, Time/batch_file : 9.2403, Training time: 19532.8429\n",
      "Epoch : 422/500 data_batch_3,  Train_loss : 0.1425  Test_loss : 0.1362, Time/batch_file : 9.1594, Training time: 19542.0025\n",
      "Epoch : 422/500 data_batch_4,  Train_loss : 0.1408  Test_loss : 0.1383, Time/batch_file : 9.0968, Training time: 19551.0995\n",
      "Epoch : 422/500 data_batch_5,  Train_loss : 0.1411  Test_loss : 0.1399, Time/batch_file : 9.2822, Training time: 19560.3821\n",
      "Epoch : 423/500 data_batch_1,  Train_loss : 0.1378  Test_loss : 0.1423, Time/batch_file : 9.3053, Training time: 19569.6877\n",
      "Epoch : 423/500 data_batch_2,  Train_loss : 0.1442  Test_loss : 0.1433, Time/batch_file : 9.6042, Training time: 19579.2921\n",
      "Epoch : 423/500 data_batch_3,  Train_loss : 0.1381  Test_loss : 0.1394, Time/batch_file : 9.2675, Training time: 19588.5601\n",
      "Epoch : 423/500 data_batch_4,  Train_loss : 0.1450  Test_loss : 0.1440, Time/batch_file : 9.2593, Training time: 19597.8197\n",
      "Epoch : 423/500 data_batch_5,  Train_loss : 0.1417  Test_loss : 0.1452, Time/batch_file : 9.0756, Training time: 19606.8957\n",
      "Epoch : 424/500 data_batch_1,  Train_loss : 0.1395  Test_loss : 0.1420, Time/batch_file : 9.3315, Training time: 19616.2276\n",
      "Epoch : 424/500 data_batch_2,  Train_loss : 0.1385  Test_loss : 0.1402, Time/batch_file : 9.0792, Training time: 19625.3071\n",
      "Epoch : 424/500 data_batch_3,  Train_loss : 0.1424  Test_loss : 0.1418, Time/batch_file : 9.3549, Training time: 19634.6626\n",
      "Epoch : 424/500 data_batch_4,  Train_loss : 0.1397  Test_loss : 0.1422, Time/batch_file : 9.0513, Training time: 19643.7142\n",
      "Epoch : 424/500 data_batch_5,  Train_loss : 0.1402  Test_loss : 0.1385, Time/batch_file : 9.2757, Training time: 19652.9902\n",
      "Epoch : 425/500 data_batch_1,  Train_loss : 0.1370  Test_loss : 0.1304, Time/batch_file : 9.0543, Training time: 19662.0447\n",
      "Epoch : 425/500 data_batch_2,  Train_loss : 0.1414  Test_loss : 0.1337, Time/batch_file : 9.3048, Training time: 19671.3498\n",
      "Epoch : 425/500 data_batch_3,  Train_loss : 0.1409  Test_loss : 0.1330, Time/batch_file : 9.1942, Training time: 19680.5444\n",
      "Epoch : 425/500 data_batch_4,  Train_loss : 0.1408  Test_loss : 0.1284, Time/batch_file : 9.0697, Training time: 19689.6143\n",
      "Epoch : 425/500 data_batch_5,  Train_loss : 0.1422  Test_loss : 0.1304, Time/batch_file : 9.0449, Training time: 19698.6595\n",
      "Epoch : 426/500 data_batch_1,  Train_loss : 0.1389  Test_loss : 0.1393, Time/batch_file : 9.1118, Training time: 19709.3457\n",
      "Epoch : 426/500 data_batch_2,  Train_loss : 0.1398  Test_loss : 0.1385, Time/batch_file : 9.1268, Training time: 19718.4728\n",
      "Epoch : 426/500 data_batch_3,  Train_loss : 0.1412  Test_loss : 0.1468, Time/batch_file : 9.3307, Training time: 19727.8037\n",
      "Epoch : 426/500 data_batch_4,  Train_loss : 0.1379  Test_loss : 0.1466, Time/batch_file : 9.1482, Training time: 19736.9522\n",
      "Epoch : 426/500 data_batch_5,  Train_loss : 0.1388  Test_loss : 0.1418, Time/batch_file : 9.3505, Training time: 19746.3029\n",
      "Epoch : 427/500 data_batch_1,  Train_loss : 0.1411  Test_loss : 0.1466, Time/batch_file : 9.0724, Training time: 19755.3756\n",
      "Epoch : 427/500 data_batch_2,  Train_loss : 0.1409  Test_loss : 0.1427, Time/batch_file : 9.3936, Training time: 19764.7695\n",
      "Epoch : 427/500 data_batch_3,  Train_loss : 0.1382  Test_loss : 0.1445, Time/batch_file : 9.0695, Training time: 19773.8393\n",
      "Epoch : 427/500 data_batch_4,  Train_loss : 0.1415  Test_loss : 0.1478, Time/batch_file : 9.2776, Training time: 19783.1171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 427/500 data_batch_5,  Train_loss : 0.1403  Test_loss : 0.1457, Time/batch_file : 9.0361, Training time: 19792.1535\n",
      "Epoch : 428/500 data_batch_1,  Train_loss : 0.1423  Test_loss : 0.1376, Time/batch_file : 9.1743, Training time: 19801.3281\n",
      "Epoch : 428/500 data_batch_2,  Train_loss : 0.1342  Test_loss : 0.1360, Time/batch_file : 9.0333, Training time: 19810.3617\n",
      "Epoch : 428/500 data_batch_3,  Train_loss : 0.1430  Test_loss : 0.1342, Time/batch_file : 9.2754, Training time: 19819.6375\n",
      "Epoch : 428/500 data_batch_4,  Train_loss : 0.1351  Test_loss : 0.1412, Time/batch_file : 8.9986, Training time: 19828.6363\n",
      "Epoch : 428/500 data_batch_5,  Train_loss : 0.1335  Test_loss : 0.1358, Time/batch_file : 9.1394, Training time: 19837.7760\n",
      "Epoch : 429/500 data_batch_1,  Train_loss : 0.1432  Test_loss : 0.1509, Time/batch_file : 9.3667, Training time: 19847.1430\n",
      "Epoch : 429/500 data_batch_2,  Train_loss : 0.1457  Test_loss : 0.1551, Time/batch_file : 9.0698, Training time: 19856.2132\n",
      "Epoch : 429/500 data_batch_3,  Train_loss : 0.1468  Test_loss : 0.1521, Time/batch_file : 9.3056, Training time: 19865.5190\n",
      "Epoch : 429/500 data_batch_4,  Train_loss : 0.1425  Test_loss : 0.1466, Time/batch_file : 9.0428, Training time: 19874.5621\n",
      "Epoch : 429/500 data_batch_5,  Train_loss : 0.1412  Test_loss : 0.1544, Time/batch_file : 9.2265, Training time: 19883.7889\n",
      "Epoch : 430/500 data_batch_1,  Train_loss : 0.1352  Test_loss : 0.1384, Time/batch_file : 9.3660, Training time: 19893.1553\n",
      "Epoch : 430/500 data_batch_2,  Train_loss : 0.1361  Test_loss : 0.1370, Time/batch_file : 9.2176, Training time: 19902.3733\n",
      "Epoch : 430/500 data_batch_3,  Train_loss : 0.1354  Test_loss : 0.1380, Time/batch_file : 9.1858, Training time: 19911.5594\n",
      "Epoch : 430/500 data_batch_4,  Train_loss : 0.1410  Test_loss : 0.1376, Time/batch_file : 9.3091, Training time: 19920.8688\n",
      "Epoch : 430/500 data_batch_5,  Train_loss : 0.1377  Test_loss : 0.1321, Time/batch_file : 9.5552, Training time: 19930.4242\n",
      "Epoch : 431/500 data_batch_1,  Train_loss : 0.1371  Test_loss : 0.1417, Time/batch_file : 9.7324, Training time: 19941.7555\n",
      "Epoch : 431/500 data_batch_2,  Train_loss : 0.1267  Test_loss : 0.1392, Time/batch_file : 9.2491, Training time: 19951.0049\n",
      "Epoch : 431/500 data_batch_3,  Train_loss : 0.1333  Test_loss : 0.1427, Time/batch_file : 9.0061, Training time: 19960.0112\n",
      "Epoch : 431/500 data_batch_4,  Train_loss : 0.1363  Test_loss : 0.1444, Time/batch_file : 9.0944, Training time: 19969.1060\n",
      "Epoch : 431/500 data_batch_5,  Train_loss : 0.1273  Test_loss : 0.1438, Time/batch_file : 9.0625, Training time: 19978.1688\n",
      "Epoch : 432/500 data_batch_1,  Train_loss : 0.1318  Test_loss : 0.1351, Time/batch_file : 9.1528, Training time: 19987.3220\n",
      "Epoch : 432/500 data_batch_2,  Train_loss : 0.1300  Test_loss : 0.1378, Time/batch_file : 9.0024, Training time: 19996.3245\n",
      "Epoch : 432/500 data_batch_3,  Train_loss : 0.1313  Test_loss : 0.1387, Time/batch_file : 9.1480, Training time: 20005.4728\n",
      "Epoch : 432/500 data_batch_4,  Train_loss : 0.1314  Test_loss : 0.1363, Time/batch_file : 9.3302, Training time: 20014.8031\n",
      "Epoch : 432/500 data_batch_5,  Train_loss : 0.1277  Test_loss : 0.1393, Time/batch_file : 9.4365, Training time: 20024.2400\n",
      "Epoch : 433/500 data_batch_1,  Train_loss : 0.1393  Test_loss : 0.1216, Time/batch_file : 9.1752, Training time: 20033.4156\n",
      "Epoch : 433/500 data_batch_2,  Train_loss : 0.1453  Test_loss : 0.1185, Time/batch_file : 9.0844, Training time: 20042.5002\n",
      "Epoch : 433/500 data_batch_3,  Train_loss : 0.1367  Test_loss : 0.1295, Time/batch_file : 9.1646, Training time: 20051.6650\n",
      "Epoch : 433/500 data_batch_4,  Train_loss : 0.1361  Test_loss : 0.1274, Time/batch_file : 9.1213, Training time: 20060.7865\n",
      "Epoch : 433/500 data_batch_5,  Train_loss : 0.1432  Test_loss : 0.1207, Time/batch_file : 9.1190, Training time: 20069.9057\n",
      "Epoch : 434/500 data_batch_1,  Train_loss : 0.1390  Test_loss : 0.1475, Time/batch_file : 9.3271, Training time: 20079.2330\n",
      "Epoch : 434/500 data_batch_2,  Train_loss : 0.1390  Test_loss : 0.1463, Time/batch_file : 9.2941, Training time: 20088.5275\n",
      "Epoch : 434/500 data_batch_3,  Train_loss : 0.1397  Test_loss : 0.1453, Time/batch_file : 9.0177, Training time: 20097.5455\n",
      "Epoch : 434/500 data_batch_4,  Train_loss : 0.1436  Test_loss : 0.1399, Time/batch_file : 8.8893, Training time: 20106.4351\n",
      "Epoch : 434/500 data_batch_5,  Train_loss : 0.1406  Test_loss : 0.1410, Time/batch_file : 9.2264, Training time: 20115.6619\n",
      "Epoch : 435/500 data_batch_1,  Train_loss : 0.1350  Test_loss : 0.1363, Time/batch_file : 9.2650, Training time: 20124.9272\n",
      "Epoch : 435/500 data_batch_2,  Train_loss : 0.1396  Test_loss : 0.1353, Time/batch_file : 9.1389, Training time: 20134.0665\n",
      "Epoch : 435/500 data_batch_3,  Train_loss : 0.1395  Test_loss : 0.1338, Time/batch_file : 9.2325, Training time: 20143.2993\n",
      "Epoch : 435/500 data_batch_4,  Train_loss : 0.1369  Test_loss : 0.1331, Time/batch_file : 9.2116, Training time: 20152.5111\n",
      "Epoch : 435/500 data_batch_5,  Train_loss : 0.1356  Test_loss : 0.1331, Time/batch_file : 8.9592, Training time: 20161.4706\n",
      "Epoch : 436/500 data_batch_1,  Train_loss : 0.1386  Test_loss : 0.1483, Time/batch_file : 9.0933, Training time: 20172.1497\n",
      "Epoch : 436/500 data_batch_2,  Train_loss : 0.1427  Test_loss : 0.1383, Time/batch_file : 9.5533, Training time: 20181.7033\n",
      "Epoch : 436/500 data_batch_3,  Train_loss : 0.1446  Test_loss : 0.1389, Time/batch_file : 9.3728, Training time: 20191.0764\n",
      "Epoch : 436/500 data_batch_4,  Train_loss : 0.1423  Test_loss : 0.1457, Time/batch_file : 9.2268, Training time: 20200.3035\n",
      "Epoch : 436/500 data_batch_5,  Train_loss : 0.1478  Test_loss : 0.1399, Time/batch_file : 9.2882, Training time: 20209.5920\n",
      "Epoch : 437/500 data_batch_1,  Train_loss : 0.1265  Test_loss : 0.1356, Time/batch_file : 9.0346, Training time: 20218.6269\n",
      "Epoch : 437/500 data_batch_2,  Train_loss : 0.1347  Test_loss : 0.1389, Time/batch_file : 9.0991, Training time: 20227.7263\n",
      "Epoch : 437/500 data_batch_3,  Train_loss : 0.1406  Test_loss : 0.1367, Time/batch_file : 9.2355, Training time: 20236.9620\n",
      "Epoch : 437/500 data_batch_4,  Train_loss : 0.1339  Test_loss : 0.1385, Time/batch_file : 8.9937, Training time: 20245.9560\n",
      "Epoch : 437/500 data_batch_5,  Train_loss : 0.1359  Test_loss : 0.1347, Time/batch_file : 9.1535, Training time: 20255.1098\n",
      "Epoch : 438/500 data_batch_1,  Train_loss : 0.1260  Test_loss : 0.1371, Time/batch_file : 9.1222, Training time: 20264.2323\n",
      "Epoch : 438/500 data_batch_2,  Train_loss : 0.1305  Test_loss : 0.1438, Time/batch_file : 9.3135, Training time: 20273.5461\n",
      "Epoch : 438/500 data_batch_3,  Train_loss : 0.1270  Test_loss : 0.1383, Time/batch_file : 9.2395, Training time: 20282.7858\n",
      "Epoch : 438/500 data_batch_4,  Train_loss : 0.1274  Test_loss : 0.1324, Time/batch_file : 9.2368, Training time: 20292.0229\n",
      "Epoch : 438/500 data_batch_5,  Train_loss : 0.1312  Test_loss : 0.1360, Time/batch_file : 9.4318, Training time: 20301.4549\n",
      "Epoch : 439/500 data_batch_1,  Train_loss : 0.1451  Test_loss : 0.1372, Time/batch_file : 9.3187, Training time: 20310.7739\n",
      "Epoch : 439/500 data_batch_2,  Train_loss : 0.1453  Test_loss : 0.1365, Time/batch_file : 9.0974, Training time: 20319.8716\n",
      "Epoch : 439/500 data_batch_3,  Train_loss : 0.1455  Test_loss : 0.1382, Time/batch_file : 9.3656, Training time: 20329.2374\n",
      "Epoch : 439/500 data_batch_4,  Train_loss : 0.1480  Test_loss : 0.1381, Time/batch_file : 9.1837, Training time: 20338.4212\n",
      "Epoch : 439/500 data_batch_5,  Train_loss : 0.1436  Test_loss : 0.1368, Time/batch_file : 9.3804, Training time: 20347.8019\n",
      "Epoch : 440/500 data_batch_1,  Train_loss : 0.1361  Test_loss : 0.1408, Time/batch_file : 9.5027, Training time: 20357.3050\n",
      "Epoch : 440/500 data_batch_2,  Train_loss : 0.1374  Test_loss : 0.1430, Time/batch_file : 9.1744, Training time: 20366.4796\n",
      "Epoch : 440/500 data_batch_3,  Train_loss : 0.1408  Test_loss : 0.1383, Time/batch_file : 9.3693, Training time: 20375.8492\n",
      "Epoch : 440/500 data_batch_4,  Train_loss : 0.1281  Test_loss : 0.1440, Time/batch_file : 9.1631, Training time: 20385.0127\n",
      "Epoch : 440/500 data_batch_5,  Train_loss : 0.1357  Test_loss : 0.1391, Time/batch_file : 9.0974, Training time: 20394.1103\n",
      "[./nets/net-440.ckpt] SAVED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 441/500 data_batch_1,  Train_loss : 0.1495  Test_loss : 0.1440, Time/batch_file : 9.3253, Training time: 20405.2261\n",
      "Epoch : 441/500 data_batch_2,  Train_loss : 0.1437  Test_loss : 0.1373, Time/batch_file : 9.0663, Training time: 20414.2928\n",
      "Epoch : 441/500 data_batch_3,  Train_loss : 0.1465  Test_loss : 0.1403, Time/batch_file : 9.1529, Training time: 20423.4460\n",
      "Epoch : 441/500 data_batch_4,  Train_loss : 0.1451  Test_loss : 0.1369, Time/batch_file : 9.4555, Training time: 20432.9018\n",
      "Epoch : 441/500 data_batch_5,  Train_loss : 0.1488  Test_loss : 0.1451, Time/batch_file : 9.4951, Training time: 20442.3971\n",
      "Epoch : 442/500 data_batch_1,  Train_loss : 0.1384  Test_loss : 0.1406, Time/batch_file : 9.0389, Training time: 20451.4363\n",
      "Epoch : 442/500 data_batch_2,  Train_loss : 0.1448  Test_loss : 0.1454, Time/batch_file : 9.0643, Training time: 20460.5010\n",
      "Epoch : 442/500 data_batch_3,  Train_loss : 0.1412  Test_loss : 0.1361, Time/batch_file : 9.6726, Training time: 20470.1739\n",
      "Epoch : 442/500 data_batch_4,  Train_loss : 0.1434  Test_loss : 0.1379, Time/batch_file : 9.1509, Training time: 20479.3251\n",
      "Epoch : 442/500 data_batch_5,  Train_loss : 0.1410  Test_loss : 0.1455, Time/batch_file : 9.1716, Training time: 20488.4970\n",
      "Epoch : 443/500 data_batch_1,  Train_loss : 0.1347  Test_loss : 0.1428, Time/batch_file : 9.3389, Training time: 20497.8362\n",
      "Epoch : 443/500 data_batch_2,  Train_loss : 0.1428  Test_loss : 0.1467, Time/batch_file : 9.0970, Training time: 20506.9335\n",
      "Epoch : 443/500 data_batch_3,  Train_loss : 0.1407  Test_loss : 0.1470, Time/batch_file : 9.2936, Training time: 20516.2273\n",
      "Epoch : 443/500 data_batch_4,  Train_loss : 0.1381  Test_loss : 0.1429, Time/batch_file : 9.1394, Training time: 20525.3670\n",
      "Epoch : 443/500 data_batch_5,  Train_loss : 0.1388  Test_loss : 0.1478, Time/batch_file : 9.1396, Training time: 20534.5069\n",
      "Epoch : 444/500 data_batch_1,  Train_loss : 0.1437  Test_loss : 0.1335, Time/batch_file : 9.1360, Training time: 20543.6434\n",
      "Epoch : 444/500 data_batch_2,  Train_loss : 0.1429  Test_loss : 0.1386, Time/batch_file : 9.4609, Training time: 20553.1046\n",
      "Epoch : 444/500 data_batch_3,  Train_loss : 0.1489  Test_loss : 0.1354, Time/batch_file : 9.2639, Training time: 20562.3688\n",
      "Epoch : 444/500 data_batch_4,  Train_loss : 0.1438  Test_loss : 0.1409, Time/batch_file : 9.2894, Training time: 20571.6585\n",
      "Epoch : 444/500 data_batch_5,  Train_loss : 0.1464  Test_loss : 0.1404, Time/batch_file : 9.2287, Training time: 20580.8874\n",
      "Epoch : 445/500 data_batch_1,  Train_loss : 0.1327  Test_loss : 0.1400, Time/batch_file : 9.3118, Training time: 20590.1997\n",
      "Epoch : 445/500 data_batch_2,  Train_loss : 0.1383  Test_loss : 0.1396, Time/batch_file : 9.0541, Training time: 20599.2540\n",
      "Epoch : 445/500 data_batch_3,  Train_loss : 0.1402  Test_loss : 0.1402, Time/batch_file : 9.0280, Training time: 20608.2823\n",
      "Epoch : 445/500 data_batch_4,  Train_loss : 0.1372  Test_loss : 0.1441, Time/batch_file : 9.0931, Training time: 20617.3758\n",
      "Epoch : 445/500 data_batch_5,  Train_loss : 0.1394  Test_loss : 0.1403, Time/batch_file : 9.1576, Training time: 20626.5336\n",
      "Epoch : 446/500 data_batch_1,  Train_loss : 0.1435  Test_loss : 0.1418, Time/batch_file : 9.0890, Training time: 20637.4929\n",
      "Epoch : 446/500 data_batch_2,  Train_loss : 0.1407  Test_loss : 0.1365, Time/batch_file : 9.3638, Training time: 20646.8571\n",
      "Epoch : 446/500 data_batch_3,  Train_loss : 0.1488  Test_loss : 0.1440, Time/batch_file : 9.3561, Training time: 20656.2134\n",
      "Epoch : 446/500 data_batch_4,  Train_loss : 0.1485  Test_loss : 0.1391, Time/batch_file : 9.3307, Training time: 20665.5443\n",
      "Epoch : 446/500 data_batch_5,  Train_loss : 0.1463  Test_loss : 0.1386, Time/batch_file : 9.2551, Training time: 20674.7996\n",
      "Epoch : 447/500 data_batch_1,  Train_loss : 0.1371  Test_loss : 0.1329, Time/batch_file : 9.3727, Training time: 20684.1727\n",
      "Epoch : 447/500 data_batch_2,  Train_loss : 0.1439  Test_loss : 0.1338, Time/batch_file : 9.1442, Training time: 20693.3171\n",
      "Epoch : 447/500 data_batch_3,  Train_loss : 0.1424  Test_loss : 0.1289, Time/batch_file : 9.1010, Training time: 20702.4183\n",
      "Epoch : 447/500 data_batch_4,  Train_loss : 0.1423  Test_loss : 0.1366, Time/batch_file : 9.1566, Training time: 20711.5752\n",
      "Epoch : 447/500 data_batch_5,  Train_loss : 0.1463  Test_loss : 0.1283, Time/batch_file : 9.2243, Training time: 20720.7998\n",
      "Epoch : 448/500 data_batch_1,  Train_loss : 0.1353  Test_loss : 0.1348, Time/batch_file : 9.1948, Training time: 20729.9950\n",
      "Epoch : 448/500 data_batch_2,  Train_loss : 0.1428  Test_loss : 0.1358, Time/batch_file : 9.2649, Training time: 20739.2600\n",
      "Epoch : 448/500 data_batch_3,  Train_loss : 0.1380  Test_loss : 0.1343, Time/batch_file : 9.3230, Training time: 20748.5836\n",
      "Epoch : 448/500 data_batch_4,  Train_loss : 0.1373  Test_loss : 0.1344, Time/batch_file : 9.1428, Training time: 20757.7267\n",
      "Epoch : 448/500 data_batch_5,  Train_loss : 0.1431  Test_loss : 0.1311, Time/batch_file : 9.3287, Training time: 20767.0557\n",
      "Epoch : 449/500 data_batch_1,  Train_loss : 0.1426  Test_loss : 0.1340, Time/batch_file : 9.5006, Training time: 20776.5566\n",
      "Epoch : 449/500 data_batch_2,  Train_loss : 0.1382  Test_loss : 0.1396, Time/batch_file : 9.4684, Training time: 20786.0253\n",
      "Epoch : 449/500 data_batch_3,  Train_loss : 0.1357  Test_loss : 0.1396, Time/batch_file : 9.2023, Training time: 20795.2278\n",
      "Epoch : 449/500 data_batch_4,  Train_loss : 0.1376  Test_loss : 0.1360, Time/batch_file : 9.2534, Training time: 20804.4817\n",
      "Epoch : 449/500 data_batch_5,  Train_loss : 0.1369  Test_loss : 0.1350, Time/batch_file : 9.1353, Training time: 20813.6173\n",
      "Epoch : 450/500 data_batch_1,  Train_loss : 0.1414  Test_loss : 0.1333, Time/batch_file : 9.1561, Training time: 20822.7737\n",
      "Epoch : 450/500 data_batch_2,  Train_loss : 0.1367  Test_loss : 0.1311, Time/batch_file : 9.0323, Training time: 20831.8062\n",
      "Epoch : 450/500 data_batch_3,  Train_loss : 0.1386  Test_loss : 0.1357, Time/batch_file : 9.1677, Training time: 20840.9741\n",
      "Epoch : 450/500 data_batch_4,  Train_loss : 0.1391  Test_loss : 0.1304, Time/batch_file : 9.0864, Training time: 20850.0608\n",
      "Epoch : 450/500 data_batch_5,  Train_loss : 0.1381  Test_loss : 0.1323, Time/batch_file : 9.1651, Training time: 20859.2262\n",
      "Epoch : 451/500 data_batch_1,  Train_loss : 0.1350  Test_loss : 0.1451, Time/batch_file : 9.2829, Training time: 20870.0946\n",
      "Epoch : 451/500 data_batch_2,  Train_loss : 0.1337  Test_loss : 0.1472, Time/batch_file : 9.4007, Training time: 20879.4956\n",
      "Epoch : 451/500 data_batch_3,  Train_loss : 0.1360  Test_loss : 0.1444, Time/batch_file : 9.2038, Training time: 20888.6998\n",
      "Epoch : 451/500 data_batch_4,  Train_loss : 0.1307  Test_loss : 0.1408, Time/batch_file : 9.0304, Training time: 20897.7304\n",
      "Epoch : 451/500 data_batch_5,  Train_loss : 0.1351  Test_loss : 0.1417, Time/batch_file : 8.8811, Training time: 20906.6118\n",
      "Epoch : 452/500 data_batch_1,  Train_loss : 0.1493  Test_loss : 0.1400, Time/batch_file : 8.8865, Training time: 20915.4986\n",
      "Epoch : 452/500 data_batch_2,  Train_loss : 0.1434  Test_loss : 0.1390, Time/batch_file : 9.0707, Training time: 20924.5696\n",
      "Epoch : 452/500 data_batch_3,  Train_loss : 0.1511  Test_loss : 0.1380, Time/batch_file : 9.2605, Training time: 20933.8302\n",
      "Epoch : 452/500 data_batch_4,  Train_loss : 0.1513  Test_loss : 0.1386, Time/batch_file : 9.2287, Training time: 20943.0592\n",
      "Epoch : 452/500 data_batch_5,  Train_loss : 0.1458  Test_loss : 0.1387, Time/batch_file : 9.4766, Training time: 20952.5362\n",
      "Epoch : 453/500 data_batch_1,  Train_loss : 0.1421  Test_loss : 0.1361, Time/batch_file : 9.1669, Training time: 20961.7034\n",
      "Epoch : 453/500 data_batch_2,  Train_loss : 0.1441  Test_loss : 0.1353, Time/batch_file : 9.1719, Training time: 20970.8756\n",
      "Epoch : 453/500 data_batch_3,  Train_loss : 0.1442  Test_loss : 0.1305, Time/batch_file : 9.2246, Training time: 20980.1005\n",
      "Epoch : 453/500 data_batch_4,  Train_loss : 0.1436  Test_loss : 0.1366, Time/batch_file : 9.4560, Training time: 20989.5568\n",
      "Epoch : 453/500 data_batch_5,  Train_loss : 0.1441  Test_loss : 0.1415, Time/batch_file : 8.9340, Training time: 20998.4911\n",
      "Epoch : 454/500 data_batch_1,  Train_loss : 0.1445  Test_loss : 0.1362, Time/batch_file : 9.3726, Training time: 21007.8640\n",
      "Epoch : 454/500 data_batch_2,  Train_loss : 0.1435  Test_loss : 0.1372, Time/batch_file : 9.0593, Training time: 21016.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 454/500 data_batch_3,  Train_loss : 0.1393  Test_loss : 0.1355, Time/batch_file : 9.1663, Training time: 21026.0903\n",
      "Epoch : 454/500 data_batch_4,  Train_loss : 0.1385  Test_loss : 0.1375, Time/batch_file : 9.4371, Training time: 21035.5276\n",
      "Epoch : 454/500 data_batch_5,  Train_loss : 0.1364  Test_loss : 0.1381, Time/batch_file : 9.0335, Training time: 21044.5614\n",
      "Epoch : 455/500 data_batch_1,  Train_loss : 0.1360  Test_loss : 0.1335, Time/batch_file : 9.0311, Training time: 21053.5928\n",
      "Epoch : 455/500 data_batch_2,  Train_loss : 0.1376  Test_loss : 0.1380, Time/batch_file : 9.2408, Training time: 21062.8339\n",
      "Epoch : 455/500 data_batch_3,  Train_loss : 0.1387  Test_loss : 0.1384, Time/batch_file : 9.1893, Training time: 21072.0236\n",
      "Epoch : 455/500 data_batch_4,  Train_loss : 0.1390  Test_loss : 0.1350, Time/batch_file : 9.2499, Training time: 21081.2738\n",
      "Epoch : 455/500 data_batch_5,  Train_loss : 0.1380  Test_loss : 0.1343, Time/batch_file : 9.1717, Training time: 21090.4457\n",
      "Epoch : 456/500 data_batch_1,  Train_loss : 0.1380  Test_loss : 0.1368, Time/batch_file : 9.1464, Training time: 21101.2003\n",
      "Epoch : 456/500 data_batch_2,  Train_loss : 0.1396  Test_loss : 0.1295, Time/batch_file : 9.2560, Training time: 21110.4565\n",
      "Epoch : 456/500 data_batch_3,  Train_loss : 0.1393  Test_loss : 0.1358, Time/batch_file : 9.1038, Training time: 21119.5604\n",
      "Epoch : 456/500 data_batch_4,  Train_loss : 0.1344  Test_loss : 0.1418, Time/batch_file : 9.3242, Training time: 21128.8851\n",
      "Epoch : 456/500 data_batch_5,  Train_loss : 0.1392  Test_loss : 0.1362, Time/batch_file : 9.2977, Training time: 21138.1831\n",
      "Epoch : 457/500 data_batch_1,  Train_loss : 0.1463  Test_loss : 0.1395, Time/batch_file : 9.1586, Training time: 21147.3420\n",
      "Epoch : 457/500 data_batch_2,  Train_loss : 0.1414  Test_loss : 0.1439, Time/batch_file : 8.9641, Training time: 21156.3063\n",
      "Epoch : 457/500 data_batch_3,  Train_loss : 0.1486  Test_loss : 0.1413, Time/batch_file : 9.1017, Training time: 21165.4083\n",
      "Epoch : 457/500 data_batch_4,  Train_loss : 0.1450  Test_loss : 0.1451, Time/batch_file : 9.4315, Training time: 21174.8402\n",
      "Epoch : 457/500 data_batch_5,  Train_loss : 0.1449  Test_loss : 0.1419, Time/batch_file : 9.3257, Training time: 21184.1662\n",
      "Epoch : 458/500 data_batch_1,  Train_loss : 0.1358  Test_loss : 0.1348, Time/batch_file : 9.1992, Training time: 21193.3657\n",
      "Epoch : 458/500 data_batch_2,  Train_loss : 0.1335  Test_loss : 0.1327, Time/batch_file : 9.2069, Training time: 21202.5729\n",
      "Epoch : 458/500 data_batch_3,  Train_loss : 0.1346  Test_loss : 0.1312, Time/batch_file : 9.1784, Training time: 21211.7516\n",
      "Epoch : 458/500 data_batch_4,  Train_loss : 0.1379  Test_loss : 0.1375, Time/batch_file : 9.0079, Training time: 21220.7598\n",
      "Epoch : 458/500 data_batch_5,  Train_loss : 0.1353  Test_loss : 0.1370, Time/batch_file : 9.1772, Training time: 21229.9372\n",
      "Epoch : 459/500 data_batch_1,  Train_loss : 0.1330  Test_loss : 0.1318, Time/batch_file : 9.4367, Training time: 21239.3763\n",
      "Epoch : 459/500 data_batch_2,  Train_loss : 0.1403  Test_loss : 0.1305, Time/batch_file : 9.5067, Training time: 21248.8832\n",
      "Epoch : 459/500 data_batch_3,  Train_loss : 0.1393  Test_loss : 0.1324, Time/batch_file : 9.3939, Training time: 21258.2774\n",
      "Epoch : 459/500 data_batch_4,  Train_loss : 0.1360  Test_loss : 0.1353, Time/batch_file : 9.1134, Training time: 21267.3911\n",
      "Epoch : 459/500 data_batch_5,  Train_loss : 0.1366  Test_loss : 0.1318, Time/batch_file : 9.2008, Training time: 21276.5923\n",
      "Epoch : 460/500 data_batch_1,  Train_loss : 0.1331  Test_loss : 0.1353, Time/batch_file : 9.2690, Training time: 21285.8616\n",
      "Epoch : 460/500 data_batch_2,  Train_loss : 0.1365  Test_loss : 0.1383, Time/batch_file : 9.2328, Training time: 21295.0947\n",
      "Epoch : 460/500 data_batch_3,  Train_loss : 0.1306  Test_loss : 0.1363, Time/batch_file : 9.0649, Training time: 21304.1600\n",
      "Epoch : 460/500 data_batch_4,  Train_loss : 0.1330  Test_loss : 0.1359, Time/batch_file : 9.1762, Training time: 21313.3365\n",
      "Epoch : 460/500 data_batch_5,  Train_loss : 0.1281  Test_loss : 0.1393, Time/batch_file : 9.1213, Training time: 21322.4581\n",
      "[./nets/net-460.ckpt] SAVED\n",
      "Epoch : 461/500 data_batch_1,  Train_loss : 0.1438  Test_loss : 0.1462, Time/batch_file : 9.3619, Training time: 21333.6234\n",
      "Epoch : 461/500 data_batch_2,  Train_loss : 0.1473  Test_loss : 0.1460, Time/batch_file : 9.0007, Training time: 21342.6243\n",
      "Epoch : 461/500 data_batch_3,  Train_loss : 0.1464  Test_loss : 0.1469, Time/batch_file : 9.1855, Training time: 21351.8101\n",
      "Epoch : 461/500 data_batch_4,  Train_loss : 0.1466  Test_loss : 0.1495, Time/batch_file : 8.9943, Training time: 21360.8047\n",
      "Epoch : 461/500 data_batch_5,  Train_loss : 0.1489  Test_loss : 0.1438, Time/batch_file : 9.0575, Training time: 21369.8625\n",
      "Epoch : 462/500 data_batch_1,  Train_loss : 0.1338  Test_loss : 0.1363, Time/batch_file : 9.2370, Training time: 21379.1000\n",
      "Epoch : 462/500 data_batch_2,  Train_loss : 0.1312  Test_loss : 0.1368, Time/batch_file : 9.2560, Training time: 21388.3564\n",
      "Epoch : 462/500 data_batch_3,  Train_loss : 0.1335  Test_loss : 0.1416, Time/batch_file : 9.3196, Training time: 21397.6765\n",
      "Epoch : 462/500 data_batch_4,  Train_loss : 0.1357  Test_loss : 0.1320, Time/batch_file : 9.2185, Training time: 21406.8952\n",
      "Epoch : 462/500 data_batch_5,  Train_loss : 0.1339  Test_loss : 0.1360, Time/batch_file : 9.1544, Training time: 21416.0498\n",
      "Epoch : 463/500 data_batch_1,  Train_loss : 0.1462  Test_loss : 0.1418, Time/batch_file : 9.0251, Training time: 21425.0752\n",
      "Epoch : 463/500 data_batch_2,  Train_loss : 0.1413  Test_loss : 0.1468, Time/batch_file : 9.3452, Training time: 21434.4207\n",
      "Epoch : 463/500 data_batch_3,  Train_loss : 0.1351  Test_loss : 0.1467, Time/batch_file : 9.3272, Training time: 21443.7482\n",
      "Epoch : 463/500 data_batch_4,  Train_loss : 0.1338  Test_loss : 0.1487, Time/batch_file : 9.1365, Training time: 21452.8849\n",
      "Epoch : 463/500 data_batch_5,  Train_loss : 0.1396  Test_loss : 0.1395, Time/batch_file : 9.3112, Training time: 21462.1963\n",
      "Epoch : 464/500 data_batch_1,  Train_loss : 0.1453  Test_loss : 0.1452, Time/batch_file : 9.0325, Training time: 21471.2291\n",
      "Epoch : 464/500 data_batch_2,  Train_loss : 0.1406  Test_loss : 0.1446, Time/batch_file : 9.1655, Training time: 21480.3947\n",
      "Epoch : 464/500 data_batch_3,  Train_loss : 0.1393  Test_loss : 0.1467, Time/batch_file : 9.3797, Training time: 21489.7748\n",
      "Epoch : 464/500 data_batch_4,  Train_loss : 0.1405  Test_loss : 0.1404, Time/batch_file : 9.1742, Training time: 21498.9492\n",
      "Epoch : 464/500 data_batch_5,  Train_loss : 0.1425  Test_loss : 0.1434, Time/batch_file : 9.4641, Training time: 21508.4136\n",
      "Epoch : 465/500 data_batch_1,  Train_loss : 0.1321  Test_loss : 0.1329, Time/batch_file : 9.2929, Training time: 21517.7069\n",
      "Epoch : 465/500 data_batch_2,  Train_loss : 0.1372  Test_loss : 0.1402, Time/batch_file : 9.4362, Training time: 21527.1433\n",
      "Epoch : 465/500 data_batch_3,  Train_loss : 0.1355  Test_loss : 0.1411, Time/batch_file : 9.2125, Training time: 21536.3561\n",
      "Epoch : 465/500 data_batch_4,  Train_loss : 0.1364  Test_loss : 0.1380, Time/batch_file : 9.0294, Training time: 21545.3858\n",
      "Epoch : 465/500 data_batch_5,  Train_loss : 0.1328  Test_loss : 0.1384, Time/batch_file : 9.2131, Training time: 21554.5993\n",
      "Epoch : 466/500 data_batch_1,  Train_loss : 0.1358  Test_loss : 0.1455, Time/batch_file : 9.2870, Training time: 21565.4615\n",
      "Epoch : 466/500 data_batch_2,  Train_loss : 0.1408  Test_loss : 0.1435, Time/batch_file : 9.2557, Training time: 21574.7174\n",
      "Epoch : 466/500 data_batch_3,  Train_loss : 0.1457  Test_loss : 0.1493, Time/batch_file : 9.0958, Training time: 21583.8136\n",
      "Epoch : 466/500 data_batch_4,  Train_loss : 0.1415  Test_loss : 0.1466, Time/batch_file : 9.1998, Training time: 21593.0138\n",
      "Epoch : 466/500 data_batch_5,  Train_loss : 0.1438  Test_loss : 0.1433, Time/batch_file : 9.3759, Training time: 21602.3900\n",
      "Epoch : 467/500 data_batch_1,  Train_loss : 0.1384  Test_loss : 0.1439, Time/batch_file : 9.0174, Training time: 21611.4077\n",
      "Epoch : 467/500 data_batch_2,  Train_loss : 0.1375  Test_loss : 0.1418, Time/batch_file : 9.2240, Training time: 21620.6319\n",
      "Epoch : 467/500 data_batch_3,  Train_loss : 0.1375  Test_loss : 0.1512, Time/batch_file : 9.2146, Training time: 21629.8469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 467/500 data_batch_4,  Train_loss : 0.1401  Test_loss : 0.1440, Time/batch_file : 9.2495, Training time: 21639.0967\n",
      "Epoch : 467/500 data_batch_5,  Train_loss : 0.1356  Test_loss : 0.1490, Time/batch_file : 9.2965, Training time: 21648.3935\n",
      "Epoch : 468/500 data_batch_1,  Train_loss : 0.1417  Test_loss : 0.1310, Time/batch_file : 9.3192, Training time: 21657.7131\n",
      "Epoch : 468/500 data_batch_2,  Train_loss : 0.1401  Test_loss : 0.1373, Time/batch_file : 9.0088, Training time: 21666.7224\n",
      "Epoch : 468/500 data_batch_3,  Train_loss : 0.1401  Test_loss : 0.1362, Time/batch_file : 8.9411, Training time: 21675.6638\n",
      "Epoch : 468/500 data_batch_4,  Train_loss : 0.1431  Test_loss : 0.1375, Time/batch_file : 9.1269, Training time: 21684.7910\n",
      "Epoch : 468/500 data_batch_5,  Train_loss : 0.1428  Test_loss : 0.1360, Time/batch_file : 9.2507, Training time: 21694.0420\n",
      "Epoch : 469/500 data_batch_1,  Train_loss : 0.1498  Test_loss : 0.1391, Time/batch_file : 9.1066, Training time: 21703.1488\n",
      "Epoch : 469/500 data_batch_2,  Train_loss : 0.1479  Test_loss : 0.1352, Time/batch_file : 9.3681, Training time: 21712.5170\n",
      "Epoch : 469/500 data_batch_3,  Train_loss : 0.1512  Test_loss : 0.1382, Time/batch_file : 9.0365, Training time: 21721.5538\n",
      "Epoch : 469/500 data_batch_4,  Train_loss : 0.1410  Test_loss : 0.1342, Time/batch_file : 9.3848, Training time: 21730.9389\n",
      "Epoch : 469/500 data_batch_5,  Train_loss : 0.1488  Test_loss : 0.1393, Time/batch_file : 9.3296, Training time: 21740.2688\n",
      "Epoch : 470/500 data_batch_1,  Train_loss : 0.1370  Test_loss : 0.1433, Time/batch_file : 9.0649, Training time: 21749.3340\n",
      "Epoch : 470/500 data_batch_2,  Train_loss : 0.1414  Test_loss : 0.1456, Time/batch_file : 9.1945, Training time: 21758.5288\n",
      "Epoch : 470/500 data_batch_3,  Train_loss : 0.1388  Test_loss : 0.1483, Time/batch_file : 9.0255, Training time: 21767.5545\n",
      "Epoch : 470/500 data_batch_4,  Train_loss : 0.1389  Test_loss : 0.1464, Time/batch_file : 9.1130, Training time: 21776.6678\n",
      "Epoch : 470/500 data_batch_5,  Train_loss : 0.1336  Test_loss : 0.1442, Time/batch_file : 9.5298, Training time: 21786.1980\n",
      "Epoch : 471/500 data_batch_1,  Train_loss : 0.1334  Test_loss : 0.1445, Time/batch_file : 9.2884, Training time: 21797.2524\n",
      "Epoch : 471/500 data_batch_2,  Train_loss : 0.1384  Test_loss : 0.1440, Time/batch_file : 9.5571, Training time: 21806.8097\n",
      "Epoch : 471/500 data_batch_3,  Train_loss : 0.1344  Test_loss : 0.1389, Time/batch_file : 9.1531, Training time: 21815.9630\n",
      "Epoch : 471/500 data_batch_4,  Train_loss : 0.1434  Test_loss : 0.1403, Time/batch_file : 9.1713, Training time: 21825.1346\n",
      "Epoch : 471/500 data_batch_5,  Train_loss : 0.1399  Test_loss : 0.1412, Time/batch_file : 9.0293, Training time: 21834.1641\n",
      "Epoch : 472/500 data_batch_1,  Train_loss : 0.1357  Test_loss : 0.1515, Time/batch_file : 9.2098, Training time: 21843.3743\n",
      "Epoch : 472/500 data_batch_2,  Train_loss : 0.1372  Test_loss : 0.1469, Time/batch_file : 9.3129, Training time: 21852.6874\n",
      "Epoch : 472/500 data_batch_3,  Train_loss : 0.1364  Test_loss : 0.1459, Time/batch_file : 9.2864, Training time: 21861.9741\n",
      "Epoch : 472/500 data_batch_4,  Train_loss : 0.1380  Test_loss : 0.1479, Time/batch_file : 8.9732, Training time: 21870.9476\n",
      "Epoch : 472/500 data_batch_5,  Train_loss : 0.1370  Test_loss : 0.1473, Time/batch_file : 9.1444, Training time: 21880.0924\n",
      "Epoch : 473/500 data_batch_1,  Train_loss : 0.1360  Test_loss : 0.1361, Time/batch_file : 9.0579, Training time: 21889.1507\n",
      "Epoch : 473/500 data_batch_2,  Train_loss : 0.1389  Test_loss : 0.1303, Time/batch_file : 9.1570, Training time: 21898.3079\n",
      "Epoch : 473/500 data_batch_3,  Train_loss : 0.1430  Test_loss : 0.1390, Time/batch_file : 9.2178, Training time: 21907.5260\n",
      "Epoch : 473/500 data_batch_4,  Train_loss : 0.1439  Test_loss : 0.1321, Time/batch_file : 9.1736, Training time: 21916.6998\n",
      "Epoch : 473/500 data_batch_5,  Train_loss : 0.1398  Test_loss : 0.1322, Time/batch_file : 9.1413, Training time: 21925.8414\n",
      "Epoch : 474/500 data_batch_1,  Train_loss : 0.1405  Test_loss : 0.1404, Time/batch_file : 9.2778, Training time: 21935.1194\n",
      "Epoch : 474/500 data_batch_2,  Train_loss : 0.1386  Test_loss : 0.1411, Time/batch_file : 9.4524, Training time: 21944.5722\n",
      "Epoch : 474/500 data_batch_3,  Train_loss : 0.1424  Test_loss : 0.1379, Time/batch_file : 9.1161, Training time: 21953.6886\n",
      "Epoch : 474/500 data_batch_4,  Train_loss : 0.1355  Test_loss : 0.1379, Time/batch_file : 9.2276, Training time: 21962.9167\n",
      "Epoch : 474/500 data_batch_5,  Train_loss : 0.1419  Test_loss : 0.1411, Time/batch_file : 9.3046, Training time: 21972.2215\n",
      "Epoch : 475/500 data_batch_1,  Train_loss : 0.1420  Test_loss : 0.1346, Time/batch_file : 9.1863, Training time: 21981.4080\n",
      "Epoch : 475/500 data_batch_2,  Train_loss : 0.1443  Test_loss : 0.1417, Time/batch_file : 9.3059, Training time: 21990.7142\n",
      "Epoch : 475/500 data_batch_3,  Train_loss : 0.1395  Test_loss : 0.1414, Time/batch_file : 9.0592, Training time: 21999.7737\n",
      "Epoch : 475/500 data_batch_4,  Train_loss : 0.1404  Test_loss : 0.1356, Time/batch_file : 9.3378, Training time: 22009.1118\n",
      "Epoch : 475/500 data_batch_5,  Train_loss : 0.1394  Test_loss : 0.1418, Time/batch_file : 9.3272, Training time: 22018.4393\n",
      "Epoch : 476/500 data_batch_1,  Train_loss : 0.1345  Test_loss : 0.1330, Time/batch_file : 9.2209, Training time: 22029.2144\n",
      "Epoch : 476/500 data_batch_2,  Train_loss : 0.1310  Test_loss : 0.1398, Time/batch_file : 9.0586, Training time: 22038.2733\n",
      "Epoch : 476/500 data_batch_3,  Train_loss : 0.1328  Test_loss : 0.1370, Time/batch_file : 9.0947, Training time: 22047.3683\n",
      "Epoch : 476/500 data_batch_4,  Train_loss : 0.1337  Test_loss : 0.1328, Time/batch_file : 8.9590, Training time: 22056.3276\n",
      "Epoch : 476/500 data_batch_5,  Train_loss : 0.1331  Test_loss : 0.1279, Time/batch_file : 9.2245, Training time: 22065.5523\n",
      "Epoch : 477/500 data_batch_1,  Train_loss : 0.1357  Test_loss : 0.1311, Time/batch_file : 9.0553, Training time: 22074.6080\n",
      "Epoch : 477/500 data_batch_2,  Train_loss : 0.1385  Test_loss : 0.1300, Time/batch_file : 9.2357, Training time: 22083.8441\n",
      "Epoch : 477/500 data_batch_3,  Train_loss : 0.1349  Test_loss : 0.1308, Time/batch_file : 9.1282, Training time: 22092.9726\n",
      "Epoch : 477/500 data_batch_4,  Train_loss : 0.1360  Test_loss : 0.1282, Time/batch_file : 9.5236, Training time: 22102.4965\n",
      "Epoch : 477/500 data_batch_5,  Train_loss : 0.1373  Test_loss : 0.1352, Time/batch_file : 9.2303, Training time: 22111.7271\n",
      "Epoch : 478/500 data_batch_1,  Train_loss : 0.1283  Test_loss : 0.1353, Time/batch_file : 9.3656, Training time: 22121.0931\n",
      "Epoch : 478/500 data_batch_2,  Train_loss : 0.1314  Test_loss : 0.1342, Time/batch_file : 9.2046, Training time: 22130.2981\n",
      "Epoch : 478/500 data_batch_3,  Train_loss : 0.1320  Test_loss : 0.1399, Time/batch_file : 9.1676, Training time: 22139.4659\n",
      "Epoch : 478/500 data_batch_4,  Train_loss : 0.1203  Test_loss : 0.1378, Time/batch_file : 9.5065, Training time: 22148.9726\n",
      "Epoch : 478/500 data_batch_5,  Train_loss : 0.1284  Test_loss : 0.1340, Time/batch_file : 9.4104, Training time: 22158.3833\n",
      "Epoch : 479/500 data_batch_1,  Train_loss : 0.1356  Test_loss : 0.1352, Time/batch_file : 9.1505, Training time: 22167.5339\n",
      "Epoch : 479/500 data_batch_2,  Train_loss : 0.1367  Test_loss : 0.1376, Time/batch_file : 9.0923, Training time: 22176.6265\n",
      "Epoch : 479/500 data_batch_3,  Train_loss : 0.1384  Test_loss : 0.1350, Time/batch_file : 9.2801, Training time: 22185.9070\n",
      "Epoch : 479/500 data_batch_4,  Train_loss : 0.1355  Test_loss : 0.1441, Time/batch_file : 9.2881, Training time: 22195.1954\n",
      "Epoch : 479/500 data_batch_5,  Train_loss : 0.1346  Test_loss : 0.1380, Time/batch_file : 9.1100, Training time: 22204.3058\n",
      "Epoch : 480/500 data_batch_1,  Train_loss : 0.1354  Test_loss : 0.1427, Time/batch_file : 9.1436, Training time: 22213.4497\n",
      "Epoch : 480/500 data_batch_2,  Train_loss : 0.1379  Test_loss : 0.1453, Time/batch_file : 9.4549, Training time: 22222.9048\n",
      "Epoch : 480/500 data_batch_3,  Train_loss : 0.1431  Test_loss : 0.1485, Time/batch_file : 9.3905, Training time: 22232.2956\n",
      "Epoch : 480/500 data_batch_4,  Train_loss : 0.1374  Test_loss : 0.1417, Time/batch_file : 9.1539, Training time: 22241.4498\n",
      "Epoch : 480/500 data_batch_5,  Train_loss : 0.1349  Test_loss : 0.1436, Time/batch_file : 9.2076, Training time: 22250.6578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[./nets/net-480.ckpt] SAVED\n",
      "Epoch : 481/500 data_batch_1,  Train_loss : 0.1377  Test_loss : 0.1380, Time/batch_file : 9.2829, Training time: 22261.7914\n",
      "Epoch : 481/500 data_batch_2,  Train_loss : 0.1424  Test_loss : 0.1371, Time/batch_file : 9.4422, Training time: 22271.2338\n",
      "Epoch : 481/500 data_batch_3,  Train_loss : 0.1439  Test_loss : 0.1317, Time/batch_file : 8.9743, Training time: 22280.2085\n",
      "Epoch : 481/500 data_batch_4,  Train_loss : 0.1372  Test_loss : 0.1333, Time/batch_file : 9.2167, Training time: 22289.4255\n",
      "Epoch : 481/500 data_batch_5,  Train_loss : 0.1396  Test_loss : 0.1374, Time/batch_file : 9.1522, Training time: 22298.5779\n",
      "Epoch : 482/500 data_batch_1,  Train_loss : 0.1377  Test_loss : 0.1324, Time/batch_file : 9.2327, Training time: 22307.8110\n",
      "Epoch : 482/500 data_batch_2,  Train_loss : 0.1419  Test_loss : 0.1313, Time/batch_file : 9.0375, Training time: 22316.8488\n",
      "Epoch : 482/500 data_batch_3,  Train_loss : 0.1362  Test_loss : 0.1313, Time/batch_file : 9.0836, Training time: 22325.9328\n",
      "Epoch : 482/500 data_batch_4,  Train_loss : 0.1446  Test_loss : 0.1308, Time/batch_file : 9.3809, Training time: 22335.3139\n",
      "Epoch : 482/500 data_batch_5,  Train_loss : 0.1447  Test_loss : 0.1315, Time/batch_file : 9.2728, Training time: 22344.5871\n",
      "Epoch : 483/500 data_batch_1,  Train_loss : 0.1317  Test_loss : 0.1376, Time/batch_file : 9.2316, Training time: 22353.8189\n",
      "Epoch : 483/500 data_batch_2,  Train_loss : 0.1341  Test_loss : 0.1361, Time/batch_file : 9.0867, Training time: 22362.9060\n",
      "Epoch : 483/500 data_batch_3,  Train_loss : 0.1334  Test_loss : 0.1379, Time/batch_file : 9.3134, Training time: 22372.2198\n",
      "Epoch : 483/500 data_batch_4,  Train_loss : 0.1308  Test_loss : 0.1427, Time/batch_file : 9.0828, Training time: 22381.3028\n",
      "Epoch : 483/500 data_batch_5,  Train_loss : 0.1350  Test_loss : 0.1398, Time/batch_file : 9.0224, Training time: 22390.3256\n",
      "Epoch : 484/500 data_batch_1,  Train_loss : 0.1344  Test_loss : 0.1371, Time/batch_file : 9.1189, Training time: 22399.4448\n",
      "Epoch : 484/500 data_batch_2,  Train_loss : 0.1363  Test_loss : 0.1373, Time/batch_file : 9.2090, Training time: 22408.6541\n",
      "Epoch : 484/500 data_batch_3,  Train_loss : 0.1341  Test_loss : 0.1343, Time/batch_file : 9.1939, Training time: 22417.8483\n",
      "Epoch : 484/500 data_batch_4,  Train_loss : 0.1359  Test_loss : 0.1363, Time/batch_file : 9.2249, Training time: 22427.0734\n",
      "Epoch : 484/500 data_batch_5,  Train_loss : 0.1334  Test_loss : 0.1332, Time/batch_file : 9.3489, Training time: 22436.4226\n",
      "Epoch : 485/500 data_batch_1,  Train_loss : 0.1343  Test_loss : 0.1444, Time/batch_file : 9.3301, Training time: 22445.7531\n",
      "Epoch : 485/500 data_batch_2,  Train_loss : 0.1333  Test_loss : 0.1381, Time/batch_file : 9.3075, Training time: 22455.0609\n",
      "Epoch : 485/500 data_batch_3,  Train_loss : 0.1338  Test_loss : 0.1470, Time/batch_file : 9.4251, Training time: 22464.4863\n",
      "Epoch : 485/500 data_batch_4,  Train_loss : 0.1335  Test_loss : 0.1464, Time/batch_file : 9.4189, Training time: 22473.9054\n",
      "Epoch : 485/500 data_batch_5,  Train_loss : 0.1342  Test_loss : 0.1399, Time/batch_file : 9.2566, Training time: 22483.1623\n",
      "Epoch : 486/500 data_batch_1,  Train_loss : 0.1264  Test_loss : 0.1457, Time/batch_file : 9.0400, Training time: 22493.9704\n",
      "Epoch : 486/500 data_batch_2,  Train_loss : 0.1283  Test_loss : 0.1424, Time/batch_file : 9.2499, Training time: 22503.2205\n",
      "Epoch : 486/500 data_batch_3,  Train_loss : 0.1306  Test_loss : 0.1418, Time/batch_file : 9.1422, Training time: 22512.3629\n",
      "Epoch : 486/500 data_batch_4,  Train_loss : 0.1316  Test_loss : 0.1433, Time/batch_file : 8.9813, Training time: 22521.3445\n",
      "Epoch : 486/500 data_batch_5,  Train_loss : 0.1316  Test_loss : 0.1426, Time/batch_file : 9.3323, Training time: 22530.6770\n",
      "Epoch : 487/500 data_batch_1,  Train_loss : 0.1406  Test_loss : 0.1346, Time/batch_file : 9.1043, Training time: 22539.7817\n",
      "Epoch : 487/500 data_batch_2,  Train_loss : 0.1444  Test_loss : 0.1394, Time/batch_file : 9.4166, Training time: 22549.1985\n",
      "Epoch : 487/500 data_batch_3,  Train_loss : 0.1458  Test_loss : 0.1333, Time/batch_file : 9.1782, Training time: 22558.3770\n",
      "Epoch : 487/500 data_batch_4,  Train_loss : 0.1418  Test_loss : 0.1379, Time/batch_file : 9.2656, Training time: 22567.6429\n",
      "Epoch : 487/500 data_batch_5,  Train_loss : 0.1398  Test_loss : 0.1319, Time/batch_file : 9.3157, Training time: 22576.9588\n",
      "Epoch : 488/500 data_batch_1,  Train_loss : 0.1442  Test_loss : 0.1339, Time/batch_file : 9.0664, Training time: 22586.0254\n",
      "Epoch : 488/500 data_batch_2,  Train_loss : 0.1515  Test_loss : 0.1289, Time/batch_file : 9.2411, Training time: 22595.2668\n",
      "Epoch : 488/500 data_batch_3,  Train_loss : 0.1471  Test_loss : 0.1374, Time/batch_file : 9.3240, Training time: 22604.5912\n",
      "Epoch : 488/500 data_batch_4,  Train_loss : 0.1470  Test_loss : 0.1323, Time/batch_file : 8.9680, Training time: 22613.5595\n",
      "Epoch : 488/500 data_batch_5,  Train_loss : 0.1518  Test_loss : 0.1379, Time/batch_file : 9.1313, Training time: 22622.6910\n",
      "Epoch : 489/500 data_batch_1,  Train_loss : 0.1348  Test_loss : 0.1361, Time/batch_file : 9.0983, Training time: 22631.7898\n",
      "Epoch : 489/500 data_batch_2,  Train_loss : 0.1384  Test_loss : 0.1387, Time/batch_file : 9.0956, Training time: 22640.8857\n",
      "Epoch : 489/500 data_batch_3,  Train_loss : 0.1385  Test_loss : 0.1350, Time/batch_file : 9.1560, Training time: 22650.0420\n",
      "Epoch : 489/500 data_batch_4,  Train_loss : 0.1413  Test_loss : 0.1360, Time/batch_file : 9.2283, Training time: 22659.2706\n",
      "Epoch : 489/500 data_batch_5,  Train_loss : 0.1393  Test_loss : 0.1322, Time/batch_file : 9.1239, Training time: 22668.3948\n",
      "Epoch : 490/500 data_batch_1,  Train_loss : 0.1395  Test_loss : 0.1343, Time/batch_file : 9.1151, Training time: 22677.5101\n",
      "Epoch : 490/500 data_batch_2,  Train_loss : 0.1386  Test_loss : 0.1361, Time/batch_file : 9.4512, Training time: 22686.9616\n",
      "Epoch : 490/500 data_batch_3,  Train_loss : 0.1442  Test_loss : 0.1379, Time/batch_file : 8.8433, Training time: 22695.8051\n",
      "Epoch : 490/500 data_batch_4,  Train_loss : 0.1446  Test_loss : 0.1377, Time/batch_file : 8.7408, Training time: 22704.5461\n",
      "Epoch : 490/500 data_batch_5,  Train_loss : 0.1394  Test_loss : 0.1358, Time/batch_file : 8.7903, Training time: 22713.3367\n",
      "Epoch : 491/500 data_batch_1,  Train_loss : 0.1414  Test_loss : 0.1279, Time/batch_file : 8.8428, Training time: 22723.6547\n",
      "Epoch : 491/500 data_batch_2,  Train_loss : 0.1405  Test_loss : 0.1272, Time/batch_file : 8.6954, Training time: 22732.3503\n",
      "Epoch : 491/500 data_batch_3,  Train_loss : 0.1386  Test_loss : 0.1317, Time/batch_file : 8.8535, Training time: 22741.2040\n",
      "Epoch : 491/500 data_batch_4,  Train_loss : 0.1356  Test_loss : 0.1288, Time/batch_file : 8.7428, Training time: 22749.9471\n",
      "Epoch : 491/500 data_batch_5,  Train_loss : 0.1397  Test_loss : 0.1292, Time/batch_file : 8.5941, Training time: 22758.5416\n",
      "Epoch : 492/500 data_batch_1,  Train_loss : 0.1440  Test_loss : 0.1450, Time/batch_file : 8.7412, Training time: 22767.2832\n",
      "Epoch : 492/500 data_batch_2,  Train_loss : 0.1427  Test_loss : 0.1430, Time/batch_file : 8.8547, Training time: 22776.1382\n",
      "Epoch : 492/500 data_batch_3,  Train_loss : 0.1413  Test_loss : 0.1430, Time/batch_file : 8.7510, Training time: 22784.8895\n",
      "Epoch : 492/500 data_batch_4,  Train_loss : 0.1406  Test_loss : 0.1441, Time/batch_file : 8.8754, Training time: 22793.7651\n",
      "Epoch : 492/500 data_batch_5,  Train_loss : 0.1444  Test_loss : 0.1415, Time/batch_file : 8.7272, Training time: 22802.4926\n",
      "Epoch : 493/500 data_batch_1,  Train_loss : 0.1403  Test_loss : 0.1400, Time/batch_file : 8.9861, Training time: 22811.4790\n",
      "Epoch : 493/500 data_batch_2,  Train_loss : 0.1516  Test_loss : 0.1401, Time/batch_file : 8.8675, Training time: 22820.3467\n",
      "Epoch : 493/500 data_batch_3,  Train_loss : 0.1402  Test_loss : 0.1346, Time/batch_file : 8.7325, Training time: 22829.0795\n",
      "Epoch : 493/500 data_batch_4,  Train_loss : 0.1405  Test_loss : 0.1378, Time/batch_file : 8.8600, Training time: 22837.9397\n",
      "Epoch : 493/500 data_batch_5,  Train_loss : 0.1391  Test_loss : 0.1427, Time/batch_file : 8.9322, Training time: 22846.8722\n",
      "Epoch : 494/500 data_batch_1,  Train_loss : 0.1352  Test_loss : 0.1302, Time/batch_file : 8.8376, Training time: 22855.7100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 494/500 data_batch_2,  Train_loss : 0.1340  Test_loss : 0.1319, Time/batch_file : 8.7879, Training time: 22864.4982\n",
      "Epoch : 494/500 data_batch_3,  Train_loss : 0.1380  Test_loss : 0.1325, Time/batch_file : 8.9574, Training time: 22873.4558\n",
      "Epoch : 494/500 data_batch_4,  Train_loss : 0.1326  Test_loss : 0.1369, Time/batch_file : 8.6882, Training time: 22882.1442\n",
      "Epoch : 494/500 data_batch_5,  Train_loss : 0.1373  Test_loss : 0.1325, Time/batch_file : 8.7660, Training time: 22890.9104\n",
      "Epoch : 495/500 data_batch_1,  Train_loss : 0.1485  Test_loss : 0.1442, Time/batch_file : 8.6443, Training time: 22899.5550\n",
      "Epoch : 495/500 data_batch_2,  Train_loss : 0.1444  Test_loss : 0.1437, Time/batch_file : 8.7978, Training time: 22908.3531\n",
      "Epoch : 495/500 data_batch_3,  Train_loss : 0.1456  Test_loss : 0.1373, Time/batch_file : 8.7461, Training time: 22917.0994\n",
      "Epoch : 495/500 data_batch_4,  Train_loss : 0.1425  Test_loss : 0.1434, Time/batch_file : 8.8608, Training time: 22925.9606\n",
      "Epoch : 495/500 data_batch_5,  Train_loss : 0.1447  Test_loss : 0.1430, Time/batch_file : 8.8711, Training time: 22934.8319\n",
      "Epoch : 496/500 data_batch_1,  Train_loss : 0.1400  Test_loss : 0.1338, Time/batch_file : 8.8909, Training time: 22945.1456\n",
      "Epoch : 496/500 data_batch_2,  Train_loss : 0.1392  Test_loss : 0.1383, Time/batch_file : 8.6256, Training time: 22953.7714\n",
      "Epoch : 496/500 data_batch_3,  Train_loss : 0.1415  Test_loss : 0.1393, Time/batch_file : 8.7738, Training time: 22962.5454\n",
      "Epoch : 496/500 data_batch_4,  Train_loss : 0.1402  Test_loss : 0.1302, Time/batch_file : 8.8102, Training time: 22971.3559\n",
      "Epoch : 496/500 data_batch_5,  Train_loss : 0.1298  Test_loss : 0.1331, Time/batch_file : 8.7985, Training time: 22980.1548\n",
      "Epoch : 497/500 data_batch_1,  Train_loss : 0.1447  Test_loss : 0.1370, Time/batch_file : 8.7531, Training time: 22988.9082\n",
      "Epoch : 497/500 data_batch_2,  Train_loss : 0.1410  Test_loss : 0.1304, Time/batch_file : 8.7165, Training time: 22997.6248\n",
      "Epoch : 497/500 data_batch_3,  Train_loss : 0.1347  Test_loss : 0.1312, Time/batch_file : 8.6928, Training time: 23006.3178\n",
      "Epoch : 497/500 data_batch_4,  Train_loss : 0.1362  Test_loss : 0.1296, Time/batch_file : 8.7741, Training time: 23015.0922\n",
      "Epoch : 497/500 data_batch_5,  Train_loss : 0.1372  Test_loss : 0.1325, Time/batch_file : 8.8945, Training time: 23023.9869\n",
      "Epoch : 498/500 data_batch_1,  Train_loss : 0.1349  Test_loss : 0.1348, Time/batch_file : 8.9781, Training time: 23032.9652\n",
      "Epoch : 498/500 data_batch_2,  Train_loss : 0.1380  Test_loss : 0.1334, Time/batch_file : 8.8285, Training time: 23041.7939\n",
      "Epoch : 498/500 data_batch_3,  Train_loss : 0.1372  Test_loss : 0.1387, Time/batch_file : 8.7399, Training time: 23050.5340\n",
      "Epoch : 498/500 data_batch_4,  Train_loss : 0.1328  Test_loss : 0.1385, Time/batch_file : 8.7298, Training time: 23059.2643\n",
      "Epoch : 498/500 data_batch_5,  Train_loss : 0.1352  Test_loss : 0.1393, Time/batch_file : 8.8333, Training time: 23068.0979\n",
      "Epoch : 499/500 data_batch_1,  Train_loss : 0.1317  Test_loss : 0.1396, Time/batch_file : 8.8167, Training time: 23076.9161\n",
      "Epoch : 499/500 data_batch_2,  Train_loss : 0.1353  Test_loss : 0.1371, Time/batch_file : 8.6460, Training time: 23085.5623\n",
      "Epoch : 499/500 data_batch_3,  Train_loss : 0.1386  Test_loss : 0.1412, Time/batch_file : 8.8485, Training time: 23094.4111\n",
      "Epoch : 499/500 data_batch_4,  Train_loss : 0.1412  Test_loss : 0.1414, Time/batch_file : 8.5858, Training time: 23102.9971\n",
      "Epoch : 499/500 data_batch_5,  Train_loss : 0.1382  Test_loss : 0.1389, Time/batch_file : 8.6289, Training time: 23111.6263\n",
      "Epoch : 500/500 data_batch_1,  Train_loss : 0.1370  Test_loss : 0.1314, Time/batch_file : 8.7941, Training time: 23120.4205\n",
      "Epoch : 500/500 data_batch_2,  Train_loss : 0.1372  Test_loss : 0.1353, Time/batch_file : 8.7732, Training time: 23129.1939\n",
      "Epoch : 500/500 data_batch_3,  Train_loss : 0.1336  Test_loss : 0.1324, Time/batch_file : 8.7503, Training time: 23137.9444\n",
      "Epoch : 500/500 data_batch_4,  Train_loss : 0.1387  Test_loss : 0.1331, Time/batch_file : 8.9102, Training time: 23146.8549\n",
      "Epoch : 500/500 data_batch_5,  Train_loss : 0.1388  Test_loss : 0.1325, Time/batch_file : 8.8681, Training time: 23155.7233\n",
      "[./nets/net-500.ckpt] SAVED\n",
      "Optimization Finished\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "# Parameters\n",
    "training_epochs = FLAGS.training_epochs\n",
    "batch_num = FLAGS.batch_num\n",
    "batch_size = FLAGS.batch_size\n",
    "n_total_batch = int(FLAGS.img_num/batch_size)\n",
    "display_step = FLAGS.display_step\n",
    "#################################################\n",
    "# Plot parameters\n",
    "n_plot = 5    # plot 5 images\n",
    "cifar10_train_img = read_cifar(FLAGS.test_dir+'/data_batch_1')     # (10000, 32, 32, 3)\n",
    "cifar10_test_img = read_cifar(FLAGS.test_dir+'/test_batch')     # (10000, 32, 32, 3)\n",
    "train_disp_idx = np.random.randint(FLAGS.img_num, size=n_plot)    # fixed during train time\n",
    "train_gt_pure = np.copy(np.take(cifar10_train_img, train_disp_idx, axis=0))    # (n_plot, 32, 32, 3) fixed\n",
    "test_disp_idx = np.random.randint(FLAGS.img_num, size=n_plot)\n",
    "test_gt_pure = np.copy(np.take(cifar10_test_img, test_disp_idx, axis=0))    # (n_plot, 32, 32, 3) fixed\n",
    "\n",
    "rand_train_idx = np.arange(FLAGS.img_num)    # for display loss\n",
    "rand_test_idx = np.arange(FLAGS.img_num)    # for display loss\n",
    "\n",
    "##################################################\n",
    "# Initialize\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)\n",
    "\n",
    "cifar10_test_img = read_cifar(FLAGS.test_dir+'/test_batch')     # (10000, 32, 32, 3)\n",
    "\n",
    "#################################################\n",
    "# Optimize\n",
    "start_optm = time.time()\n",
    "for epoch in range(training_epochs):\n",
    "    for cifar_batch_idx in range(FLAGS.batch_num):\n",
    "        with tf.device('/CPU:0'):\n",
    "            start_epoch = time.time()\n",
    "            cifar_batch_name = FLAGS.train_dir+'/data_batch_%d' %(cifar_batch_idx+1)\n",
    "            cifar10_img = read_cifar(cifar_batch_name)     # (10000, 32, 32, 3)\n",
    "             \n",
    "        np.random.seed(epoch)\n",
    "        np.random.shuffle(rand_train_idx)\n",
    "        np.random.shuffle(rand_test_idx)\n",
    "\n",
    "        ##################################################\n",
    "        # Iteration\n",
    "        for batch_idx in range(n_total_batch):\n",
    "#             with tf.device('/CPU:0'):\n",
    "            batch_pure = np.take(cifar10_img, rand_train_idx[batch_size*batch_idx:batch_size*(batch_idx+1)], axis=0)   # pure image\n",
    "            noise = noise_batch(batch_size)    # random noise\n",
    "            batch_crpt = occl(batch_pure, noise)   # corrupted image \n",
    "            train_feeds = {ph_pure: batch_pure, ph_noise: noise, ph_crpt: batch_crpt}\n",
    "            sess.run(optm, feed_dict=train_feeds)\n",
    "\n",
    "#         with tf.device('/CPU:0'):\n",
    "        train_loss, tb_train_loss = sess.run([loss,_train_loss], feed_dict=train_feeds)\n",
    "\n",
    "        test_pure = np.take(cifar10_test_img,rand_test_idx[:batch_size], axis=0)    # pure image\n",
    "        test_noise = noise_batch(batch_size)    # random noise\n",
    "        test_crpt = occl(test_pure,test_noise)   # corrupted image\n",
    "        test_feeds = {ph_pure: test_pure, ph_noise: test_noise, ph_crpt: test_crpt}\n",
    "        test_loss, tb_test_loss = sess.run([loss,_test_loss], feed_dict=test_feeds)\n",
    "\n",
    "        writer.add_summary(tb_train_loss, epoch)\n",
    "        writer.add_summary(tb_test_loss, epoch)\n",
    "        \n",
    "        epoch_time = time.time() - start_epoch\n",
    "        current_time = time.time() - start_optm\n",
    "        print(\"Epoch : %03d/%03d data_batch_%d,  Train_loss : %.4f  Test_loss : %.4f, Time/batch_file : %.4f, Training time: %.4f\" \n",
    "              % (epoch+1, training_epochs, cifar_batch_idx+1, train_loss, test_loss, epoch_time, current_time))   \n",
    "        \n",
    "    # Display\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        # train_gt_pure  # pure image\n",
    "        train_gt_noise = noise_batch(n_plot)    # random noise\n",
    "        train_gt_crpt = occl(train_gt_pure,train_gt_noise)   # corrupted image\n",
    "        train_gt_feeds = {ph_pure: train_gt_pure, ph_noise: train_gt_noise, ph_crpt: train_gt_crpt}\n",
    "        \n",
    "        # test_gt_pure   # pure image\n",
    "        test_gt_noise = noise_batch(n_plot)    # random noise\n",
    "        test_gt_crpt = occl(test_gt_pure,test_gt_noise)   # corrupted image\n",
    "        test_gt_feeds = {ph_pure: test_gt_pure, ph_noise: test_gt_noise, ph_crpt: test_gt_crpt}\n",
    "        \n",
    "        ##########################################################\n",
    "        # generated images\n",
    "        train_gen_pure, train_gen_noise, train_gen_crpt = sess.run([core_gen, shell2_gen, full_gen], \\\n",
    "                                        feed_dict=train_gt_feeds)  # 3072-d vector\n",
    "        test_gen_pure, test_gen_noise, test_gen_crpt = sess.run([core_gen, shell2_gen, full_gen], \\\n",
    "                                        feed_dict=test_gt_feeds)  # 3072-d vector\n",
    "        \n",
    "        ##########################################################\n",
    "        # plotting results from training data\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=4, ncols=n_plot, figsize=(10,2*n_plot))   # displaying 4*n_plot images\n",
    "        plt.setp(axes, xticks=np.arange(0,31,8), yticks=np.arange(0,31,8)) \n",
    "        for j in range(n_plot):\n",
    "#                 train_disp_gt_crpt = np.reshape(train_gt_crpt[j], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "            axes[0, j].imshow(train_gt_crpt[j], cmap='gray')   \n",
    "            axes[0, j].set(ylabel='gt_crpt')\n",
    "            axes[0, j].label_outer()\n",
    "\n",
    "#                 train_disp_gen_pure = np.reshape(train_gen_pure[j], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "            axes[1, j].imshow(train_gen_pure[j], cmap='gray')   \n",
    "            axes[1, j].set(ylabel='gen_pure')\n",
    "            axes[1, j].label_outer()\n",
    "\n",
    "#                 train_disp_gen_noise = np.reshape(train_gen_noise[j], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "            axes[2, j].imshow(train_gen_noise[j], cmap='gray')   \n",
    "            axes[2, j].set(ylabel='gen_noise')\n",
    "            axes[2, j].label_outer()\n",
    "\n",
    "#                 train_disp_gen_crpt = np.reshape(train_gen_crpt[j], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "            axes[3, j].imshow(train_gen_crpt[j], cmap='gray')   \n",
    "            axes[3, j].set(ylabel='gen_crpt')\n",
    "            axes[3, j].label_outer()\n",
    "\n",
    "        plt.savefig(outputdir+'/train/epoch %03d' %(epoch+1))    \n",
    "        plt.close(fig)\n",
    "\n",
    "        # plotting results from testing data\n",
    "        fig, axes = plt.subplots(nrows=4, ncols=n_plot, figsize=(10,2*n_plot))   # displaying 4*n_plot images\n",
    "        plt.setp(axes, xticks=np.arange(0,31,8), yticks=np.arange(0,31,8)) \n",
    "        for k in range(n_plot):\n",
    "#                 test_disp_gt_crpt = np.reshape(test_gt_crpt[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "            axes[0, k].imshow(test_gt_crpt[k])   \n",
    "            axes[0, k].set(ylabel='gt_crpt')\n",
    "            axes[0, k].label_outer()\n",
    "\n",
    "#                 test_disp_gen_pure = np.reshape(test_gen_pure[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "            axes[1, k].imshow(test_gen_pure[k])   \n",
    "            axes[1, k].set(ylabel='gen_pure')\n",
    "            axes[1, k].label_outer()           \n",
    "\n",
    "#                 test_disp_gen_noise = np.reshape(test_gen_noise[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "            axes[2, k].imshow(test_gen_noise[k])   \n",
    "            axes[2, k].set(ylabel='gen_noise')\n",
    "            axes[2, k].label_outer()\n",
    "\n",
    "#                 test_disp_gen_crpt = np.reshape(test_gen_crpt[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "            axes[3, k].imshow(test_gen_crpt[k])   \n",
    "            axes[3, k].set(ylabel='gen_crpt')\n",
    "            axes[3, k].label_outer()\n",
    "\n",
    "\n",
    "        plt.savefig(outputdir+'/test/epoch %03d' %(epoch+1))    \n",
    "        plt.close(fig)\n",
    "\n",
    "        # Save\n",
    "        if (epoch+1) % FLAGS.save_step ==0:\n",
    "            savename = savedir+\"/net-\"+str(epoch+1)+\".ckpt\"\n",
    "            saver.save(sess, savename)\n",
    "            print(\"[%s] SAVED\" % (savename))\n",
    "\n",
    "print(\"Optimization Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./nets/net-500.ckpt\n",
      "NETWORK RESTORED\n"
     ]
    }
   ],
   "source": [
    "do_restore = 1\n",
    "if do_restore == 1:\n",
    "    sess = tf.Session()\n",
    "    epoch = FLAGS.training_epochs\n",
    "    savename = savedir+\"/net-\"+str(epoch)+\".ckpt\"\n",
    "    saver.restore(sess, savename)\n",
    "    print (\"NETWORK RESTORED\")\n",
    "else:\n",
    "    print (\"DO NOTHING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAIsCAYAAABRBMX6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cb9423c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_disp_idx = np.random.randint(FLAGS.img_num, size=n_plot)\n",
    "test_gt_pure = np.copy(np.take(cifar10_test_img, test_disp_idx, axis=0))    # (n_plot, 3072) fixed\n",
    "test_gt_noise = noise_batch(5)    # random noise\n",
    "test_gt_crpt = occl(test_gt_pure,test_gt_noise)   # corrupted image\n",
    "test_gt_feeds = {ph_crpt: test_gt_crpt}\n",
    "test_gen_pure, test_gen_noise, test_gen_crpt = sess.run([core_gen, shell2_gen, full_gen], \\\n",
    "                                                        feed_dict=test_gt_feeds)\n",
    "\n",
    "# plotting results from testing data\n",
    "fig, axes = plt.subplots(nrows=4, ncols=n_plot, figsize=(10,2*n_plot))   # displaying 4*n_plot images\n",
    "plt.setp(axes, xticks=np.arange(0,31,8), yticks=np.arange(0,31,8)) \n",
    "for k in range(n_plot):\n",
    "#     test_disp_gt_crpt = np.reshape(test_gt_crpt[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "    axes[0, k].imshow(test_gt_crpt[k])   \n",
    "    axes[0, k].set(ylabel='gt_crpt')\n",
    "    axes[0, k].label_outer()\n",
    "\n",
    "#     test_disp_gen_pure = np.reshape(test_gen_pure[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "    axes[1, k].imshow(test_gen_pure[k])   \n",
    "    axes[1, k].set(ylabel='gen_pure')\n",
    "    axes[1, k].label_outer()           \n",
    "\n",
    "#     test_disp_gen_noise = np.reshape(test_gen_noise[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "    axes[2, k].imshow(test_gen_noise[k])   \n",
    "    axes[2, k].set(ylabel='gen_noise')\n",
    "    axes[2, k].label_outer()\n",
    "\n",
    "#     test_disp_gen_crpt = np.reshape(test_gen_crpt[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "    axes[3, k].imshow(test_gen_crpt[k])   \n",
    "    axes[3, k].set(ylabel='gen_crpt')\n",
    "    axes[3, k].label_outer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
