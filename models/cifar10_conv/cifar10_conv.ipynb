{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current version [1.3.1]\n",
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "import time\n",
    "import cPickle\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  ## just for ignore DeprcationWarning message\n",
    "print(\"Current version [%s]\" %(tf.__version__))\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAGS READY\n"
     ]
    }
   ],
   "source": [
    "# Dataset Configurations\n",
    "tf.app.flags.DEFINE_integer('img_size', 32, \"\"\"Image size of CIFAR-10 dataset\"\"\")\n",
    "tf.app.flags.DEFINE_integer('img_num', 10000, \"\"\"Number of images in one cifar batch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_num', 5, \"\"\"Number of cifar batches in dataset\"\"\")\n",
    "tf.app.flags.DEFINE_string('train_dir', './../../../Dataset/cifar-10-batches-py', \"\"\"Directory which contains the train data\"\"\")\n",
    "tf.app.flags.DEFINE_string('test_dir', './../../../Dataset/cifar-10-batches-py', \"\"\"Directory which contains the test data\"\"\")\n",
    "\n",
    "# Network Configurations\n",
    "tf.app.flags.DEFINE_integer('batch_size', 100, \"\"\"Number of images to process in a batch\"\"\")\n",
    "tf.app.flags.DEFINE_float('l1_ratio', 0.5, \"\"\"Ratio of level1\"\"\")\n",
    "tf.app.flags.DEFINE_float('l2_ratio', 0.5, \"\"\"Ratio of level2\"\"\")\n",
    "\n",
    "# Optimization Configurations\n",
    "tf.app.flags.DEFINE_float('lr', 0.001, \"\"\"Learning rate\"\"\")\n",
    "\n",
    "# Training Configurations\n",
    "tf.app.flags.DEFINE_integer('training_epochs', 2000, \"\"\"Number of epochs to run\"\"\")\n",
    "tf.app.flags.DEFINE_integer('display_step', 10, \"\"\"Number of iterations to display training output\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_step', 10, \"\"\"Number of interations to save checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_max', 10, \"\"\"Number of checkpoints to remain\"\"\")\n",
    "\n",
    "\n",
    "# Save Configurations\n",
    "tf.app.flags.DEFINE_string('nets', './nets', \"\"\"Directory where to write the checkpoints\"\"\")\n",
    "tf.app.flags.DEFINE_string('outputs', './outputs', \"\"\"Directory where to save the output images\"\"\")\n",
    "tf.app.flags.DEFINE_string('tboard', './tensorboard', \"\"\"Directory where to save the tensorboard logs\"\"\")\n",
    "\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "print(\"FLAGS READY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with tf.device('/CPU:0'):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = cPickle.load(fo)\n",
    "        return dict\n",
    "\n",
    "def read_cifar(file):\n",
    "    with tf.device('/CPU:0'):\n",
    "        _dic = unpickle(file)\n",
    "        _img = _dic['data']/255.    # float type\n",
    "        _label = _dic['labels']    # (10000, )\n",
    "\n",
    "        _img_shape = np.shape(_img)\n",
    "        _img = np.reshape(np.transpose(np.reshape(_img, (-1, 3, 32, 32)), (0,2,3,1)), _img_shape)\n",
    "        return _img   # (10000, 3072)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random noise mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_mask(prob=0.5):\n",
    "    with tf.device('/CPU:0'):\n",
    "        mask = np.zeros([FLAGS.img_size, FLAGS.img_size, 3])\n",
    "        rd = np.random.random()\n",
    "        if rd > prob:\n",
    "            # threshold of the size of masks\n",
    "            uthd = FLAGS.img_size    \n",
    "            lthd = 0     \n",
    "            # mask size should be beween 14x14, 5x5\n",
    "            while(uthd>14 or lthd<5):\n",
    "                ver1 = np.random.random_integers(0, FLAGS.img_size-1, size= 2)   # vertex1\n",
    "                ver2 = np.random.random_integers(0, FLAGS.img_size-1, size= 2)    # vertex2\n",
    "                uthd = np.maximum(np.abs(ver1[0]-ver2[0]), np.abs(ver1[1]-ver2[1]))    # upperbound\n",
    "                lthd = np.minimum(np.abs(ver1[0]-ver2[0]), np.abs(ver1[1]-ver2[1]))    # lowerbound\n",
    "            xmin = np.minimum(ver1[0], ver2[0])    # left x value\n",
    "            xmax = np.maximum(ver1[0], ver2[0])    # right x value\n",
    "            ymin = np.minimum(ver1[1], ver2[1])    # top y value\n",
    "            ymax = np.maximum(ver1[1], ver2[1])    # bottom y value\n",
    "            noise = np.random.random((xmax-xmin+1, ymax-ymin+1, 3))    # random sample in [0,1]\n",
    "            mask[xmin:xmax+1, ymin:ymax+1, :] = noise    # noise mask with location\n",
    "            mask_meta = [xmin, xmax, ymin, ymax, noise, mask]\n",
    "        mask = np.reshape(mask, [-1])\n",
    "        return mask\n",
    "\n",
    "def noise_batch(batch_num):\n",
    "    with tf.device('/CPU:0'):\n",
    "        # make random noise batch\n",
    "        mask_batch = np.zeros([batch_num, FLAGS.img_size*FLAGS.img_size*3])\n",
    "        for i in range(batch_num):\n",
    "            mask_batch[i,:] = noise_mask()\n",
    "        return mask_batch\n",
    "\n",
    "\n",
    "def occl(target, disturb):\n",
    "    with tf.device('/CPU:0'):\n",
    "        # Occlusion generation\n",
    "        mask = (disturb==0).astype(float)\n",
    "        masked_target = np.multiply(target, mask)\n",
    "        crpt = np.add(masked_target, disturb)\n",
    "        return crpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nested_mlp(l1, l2_s, l2, out_channel, name, stddev=0.1, is_init=False, is_last=False):\n",
    "    l1_shape = l1.get_shape()[1]\n",
    "    l2_shape = l2.get_shape()[1]\n",
    "    l2_s_shape = l2_s.get_shape()[1]\n",
    "    \n",
    "    if is_init:\n",
    "        # input is the input image\n",
    "        with tf.device('/CPU:0'):\n",
    "            with tf.variable_scope('level1'):\n",
    "                with tf.variable_scope(name):\n",
    "                    l1_weights = tf.get_variable('weights', \n",
    "                                                 [l1_shape, out_channel*FLAGS.l1_ratio], \n",
    "                                                 tf.float32, \n",
    "                                                 initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l1_biases = tf.get_variable('biases', \n",
    "                                                [out_channel*FLAGS.l1_ratio],\n",
    "                                                tf.float32, \n",
    "                                                initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            with tf.variable_scope('level2'):\n",
    "                with tf.variable_scope(name):\n",
    "                    l2_s_weights = tf.get_variable('weights_shell', \n",
    "                                                 [l2_s_shape, out_channel*FLAGS.l2_ratio], \n",
    "                                                 tf.float32, \n",
    "                                                 initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l2_s_biases = tf.get_variable('biases_shell', \n",
    "                                                [out_channel*FLAGS.l2_ratio],\n",
    "                                                tf.float32, \n",
    "                                                initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    \n",
    "\n",
    "        l1_mlp = tf.nn.sigmoid(tf.add(tf.matmul(l1, l1_weights), l1_biases))\n",
    "        l2_s_mlp = tf.nn.sigmoid(tf.add(tf.matmul(l2_s, l2_s_weights), l2_s_biases))\n",
    "        l2_mlp = tf.concat((l1_mlp, l2_s_mlp), 1)\n",
    "    \n",
    "    elif is_last:\n",
    "        # output is the generated image\n",
    "        with tf.device('/CPU:0'):\n",
    "            with tf.variable_scope('level1'):\n",
    "                with tf.variable_scope(name):\n",
    "                    l1_weights = tf.get_variable('weights', \n",
    "                                                 [l1_shape, out_channel], \n",
    "                                                 tf.float32, \n",
    "                                                 initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l1_biases = tf.get_variable('biases', \n",
    "                                                [out_channel],\n",
    "                                                tf.float32, \n",
    "                                                initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            with tf.variable_scope('level2'):\n",
    "                with tf.variable_scope(name):\n",
    "                    l2_s_weights = tf.get_variable('weights_shell', \n",
    "                                                 [l2_s_shape, out_channel], \n",
    "                                                 tf.float32, \n",
    "                                                 initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l2_s_biases = tf.get_variable('biases_shell', \n",
    "                                                [out_channel],\n",
    "                                                tf.float32, \n",
    "                                                initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l2_weights = tf.get_variable('weights', \n",
    "                                                 [l2_shape, out_channel], \n",
    "                                                 tf.float32, \n",
    "                                                 initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l2_biases = tf.get_variable('biases', \n",
    "                                                [out_channel],\n",
    "                                                tf.float32, \n",
    "                                                initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    \n",
    "\n",
    "        l1_mlp = tf.nn.sigmoid(tf.add(tf.matmul(l1, l1_weights), l1_biases))\n",
    "        l2_s_mlp = tf.nn.sigmoid(tf.add(tf.matmul(l2_s, l2_s_weights), l2_s_biases))\n",
    "        l2_mlp = tf.nn.sigmoid(tf.add(tf.matmul(l2, l2_weights), l2_biases))\n",
    "                                 \n",
    "    else:\n",
    "        with tf.device('/CPU:0'):\n",
    "            with tf.variable_scope('level1'):\n",
    "                with tf.variable_scope(name):\n",
    "                    l1_weights = tf.get_variable('weights', \n",
    "                                                 [l1_shape, out_channel*FLAGS.l1_ratio], \n",
    "                                                 tf.float32, \n",
    "                                                 initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l1_biases = tf.get_variable('biases', \n",
    "                                                [out_channel*FLAGS.l1_ratio],\n",
    "                                                tf.float32, \n",
    "                                                initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "            with tf.variable_scope('level2'):\n",
    "                with tf.variable_scope(name):\n",
    "                    l2_s_weights = tf.get_variable('weights_shell', \n",
    "                                                   [l2_s_shape, out_channel*FLAGS.l2_ratio], \n",
    "                                                   tf.float32, \n",
    "                                                   initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l2_s_biases = tf.get_variable('biases_shell', \n",
    "                                                  [out_channel*FLAGS.l2_ratio],\n",
    "                                                  tf.float32, \n",
    "                                                  initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l2_weights_1 = tf.get_variable('weights_1', \n",
    "                                                   [l2_s_shape, out_channel*FLAGS.l1_ratio], \n",
    "                                                   tf.float32, \n",
    "                                                   initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l2_biases_1 = tf.get_variable('biases_1', \n",
    "                                                  [out_channel*FLAGS.l1_ratio],\n",
    "                                                  tf.float32, \n",
    "                                                  initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l2_weights_2 = tf.get_variable('weights_2', \n",
    "                                                   [l1_shape, out_channel*FLAGS.l2_ratio], \n",
    "                                                   tf.float32, \n",
    "                                                   initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "                    l2_biases_2 = tf.get_variable('biases_2', \n",
    "                                                  [out_channel*FLAGS.l2_ratio],\n",
    "                                                  tf.float32, \n",
    "                                                  initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "        l1_mlp_r = tf.add(tf.matmul(l1, l1_weights), l1_biases)\n",
    "        l1_mlp = tf.nn.sigmoid(l1_mlp_r)\n",
    "        \n",
    "        l2_s_mlp = tf.nn.sigmoid(tf.add(tf.matmul(l2_s, l2_s_weights), l2_s_biases))\n",
    "        \n",
    "        l2_mlp_1_r = tf.add(tf.matmul(l2[:,l1_shape:l2_shape], l2_weights_1), l2_biases_1)\n",
    "        l2_mlp_1 = tf.nn.sigmoid(tf.add(l1_mlp_r, l2_mlp_1_r))\n",
    "        l2_mlp_2_r = tf.add(tf.matmul(l2[:,:l1_shape], l2_weights_2), l2_biases_2)\n",
    "        l2_mlp_3_r = tf.add(tf.matmul(l2[:,l1_shape:l2_shape], l2_s_weights), l2_s_biases)\n",
    "        l2_mlp_2 = tf.nn.sigmoid(tf.add(l2_mlp_2_r, l2_mlp_3_r))\n",
    "        l2_mlp = tf.concat((l2_mlp_1, l2_mlp_2), 1)\n",
    "        \n",
    "        \n",
    "    return l1_mlp, l2_s_mlp, l2_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs Ready\n"
     ]
    }
   ],
   "source": [
    "# Network Topology\n",
    "n_input = FLAGS.img_size*FLAGS.img_size*3\n",
    "n_enc1 = 1024/2\n",
    "n_enc2 = 512/2\n",
    "n_enc3 = 256/2\n",
    "n_dec1 = 512/2\n",
    "n_dec2 = 1024/2\n",
    "n_out = n_input\n",
    "\n",
    "# Inputs and Outputs\n",
    "ph_pure = tf.placeholder(\"float\", [None, n_input])    # pure image --- core\n",
    "ph_noise= tf.placeholder(\"float\", [None, n_input])    # noise --- shell1\n",
    "ph_crpt = tf.placeholder(\"float\", [None, n_input])    # corrupted image   --- level2\n",
    "\n",
    "\n",
    "# Model\n",
    "def nested_ae_mlp(_X):\n",
    "    l1_enc1, l2_s_enc1, l2_enc1 = _nested_mlp(_X, _X, _X, n_enc1, name='enc1', is_init=True)\n",
    "    l1_enc2, l2_s_enc2, l2_enc2 = _nested_mlp(l1_enc1, l2_s_enc1, l2_enc1, n_enc2, name='enc2')\n",
    "    l1_enc3, l2_s_enc3, l2_enc3 = _nested_mlp(l1_enc2, l2_s_enc2, l2_enc2, n_enc3, name='enc3')\n",
    "    l1_dec1, l2_s_dec1, l2_dec1 = _nested_mlp(l1_enc3, l2_s_enc3, l2_enc3, n_dec1, name='dec1')\n",
    "    l1_dec2, l2_s_dec2, l2_dec2 = _nested_mlp(l1_dec1, l2_s_dec1, l2_dec1, n_dec2, name='dec2')\n",
    "    l1_out, l2_s_out, l2_out = _nested_mlp(l1_dec2, l2_s_dec2, l2_dec2, n_out, name='out',is_last=True)\n",
    "    return l1_out, l2_s_out, l2_out\n",
    "\n",
    "# Generation\n",
    "core_gen, shell2_gen, full_gen = nested_ae_mlp(ph_crpt)   # [None, n_input]\n",
    "\n",
    "# Loss & Optimizer\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    loss = tf.reduce_mean(tf.nn.l2_loss(full_gen-ph_crpt)) + tf.reduce_mean(tf.nn.l2_loss(core_gen-ph_pure))\\\n",
    "            + tf.reduce_mean(tf.nn.l2_loss(shell2_gen-ph_noise))\n",
    "    _train_loss = tf.summary.scalar(\"train_loss\", loss)\n",
    "    _test_loss = tf.summary.scalar(\"test_loss\", loss)\n",
    "\n",
    "optm = tf.train.AdamOptimizer(learning_rate=FLAGS.lr).minimize(loss)\n",
    "\n",
    "\n",
    "print(\"Graphs Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Ready\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "tensorboard_path = FLAGS.tboard\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)\n",
    "writer = tf.summary.FileWriter(tensorboard_path)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "print(\"Initialize Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saver ready\n"
     ]
    }
   ],
   "source": [
    "outputdir = FLAGS.outputs\n",
    "if not os.path.exists(outputdir+'/train'):\n",
    "    os.makedirs(outputdir+'/train')\n",
    "\n",
    "if not os.path.exists(outputdir+'/test'):\n",
    "    os.makedirs(outputdir+'/test')\n",
    "    \n",
    "savedir = FLAGS.nets\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "    \n",
    "saver = tf.train.Saver(max_to_keep=FLAGS.save_max)\n",
    "print(\"Saver ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 001/2000 data_batch_1,  Train_loss : 21205.0879  Test_loss : 22354.9805, Time/batch_file : 2.5858, Training time: 2.5871\n",
      "Epoch : 001/2000 data_batch_2,  Train_loss : 17368.3965  Test_loss : 16097.6875, Time/batch_file : 2.3333, Training time: 4.9208\n",
      "Epoch : 001/2000 data_batch_3,  Train_loss : 15704.2314  Test_loss : 15438.1875, Time/batch_file : 2.3098, Training time: 7.2308\n",
      "Epoch : 001/2000 data_batch_4,  Train_loss : 15436.0898  Test_loss : 14834.8008, Time/batch_file : 2.3062, Training time: 9.5372\n",
      "Epoch : 001/2000 data_batch_5,  Train_loss : 14354.7988  Test_loss : 13697.2959, Time/batch_file : 2.3017, Training time: 11.8391\n",
      "Epoch : 002/2000 data_batch_1,  Train_loss : 13955.6797  Test_loss : 13888.5264, Time/batch_file : 2.3487, Training time: 14.1880\n",
      "Epoch : 002/2000 data_batch_2,  Train_loss : 15542.4014  Test_loss : 13841.1406, Time/batch_file : 2.3008, Training time: 16.4889\n",
      "Epoch : 002/2000 data_batch_3,  Train_loss : 14438.7930  Test_loss : 13955.3096, Time/batch_file : 2.3381, Training time: 18.8273\n",
      "Epoch : 002/2000 data_batch_4,  Train_loss : 14264.2129  Test_loss : 14019.5889, Time/batch_file : 2.3399, Training time: 21.1673\n",
      "Epoch : 002/2000 data_batch_5,  Train_loss : 14143.6465  Test_loss : 14621.1328, Time/batch_file : 2.3188, Training time: 23.4863\n",
      "Epoch : 003/2000 data_batch_1,  Train_loss : 13246.9297  Test_loss : 13307.1660, Time/batch_file : 2.3114, Training time: 25.7978\n",
      "Epoch : 003/2000 data_batch_2,  Train_loss : 13055.1836  Test_loss : 13791.6943, Time/batch_file : 2.3152, Training time: 28.1132\n",
      "Epoch : 003/2000 data_batch_3,  Train_loss : 13600.0400  Test_loss : 14289.6777, Time/batch_file : 2.3138, Training time: 30.4272\n",
      "Epoch : 003/2000 data_batch_4,  Train_loss : 13322.7275  Test_loss : 13196.1982, Time/batch_file : 2.3012, Training time: 32.7287\n",
      "Epoch : 003/2000 data_batch_5,  Train_loss : 12541.8652  Test_loss : 12851.4395, Time/batch_file : 2.3043, Training time: 35.0331\n",
      "Epoch : 004/2000 data_batch_1,  Train_loss : 13513.3701  Test_loss : 13321.1719, Time/batch_file : 2.3203, Training time: 37.3535\n",
      "Epoch : 004/2000 data_batch_2,  Train_loss : 14259.5645  Test_loss : 13216.1982, Time/batch_file : 2.3141, Training time: 39.6679\n",
      "Epoch : 004/2000 data_batch_3,  Train_loss : 13793.4209  Test_loss : 13071.1621, Time/batch_file : 2.3187, Training time: 41.9868\n",
      "Epoch : 004/2000 data_batch_4,  Train_loss : 14298.5088  Test_loss : 12711.0645, Time/batch_file : 2.3164, Training time: 44.3033\n",
      "Epoch : 004/2000 data_batch_5,  Train_loss : 13961.9629  Test_loss : 12862.4971, Time/batch_file : 2.3184, Training time: 46.6219\n",
      "Epoch : 005/2000 data_batch_1,  Train_loss : 14155.4854  Test_loss : 12062.2168, Time/batch_file : 2.3063, Training time: 48.9285\n",
      "Epoch : 005/2000 data_batch_2,  Train_loss : 13299.7852  Test_loss : 13768.4883, Time/batch_file : 2.3031, Training time: 51.2318\n",
      "Epoch : 005/2000 data_batch_3,  Train_loss : 13351.1299  Test_loss : 12763.2178, Time/batch_file : 2.3091, Training time: 53.5412\n",
      "Epoch : 005/2000 data_batch_4,  Train_loss : 13199.1064  Test_loss : 13663.5479, Time/batch_file : 2.3158, Training time: 55.8572\n",
      "Epoch : 005/2000 data_batch_5,  Train_loss : 12595.4434  Test_loss : 12376.3799, Time/batch_file : 2.3126, Training time: 58.1700\n",
      "Epoch : 006/2000 data_batch_1,  Train_loss : 14051.7285  Test_loss : 13492.1963, Time/batch_file : 2.3147, Training time: 60.4848\n",
      "Epoch : 006/2000 data_batch_2,  Train_loss : 12980.1758  Test_loss : 13392.8730, Time/batch_file : 2.2935, Training time: 62.7785\n",
      "Epoch : 006/2000 data_batch_3,  Train_loss : 13070.5762  Test_loss : 13814.3730, Time/batch_file : 2.3061, Training time: 65.0848\n",
      "Epoch : 006/2000 data_batch_4,  Train_loss : 12886.7227  Test_loss : 12917.8574, Time/batch_file : 2.3159, Training time: 67.4009\n",
      "Epoch : 006/2000 data_batch_5,  Train_loss : 12617.0488  Test_loss : 13071.8545, Time/batch_file : 2.3126, Training time: 69.7138\n",
      "Epoch : 007/2000 data_batch_1,  Train_loss : 13243.9053  Test_loss : 13259.1426, Time/batch_file : 2.2855, Training time: 71.9995\n",
      "Epoch : 007/2000 data_batch_2,  Train_loss : 13795.6143  Test_loss : 13471.2842, Time/batch_file : 2.2992, Training time: 74.2989\n",
      "Epoch : 007/2000 data_batch_3,  Train_loss : 13072.3164  Test_loss : 12587.6406, Time/batch_file : 2.3031, Training time: 76.6021\n",
      "Epoch : 007/2000 data_batch_4,  Train_loss : 12746.6738  Test_loss : 13407.9492, Time/batch_file : 2.2930, Training time: 78.8954\n",
      "Epoch : 007/2000 data_batch_5,  Train_loss : 12916.6309  Test_loss : 12623.0771, Time/batch_file : 2.3041, Training time: 81.1997\n",
      "Epoch : 008/2000 data_batch_1,  Train_loss : 13295.5449  Test_loss : 12266.9648, Time/batch_file : 2.3205, Training time: 83.5204\n",
      "Epoch : 008/2000 data_batch_2,  Train_loss : 12686.4688  Test_loss : 11883.3789, Time/batch_file : 2.3017, Training time: 85.8223\n",
      "Epoch : 008/2000 data_batch_3,  Train_loss : 12297.5713  Test_loss : 11379.5195, Time/batch_file : 2.3103, Training time: 88.1328\n",
      "Epoch : 008/2000 data_batch_4,  Train_loss : 12053.0527  Test_loss : 12045.5742, Time/batch_file : 2.3005, Training time: 90.4334\n",
      "Epoch : 008/2000 data_batch_5,  Train_loss : 13251.4951  Test_loss : 11241.1348, Time/batch_file : 2.3110, Training time: 92.7447\n",
      "Epoch : 009/2000 data_batch_1,  Train_loss : 11807.8623  Test_loss : 12079.0508, Time/batch_file : 2.2976, Training time: 95.0426\n",
      "Epoch : 009/2000 data_batch_2,  Train_loss : 11919.1904  Test_loss : 11245.1016, Time/batch_file : 2.2981, Training time: 97.3409\n",
      "Epoch : 009/2000 data_batch_3,  Train_loss : 11001.2080  Test_loss : 12974.3926, Time/batch_file : 2.2918, Training time: 99.6330\n",
      "Epoch : 009/2000 data_batch_4,  Train_loss : 11560.9941  Test_loss : 12036.0156, Time/batch_file : 2.3028, Training time: 101.9360\n",
      "Epoch : 009/2000 data_batch_5,  Train_loss : 11316.1729  Test_loss : 12414.0078, Time/batch_file : 2.2906, Training time: 104.2267\n",
      "Epoch : 010/2000 data_batch_1,  Train_loss : 12267.8115  Test_loss : 12193.0908, Time/batch_file : 2.3220, Training time: 106.5489\n",
      "Epoch : 010/2000 data_batch_2,  Train_loss : 11959.9668  Test_loss : 12912.5859, Time/batch_file : 2.3122, Training time: 108.8614\n",
      "Epoch : 010/2000 data_batch_3,  Train_loss : 11667.1553  Test_loss : 12476.0508, Time/batch_file : 2.3118, Training time: 111.1733\n",
      "Epoch : 010/2000 data_batch_4,  Train_loss : 12361.5605  Test_loss : 12560.0410, Time/batch_file : 2.3122, Training time: 113.4859\n",
      "Epoch : 010/2000 data_batch_5,  Train_loss : 9972.7861  Test_loss : 12188.1650, Time/batch_file : 2.3107, Training time: 115.7969\n",
      "[./nets/net-10.ckpt] SAVED\n",
      "Epoch : 011/2000 data_batch_1,  Train_loss : 12046.0488  Test_loss : 12660.3027, Time/batch_file : 2.2994, Training time: 119.5640\n",
      "Epoch : 011/2000 data_batch_2,  Train_loss : 12311.3506  Test_loss : 12134.6367, Time/batch_file : 2.3127, Training time: 121.8769\n",
      "Epoch : 011/2000 data_batch_3,  Train_loss : 11805.6719  Test_loss : 11413.4805, Time/batch_file : 2.2954, Training time: 124.1726\n",
      "Epoch : 011/2000 data_batch_4,  Train_loss : 12696.4414  Test_loss : 11705.8525, Time/batch_file : 2.2948, Training time: 126.4676\n",
      "Epoch : 011/2000 data_batch_5,  Train_loss : 11917.9727  Test_loss : 12650.4404, Time/batch_file : 2.3053, Training time: 128.7731\n",
      "Epoch : 012/2000 data_batch_1,  Train_loss : 11970.9395  Test_loss : 11286.7207, Time/batch_file : 2.2984, Training time: 131.0717\n",
      "Epoch : 012/2000 data_batch_2,  Train_loss : 10596.2646  Test_loss : 11624.4199, Time/batch_file : 2.3132, Training time: 133.3851\n",
      "Epoch : 012/2000 data_batch_3,  Train_loss : 11688.0615  Test_loss : 11119.9834, Time/batch_file : 2.2896, Training time: 135.6747\n",
      "Epoch : 012/2000 data_batch_4,  Train_loss : 11269.5566  Test_loss : 10979.4121, Time/batch_file : 2.3028, Training time: 137.9776\n",
      "Epoch : 012/2000 data_batch_5,  Train_loss : 10786.8066  Test_loss : 10820.5244, Time/batch_file : 2.2934, Training time: 140.2712\n",
      "Epoch : 013/2000 data_batch_1,  Train_loss : 12403.7617  Test_loss : 11974.0762, Time/batch_file : 2.3217, Training time: 142.5930\n",
      "Epoch : 013/2000 data_batch_2,  Train_loss : 10828.7910  Test_loss : 11407.7773, Time/batch_file : 2.3132, Training time: 144.9063\n",
      "Epoch : 013/2000 data_batch_3,  Train_loss : 11567.3730  Test_loss : 12209.6836, Time/batch_file : 2.3054, Training time: 147.2119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 013/2000 data_batch_4,  Train_loss : 11613.1533  Test_loss : 11011.9209, Time/batch_file : 2.3042, Training time: 149.5164\n",
      "Epoch : 013/2000 data_batch_5,  Train_loss : 11137.5664  Test_loss : 11483.2031, Time/batch_file : 2.3092, Training time: 151.8258\n",
      "Epoch : 014/2000 data_batch_1,  Train_loss : 11766.4541  Test_loss : 11567.7764, Time/batch_file : 2.2990, Training time: 154.1250\n",
      "Epoch : 014/2000 data_batch_2,  Train_loss : 10795.5762  Test_loss : 11054.9805, Time/batch_file : 2.3061, Training time: 156.4314\n",
      "Epoch : 014/2000 data_batch_3,  Train_loss : 12084.2275  Test_loss : 11706.8340, Time/batch_file : 2.2970, Training time: 158.7286\n",
      "Epoch : 014/2000 data_batch_4,  Train_loss : 11343.2852  Test_loss : 11160.5869, Time/batch_file : 2.3103, Training time: 161.0392\n",
      "Epoch : 014/2000 data_batch_5,  Train_loss : 10837.4111  Test_loss : 11144.8691, Time/batch_file : 2.3052, Training time: 163.3447\n",
      "Epoch : 015/2000 data_batch_1,  Train_loss : 11133.9277  Test_loss : 10758.7539, Time/batch_file : 2.2913, Training time: 165.6362\n",
      "Epoch : 015/2000 data_batch_2,  Train_loss : 11046.8936  Test_loss : 10361.8477, Time/batch_file : 2.2864, Training time: 167.9228\n",
      "Epoch : 015/2000 data_batch_3,  Train_loss : 10959.0000  Test_loss : 9925.0205, Time/batch_file : 2.3017, Training time: 170.2246\n",
      "Epoch : 015/2000 data_batch_4,  Train_loss : 10480.7637  Test_loss : 10880.1113, Time/batch_file : 2.2878, Training time: 172.5127\n",
      "Epoch : 015/2000 data_batch_5,  Train_loss : 10920.5371  Test_loss : 10726.0039, Time/batch_file : 2.3180, Training time: 174.8308\n",
      "Epoch : 016/2000 data_batch_1,  Train_loss : 11237.4746  Test_loss : 10909.0820, Time/batch_file : 2.2916, Training time: 177.1226\n",
      "Epoch : 016/2000 data_batch_2,  Train_loss : 11172.5986  Test_loss : 11260.3525, Time/batch_file : 2.3009, Training time: 179.4237\n",
      "Epoch : 016/2000 data_batch_3,  Train_loss : 11904.9053  Test_loss : 11205.2471, Time/batch_file : 2.2834, Training time: 181.7073\n",
      "Epoch : 016/2000 data_batch_4,  Train_loss : 10685.0801  Test_loss : 10992.1299, Time/batch_file : 2.2964, Training time: 184.0039\n",
      "Epoch : 016/2000 data_batch_5,  Train_loss : 10694.1973  Test_loss : 11211.3574, Time/batch_file : 2.2815, Training time: 186.2856\n",
      "Epoch : 017/2000 data_batch_1,  Train_loss : 11385.5801  Test_loss : 11641.3994, Time/batch_file : 2.3062, Training time: 188.5921\n",
      "Epoch : 017/2000 data_batch_2,  Train_loss : 11256.3672  Test_loss : 11223.1113, Time/batch_file : 2.3024, Training time: 190.8947\n",
      "Epoch : 017/2000 data_batch_3,  Train_loss : 10591.4424  Test_loss : 11494.8301, Time/batch_file : 2.3027, Training time: 193.1977\n",
      "Epoch : 017/2000 data_batch_4,  Train_loss : 11468.9551  Test_loss : 11468.9893, Time/batch_file : 2.2866, Training time: 195.4845\n",
      "Epoch : 017/2000 data_batch_5,  Train_loss : 11191.8232  Test_loss : 11028.7021, Time/batch_file : 2.3015, Training time: 197.7862\n",
      "Epoch : 018/2000 data_batch_1,  Train_loss : 10777.3135  Test_loss : 11209.3672, Time/batch_file : 2.2969, Training time: 200.0833\n",
      "Epoch : 018/2000 data_batch_2,  Train_loss : 10106.1367  Test_loss : 11303.0107, Time/batch_file : 2.3019, Training time: 202.3854\n",
      "Epoch : 018/2000 data_batch_3,  Train_loss : 11163.7090  Test_loss : 11192.9639, Time/batch_file : 2.2869, Training time: 204.6726\n",
      "Epoch : 018/2000 data_batch_4,  Train_loss : 10419.9258  Test_loss : 11418.7129, Time/batch_file : 2.3059, Training time: 206.9788\n",
      "Epoch : 018/2000 data_batch_5,  Train_loss : 11224.8330  Test_loss : 11154.4785, Time/batch_file : 2.2986, Training time: 209.2775\n",
      "Epoch : 019/2000 data_batch_1,  Train_loss : 11196.7412  Test_loss : 11034.3848, Time/batch_file : 2.2886, Training time: 211.5664\n",
      "Epoch : 019/2000 data_batch_2,  Train_loss : 11567.9502  Test_loss : 10628.1914, Time/batch_file : 2.2878, Training time: 213.8545\n",
      "Epoch : 019/2000 data_batch_3,  Train_loss : 11449.2109  Test_loss : 10711.9580, Time/batch_file : 2.2947, Training time: 216.1495\n",
      "Epoch : 019/2000 data_batch_4,  Train_loss : 11990.1260  Test_loss : 9557.1074, Time/batch_file : 2.2894, Training time: 218.4390\n",
      "Epoch : 019/2000 data_batch_5,  Train_loss : 10852.2988  Test_loss : 10852.4990, Time/batch_file : 2.2871, Training time: 220.7263\n",
      "Epoch : 020/2000 data_batch_1,  Train_loss : 10165.7705  Test_loss : 10586.0889, Time/batch_file : 2.2959, Training time: 223.0226\n",
      "Epoch : 020/2000 data_batch_2,  Train_loss : 10926.6865  Test_loss : 10906.9414, Time/batch_file : 2.3033, Training time: 225.3261\n",
      "Epoch : 020/2000 data_batch_3,  Train_loss : 10311.7275  Test_loss : 11524.4297, Time/batch_file : 2.2906, Training time: 227.6169\n",
      "Epoch : 020/2000 data_batch_4,  Train_loss : 9262.7793  Test_loss : 10990.0117, Time/batch_file : 2.3025, Training time: 229.9195\n",
      "Epoch : 020/2000 data_batch_5,  Train_loss : 9808.2480  Test_loss : 10905.6670, Time/batch_file : 2.2846, Training time: 232.2043\n",
      "[./nets/net-20.ckpt] SAVED\n",
      "Epoch : 021/2000 data_batch_1,  Train_loss : 11365.0312  Test_loss : 10039.2969, Time/batch_file : 2.3156, Training time: 235.9084\n",
      "Epoch : 021/2000 data_batch_2,  Train_loss : 10645.3535  Test_loss : 10780.0586, Time/batch_file : 2.3072, Training time: 238.2158\n",
      "Epoch : 021/2000 data_batch_3,  Train_loss : 9762.4922  Test_loss : 11114.3672, Time/batch_file : 2.2998, Training time: 240.5158\n",
      "Epoch : 021/2000 data_batch_4,  Train_loss : 11030.9082  Test_loss : 10369.9131, Time/batch_file : 2.2943, Training time: 242.8103\n",
      "Epoch : 021/2000 data_batch_5,  Train_loss : 10784.9297  Test_loss : 10426.1172, Time/batch_file : 2.2945, Training time: 245.1050\n",
      "Epoch : 022/2000 data_batch_1,  Train_loss : 11367.0215  Test_loss : 11084.8428, Time/batch_file : 2.3098, Training time: 247.4149\n",
      "Epoch : 022/2000 data_batch_2,  Train_loss : 11123.7588  Test_loss : 10419.5596, Time/batch_file : 2.3070, Training time: 249.7221\n",
      "Epoch : 022/2000 data_batch_3,  Train_loss : 10909.7139  Test_loss : 10938.3887, Time/batch_file : 2.3342, Training time: 252.0565\n",
      "Epoch : 022/2000 data_batch_4,  Train_loss : 10362.7666  Test_loss : 11138.2783, Time/batch_file : 2.3075, Training time: 254.3642\n",
      "Epoch : 022/2000 data_batch_5,  Train_loss : 11156.8447  Test_loss : 11226.3975, Time/batch_file : 2.3017, Training time: 256.6661\n",
      "Epoch : 023/2000 data_batch_1,  Train_loss : 10858.4121  Test_loss : 10253.3818, Time/batch_file : 2.3020, Training time: 258.9683\n",
      "Epoch : 023/2000 data_batch_2,  Train_loss : 10414.3848  Test_loss : 10149.2764, Time/batch_file : 2.3072, Training time: 261.2756\n",
      "Epoch : 023/2000 data_batch_3,  Train_loss : 10433.5820  Test_loss : 10687.9863, Time/batch_file : 2.3017, Training time: 263.5774\n",
      "Epoch : 023/2000 data_batch_4,  Train_loss : 10869.6855  Test_loss : 10278.2715, Time/batch_file : 2.2969, Training time: 265.8744\n",
      "Epoch : 023/2000 data_batch_5,  Train_loss : 10433.1143  Test_loss : 10413.2773, Time/batch_file : 2.2914, Training time: 268.1660\n",
      "Epoch : 024/2000 data_batch_1,  Train_loss : 11166.9912  Test_loss : 10813.8730, Time/batch_file : 2.3005, Training time: 270.4666\n",
      "Epoch : 024/2000 data_batch_2,  Train_loss : 10968.8506  Test_loss : 10398.8652, Time/batch_file : 2.3114, Training time: 272.7781\n",
      "Epoch : 024/2000 data_batch_3,  Train_loss : 10452.5186  Test_loss : 10514.4648, Time/batch_file : 2.2891, Training time: 275.0674\n",
      "Epoch : 024/2000 data_batch_4,  Train_loss : 10711.3135  Test_loss : 10350.1680, Time/batch_file : 2.3093, Training time: 277.3769\n",
      "Epoch : 024/2000 data_batch_5,  Train_loss : 10424.1895  Test_loss : 11387.6016, Time/batch_file : 2.3173, Training time: 279.6944\n",
      "Epoch : 025/2000 data_batch_1,  Train_loss : 10137.3848  Test_loss : 10051.1260, Time/batch_file : 2.2806, Training time: 281.9752\n",
      "Epoch : 025/2000 data_batch_2,  Train_loss : 10449.5605  Test_loss : 10174.8682, Time/batch_file : 2.2974, Training time: 284.2727\n",
      "Epoch : 025/2000 data_batch_3,  Train_loss : 9450.0371  Test_loss : 9888.7402, Time/batch_file : 2.2767, Training time: 286.5496\n",
      "Epoch : 025/2000 data_batch_4,  Train_loss : 10227.1855  Test_loss : 9780.9717, Time/batch_file : 2.2937, Training time: 288.8435\n",
      "Epoch : 025/2000 data_batch_5,  Train_loss : 10006.3203  Test_loss : 9687.8564, Time/batch_file : 2.2798, Training time: 291.1235\n",
      "Epoch : 026/2000 data_batch_1,  Train_loss : 11438.8711  Test_loss : 10402.3164, Time/batch_file : 2.2998, Training time: 293.4236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 026/2000 data_batch_2,  Train_loss : 10944.3818  Test_loss : 10832.9043, Time/batch_file : 2.3193, Training time: 295.7430\n",
      "Epoch : 026/2000 data_batch_3,  Train_loss : 11192.3828  Test_loss : 10285.2686, Time/batch_file : 2.2996, Training time: 298.0427\n",
      "Epoch : 026/2000 data_batch_4,  Train_loss : 10576.8545  Test_loss : 10679.7803, Time/batch_file : 2.3065, Training time: 300.3494\n",
      "Epoch : 026/2000 data_batch_5,  Train_loss : 11102.4209  Test_loss : 9872.4111, Time/batch_file : 2.3006, Training time: 302.6503\n",
      "Epoch : 027/2000 data_batch_1,  Train_loss : 10851.2393  Test_loss : 9249.7910, Time/batch_file : 2.2900, Training time: 304.9405\n",
      "Epoch : 027/2000 data_batch_2,  Train_loss : 10231.7412  Test_loss : 9135.9941, Time/batch_file : 2.2996, Training time: 307.2403\n",
      "Epoch : 027/2000 data_batch_3,  Train_loss : 10068.1523  Test_loss : 9635.5381, Time/batch_file : 2.3121, Training time: 309.5527\n",
      "Epoch : 027/2000 data_batch_4,  Train_loss : 9649.2734  Test_loss : 9473.8145, Time/batch_file : 2.2915, Training time: 311.8443\n",
      "Epoch : 027/2000 data_batch_5,  Train_loss : 9518.7451  Test_loss : 9594.1592, Time/batch_file : 2.3003, Training time: 314.1449\n",
      "Epoch : 028/2000 data_batch_1,  Train_loss : 10255.6865  Test_loss : 10135.1211, Time/batch_file : 2.3002, Training time: 316.4452\n",
      "Epoch : 028/2000 data_batch_2,  Train_loss : 9650.8672  Test_loss : 9501.1621, Time/batch_file : 2.2912, Training time: 318.7366\n",
      "Epoch : 028/2000 data_batch_3,  Train_loss : 10117.1855  Test_loss : 9724.7734, Time/batch_file : 2.3335, Training time: 321.0703\n",
      "Epoch : 028/2000 data_batch_4,  Train_loss : 9561.8145  Test_loss : 10453.4971, Time/batch_file : 2.2896, Training time: 323.3600\n",
      "Epoch : 028/2000 data_batch_5,  Train_loss : 9547.0928  Test_loss : 9478.9951, Time/batch_file : 2.2991, Training time: 325.6593\n",
      "Epoch : 029/2000 data_batch_1,  Train_loss : 9658.6416  Test_loss : 10145.4824, Time/batch_file : 2.2938, Training time: 327.9534\n",
      "Epoch : 029/2000 data_batch_2,  Train_loss : 10366.5508  Test_loss : 10642.1465, Time/batch_file : 2.2741, Training time: 330.2277\n",
      "Epoch : 029/2000 data_batch_3,  Train_loss : 9667.6504  Test_loss : 9850.1826, Time/batch_file : 2.3044, Training time: 332.5324\n",
      "Epoch : 029/2000 data_batch_4,  Train_loss : 9070.3467  Test_loss : 10112.7949, Time/batch_file : 2.2932, Training time: 334.8257\n",
      "Epoch : 029/2000 data_batch_5,  Train_loss : 9980.3643  Test_loss : 10413.4238, Time/batch_file : 2.2885, Training time: 337.1145\n",
      "Epoch : 030/2000 data_batch_1,  Train_loss : 9941.9629  Test_loss : 10547.3408, Time/batch_file : 2.3034, Training time: 339.4181\n",
      "Epoch : 030/2000 data_batch_2,  Train_loss : 10380.9297  Test_loss : 10282.3457, Time/batch_file : 2.2908, Training time: 341.7091\n",
      "Epoch : 030/2000 data_batch_3,  Train_loss : 9617.8535  Test_loss : 10162.5732, Time/batch_file : 2.2969, Training time: 344.0062\n",
      "Epoch : 030/2000 data_batch_4,  Train_loss : 10240.6797  Test_loss : 9178.5176, Time/batch_file : 2.2999, Training time: 346.3062\n",
      "Epoch : 030/2000 data_batch_5,  Train_loss : 9472.5791  Test_loss : 9693.0986, Time/batch_file : 2.3005, Training time: 348.6069\n",
      "[./nets/net-30.ckpt] SAVED\n",
      "Epoch : 031/2000 data_batch_1,  Train_loss : 9770.8389  Test_loss : 9520.8838, Time/batch_file : 2.2902, Training time: 352.1804\n",
      "Epoch : 031/2000 data_batch_2,  Train_loss : 9701.7314  Test_loss : 10144.7197, Time/batch_file : 2.2715, Training time: 354.4522\n",
      "Epoch : 031/2000 data_batch_3,  Train_loss : 9996.6631  Test_loss : 9383.7676, Time/batch_file : 2.2889, Training time: 356.7413\n",
      "Epoch : 031/2000 data_batch_4,  Train_loss : 9911.6084  Test_loss : 9713.3457, Time/batch_file : 2.2833, Training time: 359.0248\n",
      "Epoch : 031/2000 data_batch_5,  Train_loss : 9015.2109  Test_loss : 9076.6650, Time/batch_file : 2.2822, Training time: 361.3072\n",
      "Epoch : 032/2000 data_batch_1,  Train_loss : 10196.3447  Test_loss : 10160.1309, Time/batch_file : 2.2853, Training time: 363.5926\n",
      "Epoch : 032/2000 data_batch_2,  Train_loss : 9761.5225  Test_loss : 10407.2422, Time/batch_file : 2.2885, Training time: 365.8813\n",
      "Epoch : 032/2000 data_batch_3,  Train_loss : 9850.4736  Test_loss : 10043.0312, Time/batch_file : 2.2822, Training time: 368.1637\n",
      "Epoch : 032/2000 data_batch_4,  Train_loss : 10143.7617  Test_loss : 9920.1885, Time/batch_file : 2.2946, Training time: 370.4585\n",
      "Epoch : 032/2000 data_batch_5,  Train_loss : 9990.6689  Test_loss : 9276.7412, Time/batch_file : 2.2736, Training time: 372.7323\n",
      "Epoch : 033/2000 data_batch_1,  Train_loss : 9713.9980  Test_loss : 10001.4824, Time/batch_file : 2.2974, Training time: 375.0298\n",
      "Epoch : 033/2000 data_batch_2,  Train_loss : 8777.8008  Test_loss : 9927.6885, Time/batch_file : 2.2991, Training time: 377.3291\n",
      "Epoch : 033/2000 data_batch_3,  Train_loss : 9154.7607  Test_loss : 9946.3096, Time/batch_file : 2.2948, Training time: 379.6241\n",
      "Epoch : 033/2000 data_batch_4,  Train_loss : 8760.1377  Test_loss : 8705.3779, Time/batch_file : 2.2916, Training time: 381.9161\n",
      "Epoch : 033/2000 data_batch_5,  Train_loss : 9646.6162  Test_loss : 9255.8750, Time/batch_file : 2.2910, Training time: 384.2073\n",
      "Epoch : 034/2000 data_batch_1,  Train_loss : 9637.9893  Test_loss : 9140.8984, Time/batch_file : 2.2761, Training time: 386.4836\n",
      "Epoch : 034/2000 data_batch_2,  Train_loss : 9621.9863  Test_loss : 8930.8008, Time/batch_file : 2.3028, Training time: 388.7866\n",
      "Epoch : 034/2000 data_batch_3,  Train_loss : 9643.3438  Test_loss : 8274.2852, Time/batch_file : 2.2964, Training time: 391.0831\n",
      "Epoch : 034/2000 data_batch_4,  Train_loss : 9211.8438  Test_loss : 8929.4629, Time/batch_file : 2.2969, Training time: 393.3802\n",
      "Epoch : 034/2000 data_batch_5,  Train_loss : 9573.0137  Test_loss : 8934.7676, Time/batch_file : 2.2732, Training time: 395.6534\n",
      "Epoch : 035/2000 data_batch_1,  Train_loss : 9039.3252  Test_loss : 8681.7676, Time/batch_file : 2.3143, Training time: 397.9680\n",
      "Epoch : 035/2000 data_batch_2,  Train_loss : 9230.2754  Test_loss : 9160.9902, Time/batch_file : 2.2980, Training time: 400.2663\n",
      "Epoch : 035/2000 data_batch_3,  Train_loss : 9014.2607  Test_loss : 9110.7168, Time/batch_file : 2.2937, Training time: 402.5602\n",
      "Epoch : 035/2000 data_batch_4,  Train_loss : 9123.9688  Test_loss : 9158.0996, Time/batch_file : 2.2875, Training time: 404.8479\n",
      "Epoch : 035/2000 data_batch_5,  Train_loss : 9491.2100  Test_loss : 9253.7793, Time/batch_file : 2.3007, Training time: 407.1488\n",
      "Epoch : 036/2000 data_batch_1,  Train_loss : 8840.8516  Test_loss : 8735.8184, Time/batch_file : 2.2783, Training time: 409.4272\n",
      "Epoch : 036/2000 data_batch_2,  Train_loss : 8474.6621  Test_loss : 9113.1855, Time/batch_file : 2.2821, Training time: 411.7095\n",
      "Epoch : 036/2000 data_batch_3,  Train_loss : 8834.7490  Test_loss : 9313.0752, Time/batch_file : 2.2697, Training time: 413.9795\n",
      "Epoch : 036/2000 data_batch_4,  Train_loss : 8459.4043  Test_loss : 9206.8760, Time/batch_file : 2.3161, Training time: 416.2959\n",
      "Epoch : 036/2000 data_batch_5,  Train_loss : 9559.4785  Test_loss : 8964.2256, Time/batch_file : 2.2815, Training time: 418.5775\n",
      "Epoch : 037/2000 data_batch_1,  Train_loss : 9120.2080  Test_loss : 10168.1875, Time/batch_file : 2.2879, Training time: 420.8656\n",
      "Epoch : 037/2000 data_batch_2,  Train_loss : 9316.0869  Test_loss : 10396.1504, Time/batch_file : 2.2781, Training time: 423.1438\n",
      "Epoch : 037/2000 data_batch_3,  Train_loss : 9367.3584  Test_loss : 9848.0010, Time/batch_file : 2.2938, Training time: 425.4379\n",
      "Epoch : 037/2000 data_batch_4,  Train_loss : 8433.9395  Test_loss : 9166.9648, Time/batch_file : 2.2816, Training time: 427.7197\n",
      "Epoch : 037/2000 data_batch_5,  Train_loss : 9867.2637  Test_loss : 9371.0117, Time/batch_file : 2.2921, Training time: 430.0120\n",
      "Epoch : 038/2000 data_batch_1,  Train_loss : 9017.8525  Test_loss : 9171.1699, Time/batch_file : 2.2855, Training time: 432.2978\n",
      "Epoch : 038/2000 data_batch_2,  Train_loss : 9085.8857  Test_loss : 9633.9082, Time/batch_file : 2.3097, Training time: 434.6077\n",
      "Epoch : 038/2000 data_batch_3,  Train_loss : 8541.5625  Test_loss : 9714.0391, Time/batch_file : 2.2835, Training time: 436.8913\n",
      "Epoch : 038/2000 data_batch_4,  Train_loss : 8191.3613  Test_loss : 9844.4932, Time/batch_file : 2.2938, Training time: 439.1853\n",
      "Epoch : 038/2000 data_batch_5,  Train_loss : 9099.4922  Test_loss : 8868.9746, Time/batch_file : 2.2860, Training time: 441.4715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 039/2000 data_batch_1,  Train_loss : 9104.7178  Test_loss : 9022.2314, Time/batch_file : 2.3157, Training time: 443.7875\n",
      "Epoch : 039/2000 data_batch_2,  Train_loss : 9252.9277  Test_loss : 9296.6328, Time/batch_file : 2.2979, Training time: 446.0856\n",
      "Epoch : 039/2000 data_batch_3,  Train_loss : 9327.5166  Test_loss : 9239.6758, Time/batch_file : 2.3025, Training time: 448.3883\n",
      "Epoch : 039/2000 data_batch_4,  Train_loss : 9314.0664  Test_loss : 9225.2832, Time/batch_file : 2.2881, Training time: 450.6766\n",
      "Epoch : 039/2000 data_batch_5,  Train_loss : 8821.0713  Test_loss : 8966.1172, Time/batch_file : 2.3196, Training time: 452.9964\n",
      "Epoch : 040/2000 data_batch_1,  Train_loss : 9303.9902  Test_loss : 9836.0869, Time/batch_file : 2.2894, Training time: 455.2859\n",
      "Epoch : 040/2000 data_batch_2,  Train_loss : 8798.0117  Test_loss : 9587.9521, Time/batch_file : 2.2839, Training time: 457.5701\n",
      "Epoch : 040/2000 data_batch_3,  Train_loss : 8145.3350  Test_loss : 9071.5791, Time/batch_file : 2.2819, Training time: 459.8523\n",
      "Epoch : 040/2000 data_batch_4,  Train_loss : 8500.3857  Test_loss : 10391.0801, Time/batch_file : 2.2994, Training time: 462.1519\n",
      "Epoch : 040/2000 data_batch_5,  Train_loss : 8470.4434  Test_loss : 9736.7617, Time/batch_file : 2.2916, Training time: 464.4436\n",
      "[./nets/net-40.ckpt] SAVED\n",
      "Epoch : 041/2000 data_batch_1,  Train_loss : 9211.6348  Test_loss : 9271.9180, Time/batch_file : 2.3197, Training time: 468.1815\n",
      "Epoch : 041/2000 data_batch_2,  Train_loss : 9332.0830  Test_loss : 9250.5400, Time/batch_file : 2.2841, Training time: 470.4658\n",
      "Epoch : 041/2000 data_batch_3,  Train_loss : 8509.6602  Test_loss : 9005.1279, Time/batch_file : 2.3005, Training time: 472.7665\n",
      "Epoch : 041/2000 data_batch_4,  Train_loss : 8932.9697  Test_loss : 8752.9336, Time/batch_file : 2.2973, Training time: 475.0640\n",
      "Epoch : 041/2000 data_batch_5,  Train_loss : 9376.2822  Test_loss : 9394.7988, Time/batch_file : 2.2912, Training time: 477.3555\n",
      "Epoch : 042/2000 data_batch_1,  Train_loss : 8353.7002  Test_loss : 8513.0059, Time/batch_file : 2.2851, Training time: 479.6408\n",
      "Epoch : 042/2000 data_batch_2,  Train_loss : 8816.7891  Test_loss : 9101.3867, Time/batch_file : 2.3001, Training time: 481.9412\n",
      "Epoch : 042/2000 data_batch_3,  Train_loss : 8174.5732  Test_loss : 8976.7002, Time/batch_file : 2.2941, Training time: 484.2354\n",
      "Epoch : 042/2000 data_batch_4,  Train_loss : 8156.4521  Test_loss : 8605.0117, Time/batch_file : 2.3040, Training time: 486.5396\n",
      "Epoch : 042/2000 data_batch_5,  Train_loss : 8294.3535  Test_loss : 8410.6123, Time/batch_file : 2.3084, Training time: 488.8483\n",
      "Epoch : 043/2000 data_batch_1,  Train_loss : 9704.4414  Test_loss : 9291.7090, Time/batch_file : 2.2726, Training time: 491.1211\n",
      "Epoch : 043/2000 data_batch_2,  Train_loss : 9360.4600  Test_loss : 8408.7607, Time/batch_file : 2.2836, Training time: 493.4048\n",
      "Epoch : 043/2000 data_batch_3,  Train_loss : 9541.4824  Test_loss : 8920.0186, Time/batch_file : 2.2850, Training time: 495.6900\n",
      "Epoch : 043/2000 data_batch_4,  Train_loss : 8443.2344  Test_loss : 8692.9492, Time/batch_file : 2.2784, Training time: 497.9686\n",
      "Epoch : 043/2000 data_batch_5,  Train_loss : 9179.1387  Test_loss : 8566.9170, Time/batch_file : 2.2837, Training time: 500.2524\n",
      "Epoch : 044/2000 data_batch_1,  Train_loss : 9141.1357  Test_loss : 9286.9561, Time/batch_file : 2.2857, Training time: 502.5384\n",
      "Epoch : 044/2000 data_batch_2,  Train_loss : 9427.4072  Test_loss : 8999.2793, Time/batch_file : 2.2822, Training time: 504.8207\n",
      "Epoch : 044/2000 data_batch_3,  Train_loss : 9263.5205  Test_loss : 8530.1934, Time/batch_file : 2.2779, Training time: 507.0988\n",
      "Epoch : 044/2000 data_batch_4,  Train_loss : 9242.1338  Test_loss : 8886.2305, Time/batch_file : 2.2784, Training time: 509.3775\n",
      "Epoch : 044/2000 data_batch_5,  Train_loss : 9386.3984  Test_loss : 8940.1377, Time/batch_file : 2.2690, Training time: 511.6466\n",
      "Epoch : 045/2000 data_batch_1,  Train_loss : 9082.2422  Test_loss : 8738.7705, Time/batch_file : 2.3065, Training time: 513.9533\n",
      "Epoch : 045/2000 data_batch_2,  Train_loss : 8955.3867  Test_loss : 9001.8711, Time/batch_file : 2.2841, Training time: 516.2377\n",
      "Epoch : 045/2000 data_batch_3,  Train_loss : 8925.3760  Test_loss : 9162.0879, Time/batch_file : 2.2901, Training time: 518.5280\n",
      "Epoch : 045/2000 data_batch_4,  Train_loss : 9053.5322  Test_loss : 8833.0898, Time/batch_file : 2.2840, Training time: 520.8122\n",
      "Epoch : 045/2000 data_batch_5,  Train_loss : 8425.6416  Test_loss : 8134.6328, Time/batch_file : 2.2868, Training time: 523.0993\n",
      "Epoch : 046/2000 data_batch_1,  Train_loss : 8832.3047  Test_loss : 9116.0703, Time/batch_file : 2.2850, Training time: 525.3845\n",
      "Epoch : 046/2000 data_batch_2,  Train_loss : 8894.0654  Test_loss : 8293.2236, Time/batch_file : 2.2775, Training time: 527.6621\n",
      "Epoch : 046/2000 data_batch_3,  Train_loss : 9360.6328  Test_loss : 8776.5059, Time/batch_file : 2.2810, Training time: 529.9433\n",
      "Epoch : 046/2000 data_batch_4,  Train_loss : 9382.3486  Test_loss : 8924.2607, Time/batch_file : 2.3001, Training time: 532.2436\n",
      "Epoch : 046/2000 data_batch_5,  Train_loss : 8779.9502  Test_loss : 8384.5400, Time/batch_file : 2.2751, Training time: 534.5190\n",
      "Epoch : 047/2000 data_batch_1,  Train_loss : 9580.2520  Test_loss : 8412.4971, Time/batch_file : 2.3007, Training time: 536.8199\n",
      "Epoch : 047/2000 data_batch_2,  Train_loss : 9095.4785  Test_loss : 8667.0576, Time/batch_file : 2.2749, Training time: 539.0950\n",
      "Epoch : 047/2000 data_batch_3,  Train_loss : 9472.0215  Test_loss : 8342.3115, Time/batch_file : 2.2906, Training time: 541.3859\n",
      "Epoch : 047/2000 data_batch_4,  Train_loss : 9051.3672  Test_loss : 8306.1553, Time/batch_file : 2.2796, Training time: 543.6657\n",
      "Epoch : 047/2000 data_batch_5,  Train_loss : 9603.3662  Test_loss : 9184.9375, Time/batch_file : 2.2882, Training time: 545.9541\n",
      "Epoch : 048/2000 data_batch_1,  Train_loss : 8854.1162  Test_loss : 9026.2764, Time/batch_file : 2.2663, Training time: 548.2206\n",
      "Epoch : 048/2000 data_batch_2,  Train_loss : 9042.6982  Test_loss : 9719.4805, Time/batch_file : 2.2856, Training time: 550.5064\n",
      "Epoch : 048/2000 data_batch_3,  Train_loss : 9700.4346  Test_loss : 9425.3740, Time/batch_file : 2.2733, Training time: 552.7799\n",
      "Epoch : 048/2000 data_batch_4,  Train_loss : 8675.3984  Test_loss : 8955.7207, Time/batch_file : 2.2917, Training time: 555.0718\n",
      "Epoch : 048/2000 data_batch_5,  Train_loss : 8428.9062  Test_loss : 9110.1865, Time/batch_file : 2.2669, Training time: 557.3388\n",
      "Epoch : 049/2000 data_batch_1,  Train_loss : 8436.7061  Test_loss : 8238.9434, Time/batch_file : 2.2857, Training time: 559.6247\n",
      "Epoch : 049/2000 data_batch_2,  Train_loss : 8314.8545  Test_loss : 8803.4248, Time/batch_file : 2.2794, Training time: 561.9043\n",
      "Epoch : 049/2000 data_batch_3,  Train_loss : 8569.0947  Test_loss : 8758.6553, Time/batch_file : 2.2823, Training time: 564.1867\n",
      "Epoch : 049/2000 data_batch_4,  Train_loss : 8367.2061  Test_loss : 8930.0977, Time/batch_file : 2.2809, Training time: 566.4679\n",
      "Epoch : 049/2000 data_batch_5,  Train_loss : 7921.7744  Test_loss : 8708.1758, Time/batch_file : 2.2955, Training time: 568.7635\n",
      "Epoch : 050/2000 data_batch_1,  Train_loss : 8772.1328  Test_loss : 9769.9971, Time/batch_file : 2.2725, Training time: 571.0363\n",
      "Epoch : 050/2000 data_batch_2,  Train_loss : 8567.0576  Test_loss : 8971.8652, Time/batch_file : 2.2927, Training time: 573.3291\n",
      "Epoch : 050/2000 data_batch_3,  Train_loss : 9155.8389  Test_loss : 8919.7959, Time/batch_file : 2.2770, Training time: 575.6064\n",
      "Epoch : 050/2000 data_batch_4,  Train_loss : 8692.6719  Test_loss : 9551.7803, Time/batch_file : 2.2838, Training time: 577.8904\n",
      "Epoch : 050/2000 data_batch_5,  Train_loss : 9215.2969  Test_loss : 9109.4092, Time/batch_file : 2.2896, Training time: 580.1803\n",
      "[./nets/net-50.ckpt] SAVED\n",
      "Epoch : 051/2000 data_batch_1,  Train_loss : 8975.2891  Test_loss : 8560.5518, Time/batch_file : 2.3076, Training time: 583.9416\n",
      "Epoch : 051/2000 data_batch_2,  Train_loss : 8051.3945  Test_loss : 8987.2422, Time/batch_file : 2.2898, Training time: 586.2316\n",
      "Epoch : 051/2000 data_batch_3,  Train_loss : 7717.5273  Test_loss : 8850.3672, Time/batch_file : 2.3054, Training time: 588.5373\n",
      "Epoch : 051/2000 data_batch_4,  Train_loss : 8527.9805  Test_loss : 8360.2207, Time/batch_file : 2.2932, Training time: 590.8308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 051/2000 data_batch_5,  Train_loss : 8636.2285  Test_loss : 9114.7803, Time/batch_file : 2.2863, Training time: 593.1173\n",
      "Epoch : 052/2000 data_batch_1,  Train_loss : 8729.6221  Test_loss : 8682.5967, Time/batch_file : 2.2813, Training time: 595.3988\n",
      "Epoch : 052/2000 data_batch_2,  Train_loss : 8680.7314  Test_loss : 8199.1230, Time/batch_file : 2.2788, Training time: 597.6778\n",
      "Epoch : 052/2000 data_batch_3,  Train_loss : 8061.9731  Test_loss : 8184.8955, Time/batch_file : 2.2844, Training time: 599.9625\n",
      "Epoch : 052/2000 data_batch_4,  Train_loss : 8258.0098  Test_loss : 8553.0078, Time/batch_file : 2.2679, Training time: 602.2307\n",
      "Epoch : 052/2000 data_batch_5,  Train_loss : 8430.6738  Test_loss : 8576.7871, Time/batch_file : 2.2916, Training time: 604.5224\n",
      "Epoch : 053/2000 data_batch_1,  Train_loss : 9244.1348  Test_loss : 8723.6348, Time/batch_file : 2.2758, Training time: 606.7984\n",
      "Epoch : 053/2000 data_batch_2,  Train_loss : 8628.3379  Test_loss : 9205.1074, Time/batch_file : 2.2660, Training time: 609.0647\n",
      "Epoch : 053/2000 data_batch_3,  Train_loss : 8903.0371  Test_loss : 8528.0010, Time/batch_file : 2.2751, Training time: 611.3400\n",
      "Epoch : 053/2000 data_batch_4,  Train_loss : 9165.0723  Test_loss : 8512.5566, Time/batch_file : 2.2810, Training time: 613.6212\n",
      "Epoch : 053/2000 data_batch_5,  Train_loss : 9105.2988  Test_loss : 8594.8359, Time/batch_file : 2.2646, Training time: 615.8859\n",
      "Epoch : 054/2000 data_batch_1,  Train_loss : 8194.5732  Test_loss : 9495.7051, Time/batch_file : 2.2889, Training time: 618.1751\n",
      "Epoch : 054/2000 data_batch_2,  Train_loss : 8176.6294  Test_loss : 9223.3291, Time/batch_file : 2.2929, Training time: 620.4682\n",
      "Epoch : 054/2000 data_batch_3,  Train_loss : 8540.0195  Test_loss : 9659.2441, Time/batch_file : 2.3016, Training time: 622.7700\n",
      "Epoch : 054/2000 data_batch_4,  Train_loss : 8676.4316  Test_loss : 9461.4922, Time/batch_file : 2.2889, Training time: 625.0591\n",
      "Epoch : 054/2000 data_batch_5,  Train_loss : 8417.5371  Test_loss : 9146.4150, Time/batch_file : 2.2997, Training time: 627.3590\n",
      "Epoch : 055/2000 data_batch_1,  Train_loss : 8462.4609  Test_loss : 9392.5205, Time/batch_file : 2.2742, Training time: 629.6334\n",
      "Epoch : 055/2000 data_batch_2,  Train_loss : 8948.4971  Test_loss : 10035.0547, Time/batch_file : 2.2899, Training time: 631.9235\n",
      "Epoch : 055/2000 data_batch_3,  Train_loss : 8620.7451  Test_loss : 9559.0527, Time/batch_file : 2.2726, Training time: 634.1962\n",
      "Epoch : 055/2000 data_batch_4,  Train_loss : 8934.5840  Test_loss : 9236.9004, Time/batch_file : 2.2743, Training time: 636.4707\n",
      "Epoch : 055/2000 data_batch_5,  Train_loss : 9081.4551  Test_loss : 9734.6484, Time/batch_file : 2.2854, Training time: 638.7564\n",
      "Epoch : 056/2000 data_batch_1,  Train_loss : 9072.9824  Test_loss : 8439.0234, Time/batch_file : 2.2943, Training time: 641.0508\n",
      "Epoch : 056/2000 data_batch_2,  Train_loss : 8415.6445  Test_loss : 8503.8496, Time/batch_file : 2.2825, Training time: 643.3335\n",
      "Epoch : 056/2000 data_batch_3,  Train_loss : 8860.3320  Test_loss : 8455.9336, Time/batch_file : 2.2897, Training time: 645.6233\n",
      "Epoch : 056/2000 data_batch_4,  Train_loss : 9186.1914  Test_loss : 8628.5439, Time/batch_file : 2.2754, Training time: 647.8990\n",
      "Epoch : 056/2000 data_batch_5,  Train_loss : 8941.2754  Test_loss : 8858.6504, Time/batch_file : 2.2895, Training time: 650.1886\n",
      "Epoch : 057/2000 data_batch_1,  Train_loss : 8684.6201  Test_loss : 8886.8682, Time/batch_file : 2.2708, Training time: 652.4597\n",
      "Epoch : 057/2000 data_batch_2,  Train_loss : 8213.9062  Test_loss : 8205.3750, Time/batch_file : 2.3183, Training time: 654.7782\n",
      "Epoch : 057/2000 data_batch_3,  Train_loss : 8663.3135  Test_loss : 8941.4365, Time/batch_file : 2.3030, Training time: 657.0815\n",
      "Epoch : 057/2000 data_batch_4,  Train_loss : 8380.2119  Test_loss : 8073.1230, Time/batch_file : 2.2828, Training time: 659.3643\n",
      "Epoch : 057/2000 data_batch_5,  Train_loss : 8176.8315  Test_loss : 8956.5020, Time/batch_file : 2.2816, Training time: 661.6461\n",
      "Epoch : 058/2000 data_batch_1,  Train_loss : 9525.6758  Test_loss : 8208.0254, Time/batch_file : 2.2906, Training time: 663.9369\n",
      "Epoch : 058/2000 data_batch_2,  Train_loss : 9320.3594  Test_loss : 8559.4199, Time/batch_file : 2.2831, Training time: 666.2201\n",
      "Epoch : 058/2000 data_batch_3,  Train_loss : 9070.3027  Test_loss : 8441.1123, Time/batch_file : 2.2753, Training time: 668.4956\n",
      "Epoch : 058/2000 data_batch_4,  Train_loss : 9116.3818  Test_loss : 8738.9375, Time/batch_file : 2.2914, Training time: 670.7871\n",
      "Epoch : 058/2000 data_batch_5,  Train_loss : 8524.1553  Test_loss : 8076.5166, Time/batch_file : 2.2908, Training time: 673.0782\n",
      "Epoch : 059/2000 data_batch_1,  Train_loss : 8212.2031  Test_loss : 8863.2012, Time/batch_file : 2.2767, Training time: 675.3552\n",
      "Epoch : 059/2000 data_batch_2,  Train_loss : 7687.8867  Test_loss : 8785.5996, Time/batch_file : 2.2760, Training time: 677.6313\n",
      "Epoch : 059/2000 data_batch_3,  Train_loss : 8326.3467  Test_loss : 9081.6201, Time/batch_file : 2.2794, Training time: 679.9109\n",
      "Epoch : 059/2000 data_batch_4,  Train_loss : 7843.5840  Test_loss : 8605.3809, Time/batch_file : 2.2885, Training time: 682.1996\n",
      "Epoch : 059/2000 data_batch_5,  Train_loss : 8008.6963  Test_loss : 8462.0664, Time/batch_file : 2.2899, Training time: 684.4898\n",
      "Epoch : 060/2000 data_batch_1,  Train_loss : 8525.0225  Test_loss : 9059.3086, Time/batch_file : 2.2969, Training time: 686.7868\n",
      "Epoch : 060/2000 data_batch_2,  Train_loss : 8952.7861  Test_loss : 8250.0898, Time/batch_file : 2.2992, Training time: 689.0863\n",
      "Epoch : 060/2000 data_batch_3,  Train_loss : 8561.7852  Test_loss : 8839.6426, Time/batch_file : 2.2830, Training time: 691.3695\n",
      "Epoch : 060/2000 data_batch_4,  Train_loss : 8385.7324  Test_loss : 8665.4404, Time/batch_file : 2.2708, Training time: 693.6405\n",
      "Epoch : 060/2000 data_batch_5,  Train_loss : 8756.6104  Test_loss : 9037.4326, Time/batch_file : 2.2982, Training time: 695.9389\n",
      "[./nets/net-60.ckpt] SAVED\n",
      "Epoch : 061/2000 data_batch_1,  Train_loss : 7979.8418  Test_loss : 8527.8809, Time/batch_file : 2.3100, Training time: 699.5345\n",
      "Epoch : 061/2000 data_batch_2,  Train_loss : 7961.5654  Test_loss : 9051.0215, Time/batch_file : 2.2926, Training time: 701.8272\n",
      "Epoch : 061/2000 data_batch_3,  Train_loss : 8423.5410  Test_loss : 8283.9570, Time/batch_file : 2.2845, Training time: 704.1119\n",
      "Epoch : 061/2000 data_batch_4,  Train_loss : 8623.4746  Test_loss : 8714.2969, Time/batch_file : 2.2922, Training time: 706.4043\n",
      "Epoch : 061/2000 data_batch_5,  Train_loss : 8547.7764  Test_loss : 8502.5742, Time/batch_file : 2.2952, Training time: 708.6998\n",
      "Epoch : 062/2000 data_batch_1,  Train_loss : 8972.7266  Test_loss : 8131.4258, Time/batch_file : 2.2972, Training time: 710.9972\n",
      "Epoch : 062/2000 data_batch_2,  Train_loss : 9013.9453  Test_loss : 8261.0029, Time/batch_file : 2.2876, Training time: 713.2850\n",
      "Epoch : 062/2000 data_batch_3,  Train_loss : 9063.9336  Test_loss : 8234.1436, Time/batch_file : 2.2925, Training time: 715.5777\n",
      "Epoch : 062/2000 data_batch_4,  Train_loss : 8923.3340  Test_loss : 7531.0195, Time/batch_file : 2.2931, Training time: 717.8710\n",
      "Epoch : 062/2000 data_batch_5,  Train_loss : 8317.2129  Test_loss : 8506.5859, Time/batch_file : 2.2855, Training time: 720.1567\n",
      "Epoch : 063/2000 data_batch_1,  Train_loss : 8096.9321  Test_loss : 8087.1230, Time/batch_file : 2.3009, Training time: 722.4577\n",
      "Epoch : 063/2000 data_batch_2,  Train_loss : 8878.8398  Test_loss : 8140.9990, Time/batch_file : 2.2973, Training time: 724.7552\n",
      "Epoch : 063/2000 data_batch_3,  Train_loss : 8359.6113  Test_loss : 7841.4165, Time/batch_file : 2.3098, Training time: 727.0652\n",
      "Epoch : 063/2000 data_batch_4,  Train_loss : 8298.8320  Test_loss : 8520.2734, Time/batch_file : 2.3114, Training time: 729.3769\n",
      "Epoch : 063/2000 data_batch_5,  Train_loss : 8241.5547  Test_loss : 8631.6230, Time/batch_file : 2.3067, Training time: 731.6837\n",
      "Epoch : 064/2000 data_batch_1,  Train_loss : 8969.3115  Test_loss : 8359.0195, Time/batch_file : 2.2973, Training time: 733.9813\n",
      "Epoch : 064/2000 data_batch_2,  Train_loss : 8034.1011  Test_loss : 8318.1826, Time/batch_file : 2.2918, Training time: 736.2733\n",
      "Epoch : 064/2000 data_batch_3,  Train_loss : 7999.1338  Test_loss : 8426.0430, Time/batch_file : 2.3058, Training time: 738.5793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 064/2000 data_batch_4,  Train_loss : 7931.7617  Test_loss : 8296.9258, Time/batch_file : 2.2960, Training time: 740.8755\n",
      "Epoch : 064/2000 data_batch_5,  Train_loss : 7852.0283  Test_loss : 7972.7246, Time/batch_file : 2.3134, Training time: 743.1890\n",
      "Epoch : 065/2000 data_batch_1,  Train_loss : 8803.5596  Test_loss : 8882.4590, Time/batch_file : 2.3011, Training time: 745.4903\n",
      "Epoch : 065/2000 data_batch_2,  Train_loss : 8743.7188  Test_loss : 9116.5674, Time/batch_file : 2.3002, Training time: 747.7907\n",
      "Epoch : 065/2000 data_batch_3,  Train_loss : 9063.9795  Test_loss : 8085.8076, Time/batch_file : 2.2964, Training time: 750.0874\n",
      "Epoch : 065/2000 data_batch_4,  Train_loss : 8999.7236  Test_loss : 8085.9551, Time/batch_file : 2.2834, Training time: 752.3711\n",
      "Epoch : 065/2000 data_batch_5,  Train_loss : 8518.1309  Test_loss : 8698.3848, Time/batch_file : 2.3000, Training time: 754.6713\n",
      "Epoch : 066/2000 data_batch_1,  Train_loss : 7985.3975  Test_loss : 8642.4434, Time/batch_file : 2.2998, Training time: 756.9714\n",
      "Epoch : 066/2000 data_batch_2,  Train_loss : 7680.7910  Test_loss : 8547.9922, Time/batch_file : 2.2951, Training time: 759.2668\n",
      "Epoch : 066/2000 data_batch_3,  Train_loss : 7653.4199  Test_loss : 8836.6621, Time/batch_file : 2.3023, Training time: 761.5693\n",
      "Epoch : 066/2000 data_batch_4,  Train_loss : 7774.9663  Test_loss : 8354.1191, Time/batch_file : 2.3005, Training time: 763.8700\n",
      "Epoch : 066/2000 data_batch_5,  Train_loss : 7185.8428  Test_loss : 9055.3691, Time/batch_file : 2.2962, Training time: 766.1665\n",
      "Epoch : 067/2000 data_batch_1,  Train_loss : 8621.3672  Test_loss : 8214.6650, Time/batch_file : 2.2806, Training time: 768.4473\n",
      "Epoch : 067/2000 data_batch_2,  Train_loss : 8262.6533  Test_loss : 9045.8828, Time/batch_file : 2.2653, Training time: 770.7129\n",
      "Epoch : 067/2000 data_batch_3,  Train_loss : 8574.6328  Test_loss : 8796.5801, Time/batch_file : 2.2826, Training time: 772.9957\n",
      "Epoch : 067/2000 data_batch_4,  Train_loss : 8223.5840  Test_loss : 8891.0898, Time/batch_file : 2.2967, Training time: 775.2925\n",
      "Epoch : 067/2000 data_batch_5,  Train_loss : 8203.1396  Test_loss : 9058.6016, Time/batch_file : 2.2738, Training time: 777.5666\n",
      "Epoch : 068/2000 data_batch_1,  Train_loss : 8112.8516  Test_loss : 8762.1621, Time/batch_file : 2.2929, Training time: 779.8597\n",
      "Epoch : 068/2000 data_batch_2,  Train_loss : 7971.7314  Test_loss : 8512.8408, Time/batch_file : 2.2915, Training time: 782.1513\n",
      "Epoch : 068/2000 data_batch_3,  Train_loss : 7754.0303  Test_loss : 8870.7949, Time/batch_file : 2.3096, Training time: 784.4611\n",
      "Epoch : 068/2000 data_batch_4,  Train_loss : 8217.0781  Test_loss : 8907.1758, Time/batch_file : 2.2854, Training time: 786.7468\n",
      "Epoch : 068/2000 data_batch_5,  Train_loss : 8434.2861  Test_loss : 8251.0938, Time/batch_file : 2.3097, Training time: 789.0567\n",
      "Epoch : 069/2000 data_batch_1,  Train_loss : 8491.2285  Test_loss : 8386.6826, Time/batch_file : 2.2940, Training time: 791.3508\n",
      "Epoch : 069/2000 data_batch_2,  Train_loss : 7867.6577  Test_loss : 8793.4805, Time/batch_file : 2.2874, Training time: 793.6385\n",
      "Epoch : 069/2000 data_batch_3,  Train_loss : 7869.5596  Test_loss : 8076.6328, Time/batch_file : 2.2911, Training time: 795.9299\n",
      "Epoch : 069/2000 data_batch_4,  Train_loss : 8056.5664  Test_loss : 8044.5083, Time/batch_file : 2.2901, Training time: 798.2201\n",
      "Epoch : 069/2000 data_batch_5,  Train_loss : 8282.7383  Test_loss : 8513.1064, Time/batch_file : 2.2940, Training time: 800.5144\n",
      "Epoch : 070/2000 data_batch_1,  Train_loss : 8219.9893  Test_loss : 8129.8418, Time/batch_file : 2.2922, Training time: 802.8067\n",
      "Epoch : 070/2000 data_batch_2,  Train_loss : 7885.5400  Test_loss : 8075.7812, Time/batch_file : 2.2929, Training time: 805.0998\n",
      "Epoch : 070/2000 data_batch_3,  Train_loss : 7769.9058  Test_loss : 7854.4043, Time/batch_file : 2.2840, Training time: 807.3839\n",
      "Epoch : 070/2000 data_batch_4,  Train_loss : 8349.3750  Test_loss : 8127.2393, Time/batch_file : 2.2897, Training time: 809.6738\n",
      "Epoch : 070/2000 data_batch_5,  Train_loss : 8050.3506  Test_loss : 8372.0537, Time/batch_file : 2.2889, Training time: 811.9629\n",
      "[./nets/net-70.ckpt] SAVED\n",
      "Epoch : 071/2000 data_batch_1,  Train_loss : 7934.8403  Test_loss : 8387.6074, Time/batch_file : 2.2926, Training time: 815.7412\n",
      "Epoch : 071/2000 data_batch_2,  Train_loss : 7464.7764  Test_loss : 8909.6572, Time/batch_file : 2.2806, Training time: 818.0220\n",
      "Epoch : 071/2000 data_batch_3,  Train_loss : 7225.4404  Test_loss : 8552.5605, Time/batch_file : 2.2802, Training time: 820.3024\n",
      "Epoch : 071/2000 data_batch_4,  Train_loss : 7867.9893  Test_loss : 8640.1777, Time/batch_file : 2.2729, Training time: 822.5754\n",
      "Epoch : 071/2000 data_batch_5,  Train_loss : 7205.3071  Test_loss : 7983.2910, Time/batch_file : 2.2771, Training time: 824.8527\n",
      "Epoch : 072/2000 data_batch_1,  Train_loss : 7926.2783  Test_loss : 8500.4570, Time/batch_file : 2.2642, Training time: 827.1171\n",
      "Epoch : 072/2000 data_batch_2,  Train_loss : 7626.0977  Test_loss : 8079.2256, Time/batch_file : 2.2784, Training time: 829.3957\n",
      "Epoch : 072/2000 data_batch_3,  Train_loss : 7857.9785  Test_loss : 7640.6104, Time/batch_file : 2.2716, Training time: 831.6675\n",
      "Epoch : 072/2000 data_batch_4,  Train_loss : 7810.6719  Test_loss : 8068.9668, Time/batch_file : 2.2772, Training time: 833.9449\n",
      "Epoch : 072/2000 data_batch_5,  Train_loss : 7363.3477  Test_loss : 8392.0820, Time/batch_file : 2.2593, Training time: 836.2044\n",
      "Epoch : 073/2000 data_batch_1,  Train_loss : 7809.6504  Test_loss : 7744.8271, Time/batch_file : 2.2910, Training time: 838.4956\n",
      "Epoch : 073/2000 data_batch_2,  Train_loss : 7982.1626  Test_loss : 7683.9727, Time/batch_file : 2.2886, Training time: 840.7844\n",
      "Epoch : 073/2000 data_batch_3,  Train_loss : 7881.3389  Test_loss : 8026.6865, Time/batch_file : 2.2862, Training time: 843.0709\n",
      "Epoch : 073/2000 data_batch_4,  Train_loss : 7571.2466  Test_loss : 7923.7046, Time/batch_file : 2.2724, Training time: 845.3435\n",
      "Epoch : 073/2000 data_batch_5,  Train_loss : 7749.8198  Test_loss : 8219.0742, Time/batch_file : 2.2986, Training time: 847.6423\n",
      "Epoch : 074/2000 data_batch_1,  Train_loss : 7807.4551  Test_loss : 7605.6519, Time/batch_file : 2.2950, Training time: 849.9376\n",
      "Epoch : 074/2000 data_batch_2,  Train_loss : 7585.9717  Test_loss : 8441.3105, Time/batch_file : 2.2844, Training time: 852.2222\n",
      "Epoch : 074/2000 data_batch_3,  Train_loss : 8093.7896  Test_loss : 8156.4253, Time/batch_file : 2.2980, Training time: 854.5204\n",
      "Epoch : 074/2000 data_batch_4,  Train_loss : 8026.4844  Test_loss : 7861.1099, Time/batch_file : 2.2944, Training time: 856.8150\n",
      "Epoch : 074/2000 data_batch_5,  Train_loss : 8121.2266  Test_loss : 8222.3594, Time/batch_file : 2.2850, Training time: 859.1002\n",
      "Epoch : 075/2000 data_batch_1,  Train_loss : 7316.1465  Test_loss : 8234.8398, Time/batch_file : 2.2854, Training time: 861.3858\n",
      "Epoch : 075/2000 data_batch_2,  Train_loss : 7462.4111  Test_loss : 8869.6426, Time/batch_file : 2.2774, Training time: 863.6633\n",
      "Epoch : 075/2000 data_batch_3,  Train_loss : 7646.9688  Test_loss : 8705.5645, Time/batch_file : 2.2991, Training time: 865.9626\n",
      "Epoch : 075/2000 data_batch_4,  Train_loss : 7932.0635  Test_loss : 8647.6592, Time/batch_file : 2.2767, Training time: 868.2394\n",
      "Epoch : 075/2000 data_batch_5,  Train_loss : 7259.9800  Test_loss : 8028.5010, Time/batch_file : 2.2831, Training time: 870.5227\n",
      "Epoch : 076/2000 data_batch_1,  Train_loss : 8133.6846  Test_loss : 8551.8535, Time/batch_file : 2.2944, Training time: 872.8173\n",
      "Epoch : 076/2000 data_batch_2,  Train_loss : 7959.0254  Test_loss : 8861.3418, Time/batch_file : 2.3081, Training time: 875.1259\n",
      "Epoch : 076/2000 data_batch_3,  Train_loss : 7962.7676  Test_loss : 8239.5303, Time/batch_file : 2.2909, Training time: 877.4170\n",
      "Epoch : 076/2000 data_batch_4,  Train_loss : 7918.0923  Test_loss : 8608.9199, Time/batch_file : 2.2858, Training time: 879.7030\n",
      "Epoch : 076/2000 data_batch_5,  Train_loss : 8039.2158  Test_loss : 8228.0410, Time/batch_file : 2.2850, Training time: 881.9882\n",
      "Epoch : 077/2000 data_batch_1,  Train_loss : 8181.3076  Test_loss : 8194.0352, Time/batch_file : 2.2682, Training time: 884.2566\n",
      "Epoch : 077/2000 data_batch_2,  Train_loss : 8679.6611  Test_loss : 8479.3730, Time/batch_file : 2.2796, Training time: 886.5364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 077/2000 data_batch_3,  Train_loss : 7978.9663  Test_loss : 7937.0518, Time/batch_file : 2.2734, Training time: 888.8100\n",
      "Epoch : 077/2000 data_batch_4,  Train_loss : 8264.9316  Test_loss : 8591.3770, Time/batch_file : 2.2680, Training time: 891.0782\n",
      "Epoch : 077/2000 data_batch_5,  Train_loss : 8250.3428  Test_loss : 9008.2373, Time/batch_file : 2.2865, Training time: 893.3649\n",
      "Epoch : 078/2000 data_batch_1,  Train_loss : 8222.3691  Test_loss : 8873.6729, Time/batch_file : 2.3011, Training time: 895.6662\n",
      "Epoch : 078/2000 data_batch_2,  Train_loss : 8558.4180  Test_loss : 8817.1777, Time/batch_file : 2.2985, Training time: 897.9650\n",
      "Epoch : 078/2000 data_batch_3,  Train_loss : 8293.1562  Test_loss : 8571.1348, Time/batch_file : 2.2912, Training time: 900.2562\n",
      "Epoch : 078/2000 data_batch_4,  Train_loss : 8521.3867  Test_loss : 8851.1855, Time/batch_file : 2.3020, Training time: 902.5584\n",
      "Epoch : 078/2000 data_batch_5,  Train_loss : 8593.1201  Test_loss : 8584.7715, Time/batch_file : 2.3008, Training time: 904.8597\n",
      "Epoch : 079/2000 data_batch_1,  Train_loss : 8105.8667  Test_loss : 7680.4395, Time/batch_file : 2.2850, Training time: 907.1450\n",
      "Epoch : 079/2000 data_batch_2,  Train_loss : 8231.3662  Test_loss : 8203.7070, Time/batch_file : 2.2927, Training time: 909.4379\n",
      "Epoch : 079/2000 data_batch_3,  Train_loss : 8340.1807  Test_loss : 8077.6304, Time/batch_file : 2.2824, Training time: 911.7205\n",
      "Epoch : 079/2000 data_batch_4,  Train_loss : 7842.6748  Test_loss : 7978.1626, Time/batch_file : 2.2918, Training time: 914.0125\n",
      "Epoch : 079/2000 data_batch_5,  Train_loss : 7702.8506  Test_loss : 8495.7607, Time/batch_file : 2.2944, Training time: 916.3072\n",
      "Epoch : 080/2000 data_batch_1,  Train_loss : 7835.7324  Test_loss : 7779.5298, Time/batch_file : 2.3014, Training time: 918.6088\n",
      "Epoch : 080/2000 data_batch_2,  Train_loss : 8117.7744  Test_loss : 8177.5190, Time/batch_file : 2.3312, Training time: 920.9403\n",
      "Epoch : 080/2000 data_batch_3,  Train_loss : 7929.3682  Test_loss : 7889.2529, Time/batch_file : 2.2899, Training time: 923.2303\n",
      "Epoch : 080/2000 data_batch_4,  Train_loss : 7723.6084  Test_loss : 7663.3320, Time/batch_file : 2.2967, Training time: 925.5273\n",
      "Epoch : 080/2000 data_batch_5,  Train_loss : 8009.4932  Test_loss : 7526.8530, Time/batch_file : 2.2924, Training time: 927.8199\n",
      "[./nets/net-80.ckpt] SAVED\n",
      "Epoch : 081/2000 data_batch_1,  Train_loss : 8242.1807  Test_loss : 8976.9629, Time/batch_file : 2.3231, Training time: 931.4409\n",
      "Epoch : 081/2000 data_batch_2,  Train_loss : 7728.4160  Test_loss : 8278.1367, Time/batch_file : 2.3275, Training time: 933.7685\n",
      "Epoch : 081/2000 data_batch_3,  Train_loss : 8663.8926  Test_loss : 8541.8770, Time/batch_file : 2.3114, Training time: 936.0802\n",
      "Epoch : 081/2000 data_batch_4,  Train_loss : 7609.7368  Test_loss : 8564.6309, Time/batch_file : 2.2975, Training time: 938.3779\n",
      "Epoch : 081/2000 data_batch_5,  Train_loss : 7734.2178  Test_loss : 8344.0029, Time/batch_file : 2.2834, Training time: 940.6615\n",
      "Epoch : 082/2000 data_batch_1,  Train_loss : 7565.2056  Test_loss : 7849.8691, Time/batch_file : 2.3108, Training time: 942.9725\n",
      "Epoch : 082/2000 data_batch_2,  Train_loss : 7061.4131  Test_loss : 8023.2422, Time/batch_file : 2.3096, Training time: 945.2823\n",
      "Epoch : 082/2000 data_batch_3,  Train_loss : 7557.2788  Test_loss : 8195.1191, Time/batch_file : 2.3079, Training time: 947.5905\n",
      "Epoch : 082/2000 data_batch_4,  Train_loss : 7520.7725  Test_loss : 8059.8169, Time/batch_file : 2.2945, Training time: 949.8851\n",
      "Epoch : 082/2000 data_batch_5,  Train_loss : 7477.7075  Test_loss : 7811.8496, Time/batch_file : 2.3092, Training time: 952.1944\n",
      "Epoch : 083/2000 data_batch_1,  Train_loss : 8019.5547  Test_loss : 8614.5635, Time/batch_file : 2.2952, Training time: 954.4899\n",
      "Epoch : 083/2000 data_batch_2,  Train_loss : 7821.0464  Test_loss : 8578.0859, Time/batch_file : 2.3092, Training time: 956.7993\n",
      "Epoch : 083/2000 data_batch_3,  Train_loss : 7781.5605  Test_loss : 8369.5449, Time/batch_file : 2.2873, Training time: 959.0867\n",
      "Epoch : 083/2000 data_batch_4,  Train_loss : 7795.1274  Test_loss : 8480.1807, Time/batch_file : 2.2882, Training time: 961.3751\n",
      "Epoch : 083/2000 data_batch_5,  Train_loss : 7770.8857  Test_loss : 8583.0518, Time/batch_file : 2.2937, Training time: 963.6690\n",
      "Epoch : 084/2000 data_batch_1,  Train_loss : 8021.6875  Test_loss : 7956.3428, Time/batch_file : 2.2909, Training time: 965.9601\n",
      "Epoch : 084/2000 data_batch_2,  Train_loss : 8321.8926  Test_loss : 7606.2905, Time/batch_file : 2.2828, Training time: 968.2431\n",
      "Epoch : 084/2000 data_batch_3,  Train_loss : 8236.5117  Test_loss : 7677.9170, Time/batch_file : 2.2825, Training time: 970.5259\n",
      "Epoch : 084/2000 data_batch_4,  Train_loss : 7593.5713  Test_loss : 7812.3506, Time/batch_file : 2.2846, Training time: 972.8107\n",
      "Epoch : 084/2000 data_batch_5,  Train_loss : 7826.0781  Test_loss : 8061.7256, Time/batch_file : 2.2796, Training time: 975.0906\n",
      "Epoch : 085/2000 data_batch_1,  Train_loss : 7958.1436  Test_loss : 7733.2417, Time/batch_file : 2.2910, Training time: 977.3817\n",
      "Epoch : 085/2000 data_batch_2,  Train_loss : 8017.9502  Test_loss : 7772.9004, Time/batch_file : 2.2842, Training time: 979.6661\n",
      "Epoch : 085/2000 data_batch_3,  Train_loss : 7950.9746  Test_loss : 7334.3120, Time/batch_file : 2.2775, Training time: 981.9439\n",
      "Epoch : 085/2000 data_batch_4,  Train_loss : 7778.3892  Test_loss : 7782.9590, Time/batch_file : 2.2793, Training time: 984.2233\n",
      "Epoch : 085/2000 data_batch_5,  Train_loss : 8393.6992  Test_loss : 7824.7153, Time/batch_file : 2.2793, Training time: 986.5028\n",
      "Epoch : 086/2000 data_batch_1,  Train_loss : 8583.9551  Test_loss : 8386.6660, Time/batch_file : 2.2927, Training time: 988.7957\n",
      "Epoch : 086/2000 data_batch_2,  Train_loss : 8446.5322  Test_loss : 8114.5146, Time/batch_file : 2.2881, Training time: 991.0841\n",
      "Epoch : 086/2000 data_batch_3,  Train_loss : 8823.9004  Test_loss : 8021.3359, Time/batch_file : 2.2892, Training time: 993.3735\n",
      "Epoch : 086/2000 data_batch_4,  Train_loss : 8639.5098  Test_loss : 8340.9346, Time/batch_file : 2.2837, Training time: 995.6574\n",
      "Epoch : 086/2000 data_batch_5,  Train_loss : 8447.2412  Test_loss : 8002.8975, Time/batch_file : 2.2833, Training time: 997.9410\n",
      "Epoch : 087/2000 data_batch_1,  Train_loss : 7581.7124  Test_loss : 7961.4062, Time/batch_file : 2.2852, Training time: 1000.2264\n",
      "Epoch : 087/2000 data_batch_2,  Train_loss : 8514.4346  Test_loss : 7747.9170, Time/batch_file : 2.2818, Training time: 1002.5083\n",
      "Epoch : 087/2000 data_batch_3,  Train_loss : 7842.3564  Test_loss : 7919.3965, Time/batch_file : 2.2887, Training time: 1004.7973\n",
      "Epoch : 087/2000 data_batch_4,  Train_loss : 8290.8691  Test_loss : 7702.6782, Time/batch_file : 2.2856, Training time: 1007.0831\n",
      "Epoch : 087/2000 data_batch_5,  Train_loss : 7826.4453  Test_loss : 8560.8857, Time/batch_file : 2.2849, Training time: 1009.3683\n",
      "Epoch : 088/2000 data_batch_1,  Train_loss : 8318.4424  Test_loss : 7893.1133, Time/batch_file : 2.2825, Training time: 1011.6510\n",
      "Epoch : 088/2000 data_batch_2,  Train_loss : 7391.4395  Test_loss : 7952.4609, Time/batch_file : 2.2858, Training time: 1013.9369\n",
      "Epoch : 088/2000 data_batch_3,  Train_loss : 8194.1787  Test_loss : 8064.1699, Time/batch_file : 2.2877, Training time: 1016.2248\n",
      "Epoch : 088/2000 data_batch_4,  Train_loss : 7686.7021  Test_loss : 8179.7109, Time/batch_file : 2.2817, Training time: 1018.5066\n",
      "Epoch : 088/2000 data_batch_5,  Train_loss : 7789.2500  Test_loss : 8163.7598, Time/batch_file : 2.2790, Training time: 1020.7859\n",
      "Epoch : 089/2000 data_batch_1,  Train_loss : 8759.8418  Test_loss : 7611.6611, Time/batch_file : 2.2890, Training time: 1023.0752\n",
      "Epoch : 089/2000 data_batch_2,  Train_loss : 7881.6455  Test_loss : 8049.4258, Time/batch_file : 2.2963, Training time: 1025.3717\n",
      "Epoch : 089/2000 data_batch_3,  Train_loss : 8452.5811  Test_loss : 7807.3403, Time/batch_file : 2.3063, Training time: 1027.6782\n",
      "Epoch : 089/2000 data_batch_4,  Train_loss : 8082.0229  Test_loss : 7665.5088, Time/batch_file : 2.3017, Training time: 1029.9802\n",
      "Epoch : 089/2000 data_batch_5,  Train_loss : 7957.1602  Test_loss : 8117.4658, Time/batch_file : 2.2916, Training time: 1032.2719\n",
      "Epoch : 090/2000 data_batch_1,  Train_loss : 8399.6953  Test_loss : 8809.0176, Time/batch_file : 2.2833, Training time: 1034.5554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 090/2000 data_batch_2,  Train_loss : 8149.3428  Test_loss : 8361.7910, Time/batch_file : 2.2977, Training time: 1036.8533\n",
      "Epoch : 090/2000 data_batch_3,  Train_loss : 8369.1680  Test_loss : 8841.1289, Time/batch_file : 2.2805, Training time: 1039.1340\n",
      "Epoch : 090/2000 data_batch_4,  Train_loss : 8426.7793  Test_loss : 8303.1230, Time/batch_file : 2.2887, Training time: 1041.4229\n",
      "Epoch : 090/2000 data_batch_5,  Train_loss : 8335.7412  Test_loss : 8696.6113, Time/batch_file : 2.2772, Training time: 1043.7004\n",
      "[./nets/net-90.ckpt] SAVED\n",
      "Epoch : 091/2000 data_batch_1,  Train_loss : 7691.1953  Test_loss : 7771.2817, Time/batch_file : 2.2982, Training time: 1047.5415\n",
      "Epoch : 091/2000 data_batch_2,  Train_loss : 7295.4946  Test_loss : 7584.1372, Time/batch_file : 2.2836, Training time: 1049.8253\n",
      "Epoch : 091/2000 data_batch_3,  Train_loss : 7636.5239  Test_loss : 7453.6108, Time/batch_file : 2.2930, Training time: 1052.1185\n",
      "Epoch : 091/2000 data_batch_4,  Train_loss : 7063.4175  Test_loss : 7968.2622, Time/batch_file : 2.3022, Training time: 1054.4208\n",
      "Epoch : 091/2000 data_batch_5,  Train_loss : 7565.8369  Test_loss : 7777.7793, Time/batch_file : 2.2898, Training time: 1056.7109\n",
      "Epoch : 092/2000 data_batch_1,  Train_loss : 8419.3184  Test_loss : 7918.6943, Time/batch_file : 2.3153, Training time: 1059.0263\n",
      "Epoch : 092/2000 data_batch_2,  Train_loss : 8114.3066  Test_loss : 8382.6641, Time/batch_file : 2.2816, Training time: 1061.3082\n",
      "Epoch : 092/2000 data_batch_3,  Train_loss : 7807.6494  Test_loss : 8353.1709, Time/batch_file : 2.3132, Training time: 1063.6216\n",
      "Epoch : 092/2000 data_batch_4,  Train_loss : 8042.0088  Test_loss : 8756.0186, Time/batch_file : 2.2969, Training time: 1065.9188\n",
      "Epoch : 092/2000 data_batch_5,  Train_loss : 8083.7607  Test_loss : 8405.6523, Time/batch_file : 2.3108, Training time: 1068.2299\n",
      "Epoch : 093/2000 data_batch_1,  Train_loss : 7752.9277  Test_loss : 7716.9893, Time/batch_file : 2.2981, Training time: 1070.5282\n",
      "Epoch : 093/2000 data_batch_2,  Train_loss : 7591.7480  Test_loss : 7567.9746, Time/batch_file : 2.3296, Training time: 1072.8581\n",
      "Epoch : 093/2000 data_batch_3,  Train_loss : 7629.7461  Test_loss : 7656.7085, Time/batch_file : 2.2856, Training time: 1075.1438\n",
      "Epoch : 093/2000 data_batch_4,  Train_loss : 7888.0376  Test_loss : 7550.1201, Time/batch_file : 2.3141, Training time: 1077.4582\n",
      "Epoch : 093/2000 data_batch_5,  Train_loss : 7152.4653  Test_loss : 8377.4639, Time/batch_file : 2.2877, Training time: 1079.7461\n",
      "Epoch : 094/2000 data_batch_1,  Train_loss : 8180.4956  Test_loss : 8852.7910, Time/batch_file : 2.3233, Training time: 1082.0696\n",
      "Epoch : 094/2000 data_batch_2,  Train_loss : 8025.3447  Test_loss : 8626.1807, Time/batch_file : 2.3052, Training time: 1084.3751\n",
      "Epoch : 094/2000 data_batch_3,  Train_loss : 7741.8765  Test_loss : 8730.0684, Time/batch_file : 2.3182, Training time: 1086.6934\n",
      "Epoch : 094/2000 data_batch_4,  Train_loss : 7667.7378  Test_loss : 8293.5986, Time/batch_file : 2.3038, Training time: 1088.9974\n",
      "Epoch : 094/2000 data_batch_5,  Train_loss : 7308.8574  Test_loss : 8996.5254, Time/batch_file : 2.3096, Training time: 1091.3072\n",
      "Epoch : 095/2000 data_batch_1,  Train_loss : 8484.9453  Test_loss : 7716.9580, Time/batch_file : 2.3212, Training time: 1093.6288\n",
      "Epoch : 095/2000 data_batch_2,  Train_loss : 7977.0879  Test_loss : 7924.3643, Time/batch_file : 2.3057, Training time: 1095.9347\n",
      "Epoch : 095/2000 data_batch_3,  Train_loss : 8012.8970  Test_loss : 7999.2158, Time/batch_file : 2.3268, Training time: 1098.2617\n",
      "Epoch : 095/2000 data_batch_4,  Train_loss : 8090.6318  Test_loss : 8039.4668, Time/batch_file : 2.2954, Training time: 1100.5572\n",
      "Epoch : 095/2000 data_batch_5,  Train_loss : 7931.7520  Test_loss : 8019.6270, Time/batch_file : 2.3110, Training time: 1102.8683\n",
      "Epoch : 096/2000 data_batch_1,  Train_loss : 7598.7051  Test_loss : 8349.8193, Time/batch_file : 2.3027, Training time: 1105.1712\n",
      "Epoch : 096/2000 data_batch_2,  Train_loss : 7694.6934  Test_loss : 7734.7593, Time/batch_file : 2.3034, Training time: 1107.4750\n",
      "Epoch : 096/2000 data_batch_3,  Train_loss : 7388.7183  Test_loss : 8020.8359, Time/batch_file : 2.3242, Training time: 1109.7994\n",
      "Epoch : 096/2000 data_batch_4,  Train_loss : 7684.3945  Test_loss : 8280.1348, Time/batch_file : 2.2980, Training time: 1112.0976\n",
      "Epoch : 096/2000 data_batch_5,  Train_loss : 7070.6641  Test_loss : 8368.8359, Time/batch_file : 2.3089, Training time: 1114.4067\n",
      "Epoch : 097/2000 data_batch_1,  Train_loss : 7762.3711  Test_loss : 8310.3740, Time/batch_file : 2.2877, Training time: 1116.6947\n",
      "Epoch : 097/2000 data_batch_2,  Train_loss : 7838.9170  Test_loss : 7934.6514, Time/batch_file : 2.3062, Training time: 1119.0011\n",
      "Epoch : 097/2000 data_batch_3,  Train_loss : 8129.4331  Test_loss : 8521.7949, Time/batch_file : 2.2972, Training time: 1121.2986\n",
      "Epoch : 097/2000 data_batch_4,  Train_loss : 7986.1826  Test_loss : 8200.5508, Time/batch_file : 2.2949, Training time: 1123.5938\n",
      "Epoch : 097/2000 data_batch_5,  Train_loss : 7847.8613  Test_loss : 8215.2305, Time/batch_file : 2.3016, Training time: 1125.8956\n",
      "Epoch : 098/2000 data_batch_1,  Train_loss : 7897.9897  Test_loss : 7941.8306, Time/batch_file : 2.3118, Training time: 1128.2076\n",
      "Epoch : 098/2000 data_batch_2,  Train_loss : 8016.5181  Test_loss : 8208.0957, Time/batch_file : 2.3138, Training time: 1130.5216\n",
      "Epoch : 098/2000 data_batch_3,  Train_loss : 7605.8950  Test_loss : 8504.6924, Time/batch_file : 2.2924, Training time: 1132.8141\n",
      "Epoch : 098/2000 data_batch_4,  Train_loss : 7562.5781  Test_loss : 7822.0093, Time/batch_file : 2.3095, Training time: 1135.1238\n",
      "Epoch : 098/2000 data_batch_5,  Train_loss : 8000.3223  Test_loss : 8033.1826, Time/batch_file : 2.2947, Training time: 1137.4188\n",
      "Epoch : 099/2000 data_batch_1,  Train_loss : 8017.9336  Test_loss : 7832.8213, Time/batch_file : 2.2959, Training time: 1139.7148\n",
      "Epoch : 099/2000 data_batch_2,  Train_loss : 7523.2480  Test_loss : 7802.6885, Time/batch_file : 2.3316, Training time: 1142.0466\n",
      "Epoch : 099/2000 data_batch_3,  Train_loss : 7720.6655  Test_loss : 8017.8486, Time/batch_file : 2.3157, Training time: 1144.3625\n",
      "Epoch : 099/2000 data_batch_4,  Train_loss : 7512.3657  Test_loss : 7959.2725, Time/batch_file : 2.3284, Training time: 1146.6910\n",
      "Epoch : 099/2000 data_batch_5,  Train_loss : 7294.5503  Test_loss : 7886.7676, Time/batch_file : 2.3315, Training time: 1149.0227\n",
      "Epoch : 100/2000 data_batch_1,  Train_loss : 7557.0522  Test_loss : 7295.2402, Time/batch_file : 2.2994, Training time: 1151.3223\n",
      "Epoch : 100/2000 data_batch_2,  Train_loss : 7620.0361  Test_loss : 7083.0137, Time/batch_file : 2.2965, Training time: 1153.6190\n",
      "Epoch : 100/2000 data_batch_3,  Train_loss : 7913.0337  Test_loss : 7190.4404, Time/batch_file : 2.2877, Training time: 1155.9069\n",
      "Epoch : 100/2000 data_batch_4,  Train_loss : 7934.0645  Test_loss : 7420.0679, Time/batch_file : 2.3180, Training time: 1158.2252\n",
      "Epoch : 100/2000 data_batch_5,  Train_loss : 7685.4131  Test_loss : 6791.2637, Time/batch_file : 2.3011, Training time: 1160.5264\n",
      "[./nets/net-100.ckpt] SAVED\n",
      "Epoch : 101/2000 data_batch_1,  Train_loss : 7626.7075  Test_loss : 7592.2119, Time/batch_file : 2.3115, Training time: 1164.1257\n",
      "Epoch : 101/2000 data_batch_2,  Train_loss : 7642.1719  Test_loss : 7563.6162, Time/batch_file : 2.2899, Training time: 1166.4158\n",
      "Epoch : 101/2000 data_batch_3,  Train_loss : 7816.6797  Test_loss : 8024.5234, Time/batch_file : 2.2967, Training time: 1168.7126\n",
      "Epoch : 101/2000 data_batch_4,  Train_loss : 7438.5898  Test_loss : 8042.9658, Time/batch_file : 2.2994, Training time: 1171.0123\n",
      "Epoch : 101/2000 data_batch_5,  Train_loss : 7288.8232  Test_loss : 7992.7451, Time/batch_file : 2.2932, Training time: 1173.3056\n",
      "Epoch : 102/2000 data_batch_1,  Train_loss : 7673.9312  Test_loss : 7316.7549, Time/batch_file : 2.2953, Training time: 1175.6011\n",
      "Epoch : 102/2000 data_batch_2,  Train_loss : 7034.7026  Test_loss : 7678.9155, Time/batch_file : 2.3330, Training time: 1177.9343\n",
      "Epoch : 102/2000 data_batch_3,  Train_loss : 7323.7437  Test_loss : 7954.6396, Time/batch_file : 2.3084, Training time: 1180.2429\n",
      "Epoch : 102/2000 data_batch_4,  Train_loss : 7490.5234  Test_loss : 7776.6558, Time/batch_file : 2.3077, Training time: 1182.5509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 102/2000 data_batch_5,  Train_loss : 7506.0737  Test_loss : 7446.5273, Time/batch_file : 2.2991, Training time: 1184.8502\n",
      "Epoch : 103/2000 data_batch_1,  Train_loss : 7481.0122  Test_loss : 8101.4238, Time/batch_file : 2.3110, Training time: 1187.1614\n",
      "Epoch : 103/2000 data_batch_2,  Train_loss : 7647.5566  Test_loss : 7542.6499, Time/batch_file : 2.2990, Training time: 1189.4606\n",
      "Epoch : 103/2000 data_batch_3,  Train_loss : 7901.0947  Test_loss : 8414.8984, Time/batch_file : 2.3133, Training time: 1191.7740\n",
      "Epoch : 103/2000 data_batch_4,  Train_loss : 7750.7393  Test_loss : 8232.3379, Time/batch_file : 2.3077, Training time: 1194.0819\n",
      "Epoch : 103/2000 data_batch_5,  Train_loss : 7648.2412  Test_loss : 8588.8301, Time/batch_file : 2.3300, Training time: 1196.4121\n",
      "Epoch : 104/2000 data_batch_1,  Train_loss : 7700.8818  Test_loss : 7913.5146, Time/batch_file : 2.3252, Training time: 1198.7375\n",
      "Epoch : 104/2000 data_batch_2,  Train_loss : 7190.2935  Test_loss : 7339.5156, Time/batch_file : 2.3344, Training time: 1201.0721\n",
      "Epoch : 104/2000 data_batch_3,  Train_loss : 7340.6709  Test_loss : 7625.5830, Time/batch_file : 2.3049, Training time: 1203.3771\n",
      "Epoch : 104/2000 data_batch_4,  Train_loss : 8008.5308  Test_loss : 7000.8472, Time/batch_file : 2.3283, Training time: 1205.7057\n",
      "Epoch : 104/2000 data_batch_5,  Train_loss : 7284.0664  Test_loss : 7330.1318, Time/batch_file : 2.3006, Training time: 1208.0064\n",
      "Epoch : 105/2000 data_batch_1,  Train_loss : 6938.3730  Test_loss : 8207.1777, Time/batch_file : 2.3015, Training time: 1210.3081\n",
      "Epoch : 105/2000 data_batch_2,  Train_loss : 7153.6499  Test_loss : 8306.7002, Time/batch_file : 2.2902, Training time: 1212.5985\n",
      "Epoch : 105/2000 data_batch_3,  Train_loss : 7124.8320  Test_loss : 8189.2930, Time/batch_file : 2.3051, Training time: 1214.9038\n",
      "Epoch : 105/2000 data_batch_4,  Train_loss : 7284.0557  Test_loss : 8535.2441, Time/batch_file : 2.2987, Training time: 1217.2028\n",
      "Epoch : 105/2000 data_batch_5,  Train_loss : 7078.7144  Test_loss : 7850.5039, Time/batch_file : 2.3064, Training time: 1219.5094\n",
      "Epoch : 106/2000 data_batch_1,  Train_loss : 6908.9995  Test_loss : 8295.5488, Time/batch_file : 2.3351, Training time: 1221.8447\n",
      "Epoch : 106/2000 data_batch_2,  Train_loss : 7338.8428  Test_loss : 8375.9844, Time/batch_file : 2.2909, Training time: 1224.1357\n",
      "Epoch : 106/2000 data_batch_3,  Train_loss : 6729.9004  Test_loss : 7951.4033, Time/batch_file : 2.3002, Training time: 1226.4361\n",
      "Epoch : 106/2000 data_batch_4,  Train_loss : 6922.8584  Test_loss : 7703.9854, Time/batch_file : 2.2877, Training time: 1228.7240\n",
      "Epoch : 106/2000 data_batch_5,  Train_loss : 7295.2295  Test_loss : 8093.9277, Time/batch_file : 2.3025, Training time: 1231.0267\n",
      "Epoch : 107/2000 data_batch_1,  Train_loss : 7404.5996  Test_loss : 7826.9658, Time/batch_file : 2.3244, Training time: 1233.3513\n",
      "Epoch : 107/2000 data_batch_2,  Train_loss : 7251.2959  Test_loss : 7928.6494, Time/batch_file : 2.3010, Training time: 1235.6525\n",
      "Epoch : 107/2000 data_batch_3,  Train_loss : 7368.2275  Test_loss : 7642.5957, Time/batch_file : 2.3298, Training time: 1237.9826\n",
      "Epoch : 107/2000 data_batch_4,  Train_loss : 7037.2446  Test_loss : 7840.0044, Time/batch_file : 2.3029, Training time: 1240.2857\n",
      "Epoch : 107/2000 data_batch_5,  Train_loss : 7328.2886  Test_loss : 7903.4131, Time/batch_file : 2.3043, Training time: 1242.5902\n",
      "Epoch : 108/2000 data_batch_1,  Train_loss : 7440.4053  Test_loss : 7410.6592, Time/batch_file : 2.3093, Training time: 1244.8997\n",
      "Epoch : 108/2000 data_batch_2,  Train_loss : 6743.3877  Test_loss : 7976.7363, Time/batch_file : 2.3041, Training time: 1247.2040\n",
      "Epoch : 108/2000 data_batch_3,  Train_loss : 7055.8564  Test_loss : 7936.3252, Time/batch_file : 2.3124, Training time: 1249.5166\n",
      "Epoch : 108/2000 data_batch_4,  Train_loss : 6828.6206  Test_loss : 7886.3931, Time/batch_file : 2.3083, Training time: 1251.8250\n",
      "Epoch : 108/2000 data_batch_5,  Train_loss : 6742.5791  Test_loss : 8046.9346, Time/batch_file : 2.3285, Training time: 1254.1538\n",
      "Epoch : 109/2000 data_batch_1,  Train_loss : 7064.1504  Test_loss : 7674.0103, Time/batch_file : 2.3047, Training time: 1256.4589\n",
      "Epoch : 109/2000 data_batch_2,  Train_loss : 6773.2148  Test_loss : 7767.6768, Time/batch_file : 2.2887, Training time: 1258.7478\n",
      "Epoch : 109/2000 data_batch_3,  Train_loss : 6775.3564  Test_loss : 7854.7407, Time/batch_file : 2.2928, Training time: 1261.0409\n",
      "Epoch : 109/2000 data_batch_4,  Train_loss : 6966.1567  Test_loss : 7873.1621, Time/batch_file : 2.2983, Training time: 1263.3394\n",
      "Epoch : 109/2000 data_batch_5,  Train_loss : 7143.9712  Test_loss : 7349.3052, Time/batch_file : 2.2885, Training time: 1265.6282\n",
      "Epoch : 110/2000 data_batch_1,  Train_loss : 7706.9058  Test_loss : 7870.7314, Time/batch_file : 2.3080, Training time: 1267.9364\n",
      "Epoch : 110/2000 data_batch_2,  Train_loss : 7929.1982  Test_loss : 8073.2207, Time/batch_file : 2.2851, Training time: 1270.2217\n",
      "Epoch : 110/2000 data_batch_3,  Train_loss : 7448.5640  Test_loss : 7277.7622, Time/batch_file : 2.3165, Training time: 1272.5383\n",
      "Epoch : 110/2000 data_batch_4,  Train_loss : 7743.0474  Test_loss : 8036.1914, Time/batch_file : 2.2917, Training time: 1274.8302\n",
      "Epoch : 110/2000 data_batch_5,  Train_loss : 7479.9932  Test_loss : 7609.7583, Time/batch_file : 2.3055, Training time: 1277.1359\n",
      "[./nets/net-110.ckpt] SAVED\n",
      "Epoch : 111/2000 data_batch_1,  Train_loss : 7788.2744  Test_loss : 7844.2808, Time/batch_file : 2.3094, Training time: 1281.0718\n",
      "Epoch : 111/2000 data_batch_2,  Train_loss : 7547.7354  Test_loss : 7773.7031, Time/batch_file : 2.3400, Training time: 1283.4121\n",
      "Epoch : 111/2000 data_batch_3,  Train_loss : 7857.4424  Test_loss : 7282.0957, Time/batch_file : 2.2899, Training time: 1285.7022\n",
      "Epoch : 111/2000 data_batch_4,  Train_loss : 7522.6084  Test_loss : 7903.5483, Time/batch_file : 2.3212, Training time: 1288.0236\n",
      "Epoch : 111/2000 data_batch_5,  Train_loss : 7151.9233  Test_loss : 7977.9570, Time/batch_file : 2.3207, Training time: 1290.3445\n",
      "Epoch : 112/2000 data_batch_1,  Train_loss : 7667.2534  Test_loss : 7063.6611, Time/batch_file : 2.3120, Training time: 1292.6567\n",
      "Epoch : 112/2000 data_batch_2,  Train_loss : 7616.6602  Test_loss : 7288.2256, Time/batch_file : 2.3099, Training time: 1294.9668\n",
      "Epoch : 112/2000 data_batch_3,  Train_loss : 7666.9590  Test_loss : 7314.2930, Time/batch_file : 2.2977, Training time: 1297.2648\n",
      "Epoch : 112/2000 data_batch_4,  Train_loss : 7944.0762  Test_loss : 7234.5186, Time/batch_file : 2.2993, Training time: 1299.5642\n",
      "Epoch : 112/2000 data_batch_5,  Train_loss : 8255.5420  Test_loss : 7264.0859, Time/batch_file : 2.3283, Training time: 1301.8927\n",
      "Epoch : 113/2000 data_batch_1,  Train_loss : 6941.3589  Test_loss : 7889.7900, Time/batch_file : 2.2972, Training time: 1304.1903\n",
      "Epoch : 113/2000 data_batch_2,  Train_loss : 7303.8408  Test_loss : 7913.8721, Time/batch_file : 2.2993, Training time: 1306.4897\n",
      "Epoch : 113/2000 data_batch_3,  Train_loss : 7527.0630  Test_loss : 8069.8091, Time/batch_file : 2.3144, Training time: 1308.8043\n",
      "Epoch : 113/2000 data_batch_4,  Train_loss : 7337.8218  Test_loss : 7897.1636, Time/batch_file : 2.3020, Training time: 1311.1065\n",
      "Epoch : 113/2000 data_batch_5,  Train_loss : 7156.2031  Test_loss : 7420.0352, Time/batch_file : 2.2828, Training time: 1313.3896\n",
      "Epoch : 114/2000 data_batch_1,  Train_loss : 7166.2065  Test_loss : 7617.8486, Time/batch_file : 2.3272, Training time: 1315.7169\n",
      "Epoch : 114/2000 data_batch_2,  Train_loss : 7168.1567  Test_loss : 7957.5625, Time/batch_file : 2.3046, Training time: 1318.0217\n",
      "Epoch : 114/2000 data_batch_3,  Train_loss : 6611.4580  Test_loss : 8440.0674, Time/batch_file : 2.3558, Training time: 1320.3778\n",
      "Epoch : 114/2000 data_batch_4,  Train_loss : 6736.2939  Test_loss : 8074.8994, Time/batch_file : 2.3113, Training time: 1322.6893\n",
      "Epoch : 114/2000 data_batch_5,  Train_loss : 6827.7603  Test_loss : 7809.3301, Time/batch_file : 2.3621, Training time: 1325.0516\n",
      "Epoch : 115/2000 data_batch_1,  Train_loss : 7963.6943  Test_loss : 7281.6108, Time/batch_file : 2.2980, Training time: 1327.3499\n",
      "Epoch : 115/2000 data_batch_2,  Train_loss : 7189.1816  Test_loss : 7619.5845, Time/batch_file : 2.3291, Training time: 1329.6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 115/2000 data_batch_3,  Train_loss : 7223.1011  Test_loss : 7629.1387, Time/batch_file : 2.3301, Training time: 1332.0096\n",
      "Epoch : 115/2000 data_batch_4,  Train_loss : 7414.5981  Test_loss : 7670.3340, Time/batch_file : 2.3282, Training time: 1334.3380\n",
      "Epoch : 115/2000 data_batch_5,  Train_loss : 7521.0698  Test_loss : 7691.5986, Time/batch_file : 2.2978, Training time: 1336.6360\n",
      "Epoch : 116/2000 data_batch_1,  Train_loss : 7524.5625  Test_loss : 7482.3672, Time/batch_file : 2.2904, Training time: 1338.9267\n",
      "Epoch : 116/2000 data_batch_2,  Train_loss : 7792.2168  Test_loss : 7839.4062, Time/batch_file : 2.3236, Training time: 1341.2505\n",
      "Epoch : 116/2000 data_batch_3,  Train_loss : 7522.3145  Test_loss : 7688.4941, Time/batch_file : 2.2899, Training time: 1343.5407\n",
      "Epoch : 116/2000 data_batch_4,  Train_loss : 7370.1270  Test_loss : 7645.1973, Time/batch_file : 2.3337, Training time: 1345.8747\n",
      "Epoch : 116/2000 data_batch_5,  Train_loss : 7525.6978  Test_loss : 7958.7334, Time/batch_file : 2.2920, Training time: 1348.1669\n",
      "Epoch : 117/2000 data_batch_1,  Train_loss : 6520.1289  Test_loss : 7382.1553, Time/batch_file : 2.3166, Training time: 1350.4837\n",
      "Epoch : 117/2000 data_batch_2,  Train_loss : 6587.5830  Test_loss : 7240.6113, Time/batch_file : 2.3258, Training time: 1352.8096\n",
      "Epoch : 117/2000 data_batch_3,  Train_loss : 6368.6611  Test_loss : 7325.5591, Time/batch_file : 2.3173, Training time: 1355.1272\n",
      "Epoch : 117/2000 data_batch_4,  Train_loss : 6285.0459  Test_loss : 7466.4756, Time/batch_file : 2.3175, Training time: 1357.4448\n",
      "Epoch : 117/2000 data_batch_5,  Train_loss : 6285.6230  Test_loss : 7102.1167, Time/batch_file : 2.3256, Training time: 1359.7705\n",
      "Epoch : 118/2000 data_batch_1,  Train_loss : 7588.7803  Test_loss : 7135.0581, Time/batch_file : 2.3294, Training time: 1362.1001\n",
      "Epoch : 118/2000 data_batch_2,  Train_loss : 7806.1289  Test_loss : 7277.7251, Time/batch_file : 2.3265, Training time: 1364.4268\n",
      "Epoch : 118/2000 data_batch_3,  Train_loss : 7612.5703  Test_loss : 7098.4756, Time/batch_file : 2.3266, Training time: 1366.7536\n",
      "Epoch : 118/2000 data_batch_4,  Train_loss : 7322.5718  Test_loss : 7511.3789, Time/batch_file : 2.3043, Training time: 1369.0582\n",
      "Epoch : 118/2000 data_batch_5,  Train_loss : 7375.2402  Test_loss : 7003.2637, Time/batch_file : 2.3537, Training time: 1371.4121\n",
      "Epoch : 119/2000 data_batch_1,  Train_loss : 7564.4600  Test_loss : 7282.0234, Time/batch_file : 2.3154, Training time: 1373.7276\n",
      "Epoch : 119/2000 data_batch_2,  Train_loss : 7303.1348  Test_loss : 7239.9751, Time/batch_file : 2.3286, Training time: 1376.0564\n",
      "Epoch : 119/2000 data_batch_3,  Train_loss : 7222.6958  Test_loss : 7530.7378, Time/batch_file : 2.3086, Training time: 1378.3653\n",
      "Epoch : 119/2000 data_batch_4,  Train_loss : 7170.6196  Test_loss : 7166.8618, Time/batch_file : 2.3133, Training time: 1380.6788\n",
      "Epoch : 119/2000 data_batch_5,  Train_loss : 7454.8804  Test_loss : 7166.2578, Time/batch_file : 2.2887, Training time: 1382.9678\n",
      "Epoch : 120/2000 data_batch_1,  Train_loss : 7311.8838  Test_loss : 7642.6904, Time/batch_file : 2.3434, Training time: 1385.3115\n",
      "Epoch : 120/2000 data_batch_2,  Train_loss : 7668.8604  Test_loss : 7540.5649, Time/batch_file : 2.3179, Training time: 1387.6296\n",
      "Epoch : 120/2000 data_batch_3,  Train_loss : 7474.3647  Test_loss : 7509.4805, Time/batch_file : 2.3179, Training time: 1389.9478\n",
      "Epoch : 120/2000 data_batch_4,  Train_loss : 7965.8125  Test_loss : 7170.2881, Time/batch_file : 2.3112, Training time: 1392.2591\n",
      "Epoch : 120/2000 data_batch_5,  Train_loss : 7236.7441  Test_loss : 7425.6533, Time/batch_file : 2.3249, Training time: 1394.5842\n",
      "[./nets/net-120.ckpt] SAVED\n",
      "Epoch : 121/2000 data_batch_1,  Train_loss : 7878.9912  Test_loss : 6675.5903, Time/batch_file : 2.3061, Training time: 1398.1900\n",
      "Epoch : 121/2000 data_batch_2,  Train_loss : 8061.7402  Test_loss : 6800.0596, Time/batch_file : 2.3285, Training time: 1400.5186\n",
      "Epoch : 121/2000 data_batch_3,  Train_loss : 7799.9775  Test_loss : 6700.2490, Time/batch_file : 2.2905, Training time: 1402.8094\n",
      "Epoch : 121/2000 data_batch_4,  Train_loss : 7895.9185  Test_loss : 7043.8618, Time/batch_file : 2.3047, Training time: 1405.1143\n",
      "Epoch : 121/2000 data_batch_5,  Train_loss : 7597.6621  Test_loss : 6777.8789, Time/batch_file : 2.3209, Training time: 1407.4355\n",
      "Epoch : 122/2000 data_batch_1,  Train_loss : 7243.9189  Test_loss : 7081.2129, Time/batch_file : 2.3079, Training time: 1409.7436\n",
      "Epoch : 122/2000 data_batch_2,  Train_loss : 6777.2441  Test_loss : 7042.1768, Time/batch_file : 2.3297, Training time: 1412.0734\n",
      "Epoch : 122/2000 data_batch_3,  Train_loss : 6609.4761  Test_loss : 7299.8867, Time/batch_file : 2.2849, Training time: 1414.3585\n",
      "Epoch : 122/2000 data_batch_4,  Train_loss : 6829.1650  Test_loss : 7088.6973, Time/batch_file : 2.3120, Training time: 1416.6708\n",
      "Epoch : 122/2000 data_batch_5,  Train_loss : 6569.4390  Test_loss : 7619.7139, Time/batch_file : 2.3140, Training time: 1418.9850\n",
      "Epoch : 123/2000 data_batch_1,  Train_loss : 6617.1807  Test_loss : 7300.1284, Time/batch_file : 2.3084, Training time: 1421.2936\n",
      "Epoch : 123/2000 data_batch_2,  Train_loss : 7065.8247  Test_loss : 7213.2598, Time/batch_file : 2.3463, Training time: 1423.6401\n",
      "Epoch : 123/2000 data_batch_3,  Train_loss : 7626.2339  Test_loss : 6952.2871, Time/batch_file : 2.2906, Training time: 1425.9309\n",
      "Epoch : 123/2000 data_batch_4,  Train_loss : 7555.7070  Test_loss : 7649.9736, Time/batch_file : 2.3262, Training time: 1428.2573\n",
      "Epoch : 123/2000 data_batch_5,  Train_loss : 7388.5732  Test_loss : 7207.1621, Time/batch_file : 2.3245, Training time: 1430.5820\n",
      "Epoch : 124/2000 data_batch_1,  Train_loss : 7144.0059  Test_loss : 6965.0806, Time/batch_file : 2.3016, Training time: 1432.8838\n",
      "Epoch : 124/2000 data_batch_2,  Train_loss : 7706.9116  Test_loss : 7200.1758, Time/batch_file : 2.3413, Training time: 1435.2253\n",
      "Epoch : 124/2000 data_batch_3,  Train_loss : 7164.8252  Test_loss : 7090.2808, Time/batch_file : 2.2920, Training time: 1437.5174\n",
      "Epoch : 124/2000 data_batch_4,  Train_loss : 7503.7915  Test_loss : 7252.3838, Time/batch_file : 2.3239, Training time: 1439.8415\n",
      "Epoch : 124/2000 data_batch_5,  Train_loss : 6792.5117  Test_loss : 7533.8105, Time/batch_file : 2.3168, Training time: 1442.1586\n",
      "Epoch : 125/2000 data_batch_1,  Train_loss : 8154.4102  Test_loss : 7530.0415, Time/batch_file : 2.3082, Training time: 1444.4670\n",
      "Epoch : 125/2000 data_batch_2,  Train_loss : 7774.3237  Test_loss : 8008.3936, Time/batch_file : 2.3413, Training time: 1446.8086\n",
      "Epoch : 125/2000 data_batch_3,  Train_loss : 7651.9238  Test_loss : 7995.8975, Time/batch_file : 2.2939, Training time: 1449.1026\n",
      "Epoch : 125/2000 data_batch_4,  Train_loss : 7556.8003  Test_loss : 7915.6748, Time/batch_file : 2.3255, Training time: 1451.4283\n",
      "Epoch : 125/2000 data_batch_5,  Train_loss : 7511.2104  Test_loss : 7415.9639, Time/batch_file : 2.3318, Training time: 1453.7604\n",
      "Epoch : 126/2000 data_batch_1,  Train_loss : 7140.1572  Test_loss : 7223.6611, Time/batch_file : 2.3049, Training time: 1456.0656\n",
      "Epoch : 126/2000 data_batch_2,  Train_loss : 6693.7134  Test_loss : 7413.0024, Time/batch_file : 2.3395, Training time: 1458.4053\n",
      "Epoch : 126/2000 data_batch_3,  Train_loss : 6673.2314  Test_loss : 7504.7832, Time/batch_file : 2.2868, Training time: 1460.6923\n",
      "Epoch : 126/2000 data_batch_4,  Train_loss : 7009.9941  Test_loss : 7826.5571, Time/batch_file : 2.3438, Training time: 1463.0364\n",
      "Epoch : 126/2000 data_batch_5,  Train_loss : 6575.5322  Test_loss : 7587.5967, Time/batch_file : 2.3220, Training time: 1465.3585\n",
      "Epoch : 127/2000 data_batch_1,  Train_loss : 6681.0850  Test_loss : 7186.6650, Time/batch_file : 2.3052, Training time: 1467.6639\n",
      "Epoch : 127/2000 data_batch_2,  Train_loss : 7219.0498  Test_loss : 7768.7852, Time/batch_file : 2.3477, Training time: 1470.0119\n",
      "Epoch : 127/2000 data_batch_3,  Train_loss : 6775.1670  Test_loss : 7517.0674, Time/batch_file : 2.2927, Training time: 1472.3048\n",
      "Epoch : 127/2000 data_batch_4,  Train_loss : 7051.9438  Test_loss : 7503.2285, Time/batch_file : 2.3375, Training time: 1474.6425\n",
      "Epoch : 127/2000 data_batch_5,  Train_loss : 6830.0093  Test_loss : 7441.2842, Time/batch_file : 2.3237, Training time: 1476.9663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 128/2000 data_batch_1,  Train_loss : 7363.1973  Test_loss : 7395.8066, Time/batch_file : 2.3076, Training time: 1479.2741\n",
      "Epoch : 128/2000 data_batch_2,  Train_loss : 7563.9053  Test_loss : 7076.6416, Time/batch_file : 2.3453, Training time: 1481.6197\n",
      "Epoch : 128/2000 data_batch_3,  Train_loss : 7306.8130  Test_loss : 7409.6309, Time/batch_file : 2.2904, Training time: 1483.9103\n",
      "Epoch : 128/2000 data_batch_4,  Train_loss : 7128.2334  Test_loss : 7411.8604, Time/batch_file : 2.3201, Training time: 1486.2307\n",
      "Epoch : 128/2000 data_batch_5,  Train_loss : 7158.9502  Test_loss : 6983.0264, Time/batch_file : 2.3125, Training time: 1488.5433\n",
      "Epoch : 129/2000 data_batch_1,  Train_loss : 7180.8364  Test_loss : 6957.2441, Time/batch_file : 2.3076, Training time: 1490.8512\n",
      "Epoch : 129/2000 data_batch_2,  Train_loss : 6857.6758  Test_loss : 7189.4805, Time/batch_file : 2.3642, Training time: 1493.2157\n",
      "Epoch : 129/2000 data_batch_3,  Train_loss : 7107.0303  Test_loss : 7403.6318, Time/batch_file : 2.2923, Training time: 1495.5081\n",
      "Epoch : 129/2000 data_batch_4,  Train_loss : 6846.6616  Test_loss : 6953.4258, Time/batch_file : 2.3287, Training time: 1497.8370\n",
      "Epoch : 129/2000 data_batch_5,  Train_loss : 7160.1206  Test_loss : 7473.1523, Time/batch_file : 2.3279, Training time: 1500.1651\n",
      "Epoch : 130/2000 data_batch_1,  Train_loss : 7510.3594  Test_loss : 7577.0176, Time/batch_file : 2.3115, Training time: 1502.4768\n",
      "Epoch : 130/2000 data_batch_2,  Train_loss : 7242.2207  Test_loss : 7494.3359, Time/batch_file : 2.3482, Training time: 1504.8253\n",
      "Epoch : 130/2000 data_batch_3,  Train_loss : 7194.3623  Test_loss : 7318.1309, Time/batch_file : 2.2952, Training time: 1507.1207\n",
      "Epoch : 130/2000 data_batch_4,  Train_loss : 7398.5723  Test_loss : 7168.3540, Time/batch_file : 2.3312, Training time: 1509.4521\n",
      "Epoch : 130/2000 data_batch_5,  Train_loss : 7104.2817  Test_loss : 7074.2549, Time/batch_file : 2.3350, Training time: 1511.7874\n",
      "[./nets/net-130.ckpt] SAVED\n",
      "Epoch : 131/2000 data_batch_1,  Train_loss : 7214.2070  Test_loss : 7518.2349, Time/batch_file : 2.3136, Training time: 1515.4113\n",
      "Epoch : 131/2000 data_batch_2,  Train_loss : 6887.2412  Test_loss : 6947.5586, Time/batch_file : 2.3139, Training time: 1517.7253\n",
      "Epoch : 131/2000 data_batch_3,  Train_loss : 6895.1709  Test_loss : 6837.8418, Time/batch_file : 2.3544, Training time: 1520.0800\n",
      "Epoch : 131/2000 data_batch_4,  Train_loss : 6886.1865  Test_loss : 6787.6621, Time/batch_file : 2.3148, Training time: 1522.3950\n",
      "Epoch : 131/2000 data_batch_5,  Train_loss : 7134.2207  Test_loss : 7333.4697, Time/batch_file : 2.3553, Training time: 1524.7504\n",
      "Epoch : 132/2000 data_batch_1,  Train_loss : 6797.6616  Test_loss : 7630.8726, Time/batch_file : 2.2977, Training time: 1527.0484\n",
      "Epoch : 132/2000 data_batch_2,  Train_loss : 6876.7134  Test_loss : 7477.0859, Time/batch_file : 2.3318, Training time: 1529.3803\n",
      "Epoch : 132/2000 data_batch_3,  Train_loss : 6727.4492  Test_loss : 7068.7725, Time/batch_file : 2.2913, Training time: 1531.6719\n",
      "Epoch : 132/2000 data_batch_4,  Train_loss : 6893.5273  Test_loss : 7539.3984, Time/batch_file : 2.3125, Training time: 1533.9846\n",
      "Epoch : 132/2000 data_batch_5,  Train_loss : 6890.9707  Test_loss : 7344.8125, Time/batch_file : 2.3182, Training time: 1536.3032\n",
      "Epoch : 133/2000 data_batch_1,  Train_loss : 6795.8862  Test_loss : 7197.1201, Time/batch_file : 2.3113, Training time: 1538.6148\n",
      "Epoch : 133/2000 data_batch_2,  Train_loss : 7026.4253  Test_loss : 7094.5112, Time/batch_file : 2.2814, Training time: 1540.8964\n",
      "Epoch : 133/2000 data_batch_3,  Train_loss : 6845.9375  Test_loss : 7104.3428, Time/batch_file : 2.3202, Training time: 1543.2168\n",
      "Epoch : 133/2000 data_batch_4,  Train_loss : 7220.2646  Test_loss : 6874.2407, Time/batch_file : 2.2929, Training time: 1545.5099\n",
      "Epoch : 133/2000 data_batch_5,  Train_loss : 7189.5889  Test_loss : 6936.6396, Time/batch_file : 2.3074, Training time: 1547.8175\n",
      "Epoch : 134/2000 data_batch_1,  Train_loss : 6894.7676  Test_loss : 7143.7056, Time/batch_file : 2.3131, Training time: 1550.1308\n",
      "Epoch : 134/2000 data_batch_2,  Train_loss : 6516.4316  Test_loss : 7141.9741, Time/batch_file : 2.3102, Training time: 1552.4412\n",
      "Epoch : 134/2000 data_batch_3,  Train_loss : 6742.0562  Test_loss : 6670.7354, Time/batch_file : 2.3035, Training time: 1554.7448\n",
      "Epoch : 134/2000 data_batch_4,  Train_loss : 7003.3545  Test_loss : 6800.4697, Time/batch_file : 2.3096, Training time: 1557.0546\n",
      "Epoch : 134/2000 data_batch_5,  Train_loss : 6715.2603  Test_loss : 6828.1094, Time/batch_file : 2.2958, Training time: 1559.3506\n",
      "Epoch : 135/2000 data_batch_1,  Train_loss : 6802.2935  Test_loss : 7038.8799, Time/batch_file : 2.3086, Training time: 1561.6594\n",
      "Epoch : 135/2000 data_batch_2,  Train_loss : 7057.5845  Test_loss : 7386.3398, Time/batch_file : 2.3135, Training time: 1563.9730\n",
      "Epoch : 135/2000 data_batch_3,  Train_loss : 6939.5293  Test_loss : 6926.4966, Time/batch_file : 2.3125, Training time: 1566.2857\n",
      "Epoch : 135/2000 data_batch_4,  Train_loss : 7090.6401  Test_loss : 7581.8867, Time/batch_file : 2.2959, Training time: 1568.5818\n",
      "Epoch : 135/2000 data_batch_5,  Train_loss : 6321.5972  Test_loss : 7184.9629, Time/batch_file : 2.3080, Training time: 1570.8900\n",
      "Epoch : 136/2000 data_batch_1,  Train_loss : 6502.4629  Test_loss : 6817.5342, Time/batch_file : 2.2915, Training time: 1573.1817\n",
      "Epoch : 136/2000 data_batch_2,  Train_loss : 6970.3105  Test_loss : 7153.6611, Time/batch_file : 2.2882, Training time: 1575.4701\n",
      "Epoch : 136/2000 data_batch_3,  Train_loss : 6630.4902  Test_loss : 7019.6514, Time/batch_file : 2.2951, Training time: 1577.7654\n",
      "Epoch : 136/2000 data_batch_4,  Train_loss : 6750.0210  Test_loss : 6412.2744, Time/batch_file : 2.3104, Training time: 1580.0759\n",
      "Epoch : 136/2000 data_batch_5,  Train_loss : 6621.8193  Test_loss : 6745.3218, Time/batch_file : 2.3058, Training time: 1582.3819\n",
      "Epoch : 137/2000 data_batch_1,  Train_loss : 7076.8359  Test_loss : 7646.8193, Time/batch_file : 2.2901, Training time: 1584.6721\n",
      "Epoch : 137/2000 data_batch_2,  Train_loss : 6627.9434  Test_loss : 7321.7759, Time/batch_file : 2.2907, Training time: 1586.9631\n",
      "Epoch : 137/2000 data_batch_3,  Train_loss : 6789.6353  Test_loss : 7063.0415, Time/batch_file : 2.3120, Training time: 1589.2753\n",
      "Epoch : 137/2000 data_batch_4,  Train_loss : 7289.1289  Test_loss : 6969.3730, Time/batch_file : 2.2877, Training time: 1591.5631\n",
      "Epoch : 137/2000 data_batch_5,  Train_loss : 7003.3838  Test_loss : 6870.7080, Time/batch_file : 2.3099, Training time: 1593.8733\n",
      "Epoch : 138/2000 data_batch_1,  Train_loss : 6482.7476  Test_loss : 7215.3633, Time/batch_file : 2.2923, Training time: 1596.1659\n",
      "Epoch : 138/2000 data_batch_2,  Train_loss : 7167.2607  Test_loss : 7087.9365, Time/batch_file : 2.3124, Training time: 1598.4784\n",
      "Epoch : 138/2000 data_batch_3,  Train_loss : 6770.4443  Test_loss : 7085.2998, Time/batch_file : 2.2973, Training time: 1600.7759\n",
      "Epoch : 138/2000 data_batch_4,  Train_loss : 6580.1475  Test_loss : 7060.0557, Time/batch_file : 2.2903, Training time: 1603.0664\n",
      "Epoch : 138/2000 data_batch_5,  Train_loss : 6836.7988  Test_loss : 7873.8984, Time/batch_file : 2.3078, Training time: 1605.3745\n",
      "Epoch : 139/2000 data_batch_1,  Train_loss : 6625.4980  Test_loss : 6744.0454, Time/batch_file : 2.3240, Training time: 1607.6988\n",
      "Epoch : 139/2000 data_batch_2,  Train_loss : 7077.0493  Test_loss : 6835.4888, Time/batch_file : 2.2956, Training time: 1609.9947\n",
      "Epoch : 139/2000 data_batch_3,  Train_loss : 7195.6304  Test_loss : 6852.3633, Time/batch_file : 2.3191, Training time: 1612.3140\n",
      "Epoch : 139/2000 data_batch_4,  Train_loss : 6996.2725  Test_loss : 6990.1191, Time/batch_file : 2.3160, Training time: 1614.6302\n",
      "Epoch : 139/2000 data_batch_5,  Train_loss : 6917.6060  Test_loss : 6722.8018, Time/batch_file : 2.3410, Training time: 1616.9714\n",
      "Epoch : 140/2000 data_batch_1,  Train_loss : 7336.5981  Test_loss : 6868.8906, Time/batch_file : 2.2901, Training time: 1619.2618\n",
      "Epoch : 140/2000 data_batch_2,  Train_loss : 7301.6094  Test_loss : 6931.3428, Time/batch_file : 2.3029, Training time: 1621.5648\n",
      "Epoch : 140/2000 data_batch_3,  Train_loss : 6858.3643  Test_loss : 6937.4883, Time/batch_file : 2.2881, Training time: 1623.8531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 140/2000 data_batch_4,  Train_loss : 6846.7197  Test_loss : 7187.7271, Time/batch_file : 2.2969, Training time: 1626.1503\n",
      "Epoch : 140/2000 data_batch_5,  Train_loss : 7240.1519  Test_loss : 6896.4551, Time/batch_file : 2.2995, Training time: 1628.4499\n",
      "[./nets/net-140.ckpt] SAVED\n",
      "Epoch : 141/2000 data_batch_1,  Train_loss : 6854.3096  Test_loss : 7228.0742, Time/batch_file : 2.3414, Training time: 1632.4991\n",
      "Epoch : 141/2000 data_batch_2,  Train_loss : 6151.1445  Test_loss : 7347.7266, Time/batch_file : 2.2982, Training time: 1634.7976\n",
      "Epoch : 141/2000 data_batch_3,  Train_loss : 6537.1816  Test_loss : 7310.1191, Time/batch_file : 2.3220, Training time: 1637.1198\n",
      "Epoch : 141/2000 data_batch_4,  Train_loss : 6239.5791  Test_loss : 6916.5830, Time/batch_file : 2.3096, Training time: 1639.4297\n",
      "Epoch : 141/2000 data_batch_5,  Train_loss : 6552.6558  Test_loss : 7050.7876, Time/batch_file : 2.3207, Training time: 1641.7506\n",
      "Epoch : 142/2000 data_batch_1,  Train_loss : 6734.6841  Test_loss : 6955.3223, Time/batch_file : 2.2832, Training time: 1644.0340\n",
      "Epoch : 142/2000 data_batch_2,  Train_loss : 6430.1265  Test_loss : 6901.7505, Time/batch_file : 2.3055, Training time: 1646.3396\n",
      "Epoch : 142/2000 data_batch_3,  Train_loss : 6684.4771  Test_loss : 6990.7275, Time/batch_file : 2.3026, Training time: 1648.6425\n",
      "Epoch : 142/2000 data_batch_4,  Train_loss : 6562.1606  Test_loss : 6458.8389, Time/batch_file : 2.3165, Training time: 1650.9592\n",
      "Epoch : 142/2000 data_batch_5,  Train_loss : 6544.6675  Test_loss : 6511.1865, Time/batch_file : 2.2893, Training time: 1653.2487\n",
      "Epoch : 143/2000 data_batch_1,  Train_loss : 6756.2090  Test_loss : 6926.3623, Time/batch_file : 2.3219, Training time: 1655.5708\n",
      "Epoch : 143/2000 data_batch_2,  Train_loss : 7358.0923  Test_loss : 6777.4600, Time/batch_file : 2.3016, Training time: 1657.8726\n",
      "Epoch : 143/2000 data_batch_3,  Train_loss : 7091.7344  Test_loss : 6508.6938, Time/batch_file : 2.3233, Training time: 1660.1960\n",
      "Epoch : 143/2000 data_batch_4,  Train_loss : 7510.0703  Test_loss : 6494.3623, Time/batch_file : 2.3019, Training time: 1662.4981\n",
      "Epoch : 143/2000 data_batch_5,  Train_loss : 7008.1934  Test_loss : 6394.9839, Time/batch_file : 2.3299, Training time: 1664.8282\n",
      "Epoch : 144/2000 data_batch_1,  Train_loss : 7097.3096  Test_loss : 7748.6436, Time/batch_file : 2.2863, Training time: 1667.1146\n",
      "Epoch : 144/2000 data_batch_2,  Train_loss : 7189.9355  Test_loss : 7676.2246, Time/batch_file : 2.3073, Training time: 1669.4222\n",
      "Epoch : 144/2000 data_batch_3,  Train_loss : 7276.5225  Test_loss : 7247.3467, Time/batch_file : 2.2884, Training time: 1671.7107\n",
      "Epoch : 144/2000 data_batch_4,  Train_loss : 7208.9673  Test_loss : 7317.6465, Time/batch_file : 2.3160, Training time: 1674.0270\n",
      "Epoch : 144/2000 data_batch_5,  Train_loss : 7018.0454  Test_loss : 7210.8442, Time/batch_file : 2.2946, Training time: 1676.3217\n",
      "Epoch : 145/2000 data_batch_1,  Train_loss : 6785.6104  Test_loss : 7266.5620, Time/batch_file : 2.3281, Training time: 1678.6500\n",
      "Epoch : 145/2000 data_batch_2,  Train_loss : 6672.4316  Test_loss : 7485.3467, Time/batch_file : 2.2969, Training time: 1680.9472\n",
      "Epoch : 145/2000 data_batch_3,  Train_loss : 7377.5981  Test_loss : 7685.8652, Time/batch_file : 2.3313, Training time: 1683.2787\n",
      "Epoch : 145/2000 data_batch_4,  Train_loss : 6597.9756  Test_loss : 7092.3281, Time/batch_file : 2.3004, Training time: 1685.5792\n",
      "Epoch : 145/2000 data_batch_5,  Train_loss : 6519.7271  Test_loss : 7774.4199, Time/batch_file : 2.3248, Training time: 1687.9041\n",
      "Epoch : 146/2000 data_batch_1,  Train_loss : 6847.7568  Test_loss : 6765.5908, Time/batch_file : 2.3152, Training time: 1690.2195\n",
      "Epoch : 146/2000 data_batch_2,  Train_loss : 6578.0259  Test_loss : 6403.6006, Time/batch_file : 2.3367, Training time: 1692.5564\n",
      "Epoch : 146/2000 data_batch_3,  Train_loss : 6627.5112  Test_loss : 6243.6543, Time/batch_file : 2.3080, Training time: 1694.8647\n",
      "Epoch : 146/2000 data_batch_4,  Train_loss : 6893.5996  Test_loss : 6703.0337, Time/batch_file : 2.3222, Training time: 1697.1871\n",
      "Epoch : 146/2000 data_batch_5,  Train_loss : 6434.0420  Test_loss : 6361.7139, Time/batch_file : 2.3140, Training time: 1699.5015\n",
      "Epoch : 147/2000 data_batch_1,  Train_loss : 6629.2275  Test_loss : 6843.9331, Time/batch_file : 2.3152, Training time: 1701.8170\n",
      "Epoch : 147/2000 data_batch_2,  Train_loss : 6437.5752  Test_loss : 7418.0781, Time/batch_file : 2.2972, Training time: 1704.1144\n",
      "Epoch : 147/2000 data_batch_3,  Train_loss : 6485.0029  Test_loss : 7087.9438, Time/batch_file : 2.3104, Training time: 1706.4250\n",
      "Epoch : 147/2000 data_batch_4,  Train_loss : 6802.1421  Test_loss : 7194.6406, Time/batch_file : 2.2907, Training time: 1708.7159\n",
      "Epoch : 147/2000 data_batch_5,  Train_loss : 6815.5957  Test_loss : 7525.2329, Time/batch_file : 2.3264, Training time: 1711.0425\n",
      "Epoch : 148/2000 data_batch_1,  Train_loss : 6676.1636  Test_loss : 6806.1538, Time/batch_file : 2.2996, Training time: 1713.3424\n",
      "Epoch : 148/2000 data_batch_2,  Train_loss : 7062.4531  Test_loss : 6736.3350, Time/batch_file : 2.2994, Training time: 1715.6421\n",
      "Epoch : 148/2000 data_batch_3,  Train_loss : 7004.8408  Test_loss : 6788.5171, Time/batch_file : 2.2926, Training time: 1717.9349\n",
      "Epoch : 148/2000 data_batch_4,  Train_loss : 6716.3828  Test_loss : 7095.8027, Time/batch_file : 2.3135, Training time: 1720.2486\n",
      "Epoch : 148/2000 data_batch_5,  Train_loss : 6813.5215  Test_loss : 7045.9062, Time/batch_file : 2.2926, Training time: 1722.5414\n",
      "Epoch : 149/2000 data_batch_1,  Train_loss : 6628.8491  Test_loss : 6903.5513, Time/batch_file : 2.3294, Training time: 1724.8710\n",
      "Epoch : 149/2000 data_batch_2,  Train_loss : 6647.3311  Test_loss : 7329.8423, Time/batch_file : 2.3043, Training time: 1727.1755\n",
      "Epoch : 149/2000 data_batch_3,  Train_loss : 6480.3188  Test_loss : 6818.5986, Time/batch_file : 2.3285, Training time: 1729.5041\n",
      "Epoch : 149/2000 data_batch_4,  Train_loss : 6612.1255  Test_loss : 7544.5186, Time/batch_file : 2.3018, Training time: 1731.8060\n",
      "Epoch : 149/2000 data_batch_5,  Train_loss : 6682.2178  Test_loss : 7209.1265, Time/batch_file : 2.3183, Training time: 1734.1247\n",
      "Epoch : 150/2000 data_batch_1,  Train_loss : 6597.0571  Test_loss : 7502.3203, Time/batch_file : 2.2999, Training time: 1736.4248\n",
      "Epoch : 150/2000 data_batch_2,  Train_loss : 6751.4409  Test_loss : 6680.1475, Time/batch_file : 2.3051, Training time: 1738.7301\n",
      "Epoch : 150/2000 data_batch_3,  Train_loss : 6897.8496  Test_loss : 7335.7920, Time/batch_file : 2.2968, Training time: 1741.0271\n",
      "Epoch : 150/2000 data_batch_4,  Train_loss : 6356.3335  Test_loss : 7046.8774, Time/batch_file : 2.3097, Training time: 1743.3370\n",
      "Epoch : 150/2000 data_batch_5,  Train_loss : 6719.1655  Test_loss : 6852.1006, Time/batch_file : 2.2928, Training time: 1745.6301\n",
      "[./nets/net-150.ckpt] SAVED\n",
      "Epoch : 151/2000 data_batch_1,  Train_loss : 6366.4146  Test_loss : 7782.7949, Time/batch_file : 2.2997, Training time: 1749.2291\n",
      "Epoch : 151/2000 data_batch_2,  Train_loss : 6236.4141  Test_loss : 8023.6816, Time/batch_file : 2.2988, Training time: 1751.5281\n",
      "Epoch : 151/2000 data_batch_3,  Train_loss : 6159.9404  Test_loss : 7352.3936, Time/batch_file : 2.2858, Training time: 1753.8141\n",
      "Epoch : 151/2000 data_batch_4,  Train_loss : 6511.8232  Test_loss : 7100.1226, Time/batch_file : 2.2829, Training time: 1756.0972\n",
      "Epoch : 151/2000 data_batch_5,  Train_loss : 6136.2959  Test_loss : 7966.2773, Time/batch_file : 2.2941, Training time: 1758.3915\n",
      "Epoch : 152/2000 data_batch_1,  Train_loss : 6331.9678  Test_loss : 7207.0308, Time/batch_file : 2.2667, Training time: 1760.6584\n",
      "Epoch : 152/2000 data_batch_2,  Train_loss : 7074.4893  Test_loss : 7503.0039, Time/batch_file : 2.2834, Training time: 1762.9420\n",
      "Epoch : 152/2000 data_batch_3,  Train_loss : 6876.9224  Test_loss : 7047.3999, Time/batch_file : 2.2574, Training time: 1765.1997\n",
      "Epoch : 152/2000 data_batch_4,  Train_loss : 6978.6602  Test_loss : 7577.2129, Time/batch_file : 2.2584, Training time: 1767.4583\n",
      "Epoch : 152/2000 data_batch_5,  Train_loss : 6507.1245  Test_loss : 7524.6279, Time/batch_file : 2.2584, Training time: 1769.7170\n",
      "Epoch : 153/2000 data_batch_1,  Train_loss : 6509.9028  Test_loss : 7673.5327, Time/batch_file : 2.2872, Training time: 1772.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 153/2000 data_batch_2,  Train_loss : 6570.0762  Test_loss : 7634.4189, Time/batch_file : 2.2999, Training time: 1774.3044\n",
      "Epoch : 153/2000 data_batch_3,  Train_loss : 6589.9146  Test_loss : 7726.4990, Time/batch_file : 2.2937, Training time: 1776.5984\n",
      "Epoch : 153/2000 data_batch_4,  Train_loss : 6582.5869  Test_loss : 7274.8447, Time/batch_file : 2.3093, Training time: 1778.9079\n",
      "Epoch : 153/2000 data_batch_5,  Train_loss : 6885.8691  Test_loss : 7414.4736, Time/batch_file : 2.2876, Training time: 1781.1956\n",
      "Epoch : 154/2000 data_batch_1,  Train_loss : 6767.8457  Test_loss : 7123.1045, Time/batch_file : 2.3072, Training time: 1783.5030\n",
      "Epoch : 154/2000 data_batch_2,  Train_loss : 6976.9585  Test_loss : 7192.5532, Time/batch_file : 2.2852, Training time: 1785.7884\n",
      "Epoch : 154/2000 data_batch_3,  Train_loss : 6951.9697  Test_loss : 6885.2061, Time/batch_file : 2.3012, Training time: 1788.0899\n",
      "Epoch : 154/2000 data_batch_4,  Train_loss : 6495.5293  Test_loss : 6770.0186, Time/batch_file : 2.2824, Training time: 1790.3725\n",
      "Epoch : 154/2000 data_batch_5,  Train_loss : 6620.8413  Test_loss : 7038.2168, Time/batch_file : 2.2984, Training time: 1792.6712\n",
      "Epoch : 155/2000 data_batch_1,  Train_loss : 7026.0190  Test_loss : 7175.2910, Time/batch_file : 2.2878, Training time: 1794.9592\n",
      "Epoch : 155/2000 data_batch_2,  Train_loss : 6852.0264  Test_loss : 6604.3896, Time/batch_file : 2.2760, Training time: 1797.2354\n",
      "Epoch : 155/2000 data_batch_3,  Train_loss : 6904.5869  Test_loss : 7042.4409, Time/batch_file : 2.2841, Training time: 1799.5197\n",
      "Epoch : 155/2000 data_batch_4,  Train_loss : 6939.4751  Test_loss : 6968.3174, Time/batch_file : 2.2737, Training time: 1801.7935\n",
      "Epoch : 155/2000 data_batch_5,  Train_loss : 6944.1777  Test_loss : 6595.3726, Time/batch_file : 2.2718, Training time: 1804.0656\n",
      "Epoch : 156/2000 data_batch_1,  Train_loss : 6443.8037  Test_loss : 6734.4346, Time/batch_file : 2.3017, Training time: 1806.3675\n",
      "Epoch : 156/2000 data_batch_2,  Train_loss : 7010.3345  Test_loss : 6482.5781, Time/batch_file : 2.2919, Training time: 1808.6596\n",
      "Epoch : 156/2000 data_batch_3,  Train_loss : 7307.7432  Test_loss : 6560.7495, Time/batch_file : 2.3001, Training time: 1810.9599\n",
      "Epoch : 156/2000 data_batch_4,  Train_loss : 6665.0381  Test_loss : 6364.2617, Time/batch_file : 2.2839, Training time: 1813.2440\n",
      "Epoch : 156/2000 data_batch_5,  Train_loss : 7110.5508  Test_loss : 6949.0977, Time/batch_file : 2.2904, Training time: 1815.5346\n",
      "Epoch : 157/2000 data_batch_1,  Train_loss : 6890.1987  Test_loss : 7183.2480, Time/batch_file : 2.2881, Training time: 1817.8229\n",
      "Epoch : 157/2000 data_batch_2,  Train_loss : 6576.5977  Test_loss : 6448.9741, Time/batch_file : 2.3144, Training time: 1820.1375\n",
      "Epoch : 157/2000 data_batch_3,  Train_loss : 6111.3906  Test_loss : 6974.1963, Time/batch_file : 2.2893, Training time: 1822.4271\n",
      "Epoch : 157/2000 data_batch_4,  Train_loss : 6204.5068  Test_loss : 6715.5654, Time/batch_file : 2.2915, Training time: 1824.7188\n",
      "Epoch : 157/2000 data_batch_5,  Train_loss : 6285.2144  Test_loss : 6483.4092, Time/batch_file : 2.3045, Training time: 1827.0234\n",
      "Epoch : 158/2000 data_batch_1,  Train_loss : 6741.9609  Test_loss : 6720.7788, Time/batch_file : 2.2821, Training time: 1829.3058\n",
      "Epoch : 158/2000 data_batch_2,  Train_loss : 7002.5557  Test_loss : 6816.1792, Time/batch_file : 2.2738, Training time: 1831.5799\n",
      "Epoch : 158/2000 data_batch_3,  Train_loss : 6835.6592  Test_loss : 6666.1450, Time/batch_file : 2.2859, Training time: 1833.8659\n",
      "Epoch : 158/2000 data_batch_4,  Train_loss : 6952.4004  Test_loss : 6846.1270, Time/batch_file : 2.2743, Training time: 1836.1404\n",
      "Epoch : 158/2000 data_batch_5,  Train_loss : 6654.0625  Test_loss : 6610.7891, Time/batch_file : 2.2809, Training time: 1838.4214\n",
      "Epoch : 159/2000 data_batch_1,  Train_loss : 6841.3691  Test_loss : 7213.6504, Time/batch_file : 2.2739, Training time: 1840.6956\n",
      "Epoch : 159/2000 data_batch_2,  Train_loss : 6900.9746  Test_loss : 7578.7109, Time/batch_file : 2.2766, Training time: 1842.9724\n",
      "Epoch : 159/2000 data_batch_3,  Train_loss : 7075.0791  Test_loss : 7221.3672, Time/batch_file : 2.2790, Training time: 1845.2517\n",
      "Epoch : 159/2000 data_batch_4,  Train_loss : 6889.9551  Test_loss : 6752.7666, Time/batch_file : 2.2888, Training time: 1847.5408\n",
      "Epoch : 159/2000 data_batch_5,  Train_loss : 7161.2451  Test_loss : 6896.7490, Time/batch_file : 2.2646, Training time: 1849.8055\n",
      "Epoch : 160/2000 data_batch_1,  Train_loss : 6105.5811  Test_loss : 6936.7402, Time/batch_file : 2.2960, Training time: 1852.1016\n",
      "Epoch : 160/2000 data_batch_2,  Train_loss : 7228.0410  Test_loss : 7114.8018, Time/batch_file : 2.2868, Training time: 1854.3886\n",
      "Epoch : 160/2000 data_batch_3,  Train_loss : 6684.8623  Test_loss : 6924.9287, Time/batch_file : 2.3187, Training time: 1856.7075\n",
      "Epoch : 160/2000 data_batch_4,  Train_loss : 6592.4980  Test_loss : 6521.9810, Time/batch_file : 2.3129, Training time: 1859.0206\n",
      "Epoch : 160/2000 data_batch_5,  Train_loss : 6515.2056  Test_loss : 6605.1851, Time/batch_file : 2.3032, Training time: 1861.3239\n",
      "[./nets/net-160.ckpt] SAVED\n",
      "Epoch : 161/2000 data_batch_1,  Train_loss : 6664.8618  Test_loss : 7585.0049, Time/batch_file : 2.3164, Training time: 1864.9483\n",
      "Epoch : 161/2000 data_batch_2,  Train_loss : 7230.2495  Test_loss : 7400.3389, Time/batch_file : 2.3097, Training time: 1867.2582\n",
      "Epoch : 161/2000 data_batch_3,  Train_loss : 6700.4355  Test_loss : 7388.8262, Time/batch_file : 2.3070, Training time: 1869.5654\n",
      "Epoch : 161/2000 data_batch_4,  Train_loss : 6550.2549  Test_loss : 7506.4727, Time/batch_file : 2.3086, Training time: 1871.8741\n",
      "Epoch : 161/2000 data_batch_5,  Train_loss : 6924.1899  Test_loss : 7438.2910, Time/batch_file : 2.2982, Training time: 1874.1724\n",
      "Epoch : 162/2000 data_batch_1,  Train_loss : 6694.1616  Test_loss : 6872.5957, Time/batch_file : 2.3149, Training time: 1876.4875\n",
      "Epoch : 162/2000 data_batch_2,  Train_loss : 6853.2173  Test_loss : 6677.3286, Time/batch_file : 2.3106, Training time: 1878.7983\n",
      "Epoch : 162/2000 data_batch_3,  Train_loss : 6487.5615  Test_loss : 6724.9424, Time/batch_file : 2.3124, Training time: 1881.1110\n",
      "Epoch : 162/2000 data_batch_4,  Train_loss : 6747.9375  Test_loss : 6634.8340, Time/batch_file : 2.2928, Training time: 1883.4040\n",
      "Epoch : 162/2000 data_batch_5,  Train_loss : 6554.4614  Test_loss : 6662.0859, Time/batch_file : 2.3060, Training time: 1885.7102\n",
      "Epoch : 163/2000 data_batch_1,  Train_loss : 5917.0107  Test_loss : 7028.1143, Time/batch_file : 2.3076, Training time: 1888.0180\n",
      "Epoch : 163/2000 data_batch_2,  Train_loss : 6236.9136  Test_loss : 7401.2246, Time/batch_file : 2.3111, Training time: 1890.3293\n",
      "Epoch : 163/2000 data_batch_3,  Train_loss : 6350.7236  Test_loss : 7162.4790, Time/batch_file : 2.2909, Training time: 1892.6205\n",
      "Epoch : 163/2000 data_batch_4,  Train_loss : 6265.1602  Test_loss : 7603.5698, Time/batch_file : 2.3205, Training time: 1894.9412\n",
      "Epoch : 163/2000 data_batch_5,  Train_loss : 6212.2227  Test_loss : 7008.8330, Time/batch_file : 2.3043, Training time: 1897.2457\n",
      "Epoch : 164/2000 data_batch_1,  Train_loss : 5771.5215  Test_loss : 6348.0884, Time/batch_file : 2.2978, Training time: 1899.5437\n",
      "Epoch : 164/2000 data_batch_2,  Train_loss : 5862.8540  Test_loss : 6198.7607, Time/batch_file : 2.2855, Training time: 1901.8294\n",
      "Epoch : 164/2000 data_batch_3,  Train_loss : 6367.3770  Test_loss : 7009.9731, Time/batch_file : 2.3020, Training time: 1904.1316\n",
      "Epoch : 164/2000 data_batch_4,  Train_loss : 6115.6343  Test_loss : 6641.2114, Time/batch_file : 2.2924, Training time: 1906.4241\n",
      "Epoch : 164/2000 data_batch_5,  Train_loss : 6165.6670  Test_loss : 6216.4707, Time/batch_file : 2.3044, Training time: 1908.7287\n",
      "Epoch : 165/2000 data_batch_1,  Train_loss : 6555.8003  Test_loss : 6731.8496, Time/batch_file : 2.2973, Training time: 1911.0262\n",
      "Epoch : 165/2000 data_batch_2,  Train_loss : 6399.6714  Test_loss : 6571.9482, Time/batch_file : 2.3139, Training time: 1913.3403\n",
      "Epoch : 165/2000 data_batch_3,  Train_loss : 7144.1938  Test_loss : 6644.7603, Time/batch_file : 2.3087, Training time: 1915.6493\n",
      "Epoch : 165/2000 data_batch_4,  Train_loss : 6880.4980  Test_loss : 6895.9888, Time/batch_file : 2.3084, Training time: 1917.9579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 165/2000 data_batch_5,  Train_loss : 6682.7393  Test_loss : 6925.1006, Time/batch_file : 2.2970, Training time: 1920.2550\n",
      "Epoch : 166/2000 data_batch_1,  Train_loss : 6214.9561  Test_loss : 6525.2354, Time/batch_file : 2.3052, Training time: 1922.5604\n",
      "Epoch : 166/2000 data_batch_2,  Train_loss : 6423.3213  Test_loss : 6787.5786, Time/batch_file : 2.2946, Training time: 1924.8552\n",
      "Epoch : 166/2000 data_batch_3,  Train_loss : 6071.4697  Test_loss : 6710.9385, Time/batch_file : 2.3097, Training time: 1927.1652\n",
      "Epoch : 166/2000 data_batch_4,  Train_loss : 6129.1401  Test_loss : 7207.3130, Time/batch_file : 2.2834, Training time: 1929.4487\n",
      "Epoch : 166/2000 data_batch_5,  Train_loss : 6325.3091  Test_loss : 6872.9297, Time/batch_file : 2.3066, Training time: 1931.7555\n",
      "Epoch : 167/2000 data_batch_1,  Train_loss : 6769.8423  Test_loss : 6701.0190, Time/batch_file : 2.2953, Training time: 1934.0510\n",
      "Epoch : 167/2000 data_batch_2,  Train_loss : 6662.6416  Test_loss : 6854.8218, Time/batch_file : 2.3113, Training time: 1936.3625\n",
      "Epoch : 167/2000 data_batch_3,  Train_loss : 6139.7734  Test_loss : 6880.6494, Time/batch_file : 2.2986, Training time: 1938.6613\n",
      "Epoch : 167/2000 data_batch_4,  Train_loss : 6449.9883  Test_loss : 7172.7031, Time/batch_file : 2.3061, Training time: 1940.9676\n",
      "Epoch : 167/2000 data_batch_5,  Train_loss : 6276.6265  Test_loss : 7076.1445, Time/batch_file : 2.2938, Training time: 1943.2615\n",
      "Epoch : 168/2000 data_batch_1,  Train_loss : 7028.2729  Test_loss : 7141.4932, Time/batch_file : 2.3129, Training time: 1945.5746\n",
      "Epoch : 168/2000 data_batch_2,  Train_loss : 6730.6538  Test_loss : 6385.4033, Time/batch_file : 2.2963, Training time: 1947.8711\n",
      "Epoch : 168/2000 data_batch_3,  Train_loss : 6748.7148  Test_loss : 6884.4219, Time/batch_file : 2.3205, Training time: 1950.1918\n",
      "Epoch : 168/2000 data_batch_4,  Train_loss : 7000.0942  Test_loss : 6849.1284, Time/batch_file : 2.3110, Training time: 1952.5030\n",
      "Epoch : 168/2000 data_batch_5,  Train_loss : 6150.2061  Test_loss : 6753.4531, Time/batch_file : 2.3188, Training time: 1954.8220\n",
      "Epoch : 169/2000 data_batch_1,  Train_loss : 6066.3506  Test_loss : 6758.3755, Time/batch_file : 2.3034, Training time: 1957.1257\n",
      "Epoch : 169/2000 data_batch_2,  Train_loss : 6807.0137  Test_loss : 6566.6079, Time/batch_file : 2.3165, Training time: 1959.4425\n",
      "Epoch : 169/2000 data_batch_3,  Train_loss : 6273.1328  Test_loss : 7065.9062, Time/batch_file : 2.3041, Training time: 1961.7468\n",
      "Epoch : 169/2000 data_batch_4,  Train_loss : 6020.6060  Test_loss : 6851.5059, Time/batch_file : 2.3129, Training time: 1964.0598\n",
      "Epoch : 169/2000 data_batch_5,  Train_loss : 6338.0049  Test_loss : 7113.1631, Time/batch_file : 2.2953, Training time: 1966.3553\n",
      "Epoch : 170/2000 data_batch_1,  Train_loss : 6460.7847  Test_loss : 6783.9453, Time/batch_file : 2.3190, Training time: 1968.6745\n",
      "Epoch : 170/2000 data_batch_2,  Train_loss : 6178.6240  Test_loss : 6638.5244, Time/batch_file : 2.3035, Training time: 1970.9784\n",
      "Epoch : 170/2000 data_batch_3,  Train_loss : 6343.2520  Test_loss : 6541.1689, Time/batch_file : 2.3190, Training time: 1973.2977\n",
      "Epoch : 170/2000 data_batch_4,  Train_loss : 6430.7114  Test_loss : 6554.2490, Time/batch_file : 2.3091, Training time: 1975.6069\n",
      "Epoch : 170/2000 data_batch_5,  Train_loss : 6577.2188  Test_loss : 6855.0376, Time/batch_file : 2.3207, Training time: 1977.9277\n",
      "[./nets/net-170.ckpt] SAVED\n",
      "Epoch : 171/2000 data_batch_1,  Train_loss : 6668.0171  Test_loss : 6461.1597, Time/batch_file : 2.3573, Training time: 1982.0883\n",
      "Epoch : 171/2000 data_batch_2,  Train_loss : 6716.4082  Test_loss : 6656.9653, Time/batch_file : 2.2984, Training time: 1984.3870\n",
      "Epoch : 171/2000 data_batch_3,  Train_loss : 7017.8843  Test_loss : 6668.9292, Time/batch_file : 2.2916, Training time: 1986.6788\n",
      "Epoch : 171/2000 data_batch_4,  Train_loss : 6728.9287  Test_loss : 6620.3301, Time/batch_file : 2.3246, Training time: 1989.0035\n",
      "Epoch : 171/2000 data_batch_5,  Train_loss : 7232.9951  Test_loss : 6572.9766, Time/batch_file : 2.3107, Training time: 1991.3144\n",
      "Epoch : 172/2000 data_batch_1,  Train_loss : 6553.5918  Test_loss : 6974.6963, Time/batch_file : 2.3370, Training time: 1993.6517\n",
      "Epoch : 172/2000 data_batch_2,  Train_loss : 6423.3960  Test_loss : 7127.0107, Time/batch_file : 2.2929, Training time: 1995.9449\n",
      "Epoch : 172/2000 data_batch_3,  Train_loss : 6963.4614  Test_loss : 6798.0771, Time/batch_file : 2.2875, Training time: 1998.2326\n",
      "Epoch : 172/2000 data_batch_4,  Train_loss : 6349.1108  Test_loss : 6956.1338, Time/batch_file : 2.2978, Training time: 2000.5308\n",
      "Epoch : 172/2000 data_batch_5,  Train_loss : 6506.5347  Test_loss : 6958.5928, Time/batch_file : 2.2935, Training time: 2002.8245\n",
      "Epoch : 173/2000 data_batch_1,  Train_loss : 7002.7363  Test_loss : 6624.1162, Time/batch_file : 2.2964, Training time: 2005.1211\n",
      "Epoch : 173/2000 data_batch_2,  Train_loss : 6818.9160  Test_loss : 6663.2778, Time/batch_file : 2.3109, Training time: 2007.4322\n",
      "Epoch : 173/2000 data_batch_3,  Train_loss : 6916.3438  Test_loss : 6800.7344, Time/batch_file : 2.2965, Training time: 2009.7289\n",
      "Epoch : 173/2000 data_batch_4,  Train_loss : 6887.9512  Test_loss : 7247.9497, Time/batch_file : 2.2972, Training time: 2012.0262\n",
      "Epoch : 173/2000 data_batch_5,  Train_loss : 7030.0508  Test_loss : 6846.6729, Time/batch_file : 2.3015, Training time: 2014.3279\n",
      "Epoch : 174/2000 data_batch_1,  Train_loss : 6823.9424  Test_loss : 7345.6387, Time/batch_file : 2.2995, Training time: 2016.6276\n",
      "Epoch : 174/2000 data_batch_2,  Train_loss : 6458.6777  Test_loss : 7226.3008, Time/batch_file : 2.2918, Training time: 2018.9195\n",
      "Epoch : 174/2000 data_batch_3,  Train_loss : 6808.7124  Test_loss : 7074.8018, Time/batch_file : 2.3027, Training time: 2021.2224\n",
      "Epoch : 174/2000 data_batch_4,  Train_loss : 6471.7715  Test_loss : 7401.2236, Time/batch_file : 2.2918, Training time: 2023.5143\n",
      "Epoch : 174/2000 data_batch_5,  Train_loss : 6787.0811  Test_loss : 7208.6094, Time/batch_file : 2.2873, Training time: 2025.8018\n",
      "Epoch : 175/2000 data_batch_1,  Train_loss : 6747.1953  Test_loss : 6869.0381, Time/batch_file : 2.2884, Training time: 2028.0905\n",
      "Epoch : 175/2000 data_batch_2,  Train_loss : 6711.9590  Test_loss : 6883.1006, Time/batch_file : 2.2932, Training time: 2030.3839\n",
      "Epoch : 175/2000 data_batch_3,  Train_loss : 6628.2227  Test_loss : 6423.5088, Time/batch_file : 2.2740, Training time: 2032.6580\n",
      "Epoch : 175/2000 data_batch_4,  Train_loss : 6684.5439  Test_loss : 6598.1953, Time/batch_file : 2.2982, Training time: 2034.9565\n",
      "Epoch : 175/2000 data_batch_5,  Train_loss : 7114.1191  Test_loss : 6781.7334, Time/batch_file : 2.2811, Training time: 2037.2378\n",
      "Epoch : 176/2000 data_batch_1,  Train_loss : 6643.7231  Test_loss : 6391.8525, Time/batch_file : 2.2889, Training time: 2039.5269\n",
      "Epoch : 176/2000 data_batch_2,  Train_loss : 6763.9033  Test_loss : 6634.7246, Time/batch_file : 2.2877, Training time: 2041.8148\n",
      "Epoch : 176/2000 data_batch_3,  Train_loss : 6630.0923  Test_loss : 6221.2866, Time/batch_file : 2.3016, Training time: 2044.1165\n",
      "Epoch : 176/2000 data_batch_4,  Train_loss : 7016.1523  Test_loss : 6586.0283, Time/batch_file : 2.2765, Training time: 2046.3932\n",
      "Epoch : 176/2000 data_batch_5,  Train_loss : 6858.4351  Test_loss : 6931.7324, Time/batch_file : 2.3065, Training time: 2048.6999\n",
      "Epoch : 177/2000 data_batch_1,  Train_loss : 6506.6572  Test_loss : 7004.3779, Time/batch_file : 2.2851, Training time: 2050.9853\n",
      "Epoch : 177/2000 data_batch_2,  Train_loss : 6206.8711  Test_loss : 6616.4404, Time/batch_file : 2.2809, Training time: 2053.2663\n",
      "Epoch : 177/2000 data_batch_3,  Train_loss : 6147.0752  Test_loss : 6572.8755, Time/batch_file : 2.2821, Training time: 2055.5487\n",
      "Epoch : 177/2000 data_batch_4,  Train_loss : 6557.8467  Test_loss : 6745.0762, Time/batch_file : 2.3012, Training time: 2057.8501\n",
      "Epoch : 177/2000 data_batch_5,  Train_loss : 6048.1855  Test_loss : 6760.7354, Time/batch_file : 2.2776, Training time: 2060.1280\n",
      "Epoch : 178/2000 data_batch_1,  Train_loss : 6925.4473  Test_loss : 6461.9121, Time/batch_file : 2.3201, Training time: 2062.4483\n",
      "Epoch : 178/2000 data_batch_2,  Train_loss : 6684.3018  Test_loss : 7029.6035, Time/batch_file : 2.3012, Training time: 2064.7497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 178/2000 data_batch_3,  Train_loss : 6767.0713  Test_loss : 6567.1270, Time/batch_file : 2.3050, Training time: 2067.0549\n",
      "Epoch : 178/2000 data_batch_4,  Train_loss : 6752.3501  Test_loss : 6671.8623, Time/batch_file : 2.3132, Training time: 2069.3683\n",
      "Epoch : 178/2000 data_batch_5,  Train_loss : 6650.2344  Test_loss : 6649.2129, Time/batch_file : 2.3060, Training time: 2071.6745\n",
      "Epoch : 179/2000 data_batch_1,  Train_loss : 6388.5488  Test_loss : 6660.8301, Time/batch_file : 2.2710, Training time: 2073.9457\n",
      "Epoch : 179/2000 data_batch_2,  Train_loss : 6591.4653  Test_loss : 6705.7158, Time/batch_file : 2.2998, Training time: 2076.2458\n",
      "Epoch : 179/2000 data_batch_3,  Train_loss : 6830.6006  Test_loss : 6838.1821, Time/batch_file : 2.2772, Training time: 2078.5232\n",
      "Epoch : 179/2000 data_batch_4,  Train_loss : 6127.2354  Test_loss : 6755.8428, Time/batch_file : 2.2876, Training time: 2080.8110\n",
      "Epoch : 179/2000 data_batch_5,  Train_loss : 6550.0776  Test_loss : 7027.4492, Time/batch_file : 2.2808, Training time: 2083.0919\n",
      "Epoch : 180/2000 data_batch_1,  Train_loss : 7158.3223  Test_loss : 7206.2588, Time/batch_file : 2.3080, Training time: 2085.4002\n",
      "Epoch : 180/2000 data_batch_2,  Train_loss : 7217.0088  Test_loss : 7135.6357, Time/batch_file : 2.2891, Training time: 2087.6896\n",
      "Epoch : 180/2000 data_batch_3,  Train_loss : 7228.9395  Test_loss : 7437.9395, Time/batch_file : 2.3197, Training time: 2090.0095\n",
      "Epoch : 180/2000 data_batch_4,  Train_loss : 7098.0879  Test_loss : 7593.8623, Time/batch_file : 2.3077, Training time: 2092.3175\n",
      "Epoch : 180/2000 data_batch_5,  Train_loss : 6957.5557  Test_loss : 7456.5869, Time/batch_file : 2.3045, Training time: 2094.6221\n",
      "[./nets/net-180.ckpt] SAVED\n",
      "Epoch : 181/2000 data_batch_1,  Train_loss : 6837.8550  Test_loss : 6306.7646, Time/batch_file : 2.3060, Training time: 2098.2365\n",
      "Epoch : 181/2000 data_batch_2,  Train_loss : 6616.2598  Test_loss : 6369.1147, Time/batch_file : 2.3094, Training time: 2100.5461\n",
      "Epoch : 181/2000 data_batch_3,  Train_loss : 6856.4971  Test_loss : 6448.8633, Time/batch_file : 2.2835, Training time: 2102.8298\n",
      "Epoch : 181/2000 data_batch_4,  Train_loss : 6878.5049  Test_loss : 6643.7173, Time/batch_file : 2.3018, Training time: 2105.1316\n",
      "Epoch : 181/2000 data_batch_5,  Train_loss : 7004.3066  Test_loss : 6429.9971, Time/batch_file : 2.2870, Training time: 2107.4188\n",
      "Epoch : 182/2000 data_batch_1,  Train_loss : 6254.8872  Test_loss : 6817.1738, Time/batch_file : 2.2803, Training time: 2109.6993\n",
      "Epoch : 182/2000 data_batch_2,  Train_loss : 5949.2979  Test_loss : 6639.2969, Time/batch_file : 2.2889, Training time: 2111.9883\n",
      "Epoch : 182/2000 data_batch_3,  Train_loss : 6109.1631  Test_loss : 6377.9302, Time/batch_file : 2.3031, Training time: 2114.2916\n",
      "Epoch : 182/2000 data_batch_4,  Train_loss : 5958.6182  Test_loss : 6496.0576, Time/batch_file : 2.2791, Training time: 2116.5709\n",
      "Epoch : 182/2000 data_batch_5,  Train_loss : 6032.4189  Test_loss : 6543.6885, Time/batch_file : 2.2839, Training time: 2118.8550\n",
      "Epoch : 183/2000 data_batch_1,  Train_loss : 6685.4077  Test_loss : 6281.8428, Time/batch_file : 2.3420, Training time: 2121.1972\n",
      "Epoch : 183/2000 data_batch_2,  Train_loss : 6373.4453  Test_loss : 6360.2861, Time/batch_file : 2.3006, Training time: 2123.4979\n",
      "Epoch : 183/2000 data_batch_3,  Train_loss : 6672.1953  Test_loss : 6319.6372, Time/batch_file : 2.2933, Training time: 2125.7914\n",
      "Epoch : 183/2000 data_batch_4,  Train_loss : 6509.8477  Test_loss : 6039.0225, Time/batch_file : 2.3184, Training time: 2128.1101\n",
      "Epoch : 183/2000 data_batch_5,  Train_loss : 6037.5972  Test_loss : 6204.5459, Time/batch_file : 2.2912, Training time: 2130.4014\n",
      "Epoch : 184/2000 data_batch_1,  Train_loss : 6815.7705  Test_loss : 6987.3232, Time/batch_file : 2.2906, Training time: 2132.6922\n",
      "Epoch : 184/2000 data_batch_2,  Train_loss : 6670.3252  Test_loss : 6842.2925, Time/batch_file : 2.2840, Training time: 2134.9764\n",
      "Epoch : 184/2000 data_batch_3,  Train_loss : 6640.6235  Test_loss : 6419.4893, Time/batch_file : 2.2950, Training time: 2137.2717\n",
      "Epoch : 184/2000 data_batch_4,  Train_loss : 6655.4097  Test_loss : 6443.0908, Time/batch_file : 2.2989, Training time: 2139.5708\n",
      "Epoch : 184/2000 data_batch_5,  Train_loss : 6594.0938  Test_loss : 6609.0405, Time/batch_file : 2.3148, Training time: 2141.8858\n",
      "Epoch : 185/2000 data_batch_1,  Train_loss : 6409.5898  Test_loss : 6573.1426, Time/batch_file : 2.3037, Training time: 2144.1897\n",
      "Epoch : 185/2000 data_batch_2,  Train_loss : 6398.5332  Test_loss : 6997.7852, Time/batch_file : 2.2921, Training time: 2146.4820\n",
      "Epoch : 185/2000 data_batch_3,  Train_loss : 6498.2827  Test_loss : 6336.4307, Time/batch_file : 2.2921, Training time: 2148.7743\n",
      "Epoch : 185/2000 data_batch_4,  Train_loss : 6192.8613  Test_loss : 6480.2158, Time/batch_file : 2.2925, Training time: 2151.0671\n",
      "Epoch : 185/2000 data_batch_5,  Train_loss : 6523.6475  Test_loss : 6354.4556, Time/batch_file : 2.2985, Training time: 2153.3658\n",
      "Epoch : 186/2000 data_batch_1,  Train_loss : 5947.7944  Test_loss : 6775.9873, Time/batch_file : 2.3109, Training time: 2155.6771\n",
      "Epoch : 186/2000 data_batch_2,  Train_loss : 6061.8403  Test_loss : 6990.6421, Time/batch_file : 2.2871, Training time: 2157.9644\n",
      "Epoch : 186/2000 data_batch_3,  Train_loss : 6151.5088  Test_loss : 6670.1597, Time/batch_file : 2.2914, Training time: 2160.2560\n",
      "Epoch : 186/2000 data_batch_4,  Train_loss : 6219.6768  Test_loss : 6649.3779, Time/batch_file : 2.2839, Training time: 2162.5401\n",
      "Epoch : 186/2000 data_batch_5,  Train_loss : 6115.0312  Test_loss : 6975.9424, Time/batch_file : 2.2967, Training time: 2164.8369\n",
      "Epoch : 187/2000 data_batch_1,  Train_loss : 5908.3140  Test_loss : 6887.4233, Time/batch_file : 2.3043, Training time: 2167.1415\n",
      "Epoch : 187/2000 data_batch_2,  Train_loss : 6040.0459  Test_loss : 6731.4976, Time/batch_file : 2.3280, Training time: 2169.4697\n",
      "Epoch : 187/2000 data_batch_3,  Train_loss : 6107.6836  Test_loss : 6692.4814, Time/batch_file : 2.2981, Training time: 2171.7679\n",
      "Epoch : 187/2000 data_batch_4,  Train_loss : 6028.0967  Test_loss : 6871.7476, Time/batch_file : 2.2986, Training time: 2174.0667\n",
      "Epoch : 187/2000 data_batch_5,  Train_loss : 5953.8340  Test_loss : 7019.8828, Time/batch_file : 2.2887, Training time: 2176.3557\n",
      "Epoch : 188/2000 data_batch_1,  Train_loss : 6285.0293  Test_loss : 6768.6455, Time/batch_file : 2.3011, Training time: 2178.6569\n",
      "Epoch : 188/2000 data_batch_2,  Train_loss : 6063.0532  Test_loss : 6570.6875, Time/batch_file : 2.2963, Training time: 2180.9534\n",
      "Epoch : 188/2000 data_batch_3,  Train_loss : 5926.7676  Test_loss : 6837.7178, Time/batch_file : 2.3176, Training time: 2183.2712\n",
      "Epoch : 188/2000 data_batch_4,  Train_loss : 6293.0898  Test_loss : 6227.1650, Time/batch_file : 2.2877, Training time: 2185.5592\n",
      "Epoch : 188/2000 data_batch_5,  Train_loss : 6135.1484  Test_loss : 6771.7031, Time/batch_file : 2.2941, Training time: 2187.8535\n",
      "Epoch : 189/2000 data_batch_1,  Train_loss : 6469.9106  Test_loss : 7043.8867, Time/batch_file : 2.2874, Training time: 2190.1411\n",
      "Epoch : 189/2000 data_batch_2,  Train_loss : 6214.9927  Test_loss : 6958.2173, Time/batch_file : 2.2943, Training time: 2192.4357\n",
      "Epoch : 189/2000 data_batch_3,  Train_loss : 6306.7969  Test_loss : 6879.6421, Time/batch_file : 2.2742, Training time: 2194.7102\n",
      "Epoch : 189/2000 data_batch_4,  Train_loss : 6519.9912  Test_loss : 7152.1162, Time/batch_file : 2.2995, Training time: 2197.0099\n",
      "Epoch : 189/2000 data_batch_5,  Train_loss : 6108.4248  Test_loss : 7750.2578, Time/batch_file : 2.2783, Training time: 2199.2883\n",
      "Epoch : 190/2000 data_batch_1,  Train_loss : 6347.6523  Test_loss : 6905.1729, Time/batch_file : 2.2866, Training time: 2201.5751\n",
      "Epoch : 190/2000 data_batch_2,  Train_loss : 6833.3730  Test_loss : 6744.9648, Time/batch_file : 2.2761, Training time: 2203.8515\n",
      "Epoch : 190/2000 data_batch_3,  Train_loss : 6568.3525  Test_loss : 6908.4634, Time/batch_file : 2.2948, Training time: 2206.1465\n",
      "Epoch : 190/2000 data_batch_4,  Train_loss : 6187.2085  Test_loss : 6367.1958, Time/batch_file : 2.2756, Training time: 2208.4223\n",
      "Epoch : 190/2000 data_batch_5,  Train_loss : 6456.4019  Test_loss : 6759.3589, Time/batch_file : 2.3057, Training time: 2210.7281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[./nets/net-190.ckpt] SAVED\n",
      "Epoch : 191/2000 data_batch_1,  Train_loss : 6798.8398  Test_loss : 6925.8945, Time/batch_file : 2.3290, Training time: 2214.3387\n",
      "Epoch : 191/2000 data_batch_2,  Train_loss : 6500.6582  Test_loss : 6392.6787, Time/batch_file : 2.3206, Training time: 2216.6595\n",
      "Epoch : 191/2000 data_batch_3,  Train_loss : 6726.8970  Test_loss : 6364.4512, Time/batch_file : 2.2852, Training time: 2218.9449\n",
      "Epoch : 191/2000 data_batch_4,  Train_loss : 6374.2812  Test_loss : 6751.8755, Time/batch_file : 2.3040, Training time: 2221.2492\n",
      "Epoch : 191/2000 data_batch_5,  Train_loss : 6786.6709  Test_loss : 6560.9258, Time/batch_file : 2.2894, Training time: 2223.5388\n",
      "Epoch : 192/2000 data_batch_1,  Train_loss : 5988.9536  Test_loss : 6298.0361, Time/batch_file : 2.3108, Training time: 2225.8498\n",
      "Epoch : 192/2000 data_batch_2,  Train_loss : 6388.6025  Test_loss : 6148.8701, Time/batch_file : 2.3062, Training time: 2228.1563\n",
      "Epoch : 192/2000 data_batch_3,  Train_loss : 6425.2285  Test_loss : 6309.6709, Time/batch_file : 2.3355, Training time: 2230.4920\n",
      "Epoch : 192/2000 data_batch_4,  Train_loss : 6100.3882  Test_loss : 6349.2158, Time/batch_file : 2.3175, Training time: 2232.8097\n",
      "Epoch : 192/2000 data_batch_5,  Train_loss : 6406.0527  Test_loss : 6097.6787, Time/batch_file : 2.3262, Training time: 2235.1361\n",
      "Epoch : 193/2000 data_batch_1,  Train_loss : 6038.7085  Test_loss : 6718.9688, Time/batch_file : 2.3144, Training time: 2237.4508\n",
      "Epoch : 193/2000 data_batch_2,  Train_loss : 6527.9585  Test_loss : 7086.6152, Time/batch_file : 2.3102, Training time: 2239.7613\n",
      "Epoch : 193/2000 data_batch_3,  Train_loss : 6062.3643  Test_loss : 6733.1504, Time/batch_file : 2.3105, Training time: 2242.0721\n",
      "Epoch : 193/2000 data_batch_4,  Train_loss : 5866.9927  Test_loss : 6649.4111, Time/batch_file : 2.2976, Training time: 2244.3698\n",
      "Epoch : 193/2000 data_batch_5,  Train_loss : 5911.5020  Test_loss : 6657.3491, Time/batch_file : 2.2928, Training time: 2246.6628\n",
      "Epoch : 194/2000 data_batch_1,  Train_loss : 6713.1953  Test_loss : 7101.9922, Time/batch_file : 2.3055, Training time: 2248.9685\n",
      "Epoch : 194/2000 data_batch_2,  Train_loss : 6675.9844  Test_loss : 7316.5176, Time/batch_file : 2.2825, Training time: 2251.2511\n",
      "Epoch : 194/2000 data_batch_3,  Train_loss : 6779.9331  Test_loss : 6800.6416, Time/batch_file : 2.2990, Training time: 2253.5505\n",
      "Epoch : 194/2000 data_batch_4,  Train_loss : 6710.2041  Test_loss : 7101.4243, Time/batch_file : 2.3148, Training time: 2255.8655\n",
      "Epoch : 194/2000 data_batch_5,  Train_loss : 6861.7856  Test_loss : 7248.3506, Time/batch_file : 2.3118, Training time: 2258.1775\n",
      "Epoch : 195/2000 data_batch_1,  Train_loss : 6342.0781  Test_loss : 6980.0532, Time/batch_file : 2.3175, Training time: 2260.4951\n",
      "Epoch : 195/2000 data_batch_2,  Train_loss : 6296.8555  Test_loss : 7332.3672, Time/batch_file : 2.3200, Training time: 2262.8153\n",
      "Epoch : 195/2000 data_batch_3,  Train_loss : 6580.0010  Test_loss : 6883.0571, Time/batch_file : 2.3229, Training time: 2265.1383\n",
      "Epoch : 195/2000 data_batch_4,  Train_loss : 6158.8613  Test_loss : 7029.0273, Time/batch_file : 2.3150, Training time: 2267.4535\n",
      "Epoch : 195/2000 data_batch_5,  Train_loss : 6358.8311  Test_loss : 6968.0107, Time/batch_file : 2.3186, Training time: 2269.7723\n",
      "Epoch : 196/2000 data_batch_1,  Train_loss : 6403.5371  Test_loss : 6837.2969, Time/batch_file : 2.3234, Training time: 2272.0959\n",
      "Epoch : 196/2000 data_batch_2,  Train_loss : 6463.9683  Test_loss : 6640.1606, Time/batch_file : 2.3053, Training time: 2274.4013\n",
      "Epoch : 196/2000 data_batch_3,  Train_loss : 6102.8276  Test_loss : 6691.6924, Time/batch_file : 2.3218, Training time: 2276.7233\n",
      "Epoch : 196/2000 data_batch_4,  Train_loss : 6301.0762  Test_loss : 6484.2383, Time/batch_file : 2.3200, Training time: 2279.0435\n",
      "Epoch : 196/2000 data_batch_5,  Train_loss : 6367.9570  Test_loss : 7013.7012, Time/batch_file : 2.3211, Training time: 2281.3648\n",
      "Epoch : 197/2000 data_batch_1,  Train_loss : 6445.9790  Test_loss : 6582.4756, Time/batch_file : 2.3077, Training time: 2283.6727\n",
      "Epoch : 197/2000 data_batch_2,  Train_loss : 6802.6318  Test_loss : 6914.0137, Time/batch_file : 2.3424, Training time: 2286.0153\n",
      "Epoch : 197/2000 data_batch_3,  Train_loss : 6657.9141  Test_loss : 6907.6973, Time/batch_file : 2.3138, Training time: 2288.3293\n",
      "Epoch : 197/2000 data_batch_4,  Train_loss : 6362.8340  Test_loss : 6282.3589, Time/batch_file : 2.3297, Training time: 2290.6592\n",
      "Epoch : 197/2000 data_batch_5,  Train_loss : 6444.7007  Test_loss : 6666.0859, Time/batch_file : 2.3066, Training time: 2292.9660\n",
      "Epoch : 198/2000 data_batch_1,  Train_loss : 6797.4126  Test_loss : 6800.8633, Time/batch_file : 2.3299, Training time: 2295.2961\n",
      "Epoch : 198/2000 data_batch_2,  Train_loss : 6357.3945  Test_loss : 7249.0532, Time/batch_file : 2.3398, Training time: 2297.6361\n",
      "Epoch : 198/2000 data_batch_3,  Train_loss : 6404.0303  Test_loss : 6940.3096, Time/batch_file : 2.3283, Training time: 2299.9646\n",
      "Epoch : 198/2000 data_batch_4,  Train_loss : 6622.1289  Test_loss : 6904.6782, Time/batch_file : 2.3035, Training time: 2302.2683\n",
      "Epoch : 198/2000 data_batch_5,  Train_loss : 6794.1846  Test_loss : 6835.3125, Time/batch_file : 2.3376, Training time: 2304.6061\n",
      "Epoch : 199/2000 data_batch_1,  Train_loss : 6363.6802  Test_loss : 6640.8516, Time/batch_file : 2.3098, Training time: 2306.9161\n",
      "Epoch : 199/2000 data_batch_2,  Train_loss : 6340.4165  Test_loss : 6540.8257, Time/batch_file : 2.3212, Training time: 2309.2376\n",
      "Epoch : 199/2000 data_batch_3,  Train_loss : 6299.1680  Test_loss : 6527.7368, Time/batch_file : 2.3173, Training time: 2311.5551\n",
      "Epoch : 199/2000 data_batch_4,  Train_loss : 6271.6577  Test_loss : 6660.0479, Time/batch_file : 2.3234, Training time: 2313.8787\n",
      "Epoch : 199/2000 data_batch_5,  Train_loss : 6010.4727  Test_loss : 6628.3765, Time/batch_file : 2.3230, Training time: 2316.2019\n",
      "Epoch : 200/2000 data_batch_1,  Train_loss : 6172.1621  Test_loss : 6801.9639, Time/batch_file : 2.3166, Training time: 2318.5187\n",
      "Epoch : 200/2000 data_batch_2,  Train_loss : 6370.6436  Test_loss : 6483.8906, Time/batch_file : 2.3234, Training time: 2320.8423\n",
      "Epoch : 200/2000 data_batch_3,  Train_loss : 6282.8975  Test_loss : 6878.3486, Time/batch_file : 2.3195, Training time: 2323.1619\n",
      "Epoch : 200/2000 data_batch_4,  Train_loss : 6308.9805  Test_loss : 6684.9092, Time/batch_file : 2.3239, Training time: 2325.4860\n",
      "Epoch : 200/2000 data_batch_5,  Train_loss : 6066.9663  Test_loss : 7054.6172, Time/batch_file : 2.3174, Training time: 2327.8036\n",
      "[./nets/net-200.ckpt] SAVED\n",
      "Epoch : 201/2000 data_batch_1,  Train_loss : 6687.2085  Test_loss : 6671.1880, Time/batch_file : 2.3364, Training time: 2331.4343\n",
      "Epoch : 201/2000 data_batch_2,  Train_loss : 6776.9248  Test_loss : 6696.7607, Time/batch_file : 2.3226, Training time: 2333.7572\n",
      "Epoch : 201/2000 data_batch_3,  Train_loss : 6622.8315  Test_loss : 6891.7148, Time/batch_file : 2.3132, Training time: 2336.0706\n",
      "Epoch : 201/2000 data_batch_4,  Train_loss : 6848.7861  Test_loss : 6812.9150, Time/batch_file : 2.3151, Training time: 2338.3859\n",
      "Epoch : 201/2000 data_batch_5,  Train_loss : 6698.6167  Test_loss : 6406.7881, Time/batch_file : 2.3075, Training time: 2340.6936\n",
      "Epoch : 202/2000 data_batch_1,  Train_loss : 6157.4375  Test_loss : 6965.7393, Time/batch_file : 2.3051, Training time: 2342.9991\n",
      "Epoch : 202/2000 data_batch_2,  Train_loss : 6352.1450  Test_loss : 6744.9185, Time/batch_file : 2.3093, Training time: 2345.3087\n",
      "Epoch : 202/2000 data_batch_3,  Train_loss : 6124.4009  Test_loss : 7057.4795, Time/batch_file : 2.3060, Training time: 2347.6149\n",
      "Epoch : 202/2000 data_batch_4,  Train_loss : 6178.7695  Test_loss : 7099.2314, Time/batch_file : 2.3033, Training time: 2349.9183\n",
      "Epoch : 202/2000 data_batch_5,  Train_loss : 6262.7954  Test_loss : 6720.4834, Time/batch_file : 2.3149, Training time: 2352.2334\n",
      "Epoch : 203/2000 data_batch_1,  Train_loss : 6235.4834  Test_loss : 6610.9370, Time/batch_file : 2.3106, Training time: 2354.5441\n",
      "Epoch : 203/2000 data_batch_2,  Train_loss : 5967.0479  Test_loss : 6853.2905, Time/batch_file : 2.3199, Training time: 2356.8643\n",
      "Epoch : 203/2000 data_batch_3,  Train_loss : 6003.8828  Test_loss : 6641.2031, Time/batch_file : 2.3032, Training time: 2359.1677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 203/2000 data_batch_4,  Train_loss : 6234.2959  Test_loss : 6845.9082, Time/batch_file : 2.3268, Training time: 2361.4946\n",
      "Epoch : 203/2000 data_batch_5,  Train_loss : 5833.6763  Test_loss : 6697.5884, Time/batch_file : 2.3126, Training time: 2363.8075\n",
      "Epoch : 204/2000 data_batch_1,  Train_loss : 6434.2632  Test_loss : 6494.2124, Time/batch_file : 2.3094, Training time: 2366.1171\n",
      "Epoch : 204/2000 data_batch_2,  Train_loss : 6443.0200  Test_loss : 6720.8008, Time/batch_file : 2.3061, Training time: 2368.4234\n",
      "Epoch : 204/2000 data_batch_3,  Train_loss : 6404.9795  Test_loss : 6639.0708, Time/batch_file : 2.3074, Training time: 2370.7310\n",
      "Epoch : 204/2000 data_batch_4,  Train_loss : 6828.6279  Test_loss : 6688.1172, Time/batch_file : 2.3065, Training time: 2373.0377\n",
      "Epoch : 204/2000 data_batch_5,  Train_loss : 6464.4956  Test_loss : 6662.8198, Time/batch_file : 2.3162, Training time: 2375.3541\n",
      "Epoch : 205/2000 data_batch_1,  Train_loss : 6360.7383  Test_loss : 6134.2256, Time/batch_file : 2.3128, Training time: 2377.6671\n",
      "Epoch : 205/2000 data_batch_2,  Train_loss : 6397.9731  Test_loss : 6576.0254, Time/batch_file : 2.3104, Training time: 2379.9777\n",
      "Epoch : 205/2000 data_batch_3,  Train_loss : 6817.1357  Test_loss : 6860.8975, Time/batch_file : 2.3032, Training time: 2382.2811\n",
      "Epoch : 205/2000 data_batch_4,  Train_loss : 6557.1851  Test_loss : 7324.0771, Time/batch_file : 2.3095, Training time: 2384.5909\n",
      "Epoch : 205/2000 data_batch_5,  Train_loss : 6575.2944  Test_loss : 6668.7939, Time/batch_file : 2.3030, Training time: 2386.8942\n",
      "Epoch : 206/2000 data_batch_1,  Train_loss : 6889.2485  Test_loss : 6379.0410, Time/batch_file : 2.3070, Training time: 2389.2015\n",
      "Epoch : 206/2000 data_batch_2,  Train_loss : 6981.9688  Test_loss : 6417.9668, Time/batch_file : 2.3089, Training time: 2391.5106\n",
      "Epoch : 206/2000 data_batch_3,  Train_loss : 6741.8359  Test_loss : 6411.1270, Time/batch_file : 2.3226, Training time: 2393.8334\n",
      "Epoch : 206/2000 data_batch_4,  Train_loss : 6833.5352  Test_loss : 6257.0059, Time/batch_file : 2.3023, Training time: 2396.1359\n",
      "Epoch : 206/2000 data_batch_5,  Train_loss : 6736.8721  Test_loss : 6376.3735, Time/batch_file : 2.3098, Training time: 2398.4458\n",
      "Epoch : 207/2000 data_batch_1,  Train_loss : 6339.0186  Test_loss : 6097.3120, Time/batch_file : 2.3102, Training time: 2400.7562\n",
      "Epoch : 207/2000 data_batch_2,  Train_loss : 7057.7651  Test_loss : 6308.5933, Time/batch_file : 2.3078, Training time: 2403.0642\n",
      "Epoch : 207/2000 data_batch_3,  Train_loss : 6312.7920  Test_loss : 6194.6426, Time/batch_file : 2.3074, Training time: 2405.3718\n",
      "Epoch : 207/2000 data_batch_4,  Train_loss : 6387.7979  Test_loss : 6331.8135, Time/batch_file : 2.3199, Training time: 2407.6919\n",
      "Epoch : 207/2000 data_batch_5,  Train_loss : 6573.7002  Test_loss : 7081.6274, Time/batch_file : 2.3125, Training time: 2410.0047\n",
      "Epoch : 208/2000 data_batch_1,  Train_loss : 6508.4985  Test_loss : 7038.2354, Time/batch_file : 2.3089, Training time: 2412.3138\n",
      "Epoch : 208/2000 data_batch_2,  Train_loss : 6278.0752  Test_loss : 6574.4258, Time/batch_file : 2.3084, Training time: 2414.6225\n",
      "Epoch : 208/2000 data_batch_3,  Train_loss : 6785.8608  Test_loss : 6723.2002, Time/batch_file : 2.3085, Training time: 2416.9311\n",
      "Epoch : 208/2000 data_batch_4,  Train_loss : 6349.7134  Test_loss : 7001.6123, Time/batch_file : 2.3079, Training time: 2419.2392\n",
      "Epoch : 208/2000 data_batch_5,  Train_loss : 6329.3564  Test_loss : 6779.4121, Time/batch_file : 2.3634, Training time: 2421.6027\n",
      "Epoch : 209/2000 data_batch_1,  Train_loss : 6515.6880  Test_loss : 5965.6035, Time/batch_file : 2.3217, Training time: 2423.9246\n",
      "Epoch : 209/2000 data_batch_2,  Train_loss : 6622.8389  Test_loss : 5971.4292, Time/batch_file : 2.3162, Training time: 2426.2410\n",
      "Epoch : 209/2000 data_batch_3,  Train_loss : 6778.6909  Test_loss : 6169.8726, Time/batch_file : 2.3138, Training time: 2428.5551\n",
      "Epoch : 209/2000 data_batch_4,  Train_loss : 6358.7095  Test_loss : 6031.5498, Time/batch_file : 2.3252, Training time: 2430.8805\n",
      "Epoch : 209/2000 data_batch_5,  Train_loss : 6674.5615  Test_loss : 6066.3857, Time/batch_file : 2.3115, Training time: 2433.1922\n",
      "Epoch : 210/2000 data_batch_1,  Train_loss : 6718.5552  Test_loss : 6121.1265, Time/batch_file : 2.3128, Training time: 2435.5052\n",
      "Epoch : 210/2000 data_batch_2,  Train_loss : 6338.9482  Test_loss : 5878.3730, Time/batch_file : 2.3066, Training time: 2437.8120\n",
      "Epoch : 210/2000 data_batch_3,  Train_loss : 6495.9331  Test_loss : 5685.3594, Time/batch_file : 2.3252, Training time: 2440.1374\n",
      "Epoch : 210/2000 data_batch_4,  Train_loss : 6505.9888  Test_loss : 5910.4932, Time/batch_file : 2.3096, Training time: 2442.4473\n",
      "Epoch : 210/2000 data_batch_5,  Train_loss : 6197.1055  Test_loss : 5967.7256, Time/batch_file : 2.3161, Training time: 2444.7635\n",
      "[./nets/net-210.ckpt] SAVED\n",
      "Epoch : 211/2000 data_batch_1,  Train_loss : 5989.3887  Test_loss : 6722.7588, Time/batch_file : 2.3382, Training time: 2449.0303\n",
      "Epoch : 211/2000 data_batch_2,  Train_loss : 6677.2222  Test_loss : 6706.6855, Time/batch_file : 2.2787, Training time: 2451.3093\n",
      "Epoch : 211/2000 data_batch_3,  Train_loss : 6354.6030  Test_loss : 6485.1060, Time/batch_file : 2.3160, Training time: 2453.6254\n",
      "Epoch : 211/2000 data_batch_4,  Train_loss : 6009.0596  Test_loss : 6560.6875, Time/batch_file : 2.3081, Training time: 2455.9337\n",
      "Epoch : 211/2000 data_batch_5,  Train_loss : 6197.0850  Test_loss : 6656.0884, Time/batch_file : 2.2921, Training time: 2458.2259\n",
      "Epoch : 212/2000 data_batch_1,  Train_loss : 6480.2476  Test_loss : 6613.1729, Time/batch_file : 2.3266, Training time: 2460.5528\n",
      "Epoch : 212/2000 data_batch_2,  Train_loss : 6225.1548  Test_loss : 6776.1787, Time/batch_file : 2.3277, Training time: 2462.8808\n",
      "Epoch : 212/2000 data_batch_3,  Train_loss : 6477.2754  Test_loss : 6864.4194, Time/batch_file : 2.3262, Training time: 2465.2072\n",
      "Epoch : 212/2000 data_batch_4,  Train_loss : 6450.3608  Test_loss : 6375.5264, Time/batch_file : 2.3241, Training time: 2467.5314\n",
      "Epoch : 212/2000 data_batch_5,  Train_loss : 6319.3516  Test_loss : 6728.7705, Time/batch_file : 2.3228, Training time: 2469.8544\n",
      "Epoch : 213/2000 data_batch_1,  Train_loss : 6774.6089  Test_loss : 5979.5693, Time/batch_file : 2.3222, Training time: 2472.1768\n",
      "Epoch : 213/2000 data_batch_2,  Train_loss : 6903.3008  Test_loss : 6712.0698, Time/batch_file : 2.3300, Training time: 2474.5070\n",
      "Epoch : 213/2000 data_batch_3,  Train_loss : 6835.8906  Test_loss : 6312.0332, Time/batch_file : 2.3241, Training time: 2476.8312\n",
      "Epoch : 213/2000 data_batch_4,  Train_loss : 6498.5000  Test_loss : 6456.5928, Time/batch_file : 2.3295, Training time: 2479.1610\n",
      "Epoch : 213/2000 data_batch_5,  Train_loss : 6427.4092  Test_loss : 6666.3164, Time/batch_file : 2.3278, Training time: 2481.4890\n",
      "Epoch : 214/2000 data_batch_1,  Train_loss : 6502.3979  Test_loss : 6967.2559, Time/batch_file : 2.3214, Training time: 2483.8105\n",
      "Epoch : 214/2000 data_batch_2,  Train_loss : 6567.1406  Test_loss : 6519.1997, Time/batch_file : 2.3120, Training time: 2486.1227\n",
      "Epoch : 214/2000 data_batch_3,  Train_loss : 6292.4634  Test_loss : 6500.0571, Time/batch_file : 2.3161, Training time: 2488.4390\n",
      "Epoch : 214/2000 data_batch_4,  Train_loss : 6251.6816  Test_loss : 6605.3242, Time/batch_file : 2.3141, Training time: 2490.7533\n",
      "Epoch : 214/2000 data_batch_5,  Train_loss : 6091.2964  Test_loss : 6938.1787, Time/batch_file : 2.3188, Training time: 2493.0723\n",
      "Epoch : 215/2000 data_batch_1,  Train_loss : 6437.1943  Test_loss : 6251.1797, Time/batch_file : 2.3275, Training time: 2495.4000\n",
      "Epoch : 215/2000 data_batch_2,  Train_loss : 6593.5503  Test_loss : 6131.0908, Time/batch_file : 2.3206, Training time: 2497.7208\n",
      "Epoch : 215/2000 data_batch_3,  Train_loss : 6207.2861  Test_loss : 5975.4258, Time/batch_file : 2.3319, Training time: 2500.0529\n",
      "Epoch : 215/2000 data_batch_4,  Train_loss : 6681.0825  Test_loss : 6676.1924, Time/batch_file : 2.3173, Training time: 2502.3704\n",
      "Epoch : 215/2000 data_batch_5,  Train_loss : 6612.9526  Test_loss : 6675.4482, Time/batch_file : 2.3266, Training time: 2504.6972\n",
      "Epoch : 216/2000 data_batch_1,  Train_loss : 6684.9082  Test_loss : 6790.8604, Time/batch_file : 2.3190, Training time: 2507.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 216/2000 data_batch_2,  Train_loss : 6696.9463  Test_loss : 6894.7368, Time/batch_file : 2.3227, Training time: 2509.3394\n",
      "Epoch : 216/2000 data_batch_3,  Train_loss : 6666.8823  Test_loss : 6681.0469, Time/batch_file : 2.3225, Training time: 2511.6621\n",
      "Epoch : 216/2000 data_batch_4,  Train_loss : 6852.5137  Test_loss : 6605.0547, Time/batch_file : 2.3183, Training time: 2513.9806\n",
      "Epoch : 216/2000 data_batch_5,  Train_loss : 6799.9258  Test_loss : 6676.4287, Time/batch_file : 2.3163, Training time: 2516.2972\n",
      "Epoch : 217/2000 data_batch_1,  Train_loss : 6412.8721  Test_loss : 6298.1030, Time/batch_file : 2.3270, Training time: 2518.6244\n",
      "Epoch : 217/2000 data_batch_2,  Train_loss : 6515.0352  Test_loss : 6492.3701, Time/batch_file : 2.3209, Training time: 2520.9455\n",
      "Epoch : 217/2000 data_batch_3,  Train_loss : 6670.2759  Test_loss : 6358.1313, Time/batch_file : 2.3293, Training time: 2523.2750\n",
      "Epoch : 217/2000 data_batch_4,  Train_loss : 6473.0293  Test_loss : 6182.9077, Time/batch_file : 2.3266, Training time: 2525.6017\n",
      "Epoch : 217/2000 data_batch_5,  Train_loss : 6430.1865  Test_loss : 5886.8945, Time/batch_file : 2.3397, Training time: 2527.9417\n",
      "Epoch : 218/2000 data_batch_1,  Train_loss : 6235.1997  Test_loss : 6356.6982, Time/batch_file : 2.3253, Training time: 2530.2672\n",
      "Epoch : 218/2000 data_batch_2,  Train_loss : 6012.5381  Test_loss : 6340.7148, Time/batch_file : 2.3236, Training time: 2532.5909\n",
      "Epoch : 218/2000 data_batch_3,  Train_loss : 6328.5273  Test_loss : 6793.3237, Time/batch_file : 2.3110, Training time: 2534.9022\n",
      "Epoch : 218/2000 data_batch_4,  Train_loss : 6060.9785  Test_loss : 6122.3535, Time/batch_file : 2.3231, Training time: 2537.2255\n",
      "Epoch : 218/2000 data_batch_5,  Train_loss : 6307.5488  Test_loss : 6233.9600, Time/batch_file : 2.3176, Training time: 2539.5432\n",
      "Epoch : 219/2000 data_batch_1,  Train_loss : 5855.8979  Test_loss : 6218.0566, Time/batch_file : 2.3179, Training time: 2541.8613\n",
      "Epoch : 219/2000 data_batch_2,  Train_loss : 5714.0430  Test_loss : 6344.9668, Time/batch_file : 2.3157, Training time: 2544.1772\n",
      "Epoch : 219/2000 data_batch_3,  Train_loss : 5886.7153  Test_loss : 6182.8374, Time/batch_file : 2.3297, Training time: 2546.5072\n",
      "Epoch : 219/2000 data_batch_4,  Train_loss : 5804.7217  Test_loss : 5978.2925, Time/batch_file : 2.3241, Training time: 2548.8316\n",
      "Epoch : 219/2000 data_batch_5,  Train_loss : 6338.8726  Test_loss : 6565.9766, Time/batch_file : 2.3159, Training time: 2551.1476\n",
      "Epoch : 220/2000 data_batch_1,  Train_loss : 5722.4209  Test_loss : 6912.0859, Time/batch_file : 2.3070, Training time: 2553.4548\n",
      "Epoch : 220/2000 data_batch_2,  Train_loss : 6009.1455  Test_loss : 6423.0439, Time/batch_file : 2.3184, Training time: 2555.7734\n",
      "Epoch : 220/2000 data_batch_3,  Train_loss : 6029.3306  Test_loss : 6478.9858, Time/batch_file : 2.3121, Training time: 2558.0857\n",
      "Epoch : 220/2000 data_batch_4,  Train_loss : 6009.5684  Test_loss : 6991.4009, Time/batch_file : 2.3183, Training time: 2560.4042\n",
      "Epoch : 220/2000 data_batch_5,  Train_loss : 6405.6104  Test_loss : 6807.4668, Time/batch_file : 2.3048, Training time: 2562.7092\n",
      "[./nets/net-220.ckpt] SAVED\n",
      "Epoch : 221/2000 data_batch_1,  Train_loss : 5833.6997  Test_loss : 6594.5381, Time/batch_file : 2.2998, Training time: 2566.3053\n",
      "Epoch : 221/2000 data_batch_2,  Train_loss : 5793.7363  Test_loss : 6202.1875, Time/batch_file : 2.2850, Training time: 2568.5905\n",
      "Epoch : 221/2000 data_batch_3,  Train_loss : 6226.0112  Test_loss : 6593.6035, Time/batch_file : 2.2743, Training time: 2570.8650\n",
      "Epoch : 221/2000 data_batch_4,  Train_loss : 6350.4014  Test_loss : 6076.2368, Time/batch_file : 2.2930, Training time: 2573.1583\n",
      "Epoch : 221/2000 data_batch_5,  Train_loss : 5709.3867  Test_loss : 6324.6274, Time/batch_file : 2.3017, Training time: 2575.4602\n",
      "Epoch : 222/2000 data_batch_1,  Train_loss : 6582.8721  Test_loss : 5922.2383, Time/batch_file : 2.3153, Training time: 2577.7757\n",
      "Epoch : 222/2000 data_batch_2,  Train_loss : 6940.3286  Test_loss : 5963.2188, Time/batch_file : 2.3042, Training time: 2580.0801\n",
      "Epoch : 222/2000 data_batch_3,  Train_loss : 7159.7812  Test_loss : 5984.6777, Time/batch_file : 2.2898, Training time: 2582.3700\n",
      "Epoch : 222/2000 data_batch_4,  Train_loss : 6974.4580  Test_loss : 6086.2129, Time/batch_file : 2.3235, Training time: 2584.6937\n",
      "Epoch : 222/2000 data_batch_5,  Train_loss : 6510.5200  Test_loss : 6253.4268, Time/batch_file : 2.2956, Training time: 2586.9894\n",
      "Epoch : 223/2000 data_batch_1,  Train_loss : 6570.8179  Test_loss : 6707.7949, Time/batch_file : 2.2938, Training time: 2589.2835\n",
      "Epoch : 223/2000 data_batch_2,  Train_loss : 6585.0337  Test_loss : 6326.1104, Time/batch_file : 2.3136, Training time: 2591.5974\n",
      "Epoch : 223/2000 data_batch_3,  Train_loss : 6330.4395  Test_loss : 6545.6377, Time/batch_file : 2.3137, Training time: 2593.9113\n",
      "Epoch : 223/2000 data_batch_4,  Train_loss : 6337.9033  Test_loss : 6342.4790, Time/batch_file : 2.3172, Training time: 2596.2287\n",
      "Epoch : 223/2000 data_batch_5,  Train_loss : 6235.4629  Test_loss : 6340.1094, Time/batch_file : 2.3116, Training time: 2598.5406\n",
      "Epoch : 224/2000 data_batch_1,  Train_loss : 5465.8267  Test_loss : 6382.1411, Time/batch_file : 2.2859, Training time: 2600.8266\n",
      "Epoch : 224/2000 data_batch_2,  Train_loss : 5836.2441  Test_loss : 6209.1343, Time/batch_file : 2.3187, Training time: 2603.1454\n",
      "Epoch : 224/2000 data_batch_3,  Train_loss : 5762.0640  Test_loss : 6685.4023, Time/batch_file : 2.2860, Training time: 2605.4316\n",
      "Epoch : 224/2000 data_batch_4,  Train_loss : 5443.8579  Test_loss : 6517.5752, Time/batch_file : 2.2901, Training time: 2607.7219\n",
      "Epoch : 224/2000 data_batch_5,  Train_loss : 5684.1821  Test_loss : 6154.5400, Time/batch_file : 2.3134, Training time: 2610.0355\n",
      "Epoch : 225/2000 data_batch_1,  Train_loss : 5807.5562  Test_loss : 6754.9736, Time/batch_file : 2.2912, Training time: 2612.3269\n",
      "Epoch : 225/2000 data_batch_2,  Train_loss : 6410.7412  Test_loss : 6438.6172, Time/batch_file : 2.3055, Training time: 2614.6328\n",
      "Epoch : 225/2000 data_batch_3,  Train_loss : 6006.0908  Test_loss : 7030.5361, Time/batch_file : 2.2965, Training time: 2616.9296\n",
      "Epoch : 225/2000 data_batch_4,  Train_loss : 6013.3135  Test_loss : 6429.1377, Time/batch_file : 2.2951, Training time: 2619.2249\n",
      "Epoch : 225/2000 data_batch_5,  Train_loss : 6458.3896  Test_loss : 6729.3047, Time/batch_file : 2.3242, Training time: 2621.5492\n",
      "Epoch : 226/2000 data_batch_1,  Train_loss : 6178.5991  Test_loss : 5846.5542, Time/batch_file : 2.2852, Training time: 2623.8347\n",
      "Epoch : 226/2000 data_batch_2,  Train_loss : 6177.0679  Test_loss : 5736.0273, Time/batch_file : 2.2799, Training time: 2626.1149\n",
      "Epoch : 226/2000 data_batch_3,  Train_loss : 5495.5532  Test_loss : 5927.2876, Time/batch_file : 2.2991, Training time: 2628.4141\n",
      "Epoch : 226/2000 data_batch_4,  Train_loss : 5798.4043  Test_loss : 6013.9585, Time/batch_file : 2.2870, Training time: 2630.7013\n",
      "Epoch : 226/2000 data_batch_5,  Train_loss : 5982.7573  Test_loss : 5522.0571, Time/batch_file : 2.2999, Training time: 2633.0014\n",
      "Epoch : 227/2000 data_batch_1,  Train_loss : 6599.9609  Test_loss : 6456.4658, Time/batch_file : 2.3023, Training time: 2635.3040\n",
      "Epoch : 227/2000 data_batch_2,  Train_loss : 6514.0898  Test_loss : 6321.2266, Time/batch_file : 2.2909, Training time: 2637.5951\n",
      "Epoch : 227/2000 data_batch_3,  Train_loss : 6332.2539  Test_loss : 6747.7905, Time/batch_file : 2.3297, Training time: 2639.9250\n",
      "Epoch : 227/2000 data_batch_4,  Train_loss : 6240.7266  Test_loss : 6902.6377, Time/batch_file : 2.3022, Training time: 2642.2274\n",
      "Epoch : 227/2000 data_batch_5,  Train_loss : 6657.5669  Test_loss : 6518.1406, Time/batch_file : 2.2966, Training time: 2644.5242\n",
      "Epoch : 228/2000 data_batch_1,  Train_loss : 5610.3706  Test_loss : 6959.4067, Time/batch_file : 2.3030, Training time: 2646.8275\n",
      "Epoch : 228/2000 data_batch_2,  Train_loss : 5777.0859  Test_loss : 6770.7007, Time/batch_file : 2.2992, Training time: 2649.1268\n",
      "Epoch : 228/2000 data_batch_3,  Train_loss : 5977.0942  Test_loss : 6865.3682, Time/batch_file : 2.3168, Training time: 2651.4439\n",
      "Epoch : 228/2000 data_batch_4,  Train_loss : 5878.1343  Test_loss : 6970.2285, Time/batch_file : 2.2961, Training time: 2653.7403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 228/2000 data_batch_5,  Train_loss : 5813.2271  Test_loss : 7207.0977, Time/batch_file : 2.2928, Training time: 2656.0333\n",
      "Epoch : 229/2000 data_batch_1,  Train_loss : 6613.9902  Test_loss : 6585.1729, Time/batch_file : 2.3070, Training time: 2658.3406\n",
      "Epoch : 229/2000 data_batch_2,  Train_loss : 6668.8848  Test_loss : 6725.6821, Time/batch_file : 2.2797, Training time: 2660.6205\n",
      "Epoch : 229/2000 data_batch_3,  Train_loss : 6126.8916  Test_loss : 6691.7954, Time/batch_file : 2.2694, Training time: 2662.8902\n",
      "Epoch : 229/2000 data_batch_4,  Train_loss : 6365.2632  Test_loss : 6522.7246, Time/batch_file : 2.2985, Training time: 2665.1889\n",
      "Epoch : 229/2000 data_batch_5,  Train_loss : 7006.3940  Test_loss : 6501.6357, Time/batch_file : 2.2856, Training time: 2667.4747\n",
      "Epoch : 230/2000 data_batch_1,  Train_loss : 6312.9951  Test_loss : 6110.9697, Time/batch_file : 2.3147, Training time: 2669.7897\n",
      "Epoch : 230/2000 data_batch_2,  Train_loss : 5753.9238  Test_loss : 6591.1084, Time/batch_file : 2.3002, Training time: 2672.0900\n",
      "Epoch : 230/2000 data_batch_3,  Train_loss : 5753.0435  Test_loss : 6490.0771, Time/batch_file : 2.3050, Training time: 2674.3953\n",
      "Epoch : 230/2000 data_batch_4,  Train_loss : 5854.6641  Test_loss : 6565.7295, Time/batch_file : 2.3266, Training time: 2676.7221\n",
      "Epoch : 230/2000 data_batch_5,  Train_loss : 5938.5142  Test_loss : 6413.2202, Time/batch_file : 2.3012, Training time: 2679.0235\n",
      "[./nets/net-230.ckpt] SAVED\n",
      "Epoch : 231/2000 data_batch_1,  Train_loss : 6618.0742  Test_loss : 6667.1436, Time/batch_file : 2.2892, Training time: 2682.6052\n",
      "Epoch : 231/2000 data_batch_2,  Train_loss : 6539.5869  Test_loss : 6423.7041, Time/batch_file : 2.2931, Training time: 2684.8985\n",
      "Epoch : 231/2000 data_batch_3,  Train_loss : 6477.9668  Test_loss : 6709.2754, Time/batch_file : 2.2695, Training time: 2687.1682\n",
      "Epoch : 231/2000 data_batch_4,  Train_loss : 6203.2246  Test_loss : 6657.1631, Time/batch_file : 2.2765, Training time: 2689.4449\n",
      "Epoch : 231/2000 data_batch_5,  Train_loss : 6683.2417  Test_loss : 6657.2856, Time/batch_file : 2.2699, Training time: 2691.7150\n",
      "Epoch : 232/2000 data_batch_1,  Train_loss : 6435.0684  Test_loss : 6377.6660, Time/batch_file : 2.2944, Training time: 2694.0096\n",
      "Epoch : 232/2000 data_batch_2,  Train_loss : 6173.1982  Test_loss : 6493.4600, Time/batch_file : 2.3129, Training time: 2696.3228\n",
      "Epoch : 232/2000 data_batch_3,  Train_loss : 6404.9268  Test_loss : 6617.4141, Time/batch_file : 2.2904, Training time: 2698.6133\n",
      "Epoch : 232/2000 data_batch_4,  Train_loss : 6534.9214  Test_loss : 6712.1904, Time/batch_file : 2.2853, Training time: 2700.8987\n",
      "Epoch : 232/2000 data_batch_5,  Train_loss : 6545.9429  Test_loss : 6445.8047, Time/batch_file : 2.2976, Training time: 2703.1965\n",
      "Epoch : 233/2000 data_batch_1,  Train_loss : 6281.0762  Test_loss : 6621.9409, Time/batch_file : 2.3237, Training time: 2705.5205\n",
      "Epoch : 233/2000 data_batch_2,  Train_loss : 6086.5435  Test_loss : 6760.2803, Time/batch_file : 2.2992, Training time: 2707.8198\n",
      "Epoch : 233/2000 data_batch_3,  Train_loss : 6274.4648  Test_loss : 6370.7749, Time/batch_file : 2.2982, Training time: 2710.1182\n",
      "Epoch : 233/2000 data_batch_4,  Train_loss : 5993.4277  Test_loss : 6612.3369, Time/batch_file : 2.3003, Training time: 2712.4186\n",
      "Epoch : 233/2000 data_batch_5,  Train_loss : 6185.1353  Test_loss : 6906.7529, Time/batch_file : 2.3231, Training time: 2714.7418\n",
      "Epoch : 234/2000 data_batch_1,  Train_loss : 6261.3145  Test_loss : 6134.2354, Time/batch_file : 2.2944, Training time: 2717.0365\n",
      "Epoch : 234/2000 data_batch_2,  Train_loss : 6416.9917  Test_loss : 6246.8657, Time/batch_file : 2.2887, Training time: 2719.3254\n",
      "Epoch : 234/2000 data_batch_3,  Train_loss : 6124.1768  Test_loss : 6440.8213, Time/batch_file : 2.3335, Training time: 2721.6592\n",
      "Epoch : 234/2000 data_batch_4,  Train_loss : 6371.1333  Test_loss : 6945.0371, Time/batch_file : 2.2932, Training time: 2723.9526\n",
      "Epoch : 234/2000 data_batch_5,  Train_loss : 6159.7158  Test_loss : 6882.5786, Time/batch_file : 2.2903, Training time: 2726.2431\n",
      "Epoch : 235/2000 data_batch_1,  Train_loss : 6072.0361  Test_loss : 6782.1846, Time/batch_file : 2.2791, Training time: 2728.5224\n",
      "Epoch : 235/2000 data_batch_2,  Train_loss : 6048.4619  Test_loss : 6281.5205, Time/batch_file : 2.2839, Training time: 2730.8065\n",
      "Epoch : 235/2000 data_batch_3,  Train_loss : 6089.9663  Test_loss : 6390.8467, Time/batch_file : 2.2956, Training time: 2733.1024\n",
      "Epoch : 235/2000 data_batch_4,  Train_loss : 6445.5005  Test_loss : 6499.4458, Time/batch_file : 2.2750, Training time: 2735.3776\n",
      "Epoch : 235/2000 data_batch_5,  Train_loss : 5886.1851  Test_loss : 6471.3110, Time/batch_file : 2.2652, Training time: 2737.6429\n",
      "Epoch : 236/2000 data_batch_1,  Train_loss : 5950.7002  Test_loss : 6910.0947, Time/batch_file : 2.2917, Training time: 2739.9347\n",
      "Epoch : 236/2000 data_batch_2,  Train_loss : 6065.1753  Test_loss : 6730.3066, Time/batch_file : 2.2857, Training time: 2742.2206\n",
      "Epoch : 236/2000 data_batch_3,  Train_loss : 5724.2803  Test_loss : 6573.9756, Time/batch_file : 2.2911, Training time: 2744.5120\n",
      "Epoch : 236/2000 data_batch_4,  Train_loss : 5795.7646  Test_loss : 6724.7920, Time/batch_file : 2.2802, Training time: 2746.7924\n",
      "Epoch : 236/2000 data_batch_5,  Train_loss : 5673.5400  Test_loss : 6410.9258, Time/batch_file : 2.2905, Training time: 2749.0832\n",
      "Epoch : 237/2000 data_batch_1,  Train_loss : 5672.7881  Test_loss : 6243.4302, Time/batch_file : 2.2941, Training time: 2751.3775\n",
      "Epoch : 237/2000 data_batch_2,  Train_loss : 5687.9048  Test_loss : 5731.7446, Time/batch_file : 2.2952, Training time: 2753.6729\n",
      "Epoch : 237/2000 data_batch_3,  Train_loss : 5827.6328  Test_loss : 6433.1182, Time/batch_file : 2.3140, Training time: 2755.9871\n",
      "Epoch : 237/2000 data_batch_4,  Train_loss : 5800.2383  Test_loss : 6321.6436, Time/batch_file : 2.3062, Training time: 2758.2934\n",
      "Epoch : 237/2000 data_batch_5,  Train_loss : 5770.0498  Test_loss : 6204.0762, Time/batch_file : 2.2864, Training time: 2760.5800\n",
      "Epoch : 238/2000 data_batch_1,  Train_loss : 6138.6162  Test_loss : 6410.1123, Time/batch_file : 2.2861, Training time: 2762.8663\n",
      "Epoch : 238/2000 data_batch_2,  Train_loss : 5859.2451  Test_loss : 5926.7344, Time/batch_file : 2.3087, Training time: 2765.1752\n",
      "Epoch : 238/2000 data_batch_3,  Train_loss : 5849.5034  Test_loss : 6238.1133, Time/batch_file : 2.2811, Training time: 2767.4565\n",
      "Epoch : 238/2000 data_batch_4,  Train_loss : 5905.6143  Test_loss : 5843.2202, Time/batch_file : 2.2823, Training time: 2769.7389\n",
      "Epoch : 238/2000 data_batch_5,  Train_loss : 6350.5400  Test_loss : 6196.5972, Time/batch_file : 2.2817, Training time: 2772.0208\n",
      "Epoch : 239/2000 data_batch_1,  Train_loss : 6331.4702  Test_loss : 6244.2036, Time/batch_file : 2.3244, Training time: 2774.3455\n",
      "Epoch : 239/2000 data_batch_2,  Train_loss : 6170.9312  Test_loss : 6229.3896, Time/batch_file : 2.2859, Training time: 2776.6316\n",
      "Epoch : 239/2000 data_batch_3,  Train_loss : 6165.6904  Test_loss : 6187.9844, Time/batch_file : 2.2875, Training time: 2778.9192\n",
      "Epoch : 239/2000 data_batch_4,  Train_loss : 6312.0996  Test_loss : 6280.1260, Time/batch_file : 2.2954, Training time: 2781.2148\n",
      "Epoch : 239/2000 data_batch_5,  Train_loss : 6213.8496  Test_loss : 6655.4438, Time/batch_file : 2.3164, Training time: 2783.5314\n",
      "Epoch : 240/2000 data_batch_1,  Train_loss : 5687.1455  Test_loss : 6553.0479, Time/batch_file : 2.2893, Training time: 2785.8209\n",
      "Epoch : 240/2000 data_batch_2,  Train_loss : 5525.1738  Test_loss : 6593.0371, Time/batch_file : 2.2956, Training time: 2788.1167\n",
      "Epoch : 240/2000 data_batch_3,  Train_loss : 5776.2188  Test_loss : 6365.0020, Time/batch_file : 2.2946, Training time: 2790.4116\n",
      "Epoch : 240/2000 data_batch_4,  Train_loss : 5547.5303  Test_loss : 6398.5942, Time/batch_file : 2.3188, Training time: 2792.7306\n",
      "Epoch : 240/2000 data_batch_5,  Train_loss : 5764.8042  Test_loss : 6088.2227, Time/batch_file : 2.2980, Training time: 2795.0288\n",
      "[./nets/net-240.ckpt] SAVED\n",
      "Epoch : 241/2000 data_batch_1,  Train_loss : 5859.1323  Test_loss : 6475.5601, Time/batch_file : 2.3056, Training time: 2798.6303\n",
      "Epoch : 241/2000 data_batch_2,  Train_loss : 5595.1943  Test_loss : 5722.6895, Time/batch_file : 2.3025, Training time: 2800.9331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 241/2000 data_batch_3,  Train_loss : 5443.9863  Test_loss : 6461.1387, Time/batch_file : 2.2921, Training time: 2803.2254\n",
      "Epoch : 241/2000 data_batch_4,  Train_loss : 5687.1172  Test_loss : 6234.3257, Time/batch_file : 2.2850, Training time: 2805.5106\n",
      "Epoch : 241/2000 data_batch_5,  Train_loss : 5427.0215  Test_loss : 6219.9824, Time/batch_file : 2.2928, Training time: 2807.8037\n",
      "Epoch : 242/2000 data_batch_1,  Train_loss : 5940.8364  Test_loss : 6153.7397, Time/batch_file : 2.2839, Training time: 2810.0879\n",
      "Epoch : 242/2000 data_batch_2,  Train_loss : 5739.8398  Test_loss : 5965.3428, Time/batch_file : 2.2726, Training time: 2812.3607\n",
      "Epoch : 242/2000 data_batch_3,  Train_loss : 5723.0337  Test_loss : 6040.4316, Time/batch_file : 2.2882, Training time: 2814.6490\n",
      "Epoch : 242/2000 data_batch_4,  Train_loss : 6013.9907  Test_loss : 5739.2861, Time/batch_file : 2.3221, Training time: 2816.9713\n",
      "Epoch : 242/2000 data_batch_5,  Train_loss : 6055.6597  Test_loss : 5925.5825, Time/batch_file : 2.2819, Training time: 2819.2534\n",
      "Epoch : 243/2000 data_batch_1,  Train_loss : 5923.8960  Test_loss : 6159.3184, Time/batch_file : 2.3038, Training time: 2821.5575\n",
      "Epoch : 243/2000 data_batch_2,  Train_loss : 6044.8506  Test_loss : 5938.1167, Time/batch_file : 2.2918, Training time: 2823.8495\n",
      "Epoch : 243/2000 data_batch_3,  Train_loss : 6099.5996  Test_loss : 6384.6387, Time/batch_file : 2.2917, Training time: 2826.1413\n",
      "Epoch : 243/2000 data_batch_4,  Train_loss : 6328.3457  Test_loss : 5966.8730, Time/batch_file : 2.2905, Training time: 2828.4320\n",
      "Epoch : 243/2000 data_batch_5,  Train_loss : 5967.7773  Test_loss : 6195.0718, Time/batch_file : 2.3026, Training time: 2830.7348\n",
      "Epoch : 244/2000 data_batch_1,  Train_loss : 6723.3193  Test_loss : 5933.8843, Time/batch_file : 2.3130, Training time: 2833.0481\n",
      "Epoch : 244/2000 data_batch_2,  Train_loss : 6559.2324  Test_loss : 6077.2764, Time/batch_file : 2.2866, Training time: 2835.3349\n",
      "Epoch : 244/2000 data_batch_3,  Train_loss : 6496.8525  Test_loss : 5573.7544, Time/batch_file : 2.3172, Training time: 2837.6522\n",
      "Epoch : 244/2000 data_batch_4,  Train_loss : 6558.0176  Test_loss : 5712.5542, Time/batch_file : 2.2919, Training time: 2839.9443\n",
      "Epoch : 244/2000 data_batch_5,  Train_loss : 6812.1079  Test_loss : 6009.0786, Time/batch_file : 2.2888, Training time: 2842.2335\n",
      "Epoch : 245/2000 data_batch_1,  Train_loss : 5944.9731  Test_loss : 6269.0840, Time/batch_file : 2.2912, Training time: 2844.5249\n",
      "Epoch : 245/2000 data_batch_2,  Train_loss : 6024.9062  Test_loss : 6228.4141, Time/batch_file : 2.2768, Training time: 2846.8018\n",
      "Epoch : 245/2000 data_batch_3,  Train_loss : 6056.6792  Test_loss : 6666.6143, Time/batch_file : 2.2808, Training time: 2849.0829\n",
      "Epoch : 245/2000 data_batch_4,  Train_loss : 5891.5132  Test_loss : 6427.1084, Time/batch_file : 2.3071, Training time: 2851.3902\n",
      "Epoch : 245/2000 data_batch_5,  Train_loss : 5735.8037  Test_loss : 6340.2617, Time/batch_file : 2.2687, Training time: 2853.6591\n",
      "Epoch : 246/2000 data_batch_1,  Train_loss : 6219.3896  Test_loss : 5794.9595, Time/batch_file : 2.2980, Training time: 2855.9573\n",
      "Epoch : 246/2000 data_batch_2,  Train_loss : 6697.0703  Test_loss : 5459.4102, Time/batch_file : 2.2836, Training time: 2858.2412\n",
      "Epoch : 246/2000 data_batch_3,  Train_loss : 6763.6602  Test_loss : 5937.9805, Time/batch_file : 2.2739, Training time: 2860.5153\n",
      "Epoch : 246/2000 data_batch_4,  Train_loss : 6362.1094  Test_loss : 5925.9336, Time/batch_file : 2.2894, Training time: 2862.8049\n",
      "Epoch : 246/2000 data_batch_5,  Train_loss : 6701.0186  Test_loss : 5576.4653, Time/batch_file : 2.2797, Training time: 2865.0849\n",
      "Epoch : 247/2000 data_batch_1,  Train_loss : 6582.9785  Test_loss : 6399.1719, Time/batch_file : 2.2853, Training time: 2867.3704\n",
      "Epoch : 247/2000 data_batch_2,  Train_loss : 6586.6133  Test_loss : 6443.4844, Time/batch_file : 2.2795, Training time: 2869.6502\n",
      "Epoch : 247/2000 data_batch_3,  Train_loss : 6544.5786  Test_loss : 6119.6284, Time/batch_file : 2.3066, Training time: 2871.9570\n",
      "Epoch : 247/2000 data_batch_4,  Train_loss : 6188.5776  Test_loss : 6110.0850, Time/batch_file : 2.3027, Training time: 2874.2600\n",
      "Epoch : 247/2000 data_batch_5,  Train_loss : 6390.3369  Test_loss : 6345.1992, Time/batch_file : 2.2807, Training time: 2876.5408\n",
      "Epoch : 248/2000 data_batch_1,  Train_loss : 5749.6372  Test_loss : 5990.4985, Time/batch_file : 2.2784, Training time: 2878.8194\n",
      "Epoch : 248/2000 data_batch_2,  Train_loss : 5767.8423  Test_loss : 6286.5557, Time/batch_file : 2.2712, Training time: 2881.0909\n",
      "Epoch : 248/2000 data_batch_3,  Train_loss : 5834.9497  Test_loss : 6217.1597, Time/batch_file : 2.2670, Training time: 2883.3581\n",
      "Epoch : 248/2000 data_batch_4,  Train_loss : 5594.6953  Test_loss : 6491.0986, Time/batch_file : 2.2813, Training time: 2885.6396\n",
      "Epoch : 248/2000 data_batch_5,  Train_loss : 5320.4585  Test_loss : 6185.9248, Time/batch_file : 2.2935, Training time: 2887.9334\n",
      "Epoch : 249/2000 data_batch_1,  Train_loss : 6454.2627  Test_loss : 7065.8857, Time/batch_file : 2.3054, Training time: 2890.2390\n",
      "Epoch : 249/2000 data_batch_2,  Train_loss : 6485.0107  Test_loss : 7428.7104, Time/batch_file : 2.2742, Training time: 2892.5134\n",
      "Epoch : 249/2000 data_batch_3,  Train_loss : 6268.2139  Test_loss : 7150.9399, Time/batch_file : 2.3031, Training time: 2894.8167\n",
      "Epoch : 249/2000 data_batch_4,  Train_loss : 6191.7061  Test_loss : 7231.0576, Time/batch_file : 2.2784, Training time: 2897.0953\n",
      "Epoch : 249/2000 data_batch_5,  Train_loss : 6564.9619  Test_loss : 7574.4404, Time/batch_file : 2.2953, Training time: 2899.3909\n",
      "Epoch : 250/2000 data_batch_1,  Train_loss : 6291.8057  Test_loss : 6212.0078, Time/batch_file : 2.2947, Training time: 2901.6858\n",
      "Epoch : 250/2000 data_batch_2,  Train_loss : 6374.9741  Test_loss : 5853.3721, Time/batch_file : 2.2786, Training time: 2903.9645\n",
      "Epoch : 250/2000 data_batch_3,  Train_loss : 6188.8652  Test_loss : 6260.7920, Time/batch_file : 2.2791, Training time: 2906.2437\n",
      "Epoch : 250/2000 data_batch_4,  Train_loss : 6350.5342  Test_loss : 6080.7275, Time/batch_file : 2.3123, Training time: 2908.5563\n",
      "Epoch : 250/2000 data_batch_5,  Train_loss : 6764.6616  Test_loss : 6468.2207, Time/batch_file : 2.2760, Training time: 2910.8325\n",
      "[./nets/net-250.ckpt] SAVED\n",
      "Epoch : 251/2000 data_batch_1,  Train_loss : 5908.4697  Test_loss : 5565.9180, Time/batch_file : 2.3201, Training time: 2914.4448\n",
      "Epoch : 251/2000 data_batch_2,  Train_loss : 6050.3667  Test_loss : 6018.7954, Time/batch_file : 2.2871, Training time: 2916.7322\n",
      "Epoch : 251/2000 data_batch_3,  Train_loss : 6140.7783  Test_loss : 6258.4751, Time/batch_file : 2.2825, Training time: 2919.0149\n",
      "Epoch : 251/2000 data_batch_4,  Train_loss : 5765.2617  Test_loss : 5830.7031, Time/batch_file : 2.3105, Training time: 2921.3256\n",
      "Epoch : 251/2000 data_batch_5,  Train_loss : 5909.7363  Test_loss : 6021.7817, Time/batch_file : 2.2822, Training time: 2923.6080\n",
      "Epoch : 252/2000 data_batch_1,  Train_loss : 6198.9385  Test_loss : 6241.2437, Time/batch_file : 2.3261, Training time: 2925.9343\n",
      "Epoch : 252/2000 data_batch_2,  Train_loss : 6298.1978  Test_loss : 6854.3896, Time/batch_file : 2.3049, Training time: 2928.2395\n",
      "Epoch : 252/2000 data_batch_3,  Train_loss : 6100.0732  Test_loss : 6076.5347, Time/batch_file : 2.3064, Training time: 2930.5461\n",
      "Epoch : 252/2000 data_batch_4,  Train_loss : 6107.1973  Test_loss : 6651.8428, Time/batch_file : 2.2909, Training time: 2932.8372\n",
      "Epoch : 252/2000 data_batch_5,  Train_loss : 6192.5215  Test_loss : 6597.0205, Time/batch_file : 2.3157, Training time: 2935.1531\n",
      "Epoch : 253/2000 data_batch_1,  Train_loss : 6449.3052  Test_loss : 7232.9316, Time/batch_file : 2.3069, Training time: 2937.4602\n",
      "Epoch : 253/2000 data_batch_2,  Train_loss : 6053.3682  Test_loss : 7023.7139, Time/batch_file : 2.3077, Training time: 2939.7681\n",
      "Epoch : 253/2000 data_batch_3,  Train_loss : 6232.1562  Test_loss : 6636.8315, Time/batch_file : 2.3253, Training time: 2942.0935\n",
      "Epoch : 253/2000 data_batch_4,  Train_loss : 6205.7739  Test_loss : 7047.5967, Time/batch_file : 2.3153, Training time: 2944.4091\n",
      "Epoch : 253/2000 data_batch_5,  Train_loss : 6217.6230  Test_loss : 7078.3916, Time/batch_file : 2.3230, Training time: 2946.7323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 254/2000 data_batch_1,  Train_loss : 6356.8906  Test_loss : 6272.9189, Time/batch_file : 2.3003, Training time: 2949.0328\n",
      "Epoch : 254/2000 data_batch_2,  Train_loss : 6647.4824  Test_loss : 6136.4561, Time/batch_file : 2.3136, Training time: 2951.3465\n",
      "Epoch : 254/2000 data_batch_3,  Train_loss : 6974.9619  Test_loss : 6415.9053, Time/batch_file : 2.2897, Training time: 2953.6364\n",
      "Epoch : 254/2000 data_batch_4,  Train_loss : 6529.3008  Test_loss : 6334.6362, Time/batch_file : 2.2999, Training time: 2955.9365\n",
      "Epoch : 254/2000 data_batch_5,  Train_loss : 6327.7070  Test_loss : 6020.6851, Time/batch_file : 2.2794, Training time: 2958.2160\n",
      "Epoch : 255/2000 data_batch_1,  Train_loss : 6303.4731  Test_loss : 6418.0649, Time/batch_file : 2.2765, Training time: 2960.4927\n",
      "Epoch : 255/2000 data_batch_2,  Train_loss : 6353.3979  Test_loss : 6479.6587, Time/batch_file : 2.2894, Training time: 2962.7822\n",
      "Epoch : 255/2000 data_batch_3,  Train_loss : 6298.7334  Test_loss : 6385.7197, Time/batch_file : 2.2788, Training time: 2965.0613\n",
      "Epoch : 255/2000 data_batch_4,  Train_loss : 6279.0459  Test_loss : 6275.9414, Time/batch_file : 2.2924, Training time: 2967.3539\n",
      "Epoch : 255/2000 data_batch_5,  Train_loss : 6122.6050  Test_loss : 6454.9224, Time/batch_file : 2.2931, Training time: 2969.6471\n",
      "Epoch : 256/2000 data_batch_1,  Train_loss : 5674.0332  Test_loss : 6491.2002, Time/batch_file : 2.2821, Training time: 2971.9295\n",
      "Epoch : 256/2000 data_batch_2,  Train_loss : 6198.4917  Test_loss : 6580.1787, Time/batch_file : 2.3035, Training time: 2974.2332\n",
      "Epoch : 256/2000 data_batch_3,  Train_loss : 6137.4272  Test_loss : 6744.0811, Time/batch_file : 2.2848, Training time: 2976.5182\n",
      "Epoch : 256/2000 data_batch_4,  Train_loss : 5910.4639  Test_loss : 6526.6309, Time/batch_file : 2.3150, Training time: 2978.8334\n",
      "Epoch : 256/2000 data_batch_5,  Train_loss : 5781.3091  Test_loss : 6807.4189, Time/batch_file : 2.2921, Training time: 2981.1257\n",
      "Epoch : 257/2000 data_batch_1,  Train_loss : 6314.2964  Test_loss : 5677.2910, Time/batch_file : 2.3024, Training time: 2983.4283\n",
      "Epoch : 257/2000 data_batch_2,  Train_loss : 6121.4316  Test_loss : 6204.3115, Time/batch_file : 2.3166, Training time: 2985.7450\n",
      "Epoch : 257/2000 data_batch_3,  Train_loss : 6384.1143  Test_loss : 6120.2939, Time/batch_file : 2.3175, Training time: 2988.0628\n",
      "Epoch : 257/2000 data_batch_4,  Train_loss : 6382.3301  Test_loss : 5875.2725, Time/batch_file : 2.2862, Training time: 2990.3491\n",
      "Epoch : 257/2000 data_batch_5,  Train_loss : 5764.9580  Test_loss : 6130.5469, Time/batch_file : 2.2952, Training time: 2992.6445\n",
      "Epoch : 258/2000 data_batch_1,  Train_loss : 5780.6572  Test_loss : 6204.5410, Time/batch_file : 2.2994, Training time: 2994.9441\n",
      "Epoch : 258/2000 data_batch_2,  Train_loss : 5932.7012  Test_loss : 6049.6367, Time/batch_file : 2.2985, Training time: 2997.2428\n",
      "Epoch : 258/2000 data_batch_3,  Train_loss : 5947.3286  Test_loss : 6067.5156, Time/batch_file : 2.2767, Training time: 2999.5197\n",
      "Epoch : 258/2000 data_batch_4,  Train_loss : 6166.1133  Test_loss : 6154.9609, Time/batch_file : 2.2822, Training time: 3001.8021\n",
      "Epoch : 258/2000 data_batch_5,  Train_loss : 6063.8447  Test_loss : 6142.7710, Time/batch_file : 2.3091, Training time: 3004.1113\n",
      "Epoch : 259/2000 data_batch_1,  Train_loss : 5902.8110  Test_loss : 6724.2734, Time/batch_file : 2.2972, Training time: 3006.4088\n",
      "Epoch : 259/2000 data_batch_2,  Train_loss : 6004.6689  Test_loss : 6033.2729, Time/batch_file : 2.2908, Training time: 3008.6998\n",
      "Epoch : 259/2000 data_batch_3,  Train_loss : 6044.2881  Test_loss : 6341.7056, Time/batch_file : 2.3317, Training time: 3011.0316\n",
      "Epoch : 259/2000 data_batch_4,  Train_loss : 5858.8726  Test_loss : 6306.8945, Time/batch_file : 2.3080, Training time: 3013.3398\n",
      "Epoch : 259/2000 data_batch_5,  Train_loss : 6080.1509  Test_loss : 6098.4932, Time/batch_file : 2.2943, Training time: 3015.6342\n",
      "Epoch : 260/2000 data_batch_1,  Train_loss : 6243.9497  Test_loss : 6724.2969, Time/batch_file : 2.2863, Training time: 3017.9207\n",
      "Epoch : 260/2000 data_batch_2,  Train_loss : 6172.0645  Test_loss : 6708.1650, Time/batch_file : 2.3176, Training time: 3020.2386\n",
      "Epoch : 260/2000 data_batch_3,  Train_loss : 6391.2559  Test_loss : 6526.7056, Time/batch_file : 2.2986, Training time: 3022.5373\n",
      "Epoch : 260/2000 data_batch_4,  Train_loss : 6049.6675  Test_loss : 6299.9209, Time/batch_file : 2.2919, Training time: 3024.8295\n",
      "Epoch : 260/2000 data_batch_5,  Train_loss : 5998.9248  Test_loss : 6593.2041, Time/batch_file : 2.3101, Training time: 3027.1397\n",
      "[./nets/net-260.ckpt] SAVED\n",
      "Epoch : 261/2000 data_batch_1,  Train_loss : 5528.7495  Test_loss : 5673.8516, Time/batch_file : 2.3110, Training time: 3031.5205\n",
      "Epoch : 261/2000 data_batch_2,  Train_loss : 5641.9780  Test_loss : 5628.7139, Time/batch_file : 2.2921, Training time: 3033.8128\n",
      "Epoch : 261/2000 data_batch_3,  Train_loss : 5463.6025  Test_loss : 5649.8550, Time/batch_file : 2.3056, Training time: 3036.1185\n",
      "Epoch : 261/2000 data_batch_4,  Train_loss : 5663.7451  Test_loss : 6106.4580, Time/batch_file : 2.2964, Training time: 3038.4151\n",
      "Epoch : 261/2000 data_batch_5,  Train_loss : 5611.1953  Test_loss : 5678.5771, Time/batch_file : 2.3093, Training time: 3040.7246\n",
      "Epoch : 262/2000 data_batch_1,  Train_loss : 5754.7207  Test_loss : 7196.5645, Time/batch_file : 2.3022, Training time: 3043.0271\n",
      "Epoch : 262/2000 data_batch_2,  Train_loss : 5796.5137  Test_loss : 7252.6797, Time/batch_file : 2.3075, Training time: 3045.3350\n",
      "Epoch : 262/2000 data_batch_3,  Train_loss : 6083.5244  Test_loss : 7121.3057, Time/batch_file : 2.3272, Training time: 3047.6624\n",
      "Epoch : 262/2000 data_batch_4,  Train_loss : 6023.2964  Test_loss : 7010.0898, Time/batch_file : 2.2938, Training time: 3049.9563\n",
      "Epoch : 262/2000 data_batch_5,  Train_loss : 5994.1016  Test_loss : 7184.2500, Time/batch_file : 2.3219, Training time: 3052.2784\n",
      "Epoch : 263/2000 data_batch_1,  Train_loss : 6018.9570  Test_loss : 6176.5835, Time/batch_file : 2.3035, Training time: 3054.5821\n",
      "Epoch : 263/2000 data_batch_2,  Train_loss : 6378.3843  Test_loss : 5764.0498, Time/batch_file : 2.3211, Training time: 3056.9035\n",
      "Epoch : 263/2000 data_batch_3,  Train_loss : 5919.2827  Test_loss : 6291.8950, Time/batch_file : 2.2918, Training time: 3059.1955\n",
      "Epoch : 263/2000 data_batch_4,  Train_loss : 6066.3955  Test_loss : 5953.4077, Time/batch_file : 2.2947, Training time: 3061.4904\n",
      "Epoch : 263/2000 data_batch_5,  Train_loss : 6442.8130  Test_loss : 5825.9033, Time/batch_file : 2.3067, Training time: 3063.7974\n",
      "Epoch : 264/2000 data_batch_1,  Train_loss : 5735.5703  Test_loss : 6036.0151, Time/batch_file : 2.2899, Training time: 3066.0875\n",
      "Epoch : 264/2000 data_batch_2,  Train_loss : 5585.5503  Test_loss : 6314.9316, Time/batch_file : 2.3084, Training time: 3068.3962\n",
      "Epoch : 264/2000 data_batch_3,  Train_loss : 5808.4849  Test_loss : 6580.4932, Time/batch_file : 2.3038, Training time: 3070.7002\n",
      "Epoch : 264/2000 data_batch_4,  Train_loss : 5887.6406  Test_loss : 6636.8530, Time/batch_file : 2.3119, Training time: 3073.0123\n",
      "Epoch : 264/2000 data_batch_5,  Train_loss : 5865.8765  Test_loss : 6530.9668, Time/batch_file : 2.2990, Training time: 3075.3115\n",
      "Epoch : 265/2000 data_batch_1,  Train_loss : 6200.1128  Test_loss : 5740.9360, Time/batch_file : 2.2997, Training time: 3077.6114\n",
      "Epoch : 265/2000 data_batch_2,  Train_loss : 6151.1343  Test_loss : 5986.1738, Time/batch_file : 2.3105, Training time: 3079.9221\n",
      "Epoch : 265/2000 data_batch_3,  Train_loss : 6231.0527  Test_loss : 5983.9346, Time/batch_file : 2.2987, Training time: 3082.2210\n",
      "Epoch : 265/2000 data_batch_4,  Train_loss : 6198.3765  Test_loss : 5739.0532, Time/batch_file : 2.3433, Training time: 3084.5645\n",
      "Epoch : 265/2000 data_batch_5,  Train_loss : 6237.4209  Test_loss : 6091.6948, Time/batch_file : 2.2996, Training time: 3086.8644\n",
      "Epoch : 266/2000 data_batch_1,  Train_loss : 6186.6494  Test_loss : 6220.3359, Time/batch_file : 2.2947, Training time: 3089.1593\n",
      "Epoch : 266/2000 data_batch_2,  Train_loss : 6130.1992  Test_loss : 6314.3213, Time/batch_file : 2.2913, Training time: 3091.4509\n",
      "Epoch : 266/2000 data_batch_3,  Train_loss : 6289.7378  Test_loss : 6516.8491, Time/batch_file : 2.2841, Training time: 3093.7352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 266/2000 data_batch_4,  Train_loss : 6261.1992  Test_loss : 6027.3755, Time/batch_file : 2.2828, Training time: 3096.0181\n",
      "Epoch : 266/2000 data_batch_5,  Train_loss : 6135.7979  Test_loss : 6110.3501, Time/batch_file : 2.3111, Training time: 3098.3293\n",
      "Epoch : 267/2000 data_batch_1,  Train_loss : 6309.8906  Test_loss : 6062.8574, Time/batch_file : 2.3041, Training time: 3100.6336\n",
      "Epoch : 267/2000 data_batch_2,  Train_loss : 6421.5518  Test_loss : 6027.9482, Time/batch_file : 2.2897, Training time: 3102.9234\n",
      "Epoch : 267/2000 data_batch_3,  Train_loss : 6341.3345  Test_loss : 5922.7549, Time/batch_file : 2.2950, Training time: 3105.2186\n",
      "Epoch : 267/2000 data_batch_4,  Train_loss : 6134.1167  Test_loss : 5867.6660, Time/batch_file : 2.2796, Training time: 3107.4983\n",
      "Epoch : 267/2000 data_batch_5,  Train_loss : 6303.3623  Test_loss : 5820.9106, Time/batch_file : 2.2808, Training time: 3109.7794\n",
      "Epoch : 268/2000 data_batch_1,  Train_loss : 6657.6587  Test_loss : 6013.9854, Time/batch_file : 2.3214, Training time: 3112.1011\n",
      "Epoch : 268/2000 data_batch_2,  Train_loss : 6063.0557  Test_loss : 6053.9302, Time/batch_file : 2.3256, Training time: 3114.4269\n",
      "Epoch : 268/2000 data_batch_3,  Train_loss : 6171.0068  Test_loss : 5998.7158, Time/batch_file : 2.3158, Training time: 3116.7428\n",
      "Epoch : 268/2000 data_batch_4,  Train_loss : 5958.0493  Test_loss : 5951.1870, Time/batch_file : 2.2887, Training time: 3119.0317\n",
      "Epoch : 268/2000 data_batch_5,  Train_loss : 6287.3677  Test_loss : 5841.9438, Time/batch_file : 2.3244, Training time: 3121.3563\n",
      "Epoch : 269/2000 data_batch_1,  Train_loss : 5760.1035  Test_loss : 6195.8569, Time/batch_file : 2.2886, Training time: 3123.6451\n",
      "Epoch : 269/2000 data_batch_2,  Train_loss : 5996.4883  Test_loss : 5988.0884, Time/batch_file : 2.3325, Training time: 3125.9778\n",
      "Epoch : 269/2000 data_batch_3,  Train_loss : 5998.5483  Test_loss : 6161.3154, Time/batch_file : 2.2947, Training time: 3128.2727\n",
      "Epoch : 269/2000 data_batch_4,  Train_loss : 6191.3931  Test_loss : 6372.2554, Time/batch_file : 2.3474, Training time: 3130.6203\n",
      "Epoch : 269/2000 data_batch_5,  Train_loss : 6378.6484  Test_loss : 5803.4951, Time/batch_file : 2.3027, Training time: 3132.9232\n",
      "Epoch : 270/2000 data_batch_1,  Train_loss : 5732.9414  Test_loss : 5675.2925, Time/batch_file : 2.3100, Training time: 3135.2334\n",
      "Epoch : 270/2000 data_batch_2,  Train_loss : 5755.3516  Test_loss : 6074.9102, Time/batch_file : 2.2916, Training time: 3137.5253\n",
      "Epoch : 270/2000 data_batch_3,  Train_loss : 5571.0610  Test_loss : 6028.8384, Time/batch_file : 2.2984, Training time: 3139.8238\n",
      "Epoch : 270/2000 data_batch_4,  Train_loss : 5591.6543  Test_loss : 5673.8091, Time/batch_file : 2.2946, Training time: 3142.1186\n",
      "Epoch : 270/2000 data_batch_5,  Train_loss : 5468.0605  Test_loss : 5850.9531, Time/batch_file : 2.2932, Training time: 3144.4121\n",
      "[./nets/net-270.ckpt] SAVED\n",
      "Epoch : 271/2000 data_batch_1,  Train_loss : 6147.6099  Test_loss : 5932.4854, Time/batch_file : 2.2980, Training time: 3147.9974\n",
      "Epoch : 271/2000 data_batch_2,  Train_loss : 6684.0088  Test_loss : 6123.0669, Time/batch_file : 2.2840, Training time: 3150.2817\n",
      "Epoch : 271/2000 data_batch_3,  Train_loss : 6365.3643  Test_loss : 6231.0713, Time/batch_file : 2.2854, Training time: 3152.5673\n",
      "Epoch : 271/2000 data_batch_4,  Train_loss : 6098.9253  Test_loss : 6365.2480, Time/batch_file : 2.2939, Training time: 3154.8614\n",
      "Epoch : 271/2000 data_batch_5,  Train_loss : 6169.5039  Test_loss : 6060.3286, Time/batch_file : 2.2834, Training time: 3157.1449\n",
      "Epoch : 272/2000 data_batch_1,  Train_loss : 6326.6201  Test_loss : 6224.8354, Time/batch_file : 2.3000, Training time: 3159.4452\n",
      "Epoch : 272/2000 data_batch_2,  Train_loss : 6167.9106  Test_loss : 6068.0200, Time/batch_file : 2.2695, Training time: 3161.7149\n",
      "Epoch : 272/2000 data_batch_3,  Train_loss : 6161.7402  Test_loss : 6020.7158, Time/batch_file : 2.3039, Training time: 3164.0190\n",
      "Epoch : 272/2000 data_batch_4,  Train_loss : 6182.9863  Test_loss : 6040.4023, Time/batch_file : 2.2967, Training time: 3166.3159\n",
      "Epoch : 272/2000 data_batch_5,  Train_loss : 6068.4297  Test_loss : 6345.9639, Time/batch_file : 2.2876, Training time: 3168.6036\n",
      "Epoch : 273/2000 data_batch_1,  Train_loss : 5602.9658  Test_loss : 6309.0264, Time/batch_file : 2.2648, Training time: 3170.8686\n",
      "Epoch : 273/2000 data_batch_2,  Train_loss : 5321.6963  Test_loss : 6327.4463, Time/batch_file : 2.2725, Training time: 3173.1413\n",
      "Epoch : 273/2000 data_batch_3,  Train_loss : 5739.5283  Test_loss : 6211.8755, Time/batch_file : 2.2760, Training time: 3175.4175\n",
      "Epoch : 273/2000 data_batch_4,  Train_loss : 5377.7031  Test_loss : 6222.3008, Time/batch_file : 2.2824, Training time: 3177.7001\n",
      "Epoch : 273/2000 data_batch_5,  Train_loss : 5432.9106  Test_loss : 5924.3369, Time/batch_file : 2.2696, Training time: 3179.9698\n",
      "Epoch : 274/2000 data_batch_1,  Train_loss : 6179.5850  Test_loss : 6416.5176, Time/batch_file : 2.3039, Training time: 3182.2739\n",
      "Epoch : 274/2000 data_batch_2,  Train_loss : 6222.7266  Test_loss : 6240.9854, Time/batch_file : 2.2880, Training time: 3184.5621\n",
      "Epoch : 274/2000 data_batch_3,  Train_loss : 6238.6963  Test_loss : 6106.4111, Time/batch_file : 2.2852, Training time: 3186.8476\n",
      "Epoch : 274/2000 data_batch_4,  Train_loss : 5911.3369  Test_loss : 6293.8022, Time/batch_file : 2.2793, Training time: 3189.1270\n",
      "Epoch : 274/2000 data_batch_5,  Train_loss : 6007.8140  Test_loss : 6132.9082, Time/batch_file : 2.2923, Training time: 3191.4195\n",
      "Epoch : 275/2000 data_batch_1,  Train_loss : 5800.8398  Test_loss : 6252.3506, Time/batch_file : 2.2773, Training time: 3193.6970\n",
      "Epoch : 275/2000 data_batch_2,  Train_loss : 6405.8872  Test_loss : 6680.3887, Time/batch_file : 2.2836, Training time: 3195.9808\n",
      "Epoch : 275/2000 data_batch_3,  Train_loss : 6294.4536  Test_loss : 6742.6040, Time/batch_file : 2.2886, Training time: 3198.2696\n",
      "Epoch : 275/2000 data_batch_4,  Train_loss : 6016.9141  Test_loss : 6386.6494, Time/batch_file : 2.3059, Training time: 3200.5757\n",
      "Epoch : 275/2000 data_batch_5,  Train_loss : 6020.9648  Test_loss : 6811.0244, Time/batch_file : 2.2771, Training time: 3202.8530\n",
      "Epoch : 276/2000 data_batch_1,  Train_loss : 5907.1538  Test_loss : 6252.5630, Time/batch_file : 2.2894, Training time: 3205.1426\n",
      "Epoch : 276/2000 data_batch_2,  Train_loss : 5340.9102  Test_loss : 6135.2642, Time/batch_file : 2.2842, Training time: 3207.4271\n",
      "Epoch : 276/2000 data_batch_3,  Train_loss : 6018.1797  Test_loss : 6591.2920, Time/batch_file : 2.3025, Training time: 3209.7299\n",
      "Epoch : 276/2000 data_batch_4,  Train_loss : 5338.7261  Test_loss : 6747.0083, Time/batch_file : 2.2920, Training time: 3212.0220\n",
      "Epoch : 276/2000 data_batch_5,  Train_loss : 5787.9438  Test_loss : 6654.7598, Time/batch_file : 2.3070, Training time: 3214.3292\n",
      "Epoch : 277/2000 data_batch_1,  Train_loss : 6554.8882  Test_loss : 6488.2480, Time/batch_file : 2.2833, Training time: 3216.6127\n",
      "Epoch : 277/2000 data_batch_2,  Train_loss : 6229.1890  Test_loss : 6531.6167, Time/batch_file : 2.3048, Training time: 3218.9177\n",
      "Epoch : 277/2000 data_batch_3,  Train_loss : 6173.2295  Test_loss : 6755.8271, Time/batch_file : 2.2740, Training time: 3221.1920\n",
      "Epoch : 277/2000 data_batch_4,  Train_loss : 6595.7939  Test_loss : 6242.7544, Time/batch_file : 2.2795, Training time: 3223.4718\n",
      "Epoch : 277/2000 data_batch_5,  Train_loss : 6378.2920  Test_loss : 6444.6553, Time/batch_file : 2.2805, Training time: 3225.7524\n",
      "Epoch : 278/2000 data_batch_1,  Train_loss : 6210.9707  Test_loss : 6235.0933, Time/batch_file : 2.3122, Training time: 3228.0648\n",
      "Epoch : 278/2000 data_batch_2,  Train_loss : 6346.8081  Test_loss : 6338.0361, Time/batch_file : 2.3037, Training time: 3230.3687\n",
      "Epoch : 278/2000 data_batch_3,  Train_loss : 6157.9683  Test_loss : 6094.0166, Time/batch_file : 2.3086, Training time: 3232.6776\n",
      "Epoch : 278/2000 data_batch_4,  Train_loss : 5997.7026  Test_loss : 6236.0137, Time/batch_file : 2.2998, Training time: 3234.9775\n",
      "Epoch : 278/2000 data_batch_5,  Train_loss : 6221.3486  Test_loss : 6102.0508, Time/batch_file : 2.3145, Training time: 3237.2922\n",
      "Epoch : 279/2000 data_batch_1,  Train_loss : 5974.6064  Test_loss : 6151.3242, Time/batch_file : 2.2877, Training time: 3239.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 279/2000 data_batch_2,  Train_loss : 5955.2441  Test_loss : 6223.6748, Time/batch_file : 2.2899, Training time: 3241.8701\n",
      "Epoch : 279/2000 data_batch_3,  Train_loss : 5724.8389  Test_loss : 6367.6587, Time/batch_file : 2.2875, Training time: 3244.1578\n",
      "Epoch : 279/2000 data_batch_4,  Train_loss : 5960.5024  Test_loss : 5840.5405, Time/batch_file : 2.3036, Training time: 3246.4616\n",
      "Epoch : 279/2000 data_batch_5,  Train_loss : 6220.7510  Test_loss : 5833.1050, Time/batch_file : 2.2931, Training time: 3248.7549\n",
      "Epoch : 280/2000 data_batch_1,  Train_loss : 6134.9561  Test_loss : 6002.6245, Time/batch_file : 2.2952, Training time: 3251.0503\n",
      "Epoch : 280/2000 data_batch_2,  Train_loss : 6070.8911  Test_loss : 6382.2637, Time/batch_file : 2.2796, Training time: 3253.3301\n",
      "Epoch : 280/2000 data_batch_3,  Train_loss : 6102.0474  Test_loss : 6431.1646, Time/batch_file : 2.2986, Training time: 3255.6289\n",
      "Epoch : 280/2000 data_batch_4,  Train_loss : 6058.2036  Test_loss : 6440.1465, Time/batch_file : 2.2806, Training time: 3257.9097\n",
      "Epoch : 280/2000 data_batch_5,  Train_loss : 5806.6357  Test_loss : 6216.2212, Time/batch_file : 2.2904, Training time: 3260.2003\n",
      "[./nets/net-280.ckpt] SAVED\n",
      "Epoch : 281/2000 data_batch_1,  Train_loss : 5549.8281  Test_loss : 6453.1802, Time/batch_file : 2.3160, Training time: 3263.7983\n",
      "Epoch : 281/2000 data_batch_2,  Train_loss : 5578.7402  Test_loss : 6020.7266, Time/batch_file : 2.3094, Training time: 3266.1080\n",
      "Epoch : 281/2000 data_batch_3,  Train_loss : 5321.5771  Test_loss : 6543.1963, Time/batch_file : 2.3020, Training time: 3268.4102\n",
      "Epoch : 281/2000 data_batch_4,  Train_loss : 5418.5000  Test_loss : 6417.8633, Time/batch_file : 2.2843, Training time: 3270.6948\n",
      "Epoch : 281/2000 data_batch_5,  Train_loss : 5489.4204  Test_loss : 6305.3081, Time/batch_file : 2.3073, Training time: 3273.0022\n",
      "Epoch : 282/2000 data_batch_1,  Train_loss : 5558.1387  Test_loss : 6328.2090, Time/batch_file : 2.2637, Training time: 3275.2661\n",
      "Epoch : 282/2000 data_batch_2,  Train_loss : 5726.9390  Test_loss : 5934.1548, Time/batch_file : 2.2779, Training time: 3277.5442\n",
      "Epoch : 282/2000 data_batch_3,  Train_loss : 5413.3677  Test_loss : 6109.7769, Time/batch_file : 2.2720, Training time: 3279.8165\n",
      "Epoch : 282/2000 data_batch_4,  Train_loss : 5875.4458  Test_loss : 5860.4971, Time/batch_file : 2.2764, Training time: 3282.0930\n",
      "Epoch : 282/2000 data_batch_5,  Train_loss : 5743.4507  Test_loss : 6355.3555, Time/batch_file : 2.2806, Training time: 3284.3739\n",
      "Epoch : 283/2000 data_batch_1,  Train_loss : 5676.6191  Test_loss : 6523.4082, Time/batch_file : 2.2847, Training time: 3286.6588\n",
      "Epoch : 283/2000 data_batch_2,  Train_loss : 5344.3828  Test_loss : 6645.0225, Time/batch_file : 2.2825, Training time: 3288.9415\n",
      "Epoch : 283/2000 data_batch_3,  Train_loss : 5736.9209  Test_loss : 6433.3994, Time/batch_file : 2.2959, Training time: 3291.2375\n",
      "Epoch : 283/2000 data_batch_4,  Train_loss : 5494.0933  Test_loss : 6940.2739, Time/batch_file : 2.2885, Training time: 3293.5262\n",
      "Epoch : 283/2000 data_batch_5,  Train_loss : 5297.7646  Test_loss : 6946.7539, Time/batch_file : 2.2938, Training time: 3295.8202\n",
      "Epoch : 284/2000 data_batch_1,  Train_loss : 5557.3613  Test_loss : 5950.8423, Time/batch_file : 2.2974, Training time: 3298.1178\n",
      "Epoch : 284/2000 data_batch_2,  Train_loss : 5958.4365  Test_loss : 5998.8721, Time/batch_file : 2.2917, Training time: 3300.4096\n",
      "Epoch : 284/2000 data_batch_3,  Train_loss : 5846.7378  Test_loss : 5717.0376, Time/batch_file : 2.2869, Training time: 3302.6967\n",
      "Epoch : 284/2000 data_batch_4,  Train_loss : 5488.9336  Test_loss : 5826.5635, Time/batch_file : 2.2866, Training time: 3304.9834\n",
      "Epoch : 284/2000 data_batch_5,  Train_loss : 5637.3105  Test_loss : 6330.8896, Time/batch_file : 2.2798, Training time: 3307.2634\n",
      "Epoch : 285/2000 data_batch_1,  Train_loss : 5741.5801  Test_loss : 6359.5420, Time/batch_file : 2.2875, Training time: 3309.5512\n",
      "Epoch : 285/2000 data_batch_2,  Train_loss : 5451.0542  Test_loss : 5968.5093, Time/batch_file : 2.2864, Training time: 3311.8377\n",
      "Epoch : 285/2000 data_batch_3,  Train_loss : 5778.6987  Test_loss : 6114.6201, Time/batch_file : 2.2704, Training time: 3314.1084\n",
      "Epoch : 285/2000 data_batch_4,  Train_loss : 5626.1240  Test_loss : 6261.6387, Time/batch_file : 2.2629, Training time: 3316.3715\n",
      "Epoch : 285/2000 data_batch_5,  Train_loss : 5548.8359  Test_loss : 6368.4375, Time/batch_file : 2.2717, Training time: 3318.6434\n",
      "Epoch : 286/2000 data_batch_1,  Train_loss : 5743.7075  Test_loss : 6581.9575, Time/batch_file : 2.3065, Training time: 3320.9501\n",
      "Epoch : 286/2000 data_batch_2,  Train_loss : 5247.5059  Test_loss : 6439.7969, Time/batch_file : 2.2866, Training time: 3323.2368\n",
      "Epoch : 286/2000 data_batch_3,  Train_loss : 5418.4370  Test_loss : 6562.0361, Time/batch_file : 2.2765, Training time: 3325.5136\n",
      "Epoch : 286/2000 data_batch_4,  Train_loss : 5635.9238  Test_loss : 6525.6572, Time/batch_file : 2.2793, Training time: 3327.7931\n",
      "Epoch : 286/2000 data_batch_5,  Train_loss : 5419.5684  Test_loss : 6323.7734, Time/batch_file : 2.2911, Training time: 3330.0844\n",
      "Epoch : 287/2000 data_batch_1,  Train_loss : 5718.7432  Test_loss : 6366.1211, Time/batch_file : 2.2788, Training time: 3332.3635\n",
      "Epoch : 287/2000 data_batch_2,  Train_loss : 6105.7173  Test_loss : 6208.3506, Time/batch_file : 2.2812, Training time: 3334.6449\n",
      "Epoch : 287/2000 data_batch_3,  Train_loss : 5637.0166  Test_loss : 6497.9932, Time/batch_file : 2.2831, Training time: 3336.9282\n",
      "Epoch : 287/2000 data_batch_4,  Train_loss : 5732.4077  Test_loss : 6253.4946, Time/batch_file : 2.2834, Training time: 3339.2118\n",
      "Epoch : 287/2000 data_batch_5,  Train_loss : 5995.0083  Test_loss : 6013.3296, Time/batch_file : 2.2779, Training time: 3341.4898\n",
      "Epoch : 288/2000 data_batch_1,  Train_loss : 6040.5342  Test_loss : 6521.2070, Time/batch_file : 2.2916, Training time: 3343.7816\n",
      "Epoch : 288/2000 data_batch_2,  Train_loss : 6412.7427  Test_loss : 6400.2207, Time/batch_file : 2.3070, Training time: 3346.0888\n",
      "Epoch : 288/2000 data_batch_3,  Train_loss : 6252.5044  Test_loss : 6535.4595, Time/batch_file : 2.2783, Training time: 3348.3673\n",
      "Epoch : 288/2000 data_batch_4,  Train_loss : 5967.2129  Test_loss : 6670.7280, Time/batch_file : 2.3052, Training time: 3350.6727\n",
      "Epoch : 288/2000 data_batch_5,  Train_loss : 6086.9043  Test_loss : 6445.6904, Time/batch_file : 2.2923, Training time: 3352.9651\n",
      "Epoch : 289/2000 data_batch_1,  Train_loss : 6297.4199  Test_loss : 6002.9980, Time/batch_file : 2.2938, Training time: 3355.2592\n",
      "Epoch : 289/2000 data_batch_2,  Train_loss : 6009.9043  Test_loss : 5961.2637, Time/batch_file : 2.2973, Training time: 3357.5568\n",
      "Epoch : 289/2000 data_batch_3,  Train_loss : 6063.3325  Test_loss : 5882.4478, Time/batch_file : 2.2917, Training time: 3359.8487\n",
      "Epoch : 289/2000 data_batch_4,  Train_loss : 6107.1812  Test_loss : 5633.5869, Time/batch_file : 2.2859, Training time: 3362.1347\n",
      "Epoch : 289/2000 data_batch_5,  Train_loss : 6310.0205  Test_loss : 5737.8555, Time/batch_file : 2.2983, Training time: 3364.4332\n",
      "Epoch : 290/2000 data_batch_1,  Train_loss : 5756.3848  Test_loss : 6657.0596, Time/batch_file : 2.2852, Training time: 3366.7185\n",
      "Epoch : 290/2000 data_batch_2,  Train_loss : 5624.7876  Test_loss : 6238.5723, Time/batch_file : 2.2848, Training time: 3369.0037\n",
      "Epoch : 290/2000 data_batch_3,  Train_loss : 5887.4805  Test_loss : 6295.5049, Time/batch_file : 2.2671, Training time: 3371.2711\n",
      "Epoch : 290/2000 data_batch_4,  Train_loss : 5905.9380  Test_loss : 6687.4531, Time/batch_file : 2.2951, Training time: 3373.5664\n",
      "Epoch : 290/2000 data_batch_5,  Train_loss : 5737.5781  Test_loss : 6560.1641, Time/batch_file : 2.2701, Training time: 3375.8368\n",
      "[./nets/net-290.ckpt] SAVED\n",
      "Epoch : 291/2000 data_batch_1,  Train_loss : 5803.2578  Test_loss : 6180.6670, Time/batch_file : 2.3074, Training time: 3379.4294\n",
      "Epoch : 291/2000 data_batch_2,  Train_loss : 5614.6885  Test_loss : 6210.3579, Time/batch_file : 2.2767, Training time: 3381.7064\n",
      "Epoch : 291/2000 data_batch_3,  Train_loss : 5515.0420  Test_loss : 6539.9785, Time/batch_file : 2.2959, Training time: 3384.0024\n",
      "Epoch : 291/2000 data_batch_4,  Train_loss : 5385.5386  Test_loss : 6339.2524, Time/batch_file : 2.2802, Training time: 3386.2828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 291/2000 data_batch_5,  Train_loss : 5430.0430  Test_loss : 6565.5327, Time/batch_file : 2.2777, Training time: 3388.5606\n",
      "Epoch : 292/2000 data_batch_1,  Train_loss : 6388.0112  Test_loss : 5656.2773, Time/batch_file : 2.2813, Training time: 3390.8422\n",
      "Epoch : 292/2000 data_batch_2,  Train_loss : 6404.9746  Test_loss : 5895.8281, Time/batch_file : 2.2753, Training time: 3393.1177\n",
      "Epoch : 292/2000 data_batch_3,  Train_loss : 6215.7988  Test_loss : 5653.0347, Time/batch_file : 2.2727, Training time: 3395.3906\n",
      "Epoch : 292/2000 data_batch_4,  Train_loss : 6152.3188  Test_loss : 5807.7803, Time/batch_file : 2.2724, Training time: 3397.6632\n",
      "Epoch : 292/2000 data_batch_5,  Train_loss : 6080.9287  Test_loss : 5851.3247, Time/batch_file : 2.2759, Training time: 3399.9394\n",
      "Epoch : 293/2000 data_batch_1,  Train_loss : 5509.5957  Test_loss : 5322.9194, Time/batch_file : 2.2699, Training time: 3402.2095\n",
      "Epoch : 293/2000 data_batch_2,  Train_loss : 6182.4023  Test_loss : 5790.7090, Time/batch_file : 2.2746, Training time: 3404.4844\n",
      "Epoch : 293/2000 data_batch_3,  Train_loss : 5608.5518  Test_loss : 5722.0312, Time/batch_file : 2.2748, Training time: 3406.7592\n",
      "Epoch : 293/2000 data_batch_4,  Train_loss : 5741.8857  Test_loss : 5564.2749, Time/batch_file : 2.2723, Training time: 3409.0319\n",
      "Epoch : 293/2000 data_batch_5,  Train_loss : 5941.5381  Test_loss : 5681.4189, Time/batch_file : 2.2804, Training time: 3411.3125\n",
      "Epoch : 294/2000 data_batch_1,  Train_loss : 5749.7480  Test_loss : 5941.9863, Time/batch_file : 2.2791, Training time: 3413.5917\n",
      "Epoch : 294/2000 data_batch_2,  Train_loss : 5572.0747  Test_loss : 5620.0361, Time/batch_file : 2.2972, Training time: 3415.8891\n",
      "Epoch : 294/2000 data_batch_3,  Train_loss : 5910.1758  Test_loss : 5909.6636, Time/batch_file : 2.2741, Training time: 3418.1633\n",
      "Epoch : 294/2000 data_batch_4,  Train_loss : 5806.5049  Test_loss : 5955.4609, Time/batch_file : 2.2746, Training time: 3420.4382\n",
      "Epoch : 294/2000 data_batch_5,  Train_loss : 6045.2607  Test_loss : 5607.3140, Time/batch_file : 2.2773, Training time: 3422.7157\n",
      "Epoch : 295/2000 data_batch_1,  Train_loss : 6245.1172  Test_loss : 6092.6475, Time/batch_file : 2.2687, Training time: 3424.9846\n",
      "Epoch : 295/2000 data_batch_2,  Train_loss : 6225.0552  Test_loss : 6116.7617, Time/batch_file : 2.2605, Training time: 3427.2453\n",
      "Epoch : 295/2000 data_batch_3,  Train_loss : 6392.3843  Test_loss : 5855.0801, Time/batch_file : 2.2668, Training time: 3429.5123\n",
      "Epoch : 295/2000 data_batch_4,  Train_loss : 6172.2402  Test_loss : 5932.5903, Time/batch_file : 2.2631, Training time: 3431.7757\n",
      "Epoch : 295/2000 data_batch_5,  Train_loss : 5968.8389  Test_loss : 6082.4482, Time/batch_file : 2.2647, Training time: 3434.0406\n",
      "Epoch : 296/2000 data_batch_1,  Train_loss : 5930.6748  Test_loss : 6103.9346, Time/batch_file : 2.2686, Training time: 3436.3094\n",
      "Epoch : 296/2000 data_batch_2,  Train_loss : 6203.6777  Test_loss : 6303.7900, Time/batch_file : 2.2730, Training time: 3438.5825\n",
      "Epoch : 296/2000 data_batch_3,  Train_loss : 6275.9092  Test_loss : 5934.1963, Time/batch_file : 2.2609, Training time: 3440.8436\n",
      "Epoch : 296/2000 data_batch_4,  Train_loss : 6302.8765  Test_loss : 6058.8442, Time/batch_file : 2.2668, Training time: 3443.1106\n",
      "Epoch : 296/2000 data_batch_5,  Train_loss : 6632.5625  Test_loss : 5879.3525, Time/batch_file : 2.2621, Training time: 3445.3729\n",
      "Epoch : 297/2000 data_batch_1,  Train_loss : 5393.1274  Test_loss : 6119.0508, Time/batch_file : 2.2810, Training time: 3447.6541\n",
      "Epoch : 297/2000 data_batch_2,  Train_loss : 5596.1650  Test_loss : 5965.5664, Time/batch_file : 2.2696, Training time: 3449.9239\n",
      "Epoch : 297/2000 data_batch_3,  Train_loss : 5642.3115  Test_loss : 6235.7705, Time/batch_file : 2.2759, Training time: 3452.2001\n",
      "Epoch : 297/2000 data_batch_4,  Train_loss : 5466.8242  Test_loss : 6141.0630, Time/batch_file : 2.2704, Training time: 3454.4707\n",
      "Epoch : 297/2000 data_batch_5,  Train_loss : 5748.2881  Test_loss : 6135.4580, Time/batch_file : 2.2797, Training time: 3456.7506\n",
      "Epoch : 298/2000 data_batch_1,  Train_loss : 6063.6089  Test_loss : 5408.2021, Time/batch_file : 2.2756, Training time: 3459.0265\n",
      "Epoch : 298/2000 data_batch_2,  Train_loss : 6362.4990  Test_loss : 5648.4678, Time/batch_file : 2.2806, Training time: 3461.3073\n",
      "Epoch : 298/2000 data_batch_3,  Train_loss : 6798.9233  Test_loss : 5623.1929, Time/batch_file : 2.2712, Training time: 3463.5787\n",
      "Epoch : 298/2000 data_batch_4,  Train_loss : 6228.6919  Test_loss : 5864.2568, Time/batch_file : 2.2634, Training time: 3465.8423\n",
      "Epoch : 298/2000 data_batch_5,  Train_loss : 6246.7729  Test_loss : 5763.8545, Time/batch_file : 2.2754, Training time: 3468.1178\n",
      "Epoch : 299/2000 data_batch_1,  Train_loss : 5901.6616  Test_loss : 6567.5659, Time/batch_file : 2.2764, Training time: 3470.3945\n",
      "Epoch : 299/2000 data_batch_2,  Train_loss : 6018.7500  Test_loss : 6095.9727, Time/batch_file : 2.2688, Training time: 3472.6635\n",
      "Epoch : 299/2000 data_batch_3,  Train_loss : 5645.5254  Test_loss : 6243.6890, Time/batch_file : 2.2746, Training time: 3474.9382\n",
      "Epoch : 299/2000 data_batch_4,  Train_loss : 5751.4014  Test_loss : 6438.8340, Time/batch_file : 2.2864, Training time: 3477.2249\n",
      "Epoch : 299/2000 data_batch_5,  Train_loss : 5751.7603  Test_loss : 6418.1587, Time/batch_file : 2.2927, Training time: 3479.5177\n",
      "Epoch : 300/2000 data_batch_1,  Train_loss : 5916.8535  Test_loss : 6046.1577, Time/batch_file : 2.2912, Training time: 3481.8091\n",
      "Epoch : 300/2000 data_batch_2,  Train_loss : 5304.3145  Test_loss : 5850.5479, Time/batch_file : 2.2764, Training time: 3484.0858\n",
      "Epoch : 300/2000 data_batch_3,  Train_loss : 5601.0234  Test_loss : 6079.8301, Time/batch_file : 2.2816, Training time: 3486.3676\n",
      "Epoch : 300/2000 data_batch_4,  Train_loss : 5376.1602  Test_loss : 6010.4106, Time/batch_file : 2.2940, Training time: 3488.6617\n",
      "Epoch : 300/2000 data_batch_5,  Train_loss : 5575.8813  Test_loss : 6574.2402, Time/batch_file : 2.3002, Training time: 3490.9622\n",
      "[./nets/net-300.ckpt] SAVED\n",
      "Epoch : 301/2000 data_batch_1,  Train_loss : 6246.4326  Test_loss : 5584.5693, Time/batch_file : 2.3086, Training time: 3494.5838\n",
      "Epoch : 301/2000 data_batch_2,  Train_loss : 5889.8545  Test_loss : 5955.2451, Time/batch_file : 2.2957, Training time: 3496.8797\n",
      "Epoch : 301/2000 data_batch_3,  Train_loss : 5955.3047  Test_loss : 5828.7178, Time/batch_file : 2.3085, Training time: 3499.1883\n",
      "Epoch : 301/2000 data_batch_4,  Train_loss : 5844.3940  Test_loss : 5993.5293, Time/batch_file : 2.3065, Training time: 3501.4950\n",
      "Epoch : 301/2000 data_batch_5,  Train_loss : 5826.6504  Test_loss : 5827.2773, Time/batch_file : 2.2991, Training time: 3503.7945\n",
      "Epoch : 302/2000 data_batch_1,  Train_loss : 6260.2676  Test_loss : 5792.1641, Time/batch_file : 2.3066, Training time: 3506.1014\n",
      "Epoch : 302/2000 data_batch_2,  Train_loss : 6038.9443  Test_loss : 5987.1655, Time/batch_file : 2.3323, Training time: 3508.4339\n",
      "Epoch : 302/2000 data_batch_3,  Train_loss : 6133.8989  Test_loss : 6025.2715, Time/batch_file : 2.3206, Training time: 3510.7548\n",
      "Epoch : 302/2000 data_batch_4,  Train_loss : 6186.0029  Test_loss : 5947.5376, Time/batch_file : 2.3011, Training time: 3513.0560\n",
      "Epoch : 302/2000 data_batch_5,  Train_loss : 6020.3506  Test_loss : 6021.7471, Time/batch_file : 2.3000, Training time: 3515.3563\n",
      "Epoch : 303/2000 data_batch_1,  Train_loss : 6747.1968  Test_loss : 5645.4619, Time/batch_file : 2.3079, Training time: 3517.6644\n",
      "Epoch : 303/2000 data_batch_2,  Train_loss : 6491.5781  Test_loss : 5499.8071, Time/batch_file : 2.2958, Training time: 3519.9604\n",
      "Epoch : 303/2000 data_batch_3,  Train_loss : 6359.3818  Test_loss : 5533.6250, Time/batch_file : 2.3042, Training time: 3522.2649\n",
      "Epoch : 303/2000 data_batch_4,  Train_loss : 6342.6562  Test_loss : 5338.1377, Time/batch_file : 2.3164, Training time: 3524.5813\n",
      "Epoch : 303/2000 data_batch_5,  Train_loss : 6615.5293  Test_loss : 5900.7217, Time/batch_file : 2.2933, Training time: 3526.8748\n",
      "Epoch : 304/2000 data_batch_1,  Train_loss : 6226.1025  Test_loss : 6177.2402, Time/batch_file : 2.3002, Training time: 3529.1752\n",
      "Epoch : 304/2000 data_batch_2,  Train_loss : 6151.4600  Test_loss : 5724.2881, Time/batch_file : 2.2997, Training time: 3531.4751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 304/2000 data_batch_3,  Train_loss : 5804.2979  Test_loss : 5875.3833, Time/batch_file : 2.2786, Training time: 3533.7539\n",
      "Epoch : 304/2000 data_batch_4,  Train_loss : 5824.7891  Test_loss : 5811.5381, Time/batch_file : 2.3145, Training time: 3536.0686\n",
      "Epoch : 304/2000 data_batch_5,  Train_loss : 6116.1514  Test_loss : 5938.2974, Time/batch_file : 2.3041, Training time: 3538.3728\n",
      "Epoch : 305/2000 data_batch_1,  Train_loss : 5593.1875  Test_loss : 5946.2788, Time/batch_file : 2.2948, Training time: 3540.6678\n",
      "Epoch : 305/2000 data_batch_2,  Train_loss : 5860.0220  Test_loss : 5895.2578, Time/batch_file : 2.2816, Training time: 3542.9497\n",
      "Epoch : 305/2000 data_batch_3,  Train_loss : 6041.8442  Test_loss : 6175.2837, Time/batch_file : 2.2850, Training time: 3545.2349\n",
      "Epoch : 305/2000 data_batch_4,  Train_loss : 5592.6191  Test_loss : 6265.0234, Time/batch_file : 2.3068, Training time: 3547.5420\n",
      "Epoch : 305/2000 data_batch_5,  Train_loss : 5746.6470  Test_loss : 6437.1621, Time/batch_file : 2.3196, Training time: 3549.8617\n",
      "Epoch : 306/2000 data_batch_1,  Train_loss : 5298.1729  Test_loss : 6183.3428, Time/batch_file : 2.2878, Training time: 3552.1496\n",
      "Epoch : 306/2000 data_batch_2,  Train_loss : 5318.3965  Test_loss : 6029.9878, Time/batch_file : 2.2855, Training time: 3554.4353\n",
      "Epoch : 306/2000 data_batch_3,  Train_loss : 5497.6211  Test_loss : 6272.0068, Time/batch_file : 2.3065, Training time: 3556.7421\n",
      "Epoch : 306/2000 data_batch_4,  Train_loss : 5805.4204  Test_loss : 6636.5063, Time/batch_file : 2.3048, Training time: 3559.0471\n",
      "Epoch : 306/2000 data_batch_5,  Train_loss : 5590.5215  Test_loss : 6195.7632, Time/batch_file : 2.2751, Training time: 3561.3224\n",
      "Epoch : 307/2000 data_batch_1,  Train_loss : 5485.6904  Test_loss : 6329.4839, Time/batch_file : 2.2968, Training time: 3563.6194\n",
      "Epoch : 307/2000 data_batch_2,  Train_loss : 5485.6270  Test_loss : 6131.1411, Time/batch_file : 2.2781, Training time: 3565.8977\n",
      "Epoch : 307/2000 data_batch_3,  Train_loss : 5461.6982  Test_loss : 5789.0410, Time/batch_file : 2.3062, Training time: 3568.2043\n",
      "Epoch : 307/2000 data_batch_4,  Train_loss : 5587.3208  Test_loss : 6246.9990, Time/batch_file : 2.3019, Training time: 3570.5063\n",
      "Epoch : 307/2000 data_batch_5,  Train_loss : 5501.5376  Test_loss : 6306.2266, Time/batch_file : 2.3224, Training time: 3572.8290\n",
      "Epoch : 308/2000 data_batch_1,  Train_loss : 5477.4507  Test_loss : 5535.2891, Time/batch_file : 2.2920, Training time: 3575.1212\n",
      "Epoch : 308/2000 data_batch_2,  Train_loss : 5725.8560  Test_loss : 5930.7969, Time/batch_file : 2.2861, Training time: 3577.4075\n",
      "Epoch : 308/2000 data_batch_3,  Train_loss : 5424.6343  Test_loss : 5492.7969, Time/batch_file : 2.3138, Training time: 3579.7214\n",
      "Epoch : 308/2000 data_batch_4,  Train_loss : 5897.2334  Test_loss : 5486.0293, Time/batch_file : 2.3028, Training time: 3582.0244\n",
      "Epoch : 308/2000 data_batch_5,  Train_loss : 5565.2700  Test_loss : 5971.6284, Time/batch_file : 2.3130, Training time: 3584.3376\n",
      "Epoch : 309/2000 data_batch_1,  Train_loss : 6088.3135  Test_loss : 5996.6206, Time/batch_file : 2.2956, Training time: 3586.6334\n",
      "Epoch : 309/2000 data_batch_2,  Train_loss : 6054.3203  Test_loss : 6246.1401, Time/batch_file : 2.2882, Training time: 3588.9219\n",
      "Epoch : 309/2000 data_batch_3,  Train_loss : 6186.9883  Test_loss : 6419.9297, Time/batch_file : 2.2941, Training time: 3591.2163\n",
      "Epoch : 309/2000 data_batch_4,  Train_loss : 5631.7559  Test_loss : 6463.7056, Time/batch_file : 2.2816, Training time: 3593.4981\n",
      "Epoch : 309/2000 data_batch_5,  Train_loss : 5758.9775  Test_loss : 6469.9785, Time/batch_file : 2.2999, Training time: 3595.7981\n",
      "Epoch : 310/2000 data_batch_1,  Train_loss : 5711.0601  Test_loss : 6421.6733, Time/batch_file : 2.2879, Training time: 3598.0863\n",
      "Epoch : 310/2000 data_batch_2,  Train_loss : 6237.3984  Test_loss : 6178.6841, Time/batch_file : 2.2931, Training time: 3600.3796\n",
      "Epoch : 310/2000 data_batch_3,  Train_loss : 6133.3857  Test_loss : 5877.6353, Time/batch_file : 2.2985, Training time: 3602.6783\n",
      "Epoch : 310/2000 data_batch_4,  Train_loss : 6313.4243  Test_loss : 6107.2031, Time/batch_file : 2.2813, Training time: 3604.9597\n",
      "Epoch : 310/2000 data_batch_5,  Train_loss : 5663.9741  Test_loss : 6408.9814, Time/batch_file : 2.2543, Training time: 3607.2142\n",
      "[./nets/net-310.ckpt] SAVED\n",
      "Epoch : 311/2000 data_batch_1,  Train_loss : 5491.6602  Test_loss : 5954.8223, Time/batch_file : 2.3177, Training time: 3610.8171\n",
      "Epoch : 311/2000 data_batch_2,  Train_loss : 5171.2891  Test_loss : 5902.3628, Time/batch_file : 2.3047, Training time: 3613.1220\n",
      "Epoch : 311/2000 data_batch_3,  Train_loss : 5167.5020  Test_loss : 6062.8955, Time/batch_file : 2.3010, Training time: 3615.4232\n",
      "Epoch : 311/2000 data_batch_4,  Train_loss : 5504.1157  Test_loss : 6435.5049, Time/batch_file : 2.3163, Training time: 3617.7397\n",
      "Epoch : 311/2000 data_batch_5,  Train_loss : 5350.4111  Test_loss : 6279.8560, Time/batch_file : 2.3325, Training time: 3620.0724\n",
      "Epoch : 312/2000 data_batch_1,  Train_loss : 5495.1733  Test_loss : 5821.8447, Time/batch_file : 2.3126, Training time: 3622.3851\n",
      "Epoch : 312/2000 data_batch_2,  Train_loss : 5720.1206  Test_loss : 5679.9985, Time/batch_file : 2.3021, Training time: 3624.6873\n",
      "Epoch : 312/2000 data_batch_3,  Train_loss : 5772.4946  Test_loss : 5586.2886, Time/batch_file : 2.3050, Training time: 3626.9926\n",
      "Epoch : 312/2000 data_batch_4,  Train_loss : 5595.0503  Test_loss : 6039.8945, Time/batch_file : 2.3004, Training time: 3629.2932\n",
      "Epoch : 312/2000 data_batch_5,  Train_loss : 5456.5356  Test_loss : 5798.2695, Time/batch_file : 2.3023, Training time: 3631.5957\n",
      "Epoch : 313/2000 data_batch_1,  Train_loss : 6121.8613  Test_loss : 6049.0522, Time/batch_file : 2.3099, Training time: 3633.9058\n",
      "Epoch : 313/2000 data_batch_2,  Train_loss : 6055.0259  Test_loss : 5778.5776, Time/batch_file : 2.3127, Training time: 3636.2186\n",
      "Epoch : 313/2000 data_batch_3,  Train_loss : 5902.7524  Test_loss : 6142.5908, Time/batch_file : 2.3003, Training time: 3638.5192\n",
      "Epoch : 313/2000 data_batch_4,  Train_loss : 6208.8916  Test_loss : 5887.4746, Time/batch_file : 2.2948, Training time: 3640.8141\n",
      "Epoch : 313/2000 data_batch_5,  Train_loss : 6192.4341  Test_loss : 5935.7080, Time/batch_file : 2.3033, Training time: 3643.1176\n",
      "Epoch : 314/2000 data_batch_1,  Train_loss : 5394.6553  Test_loss : 6036.4712, Time/batch_file : 2.2930, Training time: 3645.4107\n",
      "Epoch : 314/2000 data_batch_2,  Train_loss : 5562.7949  Test_loss : 5849.1533, Time/batch_file : 2.3080, Training time: 3647.7188\n",
      "Epoch : 314/2000 data_batch_3,  Train_loss : 5049.5449  Test_loss : 5905.4082, Time/batch_file : 2.3024, Training time: 3650.0214\n",
      "Epoch : 314/2000 data_batch_4,  Train_loss : 5488.2871  Test_loss : 6005.0474, Time/batch_file : 2.3019, Training time: 3652.3235\n",
      "Epoch : 314/2000 data_batch_5,  Train_loss : 5219.6313  Test_loss : 5757.3613, Time/batch_file : 2.3117, Training time: 3654.6354\n",
      "Epoch : 315/2000 data_batch_1,  Train_loss : 5782.0000  Test_loss : 6166.0859, Time/batch_file : 2.3108, Training time: 3656.9463\n",
      "Epoch : 315/2000 data_batch_2,  Train_loss : 5350.8931  Test_loss : 5922.9106, Time/batch_file : 2.2927, Training time: 3659.2393\n",
      "Epoch : 315/2000 data_batch_3,  Train_loss : 5210.8271  Test_loss : 5989.6465, Time/batch_file : 2.3114, Training time: 3661.5509\n",
      "Epoch : 315/2000 data_batch_4,  Train_loss : 5496.4902  Test_loss : 6113.9189, Time/batch_file : 2.3218, Training time: 3663.8729\n",
      "Epoch : 315/2000 data_batch_5,  Train_loss : 5279.6230  Test_loss : 6537.4043, Time/batch_file : 2.2895, Training time: 3666.1625\n",
      "Epoch : 316/2000 data_batch_1,  Train_loss : 5848.7378  Test_loss : 5835.7764, Time/batch_file : 2.2927, Training time: 3668.4554\n",
      "Epoch : 316/2000 data_batch_2,  Train_loss : 6291.0923  Test_loss : 6358.2070, Time/batch_file : 2.2891, Training time: 3670.7446\n",
      "Epoch : 316/2000 data_batch_3,  Train_loss : 6254.0796  Test_loss : 5888.3169, Time/batch_file : 2.2911, Training time: 3673.0359\n",
      "Epoch : 316/2000 data_batch_4,  Train_loss : 6071.8486  Test_loss : 5724.9814, Time/batch_file : 2.2903, Training time: 3675.3264\n",
      "Epoch : 316/2000 data_batch_5,  Train_loss : 5995.6064  Test_loss : 6365.3926, Time/batch_file : 2.2895, Training time: 3677.6161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 317/2000 data_batch_1,  Train_loss : 6364.8711  Test_loss : 5970.3496, Time/batch_file : 2.2825, Training time: 3679.8989\n",
      "Epoch : 317/2000 data_batch_2,  Train_loss : 6400.4194  Test_loss : 5942.7583, Time/batch_file : 2.2879, Training time: 3682.1870\n",
      "Epoch : 317/2000 data_batch_3,  Train_loss : 6620.8223  Test_loss : 6009.2329, Time/batch_file : 2.2810, Training time: 3684.4681\n",
      "Epoch : 317/2000 data_batch_4,  Train_loss : 6571.8965  Test_loss : 6066.5718, Time/batch_file : 2.2787, Training time: 3686.7470\n",
      "Epoch : 317/2000 data_batch_5,  Train_loss : 6446.9487  Test_loss : 6209.6997, Time/batch_file : 2.2983, Training time: 3689.0455\n",
      "Epoch : 318/2000 data_batch_1,  Train_loss : 5053.0190  Test_loss : 6388.0552, Time/batch_file : 2.2902, Training time: 3691.3360\n",
      "Epoch : 318/2000 data_batch_2,  Train_loss : 5014.0693  Test_loss : 5866.1323, Time/batch_file : 2.2895, Training time: 3693.6258\n",
      "Epoch : 318/2000 data_batch_3,  Train_loss : 5088.8804  Test_loss : 6192.2285, Time/batch_file : 2.2780, Training time: 3695.9040\n",
      "Epoch : 318/2000 data_batch_4,  Train_loss : 4995.2534  Test_loss : 6521.1611, Time/batch_file : 2.2779, Training time: 3698.1821\n",
      "Epoch : 318/2000 data_batch_5,  Train_loss : 4906.0059  Test_loss : 5917.5596, Time/batch_file : 2.2638, Training time: 3700.4460\n",
      "Epoch : 319/2000 data_batch_1,  Train_loss : 5292.2705  Test_loss : 5789.5581, Time/batch_file : 2.2949, Training time: 3702.7411\n",
      "Epoch : 319/2000 data_batch_2,  Train_loss : 5145.7549  Test_loss : 5955.2812, Time/batch_file : 2.2935, Training time: 3705.0348\n",
      "Epoch : 319/2000 data_batch_3,  Train_loss : 5375.4023  Test_loss : 6051.8574, Time/batch_file : 2.2920, Training time: 3707.3270\n",
      "Epoch : 319/2000 data_batch_4,  Train_loss : 5371.7344  Test_loss : 6032.6460, Time/batch_file : 2.3006, Training time: 3709.6278\n",
      "Epoch : 319/2000 data_batch_5,  Train_loss : 5607.9644  Test_loss : 5946.2041, Time/batch_file : 2.2946, Training time: 3711.9225\n",
      "Epoch : 320/2000 data_batch_1,  Train_loss : 5939.6768  Test_loss : 5987.0801, Time/batch_file : 2.2817, Training time: 3714.2044\n",
      "Epoch : 320/2000 data_batch_2,  Train_loss : 6153.2061  Test_loss : 6250.9756, Time/batch_file : 2.3038, Training time: 3716.5084\n",
      "Epoch : 320/2000 data_batch_3,  Train_loss : 5835.4219  Test_loss : 6310.9033, Time/batch_file : 2.3051, Training time: 3718.8137\n",
      "Epoch : 320/2000 data_batch_4,  Train_loss : 5758.4248  Test_loss : 6318.2515, Time/batch_file : 2.2926, Training time: 3721.1065\n",
      "Epoch : 320/2000 data_batch_5,  Train_loss : 5562.0410  Test_loss : 6205.9712, Time/batch_file : 2.2787, Training time: 3723.3854\n",
      "[./nets/net-320.ckpt] SAVED\n",
      "Epoch : 321/2000 data_batch_1,  Train_loss : 5726.9048  Test_loss : 5761.0303, Time/batch_file : 2.2923, Training time: 3727.9079\n",
      "Epoch : 321/2000 data_batch_2,  Train_loss : 5916.2788  Test_loss : 5947.0698, Time/batch_file : 2.2906, Training time: 3730.1987\n",
      "Epoch : 321/2000 data_batch_3,  Train_loss : 5729.3706  Test_loss : 5541.8037, Time/batch_file : 2.2961, Training time: 3732.4950\n",
      "Epoch : 321/2000 data_batch_4,  Train_loss : 5799.4863  Test_loss : 6015.0859, Time/batch_file : 2.2916, Training time: 3734.7869\n",
      "Epoch : 321/2000 data_batch_5,  Train_loss : 5642.1704  Test_loss : 5789.5605, Time/batch_file : 2.2759, Training time: 3737.0630\n",
      "Epoch : 322/2000 data_batch_1,  Train_loss : 5845.1289  Test_loss : 5920.6968, Time/batch_file : 2.2849, Training time: 3739.3481\n",
      "Epoch : 322/2000 data_batch_2,  Train_loss : 6157.4038  Test_loss : 5963.9712, Time/batch_file : 2.2984, Training time: 3741.6467\n",
      "Epoch : 322/2000 data_batch_3,  Train_loss : 6297.6406  Test_loss : 5787.1982, Time/batch_file : 2.2920, Training time: 3743.9390\n",
      "Epoch : 322/2000 data_batch_4,  Train_loss : 6417.5420  Test_loss : 5748.5786, Time/batch_file : 2.2962, Training time: 3746.2353\n",
      "Epoch : 322/2000 data_batch_5,  Train_loss : 6404.8662  Test_loss : 6200.3838, Time/batch_file : 2.2926, Training time: 3748.5282\n",
      "Epoch : 323/2000 data_batch_1,  Train_loss : 6430.9863  Test_loss : 6293.6250, Time/batch_file : 2.3014, Training time: 3750.8299\n",
      "Epoch : 323/2000 data_batch_2,  Train_loss : 6085.1528  Test_loss : 6207.9321, Time/batch_file : 2.2943, Training time: 3753.1243\n",
      "Epoch : 323/2000 data_batch_3,  Train_loss : 6243.4902  Test_loss : 6322.9741, Time/batch_file : 2.3091, Training time: 3755.4337\n",
      "Epoch : 323/2000 data_batch_4,  Train_loss : 6095.5830  Test_loss : 6192.8501, Time/batch_file : 2.2958, Training time: 3757.7297\n",
      "Epoch : 323/2000 data_batch_5,  Train_loss : 5982.7793  Test_loss : 6342.2539, Time/batch_file : 2.3154, Training time: 3760.0454\n",
      "Epoch : 324/2000 data_batch_1,  Train_loss : 6262.9468  Test_loss : 6259.7778, Time/batch_file : 2.3090, Training time: 3762.3546\n",
      "Epoch : 324/2000 data_batch_2,  Train_loss : 6213.3330  Test_loss : 6005.5967, Time/batch_file : 2.2941, Training time: 3764.6489\n",
      "Epoch : 324/2000 data_batch_3,  Train_loss : 6026.3418  Test_loss : 6102.8916, Time/batch_file : 2.2906, Training time: 3766.9398\n",
      "Epoch : 324/2000 data_batch_4,  Train_loss : 5799.2788  Test_loss : 5703.7168, Time/batch_file : 2.2959, Training time: 3769.2358\n",
      "Epoch : 324/2000 data_batch_5,  Train_loss : 5826.5083  Test_loss : 6364.1221, Time/batch_file : 2.2916, Training time: 3771.5276\n",
      "Epoch : 325/2000 data_batch_1,  Train_loss : 5289.7842  Test_loss : 6343.1025, Time/batch_file : 2.3021, Training time: 3773.8299\n",
      "Epoch : 325/2000 data_batch_2,  Train_loss : 5375.1426  Test_loss : 6608.4819, Time/batch_file : 2.2997, Training time: 3776.1299\n",
      "Epoch : 325/2000 data_batch_3,  Train_loss : 5288.2979  Test_loss : 6019.0596, Time/batch_file : 2.3156, Training time: 3778.4457\n",
      "Epoch : 325/2000 data_batch_4,  Train_loss : 5226.1738  Test_loss : 6144.0186, Time/batch_file : 2.2960, Training time: 3780.7419\n",
      "Epoch : 325/2000 data_batch_5,  Train_loss : 5233.5571  Test_loss : 6006.9902, Time/batch_file : 2.3023, Training time: 3783.0443\n",
      "Epoch : 326/2000 data_batch_1,  Train_loss : 5468.8281  Test_loss : 6038.2627, Time/batch_file : 2.3034, Training time: 3785.3480\n",
      "Epoch : 326/2000 data_batch_2,  Train_loss : 5538.0386  Test_loss : 6001.7754, Time/batch_file : 2.3166, Training time: 3787.6649\n",
      "Epoch : 326/2000 data_batch_3,  Train_loss : 5910.9976  Test_loss : 5932.0298, Time/batch_file : 2.3100, Training time: 3789.9750\n",
      "Epoch : 326/2000 data_batch_4,  Train_loss : 5729.8203  Test_loss : 5872.8735, Time/batch_file : 2.2986, Training time: 3792.2738\n",
      "Epoch : 326/2000 data_batch_5,  Train_loss : 5540.1104  Test_loss : 6057.0415, Time/batch_file : 2.2900, Training time: 3794.5640\n",
      "Epoch : 327/2000 data_batch_1,  Train_loss : 6289.1865  Test_loss : 5759.0732, Time/batch_file : 2.2906, Training time: 3796.8549\n",
      "Epoch : 327/2000 data_batch_2,  Train_loss : 6012.4395  Test_loss : 5858.0112, Time/batch_file : 2.2849, Training time: 3799.1399\n",
      "Epoch : 327/2000 data_batch_3,  Train_loss : 6092.8252  Test_loss : 5502.3242, Time/batch_file : 2.2935, Training time: 3801.4336\n",
      "Epoch : 327/2000 data_batch_4,  Train_loss : 6059.0815  Test_loss : 5504.0532, Time/batch_file : 2.2870, Training time: 3803.7208\n",
      "Epoch : 327/2000 data_batch_5,  Train_loss : 5949.0771  Test_loss : 5764.2212, Time/batch_file : 2.2975, Training time: 3806.0184\n",
      "Epoch : 328/2000 data_batch_1,  Train_loss : 5201.7168  Test_loss : 6109.2725, Time/batch_file : 2.2842, Training time: 3808.3028\n",
      "Epoch : 328/2000 data_batch_2,  Train_loss : 5434.7656  Test_loss : 6419.5840, Time/batch_file : 2.2991, Training time: 3810.6021\n",
      "Epoch : 328/2000 data_batch_3,  Train_loss : 5075.0698  Test_loss : 6079.5244, Time/batch_file : 2.2831, Training time: 3812.8854\n",
      "Epoch : 328/2000 data_batch_4,  Train_loss : 5298.1016  Test_loss : 6539.8979, Time/batch_file : 2.3032, Training time: 3815.1888\n",
      "Epoch : 328/2000 data_batch_5,  Train_loss : 5194.0830  Test_loss : 5858.4185, Time/batch_file : 2.3182, Training time: 3817.5072\n",
      "Epoch : 329/2000 data_batch_1,  Train_loss : 5414.3369  Test_loss : 6384.8057, Time/batch_file : 2.2861, Training time: 3819.7934\n",
      "Epoch : 329/2000 data_batch_2,  Train_loss : 5593.0835  Test_loss : 5670.8145, Time/batch_file : 2.2782, Training time: 3822.0716\n",
      "Epoch : 329/2000 data_batch_3,  Train_loss : 5797.6460  Test_loss : 6053.7720, Time/batch_file : 2.2895, Training time: 3824.3614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 329/2000 data_batch_4,  Train_loss : 5508.4590  Test_loss : 5653.4375, Time/batch_file : 2.2770, Training time: 3826.6386\n",
      "Epoch : 329/2000 data_batch_5,  Train_loss : 4962.5664  Test_loss : 5747.2368, Time/batch_file : 2.3035, Training time: 3828.9422\n",
      "Epoch : 330/2000 data_batch_1,  Train_loss : 6294.3076  Test_loss : 5525.6504, Time/batch_file : 2.2906, Training time: 3831.2331\n",
      "Epoch : 330/2000 data_batch_2,  Train_loss : 6038.3447  Test_loss : 5855.6582, Time/batch_file : 2.2963, Training time: 3833.5295\n",
      "Epoch : 330/2000 data_batch_3,  Train_loss : 6296.9663  Test_loss : 5503.7529, Time/batch_file : 2.2951, Training time: 3835.8248\n",
      "Epoch : 330/2000 data_batch_4,  Train_loss : 5976.2798  Test_loss : 5780.3701, Time/batch_file : 2.3065, Training time: 3838.1316\n",
      "Epoch : 330/2000 data_batch_5,  Train_loss : 5884.5054  Test_loss : 5864.4756, Time/batch_file : 2.2929, Training time: 3840.4247\n",
      "[./nets/net-330.ckpt] SAVED\n",
      "Epoch : 331/2000 data_batch_1,  Train_loss : 5116.7363  Test_loss : 5893.5088, Time/batch_file : 2.3303, Training time: 3844.0590\n",
      "Epoch : 331/2000 data_batch_2,  Train_loss : 5282.2197  Test_loss : 6187.7324, Time/batch_file : 2.3094, Training time: 3846.3686\n",
      "Epoch : 331/2000 data_batch_3,  Train_loss : 5044.6875  Test_loss : 6097.3926, Time/batch_file : 2.2828, Training time: 3848.6516\n",
      "Epoch : 331/2000 data_batch_4,  Train_loss : 4986.2627  Test_loss : 6028.8535, Time/batch_file : 2.3054, Training time: 3850.9571\n",
      "Epoch : 331/2000 data_batch_5,  Train_loss : 5069.5669  Test_loss : 5847.6377, Time/batch_file : 2.2867, Training time: 3853.2441\n",
      "Epoch : 332/2000 data_batch_1,  Train_loss : 5491.7041  Test_loss : 5735.6294, Time/batch_file : 2.3089, Training time: 3855.5533\n",
      "Epoch : 332/2000 data_batch_2,  Train_loss : 5510.9644  Test_loss : 5783.4282, Time/batch_file : 2.3043, Training time: 3857.8578\n",
      "Epoch : 332/2000 data_batch_3,  Train_loss : 5789.8413  Test_loss : 5743.6709, Time/batch_file : 2.3011, Training time: 3860.1591\n",
      "Epoch : 332/2000 data_batch_4,  Train_loss : 5446.1953  Test_loss : 5378.6660, Time/batch_file : 2.3046, Training time: 3862.4639\n",
      "Epoch : 332/2000 data_batch_5,  Train_loss : 5239.9224  Test_loss : 5992.2920, Time/batch_file : 2.3104, Training time: 3864.7746\n",
      "Epoch : 333/2000 data_batch_1,  Train_loss : 5695.8794  Test_loss : 5813.7402, Time/batch_file : 2.2984, Training time: 3867.0732\n",
      "Epoch : 333/2000 data_batch_2,  Train_loss : 5830.3350  Test_loss : 5469.1753, Time/batch_file : 2.2853, Training time: 3869.3588\n",
      "Epoch : 333/2000 data_batch_3,  Train_loss : 5965.0146  Test_loss : 5627.0322, Time/batch_file : 2.2765, Training time: 3871.6355\n",
      "Epoch : 333/2000 data_batch_4,  Train_loss : 5790.4380  Test_loss : 5726.0991, Time/batch_file : 2.2816, Training time: 3873.9173\n",
      "Epoch : 333/2000 data_batch_5,  Train_loss : 5671.2749  Test_loss : 6001.3208, Time/batch_file : 2.2805, Training time: 3876.1981\n",
      "Epoch : 334/2000 data_batch_1,  Train_loss : 5498.1021  Test_loss : 5881.6455, Time/batch_file : 2.2831, Training time: 3878.4814\n",
      "Epoch : 334/2000 data_batch_2,  Train_loss : 5738.8887  Test_loss : 6265.4902, Time/batch_file : 2.3066, Training time: 3880.7882\n",
      "Epoch : 334/2000 data_batch_3,  Train_loss : 5480.9351  Test_loss : 6086.4712, Time/batch_file : 2.2797, Training time: 3883.0680\n",
      "Epoch : 334/2000 data_batch_4,  Train_loss : 5718.4248  Test_loss : 6482.5312, Time/batch_file : 2.3045, Training time: 3885.3726\n",
      "Epoch : 334/2000 data_batch_5,  Train_loss : 5658.1924  Test_loss : 5722.6250, Time/batch_file : 2.2792, Training time: 3887.6520\n",
      "Epoch : 335/2000 data_batch_1,  Train_loss : 5352.1641  Test_loss : 6007.1738, Time/batch_file : 2.3237, Training time: 3889.9759\n",
      "Epoch : 335/2000 data_batch_2,  Train_loss : 5546.3574  Test_loss : 6067.9233, Time/batch_file : 2.3037, Training time: 3892.2798\n",
      "Epoch : 335/2000 data_batch_3,  Train_loss : 5548.8340  Test_loss : 6281.7910, Time/batch_file : 2.2903, Training time: 3894.5703\n",
      "Epoch : 335/2000 data_batch_4,  Train_loss : 5469.7568  Test_loss : 5721.0107, Time/batch_file : 2.3083, Training time: 3896.8789\n",
      "Epoch : 335/2000 data_batch_5,  Train_loss : 5417.0479  Test_loss : 6018.7617, Time/batch_file : 2.2920, Training time: 3899.1712\n",
      "Epoch : 336/2000 data_batch_1,  Train_loss : 5593.2598  Test_loss : 6202.7847, Time/batch_file : 2.3038, Training time: 3901.4752\n",
      "Epoch : 336/2000 data_batch_2,  Train_loss : 5795.7695  Test_loss : 6210.9521, Time/batch_file : 2.2714, Training time: 3903.7467\n",
      "Epoch : 336/2000 data_batch_3,  Train_loss : 5863.6899  Test_loss : 6477.5576, Time/batch_file : 2.2958, Training time: 3906.0426\n",
      "Epoch : 336/2000 data_batch_4,  Train_loss : 5915.6562  Test_loss : 6865.6597, Time/batch_file : 2.2975, Training time: 3908.3403\n",
      "Epoch : 336/2000 data_batch_5,  Train_loss : 5890.7441  Test_loss : 6509.1484, Time/batch_file : 2.2757, Training time: 3910.6161\n",
      "Epoch : 337/2000 data_batch_1,  Train_loss : 5692.0415  Test_loss : 6831.3594, Time/batch_file : 2.3079, Training time: 3912.9243\n",
      "Epoch : 337/2000 data_batch_2,  Train_loss : 5969.5986  Test_loss : 6785.3174, Time/batch_file : 2.2761, Training time: 3915.2005\n",
      "Epoch : 337/2000 data_batch_3,  Train_loss : 5785.9131  Test_loss : 6927.4541, Time/batch_file : 2.3109, Training time: 3917.5119\n",
      "Epoch : 337/2000 data_batch_4,  Train_loss : 5984.1519  Test_loss : 7249.8145, Time/batch_file : 2.3005, Training time: 3919.8126\n",
      "Epoch : 337/2000 data_batch_5,  Train_loss : 5722.0400  Test_loss : 6828.0234, Time/batch_file : 2.3073, Training time: 3922.1201\n",
      "Epoch : 338/2000 data_batch_1,  Train_loss : 6212.4414  Test_loss : 5645.6948, Time/batch_file : 2.2929, Training time: 3924.4132\n",
      "Epoch : 338/2000 data_batch_2,  Train_loss : 5856.5361  Test_loss : 5572.2100, Time/batch_file : 2.2750, Training time: 3926.6883\n",
      "Epoch : 338/2000 data_batch_3,  Train_loss : 5827.8711  Test_loss : 5784.8955, Time/batch_file : 2.2904, Training time: 3928.9789\n",
      "Epoch : 338/2000 data_batch_4,  Train_loss : 5873.0986  Test_loss : 5605.2451, Time/batch_file : 2.2654, Training time: 3931.2445\n",
      "Epoch : 338/2000 data_batch_5,  Train_loss : 5579.0190  Test_loss : 5267.7764, Time/batch_file : 2.2887, Training time: 3933.5333\n",
      "Epoch : 339/2000 data_batch_1,  Train_loss : 6201.3135  Test_loss : 5714.5059, Time/batch_file : 2.2722, Training time: 3935.8057\n",
      "Epoch : 339/2000 data_batch_2,  Train_loss : 6133.3506  Test_loss : 5805.6641, Time/batch_file : 2.2970, Training time: 3938.1028\n",
      "Epoch : 339/2000 data_batch_3,  Train_loss : 6065.1875  Test_loss : 6185.4771, Time/batch_file : 2.2950, Training time: 3940.3980\n",
      "Epoch : 339/2000 data_batch_4,  Train_loss : 5880.4443  Test_loss : 5878.0005, Time/batch_file : 2.2839, Training time: 3942.6821\n",
      "Epoch : 339/2000 data_batch_5,  Train_loss : 6004.3696  Test_loss : 5753.7734, Time/batch_file : 2.3205, Training time: 3945.0028\n",
      "Epoch : 340/2000 data_batch_1,  Train_loss : 5605.7988  Test_loss : 5966.7808, Time/batch_file : 2.2641, Training time: 3947.2671\n",
      "Epoch : 340/2000 data_batch_2,  Train_loss : 5948.9761  Test_loss : 6290.8623, Time/batch_file : 2.2996, Training time: 3949.5669\n",
      "Epoch : 340/2000 data_batch_3,  Train_loss : 5845.3628  Test_loss : 6240.0098, Time/batch_file : 2.2706, Training time: 3951.8377\n",
      "Epoch : 340/2000 data_batch_4,  Train_loss : 5836.9604  Test_loss : 6025.1670, Time/batch_file : 2.2924, Training time: 3954.1304\n",
      "Epoch : 340/2000 data_batch_5,  Train_loss : 5590.0205  Test_loss : 6301.5083, Time/batch_file : 2.2819, Training time: 3956.4126\n",
      "[./nets/net-340.ckpt] SAVED\n",
      "Epoch : 341/2000 data_batch_1,  Train_loss : 5823.6240  Test_loss : 5900.9463, Time/batch_file : 2.3204, Training time: 3960.0251\n",
      "Epoch : 341/2000 data_batch_2,  Train_loss : 6139.4497  Test_loss : 6049.7539, Time/batch_file : 2.3016, Training time: 3962.3269\n",
      "Epoch : 341/2000 data_batch_3,  Train_loss : 5885.0420  Test_loss : 5846.5576, Time/batch_file : 2.3269, Training time: 3964.6541\n",
      "Epoch : 341/2000 data_batch_4,  Train_loss : 6065.5952  Test_loss : 5999.6035, Time/batch_file : 2.3046, Training time: 3966.9588\n",
      "Epoch : 341/2000 data_batch_5,  Train_loss : 5718.2275  Test_loss : 5901.4595, Time/batch_file : 2.3209, Training time: 3969.2799\n",
      "Epoch : 342/2000 data_batch_1,  Train_loss : 6225.1694  Test_loss : 6171.8105, Time/batch_file : 2.2997, Training time: 3971.5798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 342/2000 data_batch_2,  Train_loss : 6385.9912  Test_loss : 5887.9727, Time/batch_file : 2.3073, Training time: 3973.8873\n",
      "Epoch : 342/2000 data_batch_3,  Train_loss : 6140.4346  Test_loss : 6117.3145, Time/batch_file : 2.2858, Training time: 3976.1733\n",
      "Epoch : 342/2000 data_batch_4,  Train_loss : 6024.3730  Test_loss : 5668.2549, Time/batch_file : 2.3197, Training time: 3978.4932\n",
      "Epoch : 342/2000 data_batch_5,  Train_loss : 5997.4526  Test_loss : 5895.1768, Time/batch_file : 2.3020, Training time: 3980.7955\n",
      "Epoch : 343/2000 data_batch_1,  Train_loss : 5556.7705  Test_loss : 6139.9756, Time/batch_file : 2.2928, Training time: 3983.0884\n",
      "Epoch : 343/2000 data_batch_2,  Train_loss : 5399.9497  Test_loss : 5877.8931, Time/batch_file : 2.2786, Training time: 3985.3672\n",
      "Epoch : 343/2000 data_batch_3,  Train_loss : 5777.9199  Test_loss : 6338.4380, Time/batch_file : 2.3090, Training time: 3987.6763\n",
      "Epoch : 343/2000 data_batch_4,  Train_loss : 5407.8721  Test_loss : 6144.6396, Time/batch_file : 2.3028, Training time: 3989.9794\n",
      "Epoch : 343/2000 data_batch_5,  Train_loss : 5480.9399  Test_loss : 6146.1562, Time/batch_file : 2.2929, Training time: 3992.2724\n",
      "Epoch : 344/2000 data_batch_1,  Train_loss : 5857.2700  Test_loss : 5684.9292, Time/batch_file : 2.2911, Training time: 3994.5638\n",
      "Epoch : 344/2000 data_batch_2,  Train_loss : 6006.9473  Test_loss : 6388.1182, Time/batch_file : 2.2924, Training time: 3996.8565\n",
      "Epoch : 344/2000 data_batch_3,  Train_loss : 6050.1235  Test_loss : 5935.2134, Time/batch_file : 2.2815, Training time: 3999.1382\n",
      "Epoch : 344/2000 data_batch_4,  Train_loss : 5909.4609  Test_loss : 5874.8945, Time/batch_file : 2.2859, Training time: 4001.4243\n",
      "Epoch : 344/2000 data_batch_5,  Train_loss : 5908.6260  Test_loss : 5573.5259, Time/batch_file : 2.2951, Training time: 4003.7197\n",
      "Epoch : 345/2000 data_batch_1,  Train_loss : 5672.9834  Test_loss : 6101.4756, Time/batch_file : 2.3305, Training time: 4006.0504\n",
      "Epoch : 345/2000 data_batch_2,  Train_loss : 5563.1484  Test_loss : 6045.1133, Time/batch_file : 2.2984, Training time: 4008.3490\n",
      "Epoch : 345/2000 data_batch_3,  Train_loss : 5636.2222  Test_loss : 6162.0298, Time/batch_file : 2.3170, Training time: 4010.6662\n",
      "Epoch : 345/2000 data_batch_4,  Train_loss : 5716.2700  Test_loss : 6273.1152, Time/batch_file : 2.2813, Training time: 4012.9477\n",
      "Epoch : 345/2000 data_batch_5,  Train_loss : 5589.7803  Test_loss : 5947.4121, Time/batch_file : 2.3028, Training time: 4015.2507\n",
      "Epoch : 346/2000 data_batch_1,  Train_loss : 5760.2036  Test_loss : 5750.3892, Time/batch_file : 2.2919, Training time: 4017.5429\n",
      "Epoch : 346/2000 data_batch_2,  Train_loss : 5809.2617  Test_loss : 5940.6304, Time/batch_file : 2.2844, Training time: 4019.8275\n",
      "Epoch : 346/2000 data_batch_3,  Train_loss : 6013.2539  Test_loss : 6337.8286, Time/batch_file : 2.3233, Training time: 4022.1511\n",
      "Epoch : 346/2000 data_batch_4,  Train_loss : 6012.7041  Test_loss : 5839.9312, Time/batch_file : 2.2928, Training time: 4024.4440\n",
      "Epoch : 346/2000 data_batch_5,  Train_loss : 6205.9697  Test_loss : 5394.9409, Time/batch_file : 2.2992, Training time: 4026.7434\n",
      "Epoch : 347/2000 data_batch_1,  Train_loss : 5592.5962  Test_loss : 5795.5283, Time/batch_file : 2.2863, Training time: 4029.0300\n",
      "Epoch : 347/2000 data_batch_2,  Train_loss : 5301.2891  Test_loss : 5674.2109, Time/batch_file : 2.2992, Training time: 4031.3293\n",
      "Epoch : 347/2000 data_batch_3,  Train_loss : 5413.6362  Test_loss : 5750.5566, Time/batch_file : 2.2965, Training time: 4033.6259\n",
      "Epoch : 347/2000 data_batch_4,  Train_loss : 5428.0371  Test_loss : 5878.1836, Time/batch_file : 2.2773, Training time: 4035.9033\n",
      "Epoch : 347/2000 data_batch_5,  Train_loss : 5291.6055  Test_loss : 5697.7129, Time/batch_file : 2.3232, Training time: 4038.2267\n",
      "Epoch : 348/2000 data_batch_1,  Train_loss : 5851.9512  Test_loss : 6160.1855, Time/batch_file : 2.2942, Training time: 4040.5210\n",
      "Epoch : 348/2000 data_batch_2,  Train_loss : 6000.1187  Test_loss : 6103.9438, Time/batch_file : 2.3165, Training time: 4042.8377\n",
      "Epoch : 348/2000 data_batch_3,  Train_loss : 6072.4414  Test_loss : 6102.0742, Time/batch_file : 2.2823, Training time: 4045.1203\n",
      "Epoch : 348/2000 data_batch_4,  Train_loss : 5902.2983  Test_loss : 6400.3203, Time/batch_file : 2.2900, Training time: 4047.4105\n",
      "Epoch : 348/2000 data_batch_5,  Train_loss : 6087.2539  Test_loss : 6082.8906, Time/batch_file : 2.3030, Training time: 4049.7137\n",
      "Epoch : 349/2000 data_batch_1,  Train_loss : 5795.2827  Test_loss : 5441.7373, Time/batch_file : 2.2960, Training time: 4052.0098\n",
      "Epoch : 349/2000 data_batch_2,  Train_loss : 5670.5923  Test_loss : 5551.0039, Time/batch_file : 2.3211, Training time: 4054.3311\n",
      "Epoch : 349/2000 data_batch_3,  Train_loss : 5859.0503  Test_loss : 5134.5869, Time/batch_file : 2.3079, Training time: 4056.6391\n",
      "Epoch : 349/2000 data_batch_4,  Train_loss : 5617.3325  Test_loss : 5308.5093, Time/batch_file : 2.3108, Training time: 4058.9501\n",
      "Epoch : 349/2000 data_batch_5,  Train_loss : 5569.7905  Test_loss : 5747.9424, Time/batch_file : 2.2765, Training time: 4061.2268\n",
      "Epoch : 350/2000 data_batch_1,  Train_loss : 6112.0020  Test_loss : 5428.0859, Time/batch_file : 2.3083, Training time: 4063.5351\n",
      "Epoch : 350/2000 data_batch_2,  Train_loss : 6015.4961  Test_loss : 5265.7383, Time/batch_file : 2.2934, Training time: 4065.8287\n",
      "Epoch : 350/2000 data_batch_3,  Train_loss : 6237.9351  Test_loss : 5466.8574, Time/batch_file : 2.2771, Training time: 4068.1061\n",
      "Epoch : 350/2000 data_batch_4,  Train_loss : 6083.3608  Test_loss : 5700.6719, Time/batch_file : 2.3230, Training time: 4070.4293\n",
      "Epoch : 350/2000 data_batch_5,  Train_loss : 6038.7383  Test_loss : 5421.2817, Time/batch_file : 2.2919, Training time: 4072.7213\n",
      "[./nets/net-350.ckpt] SAVED\n",
      "Epoch : 351/2000 data_batch_1,  Train_loss : 5288.2764  Test_loss : 5928.3252, Time/batch_file : 2.2967, Training time: 4076.3047\n",
      "Epoch : 351/2000 data_batch_2,  Train_loss : 5379.1602  Test_loss : 5769.9844, Time/batch_file : 2.2804, Training time: 4078.5853\n",
      "Epoch : 351/2000 data_batch_3,  Train_loss : 5535.8848  Test_loss : 6088.0630, Time/batch_file : 2.2781, Training time: 4080.8636\n",
      "Epoch : 351/2000 data_batch_4,  Train_loss : 5811.5264  Test_loss : 5978.4951, Time/batch_file : 2.2801, Training time: 4083.1439\n",
      "Epoch : 351/2000 data_batch_5,  Train_loss : 5778.0732  Test_loss : 5922.0547, Time/batch_file : 2.2784, Training time: 4085.4225\n",
      "Epoch : 352/2000 data_batch_1,  Train_loss : 5574.4204  Test_loss : 6247.7432, Time/batch_file : 2.2811, Training time: 4087.7038\n",
      "Epoch : 352/2000 data_batch_2,  Train_loss : 6157.5044  Test_loss : 5935.2568, Time/batch_file : 2.2728, Training time: 4089.9768\n",
      "Epoch : 352/2000 data_batch_3,  Train_loss : 5979.9629  Test_loss : 5991.7314, Time/batch_file : 2.2763, Training time: 4092.2534\n",
      "Epoch : 352/2000 data_batch_4,  Train_loss : 5896.6895  Test_loss : 6265.2646, Time/batch_file : 2.2721, Training time: 4094.5256\n",
      "Epoch : 352/2000 data_batch_5,  Train_loss : 6192.4585  Test_loss : 6245.8662, Time/batch_file : 2.2867, Training time: 4096.8124\n",
      "Epoch : 353/2000 data_batch_1,  Train_loss : 5643.0527  Test_loss : 5953.8599, Time/batch_file : 2.2777, Training time: 4099.0904\n",
      "Epoch : 353/2000 data_batch_2,  Train_loss : 5878.8721  Test_loss : 6116.5674, Time/batch_file : 2.2950, Training time: 4101.3855\n",
      "Epoch : 353/2000 data_batch_3,  Train_loss : 5303.6802  Test_loss : 6110.7104, Time/batch_file : 2.2787, Training time: 4103.6644\n",
      "Epoch : 353/2000 data_batch_4,  Train_loss : 5385.4131  Test_loss : 6449.3242, Time/batch_file : 2.3008, Training time: 4105.9655\n",
      "Epoch : 353/2000 data_batch_5,  Train_loss : 5270.3345  Test_loss : 5999.6719, Time/batch_file : 2.2792, Training time: 4108.2448\n",
      "Epoch : 354/2000 data_batch_1,  Train_loss : 5946.0625  Test_loss : 5455.6978, Time/batch_file : 2.2848, Training time: 4110.5299\n",
      "Epoch : 354/2000 data_batch_2,  Train_loss : 6547.7144  Test_loss : 5325.8076, Time/batch_file : 2.2791, Training time: 4112.8092\n",
      "Epoch : 354/2000 data_batch_3,  Train_loss : 6156.5571  Test_loss : 5163.4106, Time/batch_file : 2.2869, Training time: 4115.0963\n",
      "Epoch : 354/2000 data_batch_4,  Train_loss : 6333.9727  Test_loss : 5701.6826, Time/batch_file : 2.2744, Training time: 4117.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 354/2000 data_batch_5,  Train_loss : 5864.9443  Test_loss : 5518.5317, Time/batch_file : 2.2890, Training time: 4119.6602\n",
      "Epoch : 355/2000 data_batch_1,  Train_loss : 5426.4028  Test_loss : 5804.8989, Time/batch_file : 2.2652, Training time: 4121.9257\n",
      "Epoch : 355/2000 data_batch_2,  Train_loss : 5525.6323  Test_loss : 5999.8359, Time/batch_file : 2.2941, Training time: 4124.2199\n",
      "Epoch : 355/2000 data_batch_3,  Train_loss : 5835.8730  Test_loss : 6027.5195, Time/batch_file : 2.2610, Training time: 4126.4811\n",
      "Epoch : 355/2000 data_batch_4,  Train_loss : 5897.4380  Test_loss : 6279.9531, Time/batch_file : 2.2837, Training time: 4128.7651\n",
      "Epoch : 355/2000 data_batch_5,  Train_loss : 5829.7104  Test_loss : 5696.3257, Time/batch_file : 2.2771, Training time: 4131.0424\n",
      "Epoch : 356/2000 data_batch_1,  Train_loss : 6265.3662  Test_loss : 6693.9502, Time/batch_file : 2.2832, Training time: 4133.3258\n",
      "Epoch : 356/2000 data_batch_2,  Train_loss : 6101.0142  Test_loss : 6189.6543, Time/batch_file : 2.2828, Training time: 4135.6087\n",
      "Epoch : 356/2000 data_batch_3,  Train_loss : 6190.7051  Test_loss : 6537.6860, Time/batch_file : 2.3110, Training time: 4137.9199\n",
      "Epoch : 356/2000 data_batch_4,  Train_loss : 6153.9795  Test_loss : 6525.8169, Time/batch_file : 2.2967, Training time: 4140.2169\n",
      "Epoch : 356/2000 data_batch_5,  Train_loss : 6201.6294  Test_loss : 6258.4395, Time/batch_file : 2.2836, Training time: 4142.5006\n",
      "Epoch : 357/2000 data_batch_1,  Train_loss : 6136.5132  Test_loss : 6579.5415, Time/batch_file : 2.3049, Training time: 4144.8057\n",
      "Epoch : 357/2000 data_batch_2,  Train_loss : 5832.9883  Test_loss : 6008.8789, Time/batch_file : 2.2837, Training time: 4147.0896\n",
      "Epoch : 357/2000 data_batch_3,  Train_loss : 6149.5781  Test_loss : 6364.1240, Time/batch_file : 2.2696, Training time: 4149.3593\n",
      "Epoch : 357/2000 data_batch_4,  Train_loss : 5640.5840  Test_loss : 6434.8535, Time/batch_file : 2.2889, Training time: 4151.6484\n",
      "Epoch : 357/2000 data_batch_5,  Train_loss : 5833.6978  Test_loss : 6358.4077, Time/batch_file : 2.2782, Training time: 4153.9267\n",
      "Epoch : 358/2000 data_batch_1,  Train_loss : 5914.8354  Test_loss : 5986.2207, Time/batch_file : 2.2784, Training time: 4156.2053\n",
      "Epoch : 358/2000 data_batch_2,  Train_loss : 5768.9517  Test_loss : 6190.5635, Time/batch_file : 2.2782, Training time: 4158.4837\n",
      "Epoch : 358/2000 data_batch_3,  Train_loss : 6038.3682  Test_loss : 6340.7300, Time/batch_file : 2.2633, Training time: 4160.7472\n",
      "Epoch : 358/2000 data_batch_4,  Train_loss : 5777.6924  Test_loss : 5911.0874, Time/batch_file : 2.2918, Training time: 4163.0392\n",
      "Epoch : 358/2000 data_batch_5,  Train_loss : 6163.1865  Test_loss : 5992.4214, Time/batch_file : 2.2698, Training time: 4165.3095\n",
      "Epoch : 359/2000 data_batch_1,  Train_loss : 6166.7954  Test_loss : 6345.6201, Time/batch_file : 2.2993, Training time: 4167.6090\n",
      "Epoch : 359/2000 data_batch_2,  Train_loss : 6161.6143  Test_loss : 6315.5166, Time/batch_file : 2.2835, Training time: 4169.8928\n",
      "Epoch : 359/2000 data_batch_3,  Train_loss : 6115.3018  Test_loss : 6120.6572, Time/batch_file : 2.2836, Training time: 4172.1765\n",
      "Epoch : 359/2000 data_batch_4,  Train_loss : 6504.2007  Test_loss : 6028.1460, Time/batch_file : 2.3000, Training time: 4174.4768\n",
      "Epoch : 359/2000 data_batch_5,  Train_loss : 6001.2427  Test_loss : 6269.4639, Time/batch_file : 2.2837, Training time: 4176.7607\n",
      "Epoch : 360/2000 data_batch_1,  Train_loss : 5566.9253  Test_loss : 5978.2217, Time/batch_file : 2.2855, Training time: 4179.0465\n",
      "Epoch : 360/2000 data_batch_2,  Train_loss : 5340.1074  Test_loss : 5964.6821, Time/batch_file : 2.2783, Training time: 4181.3250\n",
      "Epoch : 360/2000 data_batch_3,  Train_loss : 5762.7793  Test_loss : 6258.2744, Time/batch_file : 2.2836, Training time: 4183.6088\n",
      "Epoch : 360/2000 data_batch_4,  Train_loss : 5547.6768  Test_loss : 6027.1182, Time/batch_file : 2.2829, Training time: 4185.8918\n",
      "Epoch : 360/2000 data_batch_5,  Train_loss : 5701.8008  Test_loss : 5876.4888, Time/batch_file : 2.2915, Training time: 4188.1836\n",
      "[./nets/net-360.ckpt] SAVED\n",
      "Epoch : 361/2000 data_batch_1,  Train_loss : 5643.5420  Test_loss : 6261.5469, Time/batch_file : 2.3082, Training time: 4191.7872\n",
      "Epoch : 361/2000 data_batch_2,  Train_loss : 5522.7251  Test_loss : 6203.3389, Time/batch_file : 2.3175, Training time: 4194.1048\n",
      "Epoch : 361/2000 data_batch_3,  Train_loss : 5669.8989  Test_loss : 6652.6533, Time/batch_file : 2.2810, Training time: 4196.3860\n",
      "Epoch : 361/2000 data_batch_4,  Train_loss : 5561.5298  Test_loss : 6192.6875, Time/batch_file : 2.2964, Training time: 4198.6825\n",
      "Epoch : 361/2000 data_batch_5,  Train_loss : 5605.0815  Test_loss : 6890.9658, Time/batch_file : 2.3009, Training time: 4200.9835\n",
      "Epoch : 362/2000 data_batch_1,  Train_loss : 5447.1719  Test_loss : 5917.7744, Time/batch_file : 2.3170, Training time: 4203.3008\n",
      "Epoch : 362/2000 data_batch_2,  Train_loss : 5450.5977  Test_loss : 5356.0215, Time/batch_file : 2.3072, Training time: 4205.6082\n",
      "Epoch : 362/2000 data_batch_3,  Train_loss : 5409.8467  Test_loss : 5855.5625, Time/batch_file : 2.2971, Training time: 4207.9054\n",
      "Epoch : 362/2000 data_batch_4,  Train_loss : 5510.4531  Test_loss : 5892.0454, Time/batch_file : 2.3050, Training time: 4210.2106\n",
      "Epoch : 362/2000 data_batch_5,  Train_loss : 5729.3691  Test_loss : 5752.8672, Time/batch_file : 2.2881, Training time: 4212.4990\n",
      "Epoch : 363/2000 data_batch_1,  Train_loss : 5470.6006  Test_loss : 5754.1553, Time/batch_file : 2.3331, Training time: 4214.8322\n",
      "Epoch : 363/2000 data_batch_2,  Train_loss : 5301.1792  Test_loss : 5698.6631, Time/batch_file : 2.3063, Training time: 4217.1389\n",
      "Epoch : 363/2000 data_batch_3,  Train_loss : 5546.5820  Test_loss : 5813.9712, Time/batch_file : 2.3249, Training time: 4219.4639\n",
      "Epoch : 363/2000 data_batch_4,  Train_loss : 5339.5718  Test_loss : 5969.5391, Time/batch_file : 2.3368, Training time: 4221.8009\n",
      "Epoch : 363/2000 data_batch_5,  Train_loss : 5526.7007  Test_loss : 5703.2031, Time/batch_file : 2.3331, Training time: 4224.1342\n",
      "Epoch : 364/2000 data_batch_1,  Train_loss : 6228.8672  Test_loss : 6057.4023, Time/batch_file : 2.3119, Training time: 4226.4462\n",
      "Epoch : 364/2000 data_batch_2,  Train_loss : 6629.9551  Test_loss : 5859.7012, Time/batch_file : 2.2851, Training time: 4228.7315\n",
      "Epoch : 364/2000 data_batch_3,  Train_loss : 6041.3682  Test_loss : 5681.3281, Time/batch_file : 2.3111, Training time: 4231.0428\n",
      "Epoch : 364/2000 data_batch_4,  Train_loss : 6362.0488  Test_loss : 6068.5889, Time/batch_file : 2.3236, Training time: 4233.3667\n",
      "Epoch : 364/2000 data_batch_5,  Train_loss : 6143.8037  Test_loss : 5746.4038, Time/batch_file : 2.2941, Training time: 4235.6609\n",
      "Epoch : 365/2000 data_batch_1,  Train_loss : 5690.3472  Test_loss : 5988.5176, Time/batch_file : 2.3296, Training time: 4237.9907\n",
      "Epoch : 365/2000 data_batch_2,  Train_loss : 5527.9521  Test_loss : 5747.9976, Time/batch_file : 2.2974, Training time: 4240.2883\n",
      "Epoch : 365/2000 data_batch_3,  Train_loss : 5673.4053  Test_loss : 5595.5835, Time/batch_file : 2.3153, Training time: 4242.6040\n",
      "Epoch : 365/2000 data_batch_4,  Train_loss : 5462.2275  Test_loss : 5556.0366, Time/batch_file : 2.3041, Training time: 4244.9083\n",
      "Epoch : 365/2000 data_batch_5,  Train_loss : 5795.3301  Test_loss : 5823.2861, Time/batch_file : 2.3456, Training time: 4247.2540\n",
      "Epoch : 366/2000 data_batch_1,  Train_loss : 5524.4004  Test_loss : 5133.0352, Time/batch_file : 2.3101, Training time: 4249.5643\n",
      "Epoch : 366/2000 data_batch_2,  Train_loss : 5405.1567  Test_loss : 5458.1748, Time/batch_file : 2.3082, Training time: 4251.8728\n",
      "Epoch : 366/2000 data_batch_3,  Train_loss : 5602.9761  Test_loss : 5235.0332, Time/batch_file : 2.2961, Training time: 4254.1691\n",
      "Epoch : 366/2000 data_batch_4,  Train_loss : 5447.0190  Test_loss : 5414.6240, Time/batch_file : 2.3262, Training time: 4256.4956\n",
      "Epoch : 366/2000 data_batch_5,  Train_loss : 5336.4414  Test_loss : 5262.4316, Time/batch_file : 2.2928, Training time: 4258.7885\n",
      "Epoch : 367/2000 data_batch_1,  Train_loss : 5400.9526  Test_loss : 6399.1211, Time/batch_file : 2.3113, Training time: 4261.1001\n",
      "Epoch : 367/2000 data_batch_2,  Train_loss : 5499.9824  Test_loss : 5811.1885, Time/batch_file : 2.2924, Training time: 4263.3927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 367/2000 data_batch_3,  Train_loss : 5261.8936  Test_loss : 6023.0103, Time/batch_file : 2.3049, Training time: 4265.6978\n",
      "Epoch : 367/2000 data_batch_4,  Train_loss : 5264.0112  Test_loss : 6305.1973, Time/batch_file : 2.3152, Training time: 4268.0132\n",
      "Epoch : 367/2000 data_batch_5,  Train_loss : 5217.8252  Test_loss : 6494.0703, Time/batch_file : 2.2853, Training time: 4270.2986\n",
      "Epoch : 368/2000 data_batch_1,  Train_loss : 6173.9863  Test_loss : 5966.8032, Time/batch_file : 2.3145, Training time: 4272.6134\n",
      "Epoch : 368/2000 data_batch_2,  Train_loss : 5796.9019  Test_loss : 6059.5757, Time/batch_file : 2.3182, Training time: 4274.9318\n",
      "Epoch : 368/2000 data_batch_3,  Train_loss : 5891.2261  Test_loss : 5946.9961, Time/batch_file : 2.3023, Training time: 4277.2343\n",
      "Epoch : 368/2000 data_batch_4,  Train_loss : 5927.3691  Test_loss : 6003.5127, Time/batch_file : 2.3307, Training time: 4279.5652\n",
      "Epoch : 368/2000 data_batch_5,  Train_loss : 5967.2964  Test_loss : 5981.2056, Time/batch_file : 2.3092, Training time: 4281.8746\n",
      "Epoch : 369/2000 data_batch_1,  Train_loss : 5685.4600  Test_loss : 5832.0112, Time/batch_file : 2.3066, Training time: 4284.1815\n",
      "Epoch : 369/2000 data_batch_2,  Train_loss : 5271.9473  Test_loss : 6015.8770, Time/batch_file : 2.2913, Training time: 4286.4731\n",
      "Epoch : 369/2000 data_batch_3,  Train_loss : 5506.6665  Test_loss : 5661.8447, Time/batch_file : 2.3303, Training time: 4288.8036\n",
      "Epoch : 369/2000 data_batch_4,  Train_loss : 5373.7754  Test_loss : 5750.2739, Time/batch_file : 2.2845, Training time: 4291.0882\n",
      "Epoch : 369/2000 data_batch_5,  Train_loss : 5299.4351  Test_loss : 6060.6387, Time/batch_file : 2.3047, Training time: 4293.3931\n",
      "Epoch : 370/2000 data_batch_1,  Train_loss : 5399.1826  Test_loss : 6316.9888, Time/batch_file : 2.2973, Training time: 4295.6907\n",
      "Epoch : 370/2000 data_batch_2,  Train_loss : 5323.6309  Test_loss : 6200.6016, Time/batch_file : 2.3112, Training time: 4298.0021\n",
      "Epoch : 370/2000 data_batch_3,  Train_loss : 5734.3745  Test_loss : 6240.7051, Time/batch_file : 2.2972, Training time: 4300.2995\n",
      "Epoch : 370/2000 data_batch_4,  Train_loss : 5458.0732  Test_loss : 6183.5166, Time/batch_file : 2.3168, Training time: 4302.6164\n",
      "Epoch : 370/2000 data_batch_5,  Train_loss : 5551.2500  Test_loss : 5839.7910, Time/batch_file : 2.3047, Training time: 4304.9213\n",
      "[./nets/net-370.ckpt] SAVED\n",
      "Epoch : 371/2000 data_batch_1,  Train_loss : 5576.2969  Test_loss : 6041.0400, Time/batch_file : 2.2886, Training time: 4308.5111\n",
      "Epoch : 371/2000 data_batch_2,  Train_loss : 5625.1782  Test_loss : 6199.6143, Time/batch_file : 2.3015, Training time: 4310.8128\n",
      "Epoch : 371/2000 data_batch_3,  Train_loss : 5794.5322  Test_loss : 6032.4009, Time/batch_file : 2.2992, Training time: 4313.1122\n",
      "Epoch : 371/2000 data_batch_4,  Train_loss : 5918.4819  Test_loss : 5563.6021, Time/batch_file : 2.2835, Training time: 4315.3959\n",
      "Epoch : 371/2000 data_batch_5,  Train_loss : 5862.4678  Test_loss : 5894.4561, Time/batch_file : 2.2990, Training time: 4317.6951\n",
      "Epoch : 372/2000 data_batch_1,  Train_loss : 5513.2725  Test_loss : 5991.6074, Time/batch_file : 2.3087, Training time: 4320.0040\n",
      "Epoch : 372/2000 data_batch_2,  Train_loss : 5684.9160  Test_loss : 5919.5283, Time/batch_file : 2.2865, Training time: 4322.2907\n",
      "Epoch : 372/2000 data_batch_3,  Train_loss : 5395.9062  Test_loss : 5995.1367, Time/batch_file : 2.3000, Training time: 4324.5909\n",
      "Epoch : 372/2000 data_batch_4,  Train_loss : 5439.4360  Test_loss : 5907.2178, Time/batch_file : 2.2890, Training time: 4326.8802\n",
      "Epoch : 372/2000 data_batch_5,  Train_loss : 5571.6353  Test_loss : 6267.2417, Time/batch_file : 2.3012, Training time: 4329.1817\n",
      "Epoch : 373/2000 data_batch_1,  Train_loss : 5302.4512  Test_loss : 5801.3125, Time/batch_file : 2.3084, Training time: 4331.4904\n",
      "Epoch : 373/2000 data_batch_2,  Train_loss : 5512.0854  Test_loss : 6008.6562, Time/batch_file : 2.3051, Training time: 4333.7957\n",
      "Epoch : 373/2000 data_batch_3,  Train_loss : 5189.6475  Test_loss : 6095.8862, Time/batch_file : 2.2975, Training time: 4336.0934\n",
      "Epoch : 373/2000 data_batch_4,  Train_loss : 5276.4277  Test_loss : 6037.4531, Time/batch_file : 2.3058, Training time: 4338.3994\n",
      "Epoch : 373/2000 data_batch_5,  Train_loss : 5267.7388  Test_loss : 5867.1333, Time/batch_file : 2.2950, Training time: 4340.6946\n",
      "Epoch : 374/2000 data_batch_1,  Train_loss : 5328.7217  Test_loss : 5938.6016, Time/batch_file : 2.3124, Training time: 4343.0071\n",
      "Epoch : 374/2000 data_batch_2,  Train_loss : 5563.1782  Test_loss : 6219.2910, Time/batch_file : 2.3129, Training time: 4345.3202\n",
      "Epoch : 374/2000 data_batch_3,  Train_loss : 5432.2168  Test_loss : 5925.1035, Time/batch_file : 2.2966, Training time: 4347.6171\n",
      "Epoch : 374/2000 data_batch_4,  Train_loss : 5352.2578  Test_loss : 6075.0757, Time/batch_file : 2.2956, Training time: 4349.9129\n",
      "Epoch : 374/2000 data_batch_5,  Train_loss : 5411.1826  Test_loss : 5954.5986, Time/batch_file : 2.3014, Training time: 4352.2146\n",
      "Epoch : 375/2000 data_batch_1,  Train_loss : 6215.6377  Test_loss : 5654.5742, Time/batch_file : 2.2965, Training time: 4354.5113\n",
      "Epoch : 375/2000 data_batch_2,  Train_loss : 5947.9780  Test_loss : 5839.8857, Time/batch_file : 2.3076, Training time: 4356.8191\n",
      "Epoch : 375/2000 data_batch_3,  Train_loss : 6000.7939  Test_loss : 5695.0723, Time/batch_file : 2.3032, Training time: 4359.1226\n",
      "Epoch : 375/2000 data_batch_4,  Train_loss : 6048.2129  Test_loss : 5470.3916, Time/batch_file : 2.3043, Training time: 4361.4272\n",
      "Epoch : 375/2000 data_batch_5,  Train_loss : 6027.0054  Test_loss : 5910.3242, Time/batch_file : 2.2927, Training time: 4363.7200\n",
      "Epoch : 376/2000 data_batch_1,  Train_loss : 5460.7432  Test_loss : 6258.0928, Time/batch_file : 2.2904, Training time: 4366.0106\n",
      "Epoch : 376/2000 data_batch_2,  Train_loss : 5253.9331  Test_loss : 5835.8149, Time/batch_file : 2.2881, Training time: 4368.2989\n",
      "Epoch : 376/2000 data_batch_3,  Train_loss : 5440.3198  Test_loss : 5990.4268, Time/batch_file : 2.2898, Training time: 4370.5890\n",
      "Epoch : 376/2000 data_batch_4,  Train_loss : 5321.6816  Test_loss : 6293.6030, Time/batch_file : 2.2853, Training time: 4372.8745\n",
      "Epoch : 376/2000 data_batch_5,  Train_loss : 5570.5825  Test_loss : 6140.5840, Time/batch_file : 2.2921, Training time: 4375.1669\n",
      "Epoch : 377/2000 data_batch_1,  Train_loss : 5476.3896  Test_loss : 5905.6880, Time/batch_file : 2.3171, Training time: 4377.4842\n",
      "Epoch : 377/2000 data_batch_2,  Train_loss : 5446.5093  Test_loss : 6240.1807, Time/batch_file : 2.3015, Training time: 4379.7859\n",
      "Epoch : 377/2000 data_batch_3,  Train_loss : 5561.1973  Test_loss : 6035.6904, Time/batch_file : 2.2850, Training time: 4382.0711\n",
      "Epoch : 377/2000 data_batch_4,  Train_loss : 5928.7451  Test_loss : 5860.2979, Time/batch_file : 2.2988, Training time: 4384.3701\n",
      "Epoch : 377/2000 data_batch_5,  Train_loss : 5671.3296  Test_loss : 6073.4067, Time/batch_file : 2.2933, Training time: 4386.6637\n",
      "Epoch : 378/2000 data_batch_1,  Train_loss : 5911.2090  Test_loss : 5375.4116, Time/batch_file : 2.3062, Training time: 4388.9702\n",
      "Epoch : 378/2000 data_batch_2,  Train_loss : 5951.0444  Test_loss : 6255.8169, Time/batch_file : 2.2942, Training time: 4391.2647\n",
      "Epoch : 378/2000 data_batch_3,  Train_loss : 5804.1123  Test_loss : 5744.5161, Time/batch_file : 2.2991, Training time: 4393.5640\n",
      "Epoch : 378/2000 data_batch_4,  Train_loss : 5844.3105  Test_loss : 5693.5063, Time/batch_file : 2.2914, Training time: 4395.8555\n",
      "Epoch : 378/2000 data_batch_5,  Train_loss : 6044.0459  Test_loss : 5410.2158, Time/batch_file : 2.3002, Training time: 4398.1559\n",
      "Epoch : 379/2000 data_batch_1,  Train_loss : 5873.0718  Test_loss : 6350.2090, Time/batch_file : 2.3013, Training time: 4400.4575\n",
      "Epoch : 379/2000 data_batch_2,  Train_loss : 5984.8359  Test_loss : 6169.3745, Time/batch_file : 2.3060, Training time: 4402.7637\n",
      "Epoch : 379/2000 data_batch_3,  Train_loss : 6069.1025  Test_loss : 6294.7295, Time/batch_file : 2.2967, Training time: 4405.0607\n",
      "Epoch : 379/2000 data_batch_4,  Train_loss : 6156.2842  Test_loss : 5945.1616, Time/batch_file : 2.2977, Training time: 4407.3587\n",
      "Epoch : 379/2000 data_batch_5,  Train_loss : 6064.6484  Test_loss : 6542.0088, Time/batch_file : 2.2907, Training time: 4409.6495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 380/2000 data_batch_1,  Train_loss : 5914.4243  Test_loss : 6030.6172, Time/batch_file : 2.3060, Training time: 4411.9556\n",
      "Epoch : 380/2000 data_batch_2,  Train_loss : 5862.2471  Test_loss : 6205.2275, Time/batch_file : 2.2956, Training time: 4414.2516\n",
      "Epoch : 380/2000 data_batch_3,  Train_loss : 5706.3945  Test_loss : 6311.5723, Time/batch_file : 2.2937, Training time: 4416.5455\n",
      "Epoch : 380/2000 data_batch_4,  Train_loss : 6044.3149  Test_loss : 5951.9463, Time/batch_file : 2.2946, Training time: 4418.8404\n",
      "Epoch : 380/2000 data_batch_5,  Train_loss : 5911.1357  Test_loss : 6019.9229, Time/batch_file : 2.2961, Training time: 4421.1367\n",
      "[./nets/net-380.ckpt] SAVED\n",
      "Epoch : 381/2000 data_batch_1,  Train_loss : 5590.5156  Test_loss : 5587.1108, Time/batch_file : 2.3070, Training time: 4425.8937\n",
      "Epoch : 381/2000 data_batch_2,  Train_loss : 5649.2129  Test_loss : 5588.9023, Time/batch_file : 2.3226, Training time: 4428.2165\n",
      "Epoch : 381/2000 data_batch_3,  Train_loss : 5824.5278  Test_loss : 5340.2090, Time/batch_file : 2.2936, Training time: 4430.5105\n",
      "Epoch : 381/2000 data_batch_4,  Train_loss : 5741.6538  Test_loss : 6017.4985, Time/batch_file : 2.3050, Training time: 4432.8157\n",
      "Epoch : 381/2000 data_batch_5,  Train_loss : 5548.9219  Test_loss : 5780.4038, Time/batch_file : 2.3082, Training time: 4435.1242\n",
      "Epoch : 382/2000 data_batch_1,  Train_loss : 5040.8496  Test_loss : 6061.6299, Time/batch_file : 2.3218, Training time: 4437.4463\n",
      "Epoch : 382/2000 data_batch_2,  Train_loss : 5242.9590  Test_loss : 5550.8574, Time/batch_file : 2.3052, Training time: 4439.7517\n",
      "Epoch : 382/2000 data_batch_3,  Train_loss : 4882.4492  Test_loss : 5709.2036, Time/batch_file : 2.2930, Training time: 4442.0451\n",
      "Epoch : 382/2000 data_batch_4,  Train_loss : 4882.0718  Test_loss : 5702.1177, Time/batch_file : 2.3119, Training time: 4444.3572\n",
      "Epoch : 382/2000 data_batch_5,  Train_loss : 4824.4678  Test_loss : 5638.1543, Time/batch_file : 2.3017, Training time: 4446.6590\n",
      "Epoch : 383/2000 data_batch_1,  Train_loss : 5973.4805  Test_loss : 6009.7603, Time/batch_file : 2.3143, Training time: 4448.9736\n",
      "Epoch : 383/2000 data_batch_2,  Train_loss : 5883.5498  Test_loss : 6188.8682, Time/batch_file : 2.2939, Training time: 4451.2677\n",
      "Epoch : 383/2000 data_batch_3,  Train_loss : 5748.2666  Test_loss : 6300.8594, Time/batch_file : 2.2889, Training time: 4453.5569\n",
      "Epoch : 383/2000 data_batch_4,  Train_loss : 5580.8716  Test_loss : 5743.1182, Time/batch_file : 2.2943, Training time: 4455.8513\n",
      "Epoch : 383/2000 data_batch_5,  Train_loss : 5958.9961  Test_loss : 6182.6616, Time/batch_file : 2.2984, Training time: 4458.1500\n",
      "Epoch : 384/2000 data_batch_1,  Train_loss : 5124.9189  Test_loss : 5413.1860, Time/batch_file : 2.2863, Training time: 4460.4365\n",
      "Epoch : 384/2000 data_batch_2,  Train_loss : 5452.8013  Test_loss : 5307.1309, Time/batch_file : 2.2944, Training time: 4462.7311\n",
      "Epoch : 384/2000 data_batch_3,  Train_loss : 5337.3765  Test_loss : 5364.3110, Time/batch_file : 2.3141, Training time: 4465.0453\n",
      "Epoch : 384/2000 data_batch_4,  Train_loss : 5285.8921  Test_loss : 5320.5781, Time/batch_file : 2.2845, Training time: 4467.3301\n",
      "Epoch : 384/2000 data_batch_5,  Train_loss : 4854.7417  Test_loss : 5054.1309, Time/batch_file : 2.2967, Training time: 4469.6269\n",
      "Epoch : 385/2000 data_batch_1,  Train_loss : 5060.7197  Test_loss : 5577.2402, Time/batch_file : 2.2822, Training time: 4471.9093\n",
      "Epoch : 385/2000 data_batch_2,  Train_loss : 4996.2407  Test_loss : 5802.4878, Time/batch_file : 2.2861, Training time: 4474.1955\n",
      "Epoch : 385/2000 data_batch_3,  Train_loss : 4980.4951  Test_loss : 6207.9141, Time/batch_file : 2.2825, Training time: 4476.4781\n",
      "Epoch : 385/2000 data_batch_4,  Train_loss : 4860.2373  Test_loss : 6160.4175, Time/batch_file : 2.2830, Training time: 4478.7613\n",
      "Epoch : 385/2000 data_batch_5,  Train_loss : 4917.4937  Test_loss : 5689.8906, Time/batch_file : 2.3018, Training time: 4481.0633\n",
      "Epoch : 386/2000 data_batch_1,  Train_loss : 5572.0869  Test_loss : 5870.6353, Time/batch_file : 2.3230, Training time: 4483.3864\n",
      "Epoch : 386/2000 data_batch_2,  Train_loss : 5631.5430  Test_loss : 6057.2510, Time/batch_file : 2.3187, Training time: 4485.7053\n",
      "Epoch : 386/2000 data_batch_3,  Train_loss : 5742.5527  Test_loss : 5964.4395, Time/batch_file : 2.3177, Training time: 4488.0231\n",
      "Epoch : 386/2000 data_batch_4,  Train_loss : 5561.4043  Test_loss : 5751.5249, Time/batch_file : 2.3074, Training time: 4490.3307\n",
      "Epoch : 386/2000 data_batch_5,  Train_loss : 5667.7485  Test_loss : 5714.3374, Time/batch_file : 2.3041, Training time: 4492.6351\n",
      "Epoch : 387/2000 data_batch_1,  Train_loss : 5607.6733  Test_loss : 5801.5547, Time/batch_file : 2.3025, Training time: 4494.9378\n",
      "Epoch : 387/2000 data_batch_2,  Train_loss : 5884.1953  Test_loss : 6212.5059, Time/batch_file : 2.3172, Training time: 4497.2552\n",
      "Epoch : 387/2000 data_batch_3,  Train_loss : 5798.3428  Test_loss : 5539.7295, Time/batch_file : 2.3069, Training time: 4499.5623\n",
      "Epoch : 387/2000 data_batch_4,  Train_loss : 5560.1226  Test_loss : 5598.2769, Time/batch_file : 2.2805, Training time: 4501.8431\n",
      "Epoch : 387/2000 data_batch_5,  Train_loss : 5850.2080  Test_loss : 5766.5615, Time/batch_file : 2.2899, Training time: 4504.1331\n",
      "Epoch : 388/2000 data_batch_1,  Train_loss : 5322.0996  Test_loss : 5862.6191, Time/batch_file : 2.2967, Training time: 4506.4299\n",
      "Epoch : 388/2000 data_batch_2,  Train_loss : 5383.7451  Test_loss : 5853.5259, Time/batch_file : 2.3035, Training time: 4508.7337\n",
      "Epoch : 388/2000 data_batch_3,  Train_loss : 5278.2598  Test_loss : 6112.4077, Time/batch_file : 2.3087, Training time: 4511.0426\n",
      "Epoch : 388/2000 data_batch_4,  Train_loss : 5520.7559  Test_loss : 6000.9004, Time/batch_file : 2.2973, Training time: 4513.3402\n",
      "Epoch : 388/2000 data_batch_5,  Train_loss : 5165.0967  Test_loss : 5716.9668, Time/batch_file : 2.3076, Training time: 4515.6480\n",
      "Epoch : 389/2000 data_batch_1,  Train_loss : 5742.5381  Test_loss : 5691.7544, Time/batch_file : 2.3082, Training time: 4517.9565\n",
      "Epoch : 389/2000 data_batch_2,  Train_loss : 5825.2632  Test_loss : 5605.0811, Time/batch_file : 2.3381, Training time: 4520.2947\n",
      "Epoch : 389/2000 data_batch_3,  Train_loss : 5605.7412  Test_loss : 5422.8696, Time/batch_file : 2.3099, Training time: 4522.6047\n",
      "Epoch : 389/2000 data_batch_4,  Train_loss : 5713.9028  Test_loss : 5482.4585, Time/batch_file : 2.3062, Training time: 4524.9111\n",
      "Epoch : 389/2000 data_batch_5,  Train_loss : 5327.3242  Test_loss : 5648.5801, Time/batch_file : 2.3161, Training time: 4527.2274\n",
      "Epoch : 390/2000 data_batch_1,  Train_loss : 5207.8779  Test_loss : 6374.7188, Time/batch_file : 2.2894, Training time: 4529.5169\n",
      "Epoch : 390/2000 data_batch_2,  Train_loss : 5602.0420  Test_loss : 6513.9927, Time/batch_file : 2.2998, Training time: 4531.8169\n",
      "Epoch : 390/2000 data_batch_3,  Train_loss : 5145.9854  Test_loss : 6556.8926, Time/batch_file : 2.2940, Training time: 4534.1111\n",
      "Epoch : 390/2000 data_batch_4,  Train_loss : 5237.2832  Test_loss : 6345.3438, Time/batch_file : 2.2943, Training time: 4536.4055\n",
      "Epoch : 390/2000 data_batch_5,  Train_loss : 5315.9839  Test_loss : 6891.9062, Time/batch_file : 2.2973, Training time: 4538.7030\n",
      "[./nets/net-390.ckpt] SAVED\n",
      "Epoch : 391/2000 data_batch_1,  Train_loss : 5724.3423  Test_loss : 5587.4072, Time/batch_file : 2.3028, Training time: 4542.2988\n",
      "Epoch : 391/2000 data_batch_2,  Train_loss : 5781.5986  Test_loss : 5644.6255, Time/batch_file : 2.2998, Training time: 4544.5989\n",
      "Epoch : 391/2000 data_batch_3,  Train_loss : 5643.1094  Test_loss : 5461.5371, Time/batch_file : 2.3032, Training time: 4546.9024\n",
      "Epoch : 391/2000 data_batch_4,  Train_loss : 5626.0005  Test_loss : 5923.0410, Time/batch_file : 2.3002, Training time: 4549.2028\n",
      "Epoch : 391/2000 data_batch_5,  Train_loss : 5988.1436  Test_loss : 5661.2690, Time/batch_file : 2.3006, Training time: 4551.5036\n",
      "Epoch : 392/2000 data_batch_1,  Train_loss : 5915.5210  Test_loss : 5792.8770, Time/batch_file : 2.2835, Training time: 4553.7873\n",
      "Epoch : 392/2000 data_batch_2,  Train_loss : 5833.3945  Test_loss : 5849.7671, Time/batch_file : 2.3079, Training time: 4556.0954\n",
      "Epoch : 392/2000 data_batch_3,  Train_loss : 5580.0762  Test_loss : 5870.8594, Time/batch_file : 2.2925, Training time: 4558.3881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 392/2000 data_batch_4,  Train_loss : 5651.3247  Test_loss : 5579.7700, Time/batch_file : 2.2794, Training time: 4560.6677\n",
      "Epoch : 392/2000 data_batch_5,  Train_loss : 5889.0283  Test_loss : 5990.1821, Time/batch_file : 2.2986, Training time: 4562.9664\n",
      "Epoch : 393/2000 data_batch_1,  Train_loss : 6294.5625  Test_loss : 6103.2578, Time/batch_file : 2.2966, Training time: 4565.2631\n",
      "Epoch : 393/2000 data_batch_2,  Train_loss : 6038.1621  Test_loss : 5895.6094, Time/batch_file : 2.2931, Training time: 4567.5564\n",
      "Epoch : 393/2000 data_batch_3,  Train_loss : 6375.9922  Test_loss : 6064.6772, Time/batch_file : 2.3086, Training time: 4569.8652\n",
      "Epoch : 393/2000 data_batch_4,  Train_loss : 6146.2715  Test_loss : 6203.7100, Time/batch_file : 2.2802, Training time: 4572.1455\n",
      "Epoch : 393/2000 data_batch_5,  Train_loss : 6340.5254  Test_loss : 6082.4995, Time/batch_file : 2.2874, Training time: 4574.4331\n",
      "Epoch : 394/2000 data_batch_1,  Train_loss : 5935.8203  Test_loss : 5948.7485, Time/batch_file : 2.2929, Training time: 4576.7262\n",
      "Epoch : 394/2000 data_batch_2,  Train_loss : 5963.0137  Test_loss : 5837.8965, Time/batch_file : 2.2794, Training time: 4579.0058\n",
      "Epoch : 394/2000 data_batch_3,  Train_loss : 5860.5229  Test_loss : 5693.2090, Time/batch_file : 2.2836, Training time: 4581.2896\n",
      "Epoch : 394/2000 data_batch_4,  Train_loss : 5794.4199  Test_loss : 5828.9727, Time/batch_file : 2.2987, Training time: 4583.5886\n",
      "Epoch : 394/2000 data_batch_5,  Train_loss : 5908.9668  Test_loss : 5989.3872, Time/batch_file : 2.2727, Training time: 4585.8615\n",
      "Epoch : 395/2000 data_batch_1,  Train_loss : 5691.0146  Test_loss : 5775.2910, Time/batch_file : 2.2886, Training time: 4588.1503\n",
      "Epoch : 395/2000 data_batch_2,  Train_loss : 5802.9067  Test_loss : 6103.4868, Time/batch_file : 2.2904, Training time: 4590.4408\n",
      "Epoch : 395/2000 data_batch_3,  Train_loss : 5598.0801  Test_loss : 6117.7466, Time/batch_file : 2.3034, Training time: 4592.7444\n",
      "Epoch : 395/2000 data_batch_4,  Train_loss : 5543.4839  Test_loss : 6183.1206, Time/batch_file : 2.2869, Training time: 4595.0315\n",
      "Epoch : 395/2000 data_batch_5,  Train_loss : 5557.1133  Test_loss : 5859.0488, Time/batch_file : 2.2727, Training time: 4597.3045\n",
      "Epoch : 396/2000 data_batch_1,  Train_loss : 5295.2588  Test_loss : 5720.1362, Time/batch_file : 2.2745, Training time: 4599.5792\n",
      "Epoch : 396/2000 data_batch_2,  Train_loss : 5238.0615  Test_loss : 6127.0566, Time/batch_file : 2.2861, Training time: 4601.8656\n",
      "Epoch : 396/2000 data_batch_3,  Train_loss : 5131.4092  Test_loss : 5803.5288, Time/batch_file : 2.2800, Training time: 4604.1457\n",
      "Epoch : 396/2000 data_batch_4,  Train_loss : 5161.8662  Test_loss : 5951.6592, Time/batch_file : 2.2866, Training time: 4606.4325\n",
      "Epoch : 396/2000 data_batch_5,  Train_loss : 5092.4868  Test_loss : 6085.7998, Time/batch_file : 2.2765, Training time: 4608.7091\n",
      "Epoch : 397/2000 data_batch_1,  Train_loss : 5130.2192  Test_loss : 5906.5645, Time/batch_file : 2.3128, Training time: 4611.0222\n",
      "Epoch : 397/2000 data_batch_2,  Train_loss : 5520.2734  Test_loss : 5922.2383, Time/batch_file : 2.2889, Training time: 4613.3115\n",
      "Epoch : 397/2000 data_batch_3,  Train_loss : 5320.5293  Test_loss : 6060.1689, Time/batch_file : 2.2769, Training time: 4615.5886\n",
      "Epoch : 397/2000 data_batch_4,  Train_loss : 5562.3916  Test_loss : 5825.4346, Time/batch_file : 2.3000, Training time: 4617.8887\n",
      "Epoch : 397/2000 data_batch_5,  Train_loss : 5667.6929  Test_loss : 5908.7422, Time/batch_file : 2.2760, Training time: 4620.1651\n",
      "Epoch : 398/2000 data_batch_1,  Train_loss : 5624.1758  Test_loss : 5617.4229, Time/batch_file : 2.2670, Training time: 4622.4324\n",
      "Epoch : 398/2000 data_batch_2,  Train_loss : 5701.7495  Test_loss : 5180.2510, Time/batch_file : 2.3058, Training time: 4624.7384\n",
      "Epoch : 398/2000 data_batch_3,  Train_loss : 5773.2461  Test_loss : 5960.0898, Time/batch_file : 2.2776, Training time: 4627.0161\n",
      "Epoch : 398/2000 data_batch_4,  Train_loss : 5888.0664  Test_loss : 6018.4600, Time/batch_file : 2.2992, Training time: 4629.3155\n",
      "Epoch : 398/2000 data_batch_5,  Train_loss : 5686.9707  Test_loss : 5530.1143, Time/batch_file : 2.2732, Training time: 4631.5888\n",
      "Epoch : 399/2000 data_batch_1,  Train_loss : 5785.1597  Test_loss : 5393.4258, Time/batch_file : 2.2939, Training time: 4633.8829\n",
      "Epoch : 399/2000 data_batch_2,  Train_loss : 5239.3838  Test_loss : 5601.0474, Time/batch_file : 2.2619, Training time: 4636.1450\n",
      "Epoch : 399/2000 data_batch_3,  Train_loss : 5699.9492  Test_loss : 5740.5317, Time/batch_file : 2.2971, Training time: 4638.4423\n",
      "Epoch : 399/2000 data_batch_4,  Train_loss : 5659.0137  Test_loss : 5555.0122, Time/batch_file : 2.2832, Training time: 4640.7257\n",
      "Epoch : 399/2000 data_batch_5,  Train_loss : 6016.0308  Test_loss : 5480.6279, Time/batch_file : 2.2979, Training time: 4643.0237\n",
      "Epoch : 400/2000 data_batch_1,  Train_loss : 5112.5718  Test_loss : 6492.2285, Time/batch_file : 2.2868, Training time: 4645.3107\n",
      "Epoch : 400/2000 data_batch_2,  Train_loss : 5142.7920  Test_loss : 6556.4858, Time/batch_file : 2.2674, Training time: 4647.5784\n",
      "Epoch : 400/2000 data_batch_3,  Train_loss : 5331.1748  Test_loss : 6238.3442, Time/batch_file : 2.3126, Training time: 4649.8912\n",
      "Epoch : 400/2000 data_batch_4,  Train_loss : 5344.2109  Test_loss : 6395.8311, Time/batch_file : 2.2749, Training time: 4652.1663\n",
      "Epoch : 400/2000 data_batch_5,  Train_loss : 5412.7466  Test_loss : 6599.5664, Time/batch_file : 2.3062, Training time: 4654.4727\n",
      "[./nets/net-400.ckpt] SAVED\n",
      "Epoch : 401/2000 data_batch_1,  Train_loss : 5397.4980  Test_loss : 5704.2397, Time/batch_file : 2.3238, Training time: 4658.1005\n",
      "Epoch : 401/2000 data_batch_2,  Train_loss : 5679.0498  Test_loss : 6327.7251, Time/batch_file : 2.3030, Training time: 4660.4038\n",
      "Epoch : 401/2000 data_batch_3,  Train_loss : 5687.7891  Test_loss : 6108.7466, Time/batch_file : 2.3035, Training time: 4662.7075\n",
      "Epoch : 401/2000 data_batch_4,  Train_loss : 5786.2656  Test_loss : 5838.1406, Time/batch_file : 2.2943, Training time: 4665.0021\n",
      "Epoch : 401/2000 data_batch_5,  Train_loss : 5870.6235  Test_loss : 5693.0049, Time/batch_file : 2.3117, Training time: 4667.3140\n",
      "Epoch : 402/2000 data_batch_1,  Train_loss : 6025.8916  Test_loss : 5722.2705, Time/batch_file : 2.2760, Training time: 4669.5902\n",
      "Epoch : 402/2000 data_batch_2,  Train_loss : 6122.6611  Test_loss : 5861.4155, Time/batch_file : 2.2766, Training time: 4671.8670\n",
      "Epoch : 402/2000 data_batch_3,  Train_loss : 5914.3940  Test_loss : 5946.7783, Time/batch_file : 2.2752, Training time: 4674.1424\n",
      "Epoch : 402/2000 data_batch_4,  Train_loss : 5900.7612  Test_loss : 5709.6938, Time/batch_file : 2.2989, Training time: 4676.4415\n",
      "Epoch : 402/2000 data_batch_5,  Train_loss : 5989.9185  Test_loss : 5856.3652, Time/batch_file : 2.2909, Training time: 4678.7327\n",
      "Epoch : 403/2000 data_batch_1,  Train_loss : 5145.3994  Test_loss : 6043.9248, Time/batch_file : 2.2828, Training time: 4681.0158\n",
      "Epoch : 403/2000 data_batch_2,  Train_loss : 5128.9873  Test_loss : 6169.7607, Time/batch_file : 2.2939, Training time: 4683.3100\n",
      "Epoch : 403/2000 data_batch_3,  Train_loss : 5110.3662  Test_loss : 6064.3403, Time/batch_file : 2.2993, Training time: 4685.6094\n",
      "Epoch : 403/2000 data_batch_4,  Train_loss : 4842.4263  Test_loss : 6019.0391, Time/batch_file : 2.2889, Training time: 4687.8985\n",
      "Epoch : 403/2000 data_batch_5,  Train_loss : 5070.7944  Test_loss : 6206.0439, Time/batch_file : 2.2990, Training time: 4690.1977\n",
      "Epoch : 404/2000 data_batch_1,  Train_loss : 6098.8359  Test_loss : 6056.1240, Time/batch_file : 2.3086, Training time: 4692.5066\n",
      "Epoch : 404/2000 data_batch_2,  Train_loss : 6105.9111  Test_loss : 5764.1641, Time/batch_file : 2.3163, Training time: 4694.8231\n",
      "Epoch : 404/2000 data_batch_3,  Train_loss : 5809.2900  Test_loss : 5829.0015, Time/batch_file : 2.3022, Training time: 4697.1255\n",
      "Epoch : 404/2000 data_batch_4,  Train_loss : 5896.5645  Test_loss : 6007.0371, Time/batch_file : 2.3026, Training time: 4699.4284\n",
      "Epoch : 404/2000 data_batch_5,  Train_loss : 6105.0625  Test_loss : 5972.9438, Time/batch_file : 2.3233, Training time: 4701.7519\n",
      "Epoch : 405/2000 data_batch_1,  Train_loss : 5941.6025  Test_loss : 5614.8750, Time/batch_file : 2.2923, Training time: 4704.0444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 405/2000 data_batch_2,  Train_loss : 6128.0000  Test_loss : 5865.3350, Time/batch_file : 2.3065, Training time: 4706.3511\n",
      "Epoch : 405/2000 data_batch_3,  Train_loss : 6164.1479  Test_loss : 5882.2593, Time/batch_file : 2.2858, Training time: 4708.6370\n",
      "Epoch : 405/2000 data_batch_4,  Train_loss : 6003.0488  Test_loss : 6234.2720, Time/batch_file : 2.3057, Training time: 4710.9429\n",
      "Epoch : 405/2000 data_batch_5,  Train_loss : 5942.7422  Test_loss : 6015.1875, Time/batch_file : 2.3264, Training time: 4713.2695\n",
      "Epoch : 406/2000 data_batch_1,  Train_loss : 5644.9648  Test_loss : 5625.3916, Time/batch_file : 2.2706, Training time: 4715.5403\n",
      "Epoch : 406/2000 data_batch_2,  Train_loss : 5577.6260  Test_loss : 5767.7900, Time/batch_file : 2.2852, Training time: 4717.8257\n",
      "Epoch : 406/2000 data_batch_3,  Train_loss : 5796.0977  Test_loss : 5910.7739, Time/batch_file : 2.2850, Training time: 4720.1109\n",
      "Epoch : 406/2000 data_batch_4,  Train_loss : 5696.4829  Test_loss : 5336.0581, Time/batch_file : 2.3072, Training time: 4722.4184\n",
      "Epoch : 406/2000 data_batch_5,  Train_loss : 5789.9189  Test_loss : 5858.0259, Time/batch_file : 2.2798, Training time: 4724.6984\n",
      "Epoch : 407/2000 data_batch_1,  Train_loss : 6004.2295  Test_loss : 6186.7451, Time/batch_file : 2.2776, Training time: 4726.9761\n",
      "Epoch : 407/2000 data_batch_2,  Train_loss : 5841.0176  Test_loss : 6324.4795, Time/batch_file : 2.2810, Training time: 4729.2573\n",
      "Epoch : 407/2000 data_batch_3,  Train_loss : 5586.2354  Test_loss : 6359.9951, Time/batch_file : 2.2914, Training time: 4731.5490\n",
      "Epoch : 407/2000 data_batch_4,  Train_loss : 5974.8140  Test_loss : 5905.3979, Time/batch_file : 2.2848, Training time: 4733.8340\n",
      "Epoch : 407/2000 data_batch_5,  Train_loss : 5706.0293  Test_loss : 5894.0830, Time/batch_file : 2.2950, Training time: 4736.1292\n",
      "Epoch : 408/2000 data_batch_1,  Train_loss : 5350.0664  Test_loss : 5839.0449, Time/batch_file : 2.3119, Training time: 4738.4413\n",
      "Epoch : 408/2000 data_batch_2,  Train_loss : 5100.0962  Test_loss : 5705.5771, Time/batch_file : 2.3065, Training time: 4740.7480\n",
      "Epoch : 408/2000 data_batch_3,  Train_loss : 5293.5537  Test_loss : 6218.8296, Time/batch_file : 2.2980, Training time: 4743.0462\n",
      "Epoch : 408/2000 data_batch_4,  Train_loss : 5031.0645  Test_loss : 5907.8784, Time/batch_file : 2.2932, Training time: 4745.3395\n",
      "Epoch : 408/2000 data_batch_5,  Train_loss : 5296.4272  Test_loss : 5870.4326, Time/batch_file : 2.3258, Training time: 4747.6655\n",
      "Epoch : 409/2000 data_batch_1,  Train_loss : 5873.8164  Test_loss : 5900.7637, Time/batch_file : 2.2741, Training time: 4749.9398\n",
      "Epoch : 409/2000 data_batch_2,  Train_loss : 5881.3945  Test_loss : 5698.8770, Time/batch_file : 2.2979, Training time: 4752.2380\n",
      "Epoch : 409/2000 data_batch_3,  Train_loss : 5708.6172  Test_loss : 5897.8496, Time/batch_file : 2.2830, Training time: 4754.5212\n",
      "Epoch : 409/2000 data_batch_4,  Train_loss : 5870.9033  Test_loss : 6205.1982, Time/batch_file : 2.2977, Training time: 4756.8191\n",
      "Epoch : 409/2000 data_batch_5,  Train_loss : 5915.4263  Test_loss : 6003.7754, Time/batch_file : 2.2990, Training time: 4759.1183\n",
      "Epoch : 410/2000 data_batch_1,  Train_loss : 5073.7246  Test_loss : 5916.1611, Time/batch_file : 2.2766, Training time: 4761.3952\n",
      "Epoch : 410/2000 data_batch_2,  Train_loss : 5247.7397  Test_loss : 6233.9209, Time/batch_file : 2.2909, Training time: 4763.6864\n",
      "Epoch : 410/2000 data_batch_3,  Train_loss : 5306.5215  Test_loss : 5526.7534, Time/batch_file : 2.2820, Training time: 4765.9685\n",
      "Epoch : 410/2000 data_batch_4,  Train_loss : 5066.9434  Test_loss : 5683.4731, Time/batch_file : 2.3040, Training time: 4768.2728\n",
      "Epoch : 410/2000 data_batch_5,  Train_loss : 5161.4922  Test_loss : 5830.3301, Time/batch_file : 2.2854, Training time: 4770.5584\n",
      "[./nets/net-410.ckpt] SAVED\n",
      "Epoch : 411/2000 data_batch_1,  Train_loss : 5576.4390  Test_loss : 5608.5234, Time/batch_file : 2.2980, Training time: 4774.1452\n",
      "Epoch : 411/2000 data_batch_2,  Train_loss : 5934.6221  Test_loss : 5632.8394, Time/batch_file : 2.2955, Training time: 4776.4410\n",
      "Epoch : 411/2000 data_batch_3,  Train_loss : 5733.1143  Test_loss : 5451.8257, Time/batch_file : 2.2771, Training time: 4778.7183\n",
      "Epoch : 411/2000 data_batch_4,  Train_loss : 5714.4121  Test_loss : 5665.7134, Time/batch_file : 2.2814, Training time: 4781.0000\n",
      "Epoch : 411/2000 data_batch_5,  Train_loss : 5821.0479  Test_loss : 5525.2393, Time/batch_file : 2.2891, Training time: 4783.2893\n",
      "Epoch : 412/2000 data_batch_1,  Train_loss : 5543.1333  Test_loss : 5910.6367, Time/batch_file : 2.2877, Training time: 4785.5772\n",
      "Epoch : 412/2000 data_batch_2,  Train_loss : 5609.0034  Test_loss : 5672.0112, Time/batch_file : 2.2911, Training time: 4787.8685\n",
      "Epoch : 412/2000 data_batch_3,  Train_loss : 5573.5645  Test_loss : 6199.8198, Time/batch_file : 2.2913, Training time: 4790.1600\n",
      "Epoch : 412/2000 data_batch_4,  Train_loss : 5850.0952  Test_loss : 5585.5000, Time/batch_file : 2.2834, Training time: 4792.4435\n",
      "Epoch : 412/2000 data_batch_5,  Train_loss : 5362.2866  Test_loss : 5797.1016, Time/batch_file : 2.2969, Training time: 4794.7406\n",
      "Epoch : 413/2000 data_batch_1,  Train_loss : 5281.6514  Test_loss : 6239.2046, Time/batch_file : 2.2817, Training time: 4797.0226\n",
      "Epoch : 413/2000 data_batch_2,  Train_loss : 5347.9346  Test_loss : 6092.8379, Time/batch_file : 2.2802, Training time: 4799.3030\n",
      "Epoch : 413/2000 data_batch_3,  Train_loss : 5451.9512  Test_loss : 6154.0923, Time/batch_file : 2.2838, Training time: 4801.5871\n",
      "Epoch : 413/2000 data_batch_4,  Train_loss : 5275.8623  Test_loss : 5660.4746, Time/batch_file : 2.2840, Training time: 4803.8713\n",
      "Epoch : 413/2000 data_batch_5,  Train_loss : 5481.0737  Test_loss : 5563.2153, Time/batch_file : 2.2761, Training time: 4806.1476\n",
      "Epoch : 414/2000 data_batch_1,  Train_loss : 5658.2529  Test_loss : 5457.9512, Time/batch_file : 2.2888, Training time: 4808.4366\n",
      "Epoch : 414/2000 data_batch_2,  Train_loss : 5656.6201  Test_loss : 5956.4062, Time/batch_file : 2.3062, Training time: 4810.7430\n",
      "Epoch : 414/2000 data_batch_3,  Train_loss : 5551.0752  Test_loss : 5540.9863, Time/batch_file : 2.3022, Training time: 4813.0453\n",
      "Epoch : 414/2000 data_batch_4,  Train_loss : 5645.1313  Test_loss : 5542.7036, Time/batch_file : 2.2863, Training time: 4815.3319\n",
      "Epoch : 414/2000 data_batch_5,  Train_loss : 5740.6904  Test_loss : 5489.7778, Time/batch_file : 2.2809, Training time: 4817.6129\n",
      "Epoch : 415/2000 data_batch_1,  Train_loss : 5027.9229  Test_loss : 5755.9307, Time/batch_file : 2.3048, Training time: 4819.9180\n",
      "Epoch : 415/2000 data_batch_2,  Train_loss : 4977.4336  Test_loss : 5525.1274, Time/batch_file : 2.3019, Training time: 4822.2200\n",
      "Epoch : 415/2000 data_batch_3,  Train_loss : 5001.2769  Test_loss : 5907.8242, Time/batch_file : 2.2818, Training time: 4824.5020\n",
      "Epoch : 415/2000 data_batch_4,  Train_loss : 4908.5103  Test_loss : 5801.0435, Time/batch_file : 2.2892, Training time: 4826.7914\n",
      "Epoch : 415/2000 data_batch_5,  Train_loss : 4989.0889  Test_loss : 5674.1753, Time/batch_file : 2.2815, Training time: 4829.0732\n",
      "Epoch : 416/2000 data_batch_1,  Train_loss : 5391.5566  Test_loss : 5630.5488, Time/batch_file : 2.3008, Training time: 4831.3742\n",
      "Epoch : 416/2000 data_batch_2,  Train_loss : 5246.6860  Test_loss : 5694.7227, Time/batch_file : 2.2919, Training time: 4833.6662\n",
      "Epoch : 416/2000 data_batch_3,  Train_loss : 5046.7075  Test_loss : 5465.8140, Time/batch_file : 2.2821, Training time: 4835.9486\n",
      "Epoch : 416/2000 data_batch_4,  Train_loss : 5079.3223  Test_loss : 5905.9360, Time/batch_file : 2.2934, Training time: 4838.2422\n",
      "Epoch : 416/2000 data_batch_5,  Train_loss : 5215.0454  Test_loss : 5687.5854, Time/batch_file : 2.2938, Training time: 4840.5362\n",
      "Epoch : 417/2000 data_batch_1,  Train_loss : 4733.3936  Test_loss : 5818.5439, Time/batch_file : 2.2850, Training time: 4842.8214\n",
      "Epoch : 417/2000 data_batch_2,  Train_loss : 5131.2061  Test_loss : 6093.2905, Time/batch_file : 2.2954, Training time: 4845.1171\n",
      "Epoch : 417/2000 data_batch_3,  Train_loss : 5000.4004  Test_loss : 5920.5806, Time/batch_file : 2.2820, Training time: 4847.3993\n",
      "Epoch : 417/2000 data_batch_4,  Train_loss : 4949.7690  Test_loss : 5902.9893, Time/batch_file : 2.2982, Training time: 4849.6977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 417/2000 data_batch_5,  Train_loss : 4830.2334  Test_loss : 5910.8252, Time/batch_file : 2.2879, Training time: 4851.9857\n",
      "Epoch : 418/2000 data_batch_1,  Train_loss : 5949.3188  Test_loss : 6003.3052, Time/batch_file : 2.2932, Training time: 4854.2792\n",
      "Epoch : 418/2000 data_batch_2,  Train_loss : 6009.4087  Test_loss : 5767.0078, Time/batch_file : 2.3107, Training time: 4856.5901\n",
      "Epoch : 418/2000 data_batch_3,  Train_loss : 6207.5332  Test_loss : 6136.4370, Time/batch_file : 2.2920, Training time: 4858.8822\n",
      "Epoch : 418/2000 data_batch_4,  Train_loss : 5942.2383  Test_loss : 5942.8433, Time/batch_file : 2.2893, Training time: 4861.1717\n",
      "Epoch : 418/2000 data_batch_5,  Train_loss : 5787.5654  Test_loss : 6045.6582, Time/batch_file : 2.3048, Training time: 4863.4766\n",
      "Epoch : 419/2000 data_batch_1,  Train_loss : 5706.3877  Test_loss : 5472.8413, Time/batch_file : 2.2734, Training time: 4865.7502\n",
      "Epoch : 419/2000 data_batch_2,  Train_loss : 5556.2817  Test_loss : 6021.4277, Time/batch_file : 2.2782, Training time: 4868.0287\n",
      "Epoch : 419/2000 data_batch_3,  Train_loss : 5915.5659  Test_loss : 5797.1074, Time/batch_file : 2.2670, Training time: 4870.2959\n",
      "Epoch : 419/2000 data_batch_4,  Train_loss : 5639.2974  Test_loss : 5662.6875, Time/batch_file : 2.2770, Training time: 4872.5732\n",
      "Epoch : 419/2000 data_batch_5,  Train_loss : 5453.1382  Test_loss : 5585.2798, Time/batch_file : 2.2786, Training time: 4874.8520\n",
      "Epoch : 420/2000 data_batch_1,  Train_loss : 5519.6821  Test_loss : 5853.6680, Time/batch_file : 2.2759, Training time: 4877.1281\n",
      "Epoch : 420/2000 data_batch_2,  Train_loss : 5611.2900  Test_loss : 5707.9614, Time/batch_file : 2.2716, Training time: 4879.3999\n",
      "Epoch : 420/2000 data_batch_3,  Train_loss : 5631.9912  Test_loss : 6161.2920, Time/batch_file : 2.2816, Training time: 4881.6817\n",
      "Epoch : 420/2000 data_batch_4,  Train_loss : 5345.0557  Test_loss : 5949.1699, Time/batch_file : 2.2659, Training time: 4883.9478\n",
      "Epoch : 420/2000 data_batch_5,  Train_loss : 5454.6562  Test_loss : 6101.8691, Time/batch_file : 2.2779, Training time: 4886.2259\n",
      "[./nets/net-420.ckpt] SAVED\n",
      "Epoch : 421/2000 data_batch_1,  Train_loss : 6104.3721  Test_loss : 6067.8574, Time/batch_file : 2.3184, Training time: 4889.8348\n",
      "Epoch : 421/2000 data_batch_2,  Train_loss : 5791.9663  Test_loss : 5585.2632, Time/batch_file : 2.2989, Training time: 4892.1338\n",
      "Epoch : 421/2000 data_batch_3,  Train_loss : 6111.8315  Test_loss : 5623.9087, Time/batch_file : 2.3296, Training time: 4894.4638\n",
      "Epoch : 421/2000 data_batch_4,  Train_loss : 5995.1724  Test_loss : 5616.9941, Time/batch_file : 2.2979, Training time: 4896.7618\n",
      "Epoch : 421/2000 data_batch_5,  Train_loss : 5853.9307  Test_loss : 6080.5723, Time/batch_file : 2.2870, Training time: 4899.0489\n",
      "Epoch : 422/2000 data_batch_1,  Train_loss : 5374.4941  Test_loss : 5776.6343, Time/batch_file : 2.2750, Training time: 4901.3241\n",
      "Epoch : 422/2000 data_batch_2,  Train_loss : 5538.7007  Test_loss : 5749.4624, Time/batch_file : 2.2742, Training time: 4903.5985\n",
      "Epoch : 422/2000 data_batch_3,  Train_loss : 5748.8613  Test_loss : 5598.8940, Time/batch_file : 2.2801, Training time: 4905.8788\n",
      "Epoch : 422/2000 data_batch_4,  Train_loss : 5565.4375  Test_loss : 5814.7715, Time/batch_file : 2.2805, Training time: 4908.1596\n",
      "Epoch : 422/2000 data_batch_5,  Train_loss : 5452.3335  Test_loss : 5882.6455, Time/batch_file : 2.2874, Training time: 4910.4472\n",
      "Epoch : 423/2000 data_batch_1,  Train_loss : 5531.8330  Test_loss : 5873.9043, Time/batch_file : 2.3320, Training time: 4912.7795\n",
      "Epoch : 423/2000 data_batch_2,  Train_loss : 5815.3306  Test_loss : 5975.0879, Time/batch_file : 2.3014, Training time: 4915.0812\n",
      "Epoch : 423/2000 data_batch_3,  Train_loss : 5649.4888  Test_loss : 5796.3340, Time/batch_file : 2.3009, Training time: 4917.3823\n",
      "Epoch : 423/2000 data_batch_4,  Train_loss : 5849.6216  Test_loss : 6069.2695, Time/batch_file : 2.3059, Training time: 4919.6886\n",
      "Epoch : 423/2000 data_batch_5,  Train_loss : 5619.8066  Test_loss : 6097.4165, Time/batch_file : 2.2843, Training time: 4921.9730\n",
      "Epoch : 424/2000 data_batch_1,  Train_loss : 5669.2271  Test_loss : 5992.7744, Time/batch_file : 2.2900, Training time: 4924.2632\n",
      "Epoch : 424/2000 data_batch_2,  Train_loss : 5516.6685  Test_loss : 5796.9443, Time/batch_file : 2.3103, Training time: 4926.5737\n",
      "Epoch : 424/2000 data_batch_3,  Train_loss : 5784.3350  Test_loss : 5999.8462, Time/batch_file : 2.3064, Training time: 4928.8805\n",
      "Epoch : 424/2000 data_batch_4,  Train_loss : 5566.8999  Test_loss : 5961.2202, Time/batch_file : 2.3302, Training time: 4931.2109\n",
      "Epoch : 424/2000 data_batch_5,  Train_loss : 5596.2661  Test_loss : 5880.7231, Time/batch_file : 2.3073, Training time: 4933.5183\n",
      "Epoch : 425/2000 data_batch_1,  Train_loss : 5338.9854  Test_loss : 5221.6416, Time/batch_file : 2.3071, Training time: 4935.8257\n",
      "Epoch : 425/2000 data_batch_2,  Train_loss : 5623.5732  Test_loss : 5394.9805, Time/batch_file : 2.3327, Training time: 4938.1586\n",
      "Epoch : 425/2000 data_batch_3,  Train_loss : 5591.6787  Test_loss : 5426.9443, Time/batch_file : 2.2968, Training time: 4940.4558\n",
      "Epoch : 425/2000 data_batch_4,  Train_loss : 5439.1064  Test_loss : 5111.3569, Time/batch_file : 2.3032, Training time: 4942.7591\n",
      "Epoch : 425/2000 data_batch_5,  Train_loss : 5829.4023  Test_loss : 5298.7920, Time/batch_file : 2.2942, Training time: 4945.0535\n",
      "Epoch : 426/2000 data_batch_1,  Train_loss : 5720.5679  Test_loss : 5969.0176, Time/batch_file : 2.2950, Training time: 4947.3487\n",
      "Epoch : 426/2000 data_batch_2,  Train_loss : 5903.0176  Test_loss : 5643.8262, Time/batch_file : 2.3029, Training time: 4949.6518\n",
      "Epoch : 426/2000 data_batch_3,  Train_loss : 5863.4878  Test_loss : 6260.1704, Time/batch_file : 2.3033, Training time: 4951.9553\n",
      "Epoch : 426/2000 data_batch_4,  Train_loss : 5706.3892  Test_loss : 5846.1719, Time/batch_file : 2.2925, Training time: 4954.2480\n",
      "Epoch : 426/2000 data_batch_5,  Train_loss : 5610.0698  Test_loss : 5957.4414, Time/batch_file : 2.2882, Training time: 4956.5364\n",
      "Epoch : 427/2000 data_batch_1,  Train_loss : 5678.5586  Test_loss : 5938.8750, Time/batch_file : 2.3179, Training time: 4958.8545\n",
      "Epoch : 427/2000 data_batch_2,  Train_loss : 5594.6880  Test_loss : 6081.9160, Time/batch_file : 2.3191, Training time: 4961.1737\n",
      "Epoch : 427/2000 data_batch_3,  Train_loss : 5374.4541  Test_loss : 6050.8496, Time/batch_file : 2.3064, Training time: 4963.4804\n",
      "Epoch : 427/2000 data_batch_4,  Train_loss : 5698.6016  Test_loss : 6272.6309, Time/batch_file : 2.3025, Training time: 4965.7830\n",
      "Epoch : 427/2000 data_batch_5,  Train_loss : 5545.0146  Test_loss : 6028.7295, Time/batch_file : 2.3128, Training time: 4968.0961\n",
      "Epoch : 428/2000 data_batch_1,  Train_loss : 5740.9023  Test_loss : 5676.5254, Time/batch_file : 2.2871, Training time: 4970.3835\n",
      "Epoch : 428/2000 data_batch_2,  Train_loss : 5333.2822  Test_loss : 5641.6167, Time/batch_file : 2.2946, Training time: 4972.6783\n",
      "Epoch : 428/2000 data_batch_3,  Train_loss : 5898.4731  Test_loss : 5573.2139, Time/batch_file : 2.2906, Training time: 4974.9691\n",
      "Epoch : 428/2000 data_batch_4,  Train_loss : 5327.5781  Test_loss : 5921.9678, Time/batch_file : 2.3371, Training time: 4977.3063\n",
      "Epoch : 428/2000 data_batch_5,  Train_loss : 5241.2720  Test_loss : 5489.5259, Time/batch_file : 2.2899, Training time: 4979.5964\n",
      "Epoch : 429/2000 data_batch_1,  Train_loss : 5944.5591  Test_loss : 6153.7524, Time/batch_file : 2.2966, Training time: 4981.8932\n",
      "Epoch : 429/2000 data_batch_2,  Train_loss : 6092.2524  Test_loss : 6619.7754, Time/batch_file : 2.3170, Training time: 4984.2103\n",
      "Epoch : 429/2000 data_batch_3,  Train_loss : 6139.8120  Test_loss : 6221.5508, Time/batch_file : 2.3157, Training time: 4986.5262\n",
      "Epoch : 429/2000 data_batch_4,  Train_loss : 5753.1157  Test_loss : 6095.2559, Time/batch_file : 2.3136, Training time: 4988.8400\n",
      "Epoch : 429/2000 data_batch_5,  Train_loss : 5854.3604  Test_loss : 6635.1479, Time/batch_file : 2.2974, Training time: 4991.1377\n",
      "Epoch : 430/2000 data_batch_1,  Train_loss : 5436.0576  Test_loss : 5957.3291, Time/batch_file : 2.3178, Training time: 4993.4558\n",
      "Epoch : 430/2000 data_batch_2,  Train_loss : 5389.1475  Test_loss : 5530.7681, Time/batch_file : 2.3113, Training time: 4995.7673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 430/2000 data_batch_3,  Train_loss : 5354.2695  Test_loss : 5709.0674, Time/batch_file : 2.3087, Training time: 4998.0762\n",
      "Epoch : 430/2000 data_batch_4,  Train_loss : 5670.8906  Test_loss : 5611.9355, Time/batch_file : 2.2912, Training time: 5000.3677\n",
      "Epoch : 430/2000 data_batch_5,  Train_loss : 5531.1387  Test_loss : 5451.5493, Time/batch_file : 2.3271, Training time: 5002.6950\n",
      "[./nets/net-430.ckpt] SAVED\n",
      "Epoch : 431/2000 data_batch_1,  Train_loss : 5362.5234  Test_loss : 5812.4224, Time/batch_file : 2.2983, Training time: 5006.2882\n",
      "Epoch : 431/2000 data_batch_2,  Train_loss : 4857.4531  Test_loss : 5824.9590, Time/batch_file : 2.3019, Training time: 5008.5903\n",
      "Epoch : 431/2000 data_batch_3,  Train_loss : 5153.3262  Test_loss : 5941.1348, Time/batch_file : 2.3005, Training time: 5010.8911\n",
      "Epoch : 431/2000 data_batch_4,  Train_loss : 5201.7451  Test_loss : 6006.3467, Time/batch_file : 2.3022, Training time: 5013.1935\n",
      "Epoch : 431/2000 data_batch_5,  Train_loss : 5033.6846  Test_loss : 6033.7012, Time/batch_file : 2.3008, Training time: 5015.4944\n",
      "Epoch : 432/2000 data_batch_1,  Train_loss : 5231.3525  Test_loss : 5521.0059, Time/batch_file : 2.2890, Training time: 5017.7836\n",
      "Epoch : 432/2000 data_batch_2,  Train_loss : 5053.5059  Test_loss : 5695.8843, Time/batch_file : 2.2937, Training time: 5020.0774\n",
      "Epoch : 432/2000 data_batch_3,  Train_loss : 5014.0645  Test_loss : 5748.8076, Time/batch_file : 2.3009, Training time: 5022.3786\n",
      "Epoch : 432/2000 data_batch_4,  Train_loss : 5120.1992  Test_loss : 5404.2632, Time/batch_file : 2.3087, Training time: 5024.6874\n",
      "Epoch : 432/2000 data_batch_5,  Train_loss : 5020.0566  Test_loss : 5755.3901, Time/batch_file : 2.3126, Training time: 5027.0002\n",
      "Epoch : 433/2000 data_batch_1,  Train_loss : 5681.7354  Test_loss : 4627.8965, Time/batch_file : 2.2932, Training time: 5029.2936\n",
      "Epoch : 433/2000 data_batch_2,  Train_loss : 5859.7422  Test_loss : 4701.3999, Time/batch_file : 2.2923, Training time: 5031.5860\n",
      "Epoch : 433/2000 data_batch_3,  Train_loss : 5530.7051  Test_loss : 5242.6841, Time/batch_file : 2.3165, Training time: 5033.9028\n",
      "Epoch : 433/2000 data_batch_4,  Train_loss : 5288.4268  Test_loss : 5052.3203, Time/batch_file : 2.2918, Training time: 5036.1948\n",
      "Epoch : 433/2000 data_batch_5,  Train_loss : 5746.2148  Test_loss : 4716.9351, Time/batch_file : 2.3144, Training time: 5038.5094\n",
      "Epoch : 434/2000 data_batch_1,  Train_loss : 5491.1338  Test_loss : 6128.6699, Time/batch_file : 2.2838, Training time: 5040.7934\n",
      "Epoch : 434/2000 data_batch_2,  Train_loss : 5505.1709  Test_loss : 5959.0630, Time/batch_file : 2.3031, Training time: 5043.0967\n",
      "Epoch : 434/2000 data_batch_3,  Train_loss : 5544.7261  Test_loss : 6160.2236, Time/batch_file : 2.3069, Training time: 5045.4037\n",
      "Epoch : 434/2000 data_batch_4,  Train_loss : 5837.8311  Test_loss : 5757.9624, Time/batch_file : 2.2855, Training time: 5047.6895\n",
      "Epoch : 434/2000 data_batch_5,  Train_loss : 5648.0942  Test_loss : 5917.0981, Time/batch_file : 2.2967, Training time: 5049.9864\n",
      "Epoch : 435/2000 data_batch_1,  Train_loss : 5619.6641  Test_loss : 5689.0396, Time/batch_file : 2.3136, Training time: 5052.3002\n",
      "Epoch : 435/2000 data_batch_2,  Train_loss : 5808.0352  Test_loss : 5423.7417, Time/batch_file : 2.3026, Training time: 5054.6029\n",
      "Epoch : 435/2000 data_batch_3,  Train_loss : 5698.3477  Test_loss : 5489.1235, Time/batch_file : 2.3310, Training time: 5056.9341\n",
      "Epoch : 435/2000 data_batch_4,  Train_loss : 5457.4082  Test_loss : 5429.3071, Time/batch_file : 2.3083, Training time: 5059.2426\n",
      "Epoch : 435/2000 data_batch_5,  Train_loss : 5589.1162  Test_loss : 5425.8647, Time/batch_file : 2.3083, Training time: 5061.5512\n",
      "Epoch : 436/2000 data_batch_1,  Train_loss : 5588.4258  Test_loss : 6116.3906, Time/batch_file : 2.2992, Training time: 5063.8506\n",
      "Epoch : 436/2000 data_batch_2,  Train_loss : 5730.6592  Test_loss : 5730.5889, Time/batch_file : 2.3150, Training time: 5066.1657\n",
      "Epoch : 436/2000 data_batch_3,  Train_loss : 5987.6675  Test_loss : 5556.5161, Time/batch_file : 2.3063, Training time: 5068.4722\n",
      "Epoch : 436/2000 data_batch_4,  Train_loss : 5864.1709  Test_loss : 6177.2397, Time/batch_file : 2.2968, Training time: 5070.7693\n",
      "Epoch : 436/2000 data_batch_5,  Train_loss : 5953.9258  Test_loss : 5982.8545, Time/batch_file : 2.3190, Training time: 5073.0884\n",
      "Epoch : 437/2000 data_batch_1,  Train_loss : 4975.5107  Test_loss : 5524.8096, Time/batch_file : 2.2966, Training time: 5075.3853\n",
      "Epoch : 437/2000 data_batch_2,  Train_loss : 5379.0703  Test_loss : 5864.7285, Time/batch_file : 2.2824, Training time: 5077.6678\n",
      "Epoch : 437/2000 data_batch_3,  Train_loss : 5557.9521  Test_loss : 5689.4375, Time/batch_file : 2.2994, Training time: 5079.9673\n",
      "Epoch : 437/2000 data_batch_4,  Train_loss : 5145.8320  Test_loss : 5771.3604, Time/batch_file : 2.2768, Training time: 5082.2443\n",
      "Epoch : 437/2000 data_batch_5,  Train_loss : 5293.9785  Test_loss : 5483.7637, Time/batch_file : 2.2832, Training time: 5084.5278\n",
      "Epoch : 438/2000 data_batch_1,  Train_loss : 5051.6738  Test_loss : 5702.7881, Time/batch_file : 2.3090, Training time: 5086.8371\n",
      "Epoch : 438/2000 data_batch_2,  Train_loss : 5169.8477  Test_loss : 5896.3755, Time/batch_file : 2.3164, Training time: 5089.1537\n",
      "Epoch : 438/2000 data_batch_3,  Train_loss : 4942.6992  Test_loss : 5631.0522, Time/batch_file : 2.2984, Training time: 5091.4524\n",
      "Epoch : 438/2000 data_batch_4,  Train_loss : 4952.8301  Test_loss : 5711.2886, Time/batch_file : 2.2963, Training time: 5093.7488\n",
      "Epoch : 438/2000 data_batch_5,  Train_loss : 5023.5967  Test_loss : 5594.0962, Time/batch_file : 2.3064, Training time: 5096.0553\n",
      "Epoch : 439/2000 data_batch_1,  Train_loss : 5823.5288  Test_loss : 5689.3354, Time/batch_file : 2.3203, Training time: 5098.3758\n",
      "Epoch : 439/2000 data_batch_2,  Train_loss : 5888.2617  Test_loss : 5568.3843, Time/batch_file : 2.2929, Training time: 5100.6688\n",
      "Epoch : 439/2000 data_batch_3,  Train_loss : 5798.9736  Test_loss : 5584.3408, Time/batch_file : 2.3212, Training time: 5102.9902\n",
      "Epoch : 439/2000 data_batch_4,  Train_loss : 5999.0356  Test_loss : 5766.5986, Time/batch_file : 2.3088, Training time: 5105.2992\n",
      "Epoch : 439/2000 data_batch_5,  Train_loss : 5872.8828  Test_loss : 5777.4663, Time/batch_file : 2.3202, Training time: 5107.6197\n",
      "Epoch : 440/2000 data_batch_1,  Train_loss : 5429.4990  Test_loss : 5832.6133, Time/batch_file : 2.2992, Training time: 5109.9191\n",
      "Epoch : 440/2000 data_batch_2,  Train_loss : 5433.8657  Test_loss : 6054.3560, Time/batch_file : 2.2819, Training time: 5112.2012\n",
      "Epoch : 440/2000 data_batch_3,  Train_loss : 5635.6182  Test_loss : 5671.5264, Time/batch_file : 2.2950, Training time: 5114.4964\n",
      "Epoch : 440/2000 data_batch_4,  Train_loss : 4895.4995  Test_loss : 6031.1006, Time/batch_file : 2.3258, Training time: 5116.8224\n",
      "Epoch : 440/2000 data_batch_5,  Train_loss : 5279.3350  Test_loss : 5797.0469, Time/batch_file : 2.2919, Training time: 5119.1145\n",
      "[./nets/net-440.ckpt] SAVED\n",
      "Epoch : 441/2000 data_batch_1,  Train_loss : 6152.9434  Test_loss : 5985.2588, Time/batch_file : 2.3141, Training time: 5122.7498\n",
      "Epoch : 441/2000 data_batch_2,  Train_loss : 6004.9297  Test_loss : 5552.6152, Time/batch_file : 2.3111, Training time: 5125.0612\n",
      "Epoch : 441/2000 data_batch_3,  Train_loss : 5988.8267  Test_loss : 5773.4824, Time/batch_file : 2.3268, Training time: 5127.3882\n",
      "Epoch : 441/2000 data_batch_4,  Train_loss : 5857.1274  Test_loss : 5549.4580, Time/batch_file : 2.3053, Training time: 5129.6936\n",
      "Epoch : 441/2000 data_batch_5,  Train_loss : 5976.9932  Test_loss : 6158.3701, Time/batch_file : 2.3171, Training time: 5132.0108\n",
      "Epoch : 442/2000 data_batch_1,  Train_loss : 5621.9238  Test_loss : 5687.1230, Time/batch_file : 2.2975, Training time: 5134.3086\n",
      "Epoch : 442/2000 data_batch_2,  Train_loss : 5594.7119  Test_loss : 5997.8315, Time/batch_file : 2.3236, Training time: 5136.6325\n",
      "Epoch : 442/2000 data_batch_3,  Train_loss : 5480.2847  Test_loss : 5609.1636, Time/batch_file : 2.2950, Training time: 5138.9277\n",
      "Epoch : 442/2000 data_batch_4,  Train_loss : 5893.0527  Test_loss : 5744.4795, Time/batch_file : 2.3171, Training time: 5141.2450\n",
      "Epoch : 442/2000 data_batch_5,  Train_loss : 5533.2192  Test_loss : 5978.3931, Time/batch_file : 2.2834, Training time: 5143.5286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 443/2000 data_batch_1,  Train_loss : 5178.2231  Test_loss : 5965.0928, Time/batch_file : 2.3189, Training time: 5145.8477\n",
      "Epoch : 443/2000 data_batch_2,  Train_loss : 5639.1816  Test_loss : 6168.6592, Time/batch_file : 2.3087, Training time: 5148.1565\n",
      "Epoch : 443/2000 data_batch_3,  Train_loss : 5668.8828  Test_loss : 6127.4502, Time/batch_file : 2.3347, Training time: 5150.4915\n",
      "Epoch : 443/2000 data_batch_4,  Train_loss : 5605.3521  Test_loss : 6134.0449, Time/batch_file : 2.2996, Training time: 5152.7913\n",
      "Epoch : 443/2000 data_batch_5,  Train_loss : 5491.6670  Test_loss : 6403.0889, Time/batch_file : 2.3253, Training time: 5155.1168\n",
      "Epoch : 444/2000 data_batch_1,  Train_loss : 5923.2837  Test_loss : 5496.9087, Time/batch_file : 2.2813, Training time: 5157.3985\n",
      "Epoch : 444/2000 data_batch_2,  Train_loss : 5811.0557  Test_loss : 5557.3799, Time/batch_file : 2.3174, Training time: 5159.7161\n",
      "Epoch : 444/2000 data_batch_3,  Train_loss : 6089.0684  Test_loss : 5547.6074, Time/batch_file : 2.2921, Training time: 5162.0084\n",
      "Epoch : 444/2000 data_batch_4,  Train_loss : 6033.7310  Test_loss : 5633.8760, Time/batch_file : 2.3052, Training time: 5164.3138\n",
      "Epoch : 444/2000 data_batch_5,  Train_loss : 5896.4375  Test_loss : 5883.4932, Time/batch_file : 2.2911, Training time: 5166.6051\n",
      "Epoch : 445/2000 data_batch_1,  Train_loss : 5316.0439  Test_loss : 5739.3066, Time/batch_file : 2.3370, Training time: 5168.9423\n",
      "Epoch : 445/2000 data_batch_2,  Train_loss : 5712.1162  Test_loss : 5846.1235, Time/batch_file : 2.3140, Training time: 5171.2564\n",
      "Epoch : 445/2000 data_batch_3,  Train_loss : 5542.8057  Test_loss : 5814.1660, Time/batch_file : 2.3389, Training time: 5173.5956\n",
      "Epoch : 445/2000 data_batch_4,  Train_loss : 5309.2334  Test_loss : 6090.7510, Time/batch_file : 2.2997, Training time: 5175.8955\n",
      "Epoch : 445/2000 data_batch_5,  Train_loss : 5631.5029  Test_loss : 5881.0864, Time/batch_file : 2.3271, Training time: 5178.2227\n",
      "Epoch : 446/2000 data_batch_1,  Train_loss : 5859.0493  Test_loss : 5946.6284, Time/batch_file : 2.2936, Training time: 5180.5165\n",
      "Epoch : 446/2000 data_batch_2,  Train_loss : 5730.8271  Test_loss : 5867.0615, Time/batch_file : 2.3204, Training time: 5182.8371\n",
      "Epoch : 446/2000 data_batch_3,  Train_loss : 6116.4590  Test_loss : 6033.0000, Time/batch_file : 2.3001, Training time: 5185.1374\n",
      "Epoch : 446/2000 data_batch_4,  Train_loss : 6124.0288  Test_loss : 6134.0137, Time/batch_file : 2.3116, Training time: 5187.4491\n",
      "Epoch : 446/2000 data_batch_5,  Train_loss : 5919.7305  Test_loss : 5844.7354, Time/batch_file : 2.2869, Training time: 5189.7362\n",
      "Epoch : 447/2000 data_batch_1,  Train_loss : 5286.8950  Test_loss : 5396.6196, Time/batch_file : 2.3269, Training time: 5192.0633\n",
      "Epoch : 447/2000 data_batch_2,  Train_loss : 5787.1113  Test_loss : 5472.1606, Time/batch_file : 2.3001, Training time: 5194.3637\n",
      "Epoch : 447/2000 data_batch_3,  Train_loss : 5727.1025  Test_loss : 5283.8501, Time/batch_file : 2.3123, Training time: 5196.6761\n",
      "Epoch : 447/2000 data_batch_4,  Train_loss : 5639.8545  Test_loss : 5499.1372, Time/batch_file : 2.2952, Training time: 5198.9717\n",
      "Epoch : 447/2000 data_batch_5,  Train_loss : 5850.4912  Test_loss : 5204.6763, Time/batch_file : 2.3175, Training time: 5201.2893\n",
      "Epoch : 448/2000 data_batch_1,  Train_loss : 5468.1167  Test_loss : 5406.5625, Time/batch_file : 2.3021, Training time: 5203.5917\n",
      "Epoch : 448/2000 data_batch_2,  Train_loss : 5760.9219  Test_loss : 5789.3657, Time/batch_file : 2.3145, Training time: 5205.9064\n",
      "Epoch : 448/2000 data_batch_3,  Train_loss : 5414.9834  Test_loss : 5434.5703, Time/batch_file : 2.2968, Training time: 5208.2034\n",
      "Epoch : 448/2000 data_batch_4,  Train_loss : 5442.3330  Test_loss : 5556.7588, Time/batch_file : 2.3289, Training time: 5210.5326\n",
      "Epoch : 448/2000 data_batch_5,  Train_loss : 5688.1094  Test_loss : 5380.6538, Time/batch_file : 2.3080, Training time: 5212.8408\n",
      "Epoch : 449/2000 data_batch_1,  Train_loss : 5853.0693  Test_loss : 5386.3652, Time/batch_file : 2.3240, Training time: 5215.1651\n",
      "Epoch : 449/2000 data_batch_2,  Train_loss : 5407.0088  Test_loss : 5860.3545, Time/batch_file : 2.3114, Training time: 5217.4766\n",
      "Epoch : 449/2000 data_batch_3,  Train_loss : 5322.9121  Test_loss : 5416.3711, Time/batch_file : 2.3085, Training time: 5219.7854\n",
      "Epoch : 449/2000 data_batch_4,  Train_loss : 5343.4502  Test_loss : 5617.9741, Time/batch_file : 2.2783, Training time: 5222.0639\n",
      "Epoch : 449/2000 data_batch_5,  Train_loss : 5311.1206  Test_loss : 5519.4131, Time/batch_file : 2.3275, Training time: 5224.3916\n",
      "Epoch : 450/2000 data_batch_1,  Train_loss : 5637.9375  Test_loss : 5436.5801, Time/batch_file : 2.2851, Training time: 5226.6769\n",
      "Epoch : 450/2000 data_batch_2,  Train_loss : 5320.6689  Test_loss : 5485.0381, Time/batch_file : 2.3118, Training time: 5228.9889\n",
      "Epoch : 450/2000 data_batch_3,  Train_loss : 5462.1450  Test_loss : 5516.1133, Time/batch_file : 2.2926, Training time: 5231.2817\n",
      "Epoch : 450/2000 data_batch_4,  Train_loss : 5468.3203  Test_loss : 5176.3442, Time/batch_file : 2.3114, Training time: 5233.5932\n",
      "Epoch : 450/2000 data_batch_5,  Train_loss : 5610.7227  Test_loss : 5509.0244, Time/batch_file : 2.3057, Training time: 5235.8991\n",
      "[./nets/net-450.ckpt] SAVED\n",
      "Epoch : 451/2000 data_batch_1,  Train_loss : 5235.7583  Test_loss : 5919.5381, Time/batch_file : 2.3168, Training time: 5239.5104\n",
      "Epoch : 451/2000 data_batch_2,  Train_loss : 5191.0571  Test_loss : 6048.9268, Time/batch_file : 2.3217, Training time: 5241.8324\n",
      "Epoch : 451/2000 data_batch_3,  Train_loss : 5282.7578  Test_loss : 5813.5674, Time/batch_file : 2.3251, Training time: 5244.1577\n",
      "Epoch : 451/2000 data_batch_4,  Train_loss : 5086.1284  Test_loss : 5714.3496, Time/batch_file : 2.3013, Training time: 5246.4593\n",
      "Epoch : 451/2000 data_batch_5,  Train_loss : 5191.5791  Test_loss : 5888.9741, Time/batch_file : 2.2908, Training time: 5248.7504\n",
      "Epoch : 452/2000 data_batch_1,  Train_loss : 6208.9570  Test_loss : 5658.3745, Time/batch_file : 2.3071, Training time: 5251.0578\n",
      "Epoch : 452/2000 data_batch_2,  Train_loss : 5856.5728  Test_loss : 5578.4360, Time/batch_file : 2.2738, Training time: 5253.3318\n",
      "Epoch : 452/2000 data_batch_3,  Train_loss : 6303.7012  Test_loss : 5597.3154, Time/batch_file : 2.2872, Training time: 5255.6192\n",
      "Epoch : 452/2000 data_batch_4,  Train_loss : 6186.9990  Test_loss : 5734.5352, Time/batch_file : 2.2815, Training time: 5257.9009\n",
      "Epoch : 452/2000 data_batch_5,  Train_loss : 5795.8325  Test_loss : 5783.2725, Time/batch_file : 2.3087, Training time: 5260.2098\n",
      "Epoch : 453/2000 data_batch_1,  Train_loss : 5765.0000  Test_loss : 5591.3652, Time/batch_file : 2.2659, Training time: 5262.4758\n",
      "Epoch : 453/2000 data_batch_2,  Train_loss : 5990.6382  Test_loss : 5720.1133, Time/batch_file : 2.3155, Training time: 5264.7916\n",
      "Epoch : 453/2000 data_batch_3,  Train_loss : 5665.4946  Test_loss : 5385.0669, Time/batch_file : 2.2820, Training time: 5267.0736\n",
      "Epoch : 453/2000 data_batch_4,  Train_loss : 5641.8354  Test_loss : 5743.7471, Time/batch_file : 2.3097, Training time: 5269.3834\n",
      "Epoch : 453/2000 data_batch_5,  Train_loss : 5681.0220  Test_loss : 5806.6680, Time/batch_file : 2.2825, Training time: 5271.6661\n",
      "Epoch : 454/2000 data_batch_1,  Train_loss : 5848.6055  Test_loss : 5831.0430, Time/batch_file : 2.3147, Training time: 5273.9810\n",
      "Epoch : 454/2000 data_batch_2,  Train_loss : 5619.0786  Test_loss : 5563.0132, Time/batch_file : 2.2883, Training time: 5276.2695\n",
      "Epoch : 454/2000 data_batch_3,  Train_loss : 5656.1787  Test_loss : 5577.8809, Time/batch_file : 2.3125, Training time: 5278.5823\n",
      "Epoch : 454/2000 data_batch_4,  Train_loss : 5509.3750  Test_loss : 5563.0449, Time/batch_file : 2.2781, Training time: 5280.8606\n",
      "Epoch : 454/2000 data_batch_5,  Train_loss : 5401.0415  Test_loss : 5803.0537, Time/batch_file : 2.3246, Training time: 5283.1854\n",
      "Epoch : 455/2000 data_batch_1,  Train_loss : 5350.5288  Test_loss : 5786.5908, Time/batch_file : 2.3040, Training time: 5285.4895\n",
      "Epoch : 455/2000 data_batch_2,  Train_loss : 5240.5176  Test_loss : 5627.1953, Time/batch_file : 2.3298, Training time: 5287.8195\n",
      "Epoch : 455/2000 data_batch_3,  Train_loss : 5664.6084  Test_loss : 5708.9619, Time/batch_file : 2.2909, Training time: 5290.1107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 455/2000 data_batch_4,  Train_loss : 5634.2397  Test_loss : 5193.0820, Time/batch_file : 2.3023, Training time: 5292.4132\n",
      "Epoch : 455/2000 data_batch_5,  Train_loss : 5595.4307  Test_loss : 5584.8936, Time/batch_file : 2.2907, Training time: 5294.7043\n",
      "Epoch : 456/2000 data_batch_1,  Train_loss : 5502.9160  Test_loss : 5630.7461, Time/batch_file : 2.2875, Training time: 5296.9919\n",
      "Epoch : 456/2000 data_batch_2,  Train_loss : 5503.3774  Test_loss : 5070.7539, Time/batch_file : 2.2819, Training time: 5299.2740\n",
      "Epoch : 456/2000 data_batch_3,  Train_loss : 5585.6089  Test_loss : 5457.0869, Time/batch_file : 2.2903, Training time: 5301.5646\n",
      "Epoch : 456/2000 data_batch_4,  Train_loss : 5092.9893  Test_loss : 5690.0610, Time/batch_file : 2.2806, Training time: 5303.8453\n",
      "Epoch : 456/2000 data_batch_5,  Train_loss : 5732.2759  Test_loss : 5752.4805, Time/batch_file : 2.3000, Training time: 5306.1454\n",
      "Epoch : 457/2000 data_batch_1,  Train_loss : 5760.9717  Test_loss : 5645.0229, Time/batch_file : 2.2797, Training time: 5308.4252\n",
      "Epoch : 457/2000 data_batch_2,  Train_loss : 5590.1035  Test_loss : 5993.7725, Time/batch_file : 2.2818, Training time: 5310.7073\n",
      "Epoch : 457/2000 data_batch_3,  Train_loss : 6047.4648  Test_loss : 5941.9102, Time/batch_file : 2.2793, Training time: 5312.9868\n",
      "Epoch : 457/2000 data_batch_4,  Train_loss : 6079.6270  Test_loss : 6247.2437, Time/batch_file : 2.2944, Training time: 5315.2813\n",
      "Epoch : 457/2000 data_batch_5,  Train_loss : 5806.5654  Test_loss : 5803.7979, Time/batch_file : 2.2786, Training time: 5317.5600\n",
      "Epoch : 458/2000 data_batch_1,  Train_loss : 5454.8340  Test_loss : 5555.7920, Time/batch_file : 2.2889, Training time: 5319.8492\n",
      "Epoch : 458/2000 data_batch_2,  Train_loss : 5455.0952  Test_loss : 5558.1333, Time/batch_file : 2.2825, Training time: 5322.1319\n",
      "Epoch : 458/2000 data_batch_3,  Train_loss : 5305.6992  Test_loss : 5245.1348, Time/batch_file : 2.2917, Training time: 5324.4238\n",
      "Epoch : 458/2000 data_batch_4,  Train_loss : 5506.0942  Test_loss : 5452.1680, Time/batch_file : 2.2725, Training time: 5326.6965\n",
      "Epoch : 458/2000 data_batch_5,  Train_loss : 5369.7905  Test_loss : 5449.1685, Time/batch_file : 2.3050, Training time: 5329.0018\n",
      "Epoch : 459/2000 data_batch_1,  Train_loss : 5281.6123  Test_loss : 5515.2788, Time/batch_file : 2.2779, Training time: 5331.2800\n",
      "Epoch : 459/2000 data_batch_2,  Train_loss : 5698.9248  Test_loss : 5378.8906, Time/batch_file : 2.2956, Training time: 5333.5758\n",
      "Epoch : 459/2000 data_batch_3,  Train_loss : 5486.0767  Test_loss : 5479.8481, Time/batch_file : 2.2949, Training time: 5335.8709\n",
      "Epoch : 459/2000 data_batch_4,  Train_loss : 5231.5386  Test_loss : 5480.1440, Time/batch_file : 2.3008, Training time: 5338.1718\n",
      "Epoch : 459/2000 data_batch_5,  Train_loss : 5428.7324  Test_loss : 5335.3296, Time/batch_file : 2.2778, Training time: 5340.4498\n",
      "Epoch : 460/2000 data_batch_1,  Train_loss : 5202.8301  Test_loss : 5492.5352, Time/batch_file : 2.2971, Training time: 5342.7471\n",
      "Epoch : 460/2000 data_batch_2,  Train_loss : 5321.1499  Test_loss : 5479.7549, Time/batch_file : 2.3008, Training time: 5345.0480\n",
      "Epoch : 460/2000 data_batch_3,  Train_loss : 5164.6011  Test_loss : 5541.0205, Time/batch_file : 2.2878, Training time: 5347.3361\n",
      "Epoch : 460/2000 data_batch_4,  Train_loss : 5326.8765  Test_loss : 5725.8467, Time/batch_file : 2.3054, Training time: 5349.6416\n",
      "Epoch : 460/2000 data_batch_5,  Train_loss : 4879.8882  Test_loss : 5736.0249, Time/batch_file : 2.2901, Training time: 5351.9320\n",
      "[./nets/net-460.ckpt] SAVED\n",
      "Epoch : 461/2000 data_batch_1,  Train_loss : 5916.8857  Test_loss : 6122.1318, Time/batch_file : 2.3259, Training time: 5355.5548\n",
      "Epoch : 461/2000 data_batch_2,  Train_loss : 5805.6089  Test_loss : 6051.9873, Time/batch_file : 2.3251, Training time: 5357.8801\n",
      "Epoch : 461/2000 data_batch_3,  Train_loss : 5843.7603  Test_loss : 6224.0586, Time/batch_file : 2.3050, Training time: 5360.1853\n",
      "Epoch : 461/2000 data_batch_4,  Train_loss : 5797.3511  Test_loss : 6196.3223, Time/batch_file : 2.2864, Training time: 5362.4718\n",
      "Epoch : 461/2000 data_batch_5,  Train_loss : 5887.2202  Test_loss : 5960.7607, Time/batch_file : 2.2857, Training time: 5364.7577\n",
      "Epoch : 462/2000 data_batch_1,  Train_loss : 5351.1182  Test_loss : 5434.6997, Time/batch_file : 2.3015, Training time: 5367.0594\n",
      "Epoch : 462/2000 data_batch_2,  Train_loss : 5132.0996  Test_loss : 5589.1787, Time/batch_file : 2.2799, Training time: 5369.3395\n",
      "Epoch : 462/2000 data_batch_3,  Train_loss : 5360.6777  Test_loss : 5710.0894, Time/batch_file : 2.2788, Training time: 5371.6185\n",
      "Epoch : 462/2000 data_batch_4,  Train_loss : 5240.6377  Test_loss : 5217.9087, Time/batch_file : 2.2897, Training time: 5373.9084\n",
      "Epoch : 462/2000 data_batch_5,  Train_loss : 5082.4214  Test_loss : 5606.0449, Time/batch_file : 2.2906, Training time: 5376.1992\n",
      "Epoch : 463/2000 data_batch_1,  Train_loss : 6064.2593  Test_loss : 5848.4961, Time/batch_file : 2.2755, Training time: 5378.4749\n",
      "Epoch : 463/2000 data_batch_2,  Train_loss : 5618.8164  Test_loss : 6001.9409, Time/batch_file : 2.2729, Training time: 5380.7480\n",
      "Epoch : 463/2000 data_batch_3,  Train_loss : 5399.3867  Test_loss : 6162.1865, Time/batch_file : 2.2839, Training time: 5383.0321\n",
      "Epoch : 463/2000 data_batch_4,  Train_loss : 5333.1733  Test_loss : 6378.7979, Time/batch_file : 2.2772, Training time: 5385.3095\n",
      "Epoch : 463/2000 data_batch_5,  Train_loss : 5608.2217  Test_loss : 5644.1040, Time/batch_file : 2.2846, Training time: 5387.5943\n",
      "Epoch : 464/2000 data_batch_1,  Train_loss : 5820.9805  Test_loss : 6042.9551, Time/batch_file : 2.2859, Training time: 5389.8805\n",
      "Epoch : 464/2000 data_batch_2,  Train_loss : 5754.4023  Test_loss : 6047.5264, Time/batch_file : 2.2885, Training time: 5392.1691\n",
      "Epoch : 464/2000 data_batch_3,  Train_loss : 5422.1714  Test_loss : 6025.0234, Time/batch_file : 2.2819, Training time: 5394.4512\n",
      "Epoch : 464/2000 data_batch_4,  Train_loss : 5626.4170  Test_loss : 5560.1787, Time/batch_file : 2.2871, Training time: 5396.7386\n",
      "Epoch : 464/2000 data_batch_5,  Train_loss : 5676.5483  Test_loss : 5944.0381, Time/batch_file : 2.2897, Training time: 5399.0285\n",
      "Epoch : 465/2000 data_batch_1,  Train_loss : 5020.9990  Test_loss : 5326.1040, Time/batch_file : 2.2882, Training time: 5401.3169\n",
      "Epoch : 465/2000 data_batch_2,  Train_loss : 5175.0342  Test_loss : 5677.1777, Time/batch_file : 2.2852, Training time: 5403.6023\n",
      "Epoch : 465/2000 data_batch_3,  Train_loss : 5226.6328  Test_loss : 5718.8804, Time/batch_file : 2.2946, Training time: 5405.8971\n",
      "Epoch : 465/2000 data_batch_4,  Train_loss : 5300.7661  Test_loss : 5466.7007, Time/batch_file : 2.2940, Training time: 5408.1914\n",
      "Epoch : 465/2000 data_batch_5,  Train_loss : 5179.6484  Test_loss : 5617.5825, Time/batch_file : 2.2833, Training time: 5410.4749\n",
      "Epoch : 466/2000 data_batch_1,  Train_loss : 5185.2744  Test_loss : 5910.6729, Time/batch_file : 2.2882, Training time: 5412.7633\n",
      "Epoch : 466/2000 data_batch_2,  Train_loss : 5391.3838  Test_loss : 5919.9233, Time/batch_file : 2.2799, Training time: 5415.0434\n",
      "Epoch : 466/2000 data_batch_3,  Train_loss : 5674.0396  Test_loss : 6109.7993, Time/batch_file : 2.2841, Training time: 5417.3277\n",
      "Epoch : 466/2000 data_batch_4,  Train_loss : 5530.8457  Test_loss : 5924.6963, Time/batch_file : 2.3115, Training time: 5419.6394\n",
      "Epoch : 466/2000 data_batch_5,  Train_loss : 5755.4868  Test_loss : 5883.4048, Time/batch_file : 2.3105, Training time: 5421.9501\n",
      "Epoch : 467/2000 data_batch_1,  Train_loss : 5518.8047  Test_loss : 6240.8369, Time/batch_file : 2.2993, Training time: 5424.2496\n",
      "Epoch : 467/2000 data_batch_2,  Train_loss : 5218.7720  Test_loss : 5937.3037, Time/batch_file : 2.2939, Training time: 5426.5437\n",
      "Epoch : 467/2000 data_batch_3,  Train_loss : 5281.3667  Test_loss : 6673.3750, Time/batch_file : 2.3017, Training time: 5428.8456\n",
      "Epoch : 467/2000 data_batch_4,  Train_loss : 5603.6094  Test_loss : 5931.4717, Time/batch_file : 2.2909, Training time: 5431.1367\n",
      "Epoch : 467/2000 data_batch_5,  Train_loss : 5057.8511  Test_loss : 6331.0107, Time/batch_file : 2.3016, Training time: 5433.4385\n",
      "Epoch : 468/2000 data_batch_1,  Train_loss : 5668.5229  Test_loss : 5386.1377, Time/batch_file : 2.2800, Training time: 5435.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 468/2000 data_batch_2,  Train_loss : 5482.6572  Test_loss : 5560.3203, Time/batch_file : 2.2977, Training time: 5438.0167\n",
      "Epoch : 468/2000 data_batch_3,  Train_loss : 5413.0088  Test_loss : 5500.9595, Time/batch_file : 2.2825, Training time: 5440.2993\n",
      "Epoch : 468/2000 data_batch_4,  Train_loss : 5577.4517  Test_loss : 5640.3457, Time/batch_file : 2.2835, Training time: 5442.5830\n",
      "Epoch : 468/2000 data_batch_5,  Train_loss : 5564.2393  Test_loss : 5695.5161, Time/batch_file : 2.2834, Training time: 5444.8665\n",
      "Epoch : 469/2000 data_batch_1,  Train_loss : 6165.3296  Test_loss : 5949.4609, Time/batch_file : 2.2974, Training time: 5447.1641\n",
      "Epoch : 469/2000 data_batch_2,  Train_loss : 5887.4966  Test_loss : 5718.1641, Time/batch_file : 2.2993, Training time: 5449.4636\n",
      "Epoch : 469/2000 data_batch_3,  Train_loss : 6011.7305  Test_loss : 5831.7490, Time/batch_file : 2.3122, Training time: 5451.7761\n",
      "Epoch : 469/2000 data_batch_4,  Train_loss : 5461.0781  Test_loss : 5491.3960, Time/batch_file : 2.3034, Training time: 5454.0796\n",
      "Epoch : 469/2000 data_batch_5,  Train_loss : 6076.5166  Test_loss : 5951.0210, Time/batch_file : 2.2997, Training time: 5456.3794\n",
      "Epoch : 470/2000 data_batch_1,  Train_loss : 5475.6201  Test_loss : 5770.0283, Time/batch_file : 2.2985, Training time: 5458.6781\n",
      "Epoch : 470/2000 data_batch_2,  Train_loss : 5694.5171  Test_loss : 5972.5557, Time/batch_file : 2.2910, Training time: 5460.9693\n",
      "Epoch : 470/2000 data_batch_3,  Train_loss : 5533.0430  Test_loss : 5948.4038, Time/batch_file : 2.2861, Training time: 5463.2555\n",
      "Epoch : 470/2000 data_batch_4,  Train_loss : 5578.3018  Test_loss : 5854.6001, Time/batch_file : 2.2902, Training time: 5465.5459\n",
      "Epoch : 470/2000 data_batch_5,  Train_loss : 5220.2305  Test_loss : 5888.6050, Time/batch_file : 2.2794, Training time: 5467.8256\n",
      "[./nets/net-470.ckpt] SAVED\n",
      "Epoch : 471/2000 data_batch_1,  Train_loss : 5285.3125  Test_loss : 6130.7910, Time/batch_file : 2.3197, Training time: 5472.8371\n",
      "Epoch : 471/2000 data_batch_2,  Train_loss : 5534.1348  Test_loss : 5815.3672, Time/batch_file : 2.2767, Training time: 5475.1140\n",
      "Epoch : 471/2000 data_batch_3,  Train_loss : 5489.5918  Test_loss : 5888.5444, Time/batch_file : 2.2871, Training time: 5477.4013\n",
      "Epoch : 471/2000 data_batch_4,  Train_loss : 5735.4912  Test_loss : 5842.0210, Time/batch_file : 2.2874, Training time: 5479.6888\n",
      "Epoch : 471/2000 data_batch_5,  Train_loss : 5617.7617  Test_loss : 5767.3936, Time/batch_file : 2.2783, Training time: 5481.9673\n",
      "Epoch : 472/2000 data_batch_1,  Train_loss : 5397.3530  Test_loss : 6219.9717, Time/batch_file : 2.2922, Training time: 5484.2597\n",
      "Epoch : 472/2000 data_batch_2,  Train_loss : 5416.7427  Test_loss : 6038.5420, Time/batch_file : 2.2840, Training time: 5486.5439\n",
      "Epoch : 472/2000 data_batch_3,  Train_loss : 5349.6982  Test_loss : 6098.9023, Time/batch_file : 2.2837, Training time: 5488.8278\n",
      "Epoch : 472/2000 data_batch_4,  Train_loss : 5404.9087  Test_loss : 6194.1538, Time/batch_file : 2.2788, Training time: 5491.1068\n",
      "Epoch : 472/2000 data_batch_5,  Train_loss : 5380.5498  Test_loss : 6058.1025, Time/batch_file : 2.2865, Training time: 5493.3935\n",
      "Epoch : 473/2000 data_batch_1,  Train_loss : 5310.0981  Test_loss : 5523.7852, Time/batch_file : 2.2810, Training time: 5495.6748\n",
      "Epoch : 473/2000 data_batch_2,  Train_loss : 5428.9590  Test_loss : 5143.1772, Time/batch_file : 2.2804, Training time: 5497.9554\n",
      "Epoch : 473/2000 data_batch_3,  Train_loss : 5784.6504  Test_loss : 5685.5742, Time/batch_file : 2.2607, Training time: 5500.2164\n",
      "Epoch : 473/2000 data_batch_4,  Train_loss : 5604.6543  Test_loss : 5080.0635, Time/batch_file : 2.2827, Training time: 5502.4992\n",
      "Epoch : 473/2000 data_batch_5,  Train_loss : 5571.6182  Test_loss : 5276.5146, Time/batch_file : 2.2827, Training time: 5504.7821\n",
      "Epoch : 474/2000 data_batch_1,  Train_loss : 5774.5610  Test_loss : 5719.4424, Time/batch_file : 2.2698, Training time: 5507.0521\n",
      "Epoch : 474/2000 data_batch_2,  Train_loss : 5466.3149  Test_loss : 5725.2583, Time/batch_file : 2.2566, Training time: 5509.3090\n",
      "Epoch : 474/2000 data_batch_3,  Train_loss : 5690.3848  Test_loss : 5527.4385, Time/batch_file : 2.2878, Training time: 5511.5970\n",
      "Epoch : 474/2000 data_batch_4,  Train_loss : 5356.4424  Test_loss : 5515.1792, Time/batch_file : 2.2735, Training time: 5513.8707\n",
      "Epoch : 474/2000 data_batch_5,  Train_loss : 5594.5928  Test_loss : 6010.5537, Time/batch_file : 2.2712, Training time: 5516.1421\n",
      "Epoch : 475/2000 data_batch_1,  Train_loss : 5695.7358  Test_loss : 5425.5693, Time/batch_file : 2.2671, Training time: 5518.4094\n",
      "Epoch : 475/2000 data_batch_2,  Train_loss : 5848.8911  Test_loss : 5931.2539, Time/batch_file : 2.2912, Training time: 5520.7008\n",
      "Epoch : 475/2000 data_batch_3,  Train_loss : 5592.4878  Test_loss : 6064.8027, Time/batch_file : 2.2812, Training time: 5522.9823\n",
      "Epoch : 475/2000 data_batch_4,  Train_loss : 5447.6836  Test_loss : 5631.5703, Time/batch_file : 2.2718, Training time: 5525.2542\n",
      "Epoch : 475/2000 data_batch_5,  Train_loss : 5448.5400  Test_loss : 5868.5410, Time/batch_file : 2.2640, Training time: 5527.5184\n",
      "Epoch : 476/2000 data_batch_1,  Train_loss : 5291.2744  Test_loss : 5267.1636, Time/batch_file : 2.3072, Training time: 5529.8259\n",
      "Epoch : 476/2000 data_batch_2,  Train_loss : 5084.2983  Test_loss : 5726.2002, Time/batch_file : 2.2784, Training time: 5532.1044\n",
      "Epoch : 476/2000 data_batch_3,  Train_loss : 5267.7275  Test_loss : 5575.4395, Time/batch_file : 2.2841, Training time: 5534.3887\n",
      "Epoch : 476/2000 data_batch_4,  Train_loss : 5425.8105  Test_loss : 5296.1973, Time/batch_file : 2.2682, Training time: 5536.6572\n",
      "Epoch : 476/2000 data_batch_5,  Train_loss : 5288.2837  Test_loss : 5200.7036, Time/batch_file : 2.2931, Training time: 5538.9506\n",
      "Epoch : 477/2000 data_batch_1,  Train_loss : 5587.1719  Test_loss : 5171.3550, Time/batch_file : 2.2708, Training time: 5541.2215\n",
      "Epoch : 477/2000 data_batch_2,  Train_loss : 5658.3330  Test_loss : 5389.6426, Time/batch_file : 2.2802, Training time: 5543.5020\n",
      "Epoch : 477/2000 data_batch_3,  Train_loss : 5307.8086  Test_loss : 5230.5791, Time/batch_file : 2.2550, Training time: 5545.7572\n",
      "Epoch : 477/2000 data_batch_4,  Train_loss : 5520.8730  Test_loss : 5164.5732, Time/batch_file : 2.2859, Training time: 5548.0433\n",
      "Epoch : 477/2000 data_batch_5,  Train_loss : 5560.9985  Test_loss : 5334.8818, Time/batch_file : 2.2726, Training time: 5550.3161\n",
      "Epoch : 478/2000 data_batch_1,  Train_loss : 4985.3765  Test_loss : 5468.4600, Time/batch_file : 2.3031, Training time: 5552.6193\n",
      "Epoch : 478/2000 data_batch_2,  Train_loss : 5238.6772  Test_loss : 5379.3887, Time/batch_file : 2.2806, Training time: 5554.9001\n",
      "Epoch : 478/2000 data_batch_3,  Train_loss : 4971.9561  Test_loss : 5672.6519, Time/batch_file : 2.3033, Training time: 5557.2036\n",
      "Epoch : 478/2000 data_batch_4,  Train_loss : 4682.4326  Test_loss : 5683.0073, Time/batch_file : 2.2839, Training time: 5559.4877\n",
      "Epoch : 478/2000 data_batch_5,  Train_loss : 4898.9092  Test_loss : 5405.9639, Time/batch_file : 2.2906, Training time: 5561.7785\n",
      "Epoch : 479/2000 data_batch_1,  Train_loss : 5374.5547  Test_loss : 5413.2881, Time/batch_file : 2.2714, Training time: 5564.0501\n",
      "Epoch : 479/2000 data_batch_2,  Train_loss : 5459.5488  Test_loss : 5636.3818, Time/batch_file : 2.2999, Training time: 5566.3501\n",
      "Epoch : 479/2000 data_batch_3,  Train_loss : 5512.7310  Test_loss : 5462.3208, Time/batch_file : 2.2872, Training time: 5568.6375\n",
      "Epoch : 479/2000 data_batch_4,  Train_loss : 5177.4404  Test_loss : 5902.7202, Time/batch_file : 2.2910, Training time: 5570.9288\n",
      "Epoch : 479/2000 data_batch_5,  Train_loss : 5391.7466  Test_loss : 5792.0425, Time/batch_file : 2.2742, Training time: 5573.2033\n",
      "Epoch : 480/2000 data_batch_1,  Train_loss : 5270.3232  Test_loss : 5870.9761, Time/batch_file : 2.3159, Training time: 5575.5194\n",
      "Epoch : 480/2000 data_batch_2,  Train_loss : 5404.3247  Test_loss : 5851.5391, Time/batch_file : 2.2853, Training time: 5577.8050\n",
      "Epoch : 480/2000 data_batch_3,  Train_loss : 5699.2812  Test_loss : 6256.2827, Time/batch_file : 2.2873, Training time: 5580.0925\n",
      "Epoch : 480/2000 data_batch_4,  Train_loss : 5482.0747  Test_loss : 5717.3691, Time/batch_file : 2.2710, Training time: 5582.3638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 480/2000 data_batch_5,  Train_loss : 5305.4526  Test_loss : 5852.6450, Time/batch_file : 2.2945, Training time: 5584.6584\n",
      "[./nets/net-480.ckpt] SAVED\n",
      "Epoch : 481/2000 data_batch_1,  Train_loss : 5319.5537  Test_loss : 5508.6924, Time/batch_file : 2.3066, Training time: 5588.2733\n",
      "Epoch : 481/2000 data_batch_2,  Train_loss : 5633.6064  Test_loss : 5451.3916, Time/batch_file : 2.2863, Training time: 5590.5598\n",
      "Epoch : 481/2000 data_batch_3,  Train_loss : 5834.0312  Test_loss : 5436.6772, Time/batch_file : 2.2701, Training time: 5592.8301\n",
      "Epoch : 481/2000 data_batch_4,  Train_loss : 5238.2612  Test_loss : 5390.6196, Time/batch_file : 2.2962, Training time: 5595.1265\n",
      "Epoch : 481/2000 data_batch_5,  Train_loss : 5352.9219  Test_loss : 5537.1582, Time/batch_file : 2.2780, Training time: 5597.4047\n",
      "Epoch : 482/2000 data_batch_1,  Train_loss : 5674.1768  Test_loss : 5249.4282, Time/batch_file : 2.2871, Training time: 5599.6920\n",
      "Epoch : 482/2000 data_batch_2,  Train_loss : 5723.9648  Test_loss : 5425.0991, Time/batch_file : 2.2852, Training time: 5601.9774\n",
      "Epoch : 482/2000 data_batch_3,  Train_loss : 5407.6089  Test_loss : 5314.6245, Time/batch_file : 2.2984, Training time: 5604.2759\n",
      "Epoch : 482/2000 data_batch_4,  Train_loss : 5753.8403  Test_loss : 5290.9922, Time/batch_file : 2.2833, Training time: 5606.5593\n",
      "Epoch : 482/2000 data_batch_5,  Train_loss : 5782.8926  Test_loss : 5484.7510, Time/batch_file : 2.2812, Training time: 5608.8408\n",
      "Epoch : 483/2000 data_batch_1,  Train_loss : 5039.3750  Test_loss : 5479.5054, Time/batch_file : 2.2854, Training time: 5611.1264\n",
      "Epoch : 483/2000 data_batch_2,  Train_loss : 5253.5156  Test_loss : 5574.3418, Time/batch_file : 2.2763, Training time: 5613.4029\n",
      "Epoch : 483/2000 data_batch_3,  Train_loss : 5084.3491  Test_loss : 5459.7842, Time/batch_file : 2.2670, Training time: 5615.6700\n",
      "Epoch : 483/2000 data_batch_4,  Train_loss : 4919.3447  Test_loss : 6114.3057, Time/batch_file : 2.2857, Training time: 5617.9559\n",
      "Epoch : 483/2000 data_batch_5,  Train_loss : 5448.9473  Test_loss : 5658.8008, Time/batch_file : 2.2647, Training time: 5620.2209\n",
      "Epoch : 484/2000 data_batch_1,  Train_loss : 5330.1680  Test_loss : 5740.1211, Time/batch_file : 2.2805, Training time: 5622.5015\n",
      "Epoch : 484/2000 data_batch_2,  Train_loss : 5581.5479  Test_loss : 5748.1660, Time/batch_file : 2.2926, Training time: 5624.7945\n",
      "Epoch : 484/2000 data_batch_3,  Train_loss : 5477.0352  Test_loss : 5478.8438, Time/batch_file : 2.2794, Training time: 5627.0740\n",
      "Epoch : 484/2000 data_batch_4,  Train_loss : 5400.2178  Test_loss : 5517.1050, Time/batch_file : 2.2725, Training time: 5629.3467\n",
      "Epoch : 484/2000 data_batch_5,  Train_loss : 5385.6411  Test_loss : 5356.8940, Time/batch_file : 2.2888, Training time: 5631.6357\n",
      "Epoch : 485/2000 data_batch_1,  Train_loss : 5168.4165  Test_loss : 5891.1143, Time/batch_file : 2.2882, Training time: 5633.9240\n",
      "Epoch : 485/2000 data_batch_2,  Train_loss : 5285.1777  Test_loss : 5620.9316, Time/batch_file : 2.2917, Training time: 5636.2160\n",
      "Epoch : 485/2000 data_batch_3,  Train_loss : 5181.2373  Test_loss : 5970.3633, Time/batch_file : 2.2821, Training time: 5638.4984\n",
      "Epoch : 485/2000 data_batch_4,  Train_loss : 5194.2949  Test_loss : 6093.4448, Time/batch_file : 2.2980, Training time: 5640.7966\n",
      "Epoch : 485/2000 data_batch_5,  Train_loss : 5162.3584  Test_loss : 5909.4692, Time/batch_file : 2.2987, Training time: 5643.0956\n",
      "Epoch : 486/2000 data_batch_1,  Train_loss : 5009.7236  Test_loss : 5936.7017, Time/batch_file : 2.3264, Training time: 5645.4222\n",
      "Epoch : 486/2000 data_batch_2,  Train_loss : 5175.0713  Test_loss : 5921.0742, Time/batch_file : 2.2801, Training time: 5647.7025\n",
      "Epoch : 486/2000 data_batch_3,  Train_loss : 5189.8379  Test_loss : 5690.6382, Time/batch_file : 2.2828, Training time: 5649.9855\n",
      "Epoch : 486/2000 data_batch_4,  Train_loss : 5100.9482  Test_loss : 5906.8584, Time/batch_file : 2.2802, Training time: 5652.2659\n",
      "Epoch : 486/2000 data_batch_5,  Train_loss : 5012.5713  Test_loss : 5691.8745, Time/batch_file : 2.2931, Training time: 5654.5592\n",
      "Epoch : 487/2000 data_batch_1,  Train_loss : 5593.5479  Test_loss : 5599.3594, Time/batch_file : 2.2835, Training time: 5656.8428\n",
      "Epoch : 487/2000 data_batch_2,  Train_loss : 5741.3438  Test_loss : 5716.5630, Time/batch_file : 2.2818, Training time: 5659.1249\n",
      "Epoch : 487/2000 data_batch_3,  Train_loss : 6040.8726  Test_loss : 5411.9575, Time/batch_file : 2.2778, Training time: 5661.4029\n",
      "Epoch : 487/2000 data_batch_4,  Train_loss : 5770.1855  Test_loss : 5810.2227, Time/batch_file : 2.2796, Training time: 5663.6827\n",
      "Epoch : 487/2000 data_batch_5,  Train_loss : 5559.8457  Test_loss : 5476.8716, Time/batch_file : 2.2845, Training time: 5665.9674\n",
      "Epoch : 488/2000 data_batch_1,  Train_loss : 5858.9253  Test_loss : 5514.0742, Time/batch_file : 2.2816, Training time: 5668.2493\n",
      "Epoch : 488/2000 data_batch_2,  Train_loss : 6167.3633  Test_loss : 5236.6621, Time/batch_file : 2.3046, Training time: 5670.5540\n",
      "Epoch : 488/2000 data_batch_3,  Train_loss : 5901.5977  Test_loss : 5343.8472, Time/batch_file : 2.2981, Training time: 5672.8523\n",
      "Epoch : 488/2000 data_batch_4,  Train_loss : 6133.0381  Test_loss : 5365.1543, Time/batch_file : 2.2968, Training time: 5675.1493\n",
      "Epoch : 488/2000 data_batch_5,  Train_loss : 6452.7617  Test_loss : 5792.8667, Time/batch_file : 2.2924, Training time: 5677.4420\n",
      "Epoch : 489/2000 data_batch_1,  Train_loss : 5196.7832  Test_loss : 5621.4082, Time/batch_file : 2.2993, Training time: 5679.7415\n",
      "Epoch : 489/2000 data_batch_2,  Train_loss : 5313.8149  Test_loss : 5752.6206, Time/batch_file : 2.2862, Training time: 5682.0280\n",
      "Epoch : 489/2000 data_batch_3,  Train_loss : 5320.6230  Test_loss : 5537.4150, Time/batch_file : 2.2789, Training time: 5684.3071\n",
      "Epoch : 489/2000 data_batch_4,  Train_loss : 5388.6206  Test_loss : 5453.6870, Time/batch_file : 2.2839, Training time: 5686.5911\n",
      "Epoch : 489/2000 data_batch_5,  Train_loss : 5344.2173  Test_loss : 5378.1631, Time/batch_file : 2.2787, Training time: 5688.8700\n",
      "Epoch : 490/2000 data_batch_1,  Train_loss : 5315.1177  Test_loss : 5398.5576, Time/batch_file : 2.2892, Training time: 5691.1595\n",
      "Epoch : 490/2000 data_batch_2,  Train_loss : 5434.1108  Test_loss : 5566.9614, Time/batch_file : 2.2880, Training time: 5693.4476\n",
      "Epoch : 490/2000 data_batch_3,  Train_loss : 5766.6802  Test_loss : 5910.4487, Time/batch_file : 2.2869, Training time: 5695.7348\n",
      "Epoch : 490/2000 data_batch_4,  Train_loss : 5523.6079  Test_loss : 5422.2041, Time/batch_file : 2.2965, Training time: 5698.0315\n",
      "Epoch : 490/2000 data_batch_5,  Train_loss : 5436.0322  Test_loss : 5327.3901, Time/batch_file : 2.2863, Training time: 5700.3180\n",
      "[./nets/net-490.ckpt] SAVED\n",
      "Epoch : 491/2000 data_batch_1,  Train_loss : 5685.4824  Test_loss : 5210.1289, Time/batch_file : 2.3000, Training time: 5703.9213\n",
      "Epoch : 491/2000 data_batch_2,  Train_loss : 5664.7617  Test_loss : 4976.2168, Time/batch_file : 2.2937, Training time: 5706.2153\n",
      "Epoch : 491/2000 data_batch_3,  Train_loss : 5587.5078  Test_loss : 5172.1592, Time/batch_file : 2.2985, Training time: 5708.5140\n",
      "Epoch : 491/2000 data_batch_4,  Train_loss : 5292.7954  Test_loss : 5302.5708, Time/batch_file : 2.3114, Training time: 5710.8255\n",
      "Epoch : 491/2000 data_batch_5,  Train_loss : 5368.4673  Test_loss : 5117.6807, Time/batch_file : 2.3118, Training time: 5713.1376\n",
      "Epoch : 492/2000 data_batch_1,  Train_loss : 5699.9590  Test_loss : 5817.2139, Time/batch_file : 2.3012, Training time: 5715.4391\n",
      "Epoch : 492/2000 data_batch_2,  Train_loss : 5704.8159  Test_loss : 5810.7065, Time/batch_file : 2.2908, Training time: 5717.7301\n",
      "Epoch : 492/2000 data_batch_3,  Train_loss : 5790.3818  Test_loss : 5690.8813, Time/batch_file : 2.3046, Training time: 5720.0350\n",
      "Epoch : 492/2000 data_batch_4,  Train_loss : 5721.5117  Test_loss : 5872.5527, Time/batch_file : 2.2780, Training time: 5722.3132\n",
      "Epoch : 492/2000 data_batch_5,  Train_loss : 5922.6509  Test_loss : 5607.7593, Time/batch_file : 2.2944, Training time: 5724.6077\n",
      "Epoch : 493/2000 data_batch_1,  Train_loss : 5494.2485  Test_loss : 5703.8701, Time/batch_file : 2.2945, Training time: 5726.9024\n",
      "Epoch : 493/2000 data_batch_2,  Train_loss : 6147.6089  Test_loss : 5593.0840, Time/batch_file : 2.2869, Training time: 5729.1896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 493/2000 data_batch_3,  Train_loss : 5815.7393  Test_loss : 5377.4692, Time/batch_file : 2.2926, Training time: 5731.4823\n",
      "Epoch : 493/2000 data_batch_4,  Train_loss : 5679.3594  Test_loss : 5557.0376, Time/batch_file : 2.2867, Training time: 5733.7693\n",
      "Epoch : 493/2000 data_batch_5,  Train_loss : 5690.3291  Test_loss : 5972.9473, Time/batch_file : 2.2874, Training time: 5736.0568\n",
      "Epoch : 494/2000 data_batch_1,  Train_loss : 5356.5117  Test_loss : 5208.1978, Time/batch_file : 2.2601, Training time: 5738.3172\n",
      "Epoch : 494/2000 data_batch_2,  Train_loss : 5205.6240  Test_loss : 5388.0996, Time/batch_file : 2.2717, Training time: 5740.5890\n",
      "Epoch : 494/2000 data_batch_3,  Train_loss : 5397.3008  Test_loss : 5316.8164, Time/batch_file : 2.2687, Training time: 5742.8579\n",
      "Epoch : 494/2000 data_batch_4,  Train_loss : 5106.3735  Test_loss : 5340.4185, Time/batch_file : 2.2720, Training time: 5745.1300\n",
      "Epoch : 494/2000 data_batch_5,  Train_loss : 5272.5469  Test_loss : 5117.3960, Time/batch_file : 2.2594, Training time: 5747.3897\n",
      "Epoch : 495/2000 data_batch_1,  Train_loss : 6038.3555  Test_loss : 6050.9756, Time/batch_file : 2.2810, Training time: 5749.6711\n",
      "Epoch : 495/2000 data_batch_2,  Train_loss : 5825.9243  Test_loss : 5809.3569, Time/batch_file : 2.2821, Training time: 5751.9533\n",
      "Epoch : 495/2000 data_batch_3,  Train_loss : 5948.7812  Test_loss : 5581.9717, Time/batch_file : 2.2900, Training time: 5754.2434\n",
      "Epoch : 495/2000 data_batch_4,  Train_loss : 5673.5562  Test_loss : 5778.3730, Time/batch_file : 2.2693, Training time: 5756.5130\n",
      "Epoch : 495/2000 data_batch_5,  Train_loss : 5730.7021  Test_loss : 5725.1021, Time/batch_file : 2.2809, Training time: 5758.7942\n",
      "Epoch : 496/2000 data_batch_1,  Train_loss : 5449.4131  Test_loss : 5334.5303, Time/batch_file : 2.2786, Training time: 5761.0729\n",
      "Epoch : 496/2000 data_batch_2,  Train_loss : 5496.5542  Test_loss : 5609.7383, Time/batch_file : 2.2904, Training time: 5763.3636\n",
      "Epoch : 496/2000 data_batch_3,  Train_loss : 5624.3320  Test_loss : 5709.3218, Time/batch_file : 2.2785, Training time: 5765.6424\n",
      "Epoch : 496/2000 data_batch_4,  Train_loss : 5504.9443  Test_loss : 5435.0381, Time/batch_file : 2.2856, Training time: 5767.9281\n",
      "Epoch : 496/2000 data_batch_5,  Train_loss : 5120.8174  Test_loss : 5466.5479, Time/batch_file : 2.2979, Training time: 5770.2263\n",
      "Epoch : 497/2000 data_batch_1,  Train_loss : 5845.6338  Test_loss : 5472.0977, Time/batch_file : 2.2707, Training time: 5772.4973\n",
      "Epoch : 497/2000 data_batch_2,  Train_loss : 5466.3457  Test_loss : 5174.4424, Time/batch_file : 2.2655, Training time: 5774.7630\n",
      "Epoch : 497/2000 data_batch_3,  Train_loss : 5428.7192  Test_loss : 5242.2456, Time/batch_file : 2.2736, Training time: 5777.0368\n",
      "Epoch : 497/2000 data_batch_4,  Train_loss : 5463.2119  Test_loss : 5150.4570, Time/batch_file : 2.2773, Training time: 5779.3143\n",
      "Epoch : 497/2000 data_batch_5,  Train_loss : 5745.3032  Test_loss : 5210.2305, Time/batch_file : 2.2780, Training time: 5781.5926\n",
      "Epoch : 498/2000 data_batch_1,  Train_loss : 5377.7808  Test_loss : 5348.2163, Time/batch_file : 2.2674, Training time: 5783.8602\n",
      "Epoch : 498/2000 data_batch_2,  Train_loss : 5331.5332  Test_loss : 5501.4399, Time/batch_file : 2.2899, Training time: 5786.1504\n",
      "Epoch : 498/2000 data_batch_3,  Train_loss : 5458.8794  Test_loss : 5707.7397, Time/batch_file : 2.2752, Training time: 5788.4258\n",
      "Epoch : 498/2000 data_batch_4,  Train_loss : 5105.2764  Test_loss : 5720.6938, Time/batch_file : 2.2801, Training time: 5790.7061\n",
      "Epoch : 498/2000 data_batch_5,  Train_loss : 5257.5283  Test_loss : 5781.3643, Time/batch_file : 2.2718, Training time: 5792.9780\n",
      "Epoch : 499/2000 data_batch_1,  Train_loss : 5336.8008  Test_loss : 5714.6128, Time/batch_file : 2.2759, Training time: 5795.2541\n",
      "Epoch : 499/2000 data_batch_2,  Train_loss : 5174.8521  Test_loss : 5539.2979, Time/batch_file : 2.2692, Training time: 5797.5235\n",
      "Epoch : 499/2000 data_batch_3,  Train_loss : 5424.1431  Test_loss : 5678.3052, Time/batch_file : 2.2718, Training time: 5799.7954\n",
      "Epoch : 499/2000 data_batch_4,  Train_loss : 5509.6753  Test_loss : 5755.1416, Time/batch_file : 2.2737, Training time: 5802.0694\n",
      "Epoch : 499/2000 data_batch_5,  Train_loss : 5390.3203  Test_loss : 5662.8760, Time/batch_file : 2.2863, Training time: 5804.3559\n",
      "Epoch : 500/2000 data_batch_1,  Train_loss : 5501.7969  Test_loss : 5160.9077, Time/batch_file : 2.2789, Training time: 5806.6351\n",
      "Epoch : 500/2000 data_batch_2,  Train_loss : 5378.1421  Test_loss : 5608.7295, Time/batch_file : 2.2841, Training time: 5808.9194\n",
      "Epoch : 500/2000 data_batch_3,  Train_loss : 5294.7354  Test_loss : 5276.1597, Time/batch_file : 2.2694, Training time: 5811.1890\n",
      "Epoch : 500/2000 data_batch_4,  Train_loss : 5395.3389  Test_loss : 5567.1592, Time/batch_file : 2.2884, Training time: 5813.4777\n",
      "Epoch : 500/2000 data_batch_5,  Train_loss : 5403.9751  Test_loss : 5563.5488, Time/batch_file : 2.2823, Training time: 5815.7602\n",
      "[./nets/net-500.ckpt] SAVED\n",
      "Epoch : 501/2000 data_batch_1,  Train_loss : 5864.5439  Test_loss : 5578.1562, Time/batch_file : 2.3208, Training time: 5819.4064\n",
      "Epoch : 501/2000 data_batch_2,  Train_loss : 5435.1445  Test_loss : 5595.4517, Time/batch_file : 2.2932, Training time: 5821.6997\n",
      "Epoch : 501/2000 data_batch_3,  Train_loss : 5524.6714  Test_loss : 5754.7905, Time/batch_file : 2.3144, Training time: 5824.0144\n",
      "Epoch : 501/2000 data_batch_4,  Train_loss : 5375.2056  Test_loss : 5915.1851, Time/batch_file : 2.2933, Training time: 5826.3079\n",
      "Epoch : 501/2000 data_batch_5,  Train_loss : 5289.6392  Test_loss : 5663.7056, Time/batch_file : 2.2929, Training time: 5828.6010\n",
      "Epoch : 502/2000 data_batch_1,  Train_loss : 5687.3486  Test_loss : 6029.4546, Time/batch_file : 2.2795, Training time: 5830.8806\n",
      "Epoch : 502/2000 data_batch_2,  Train_loss : 5601.3037  Test_loss : 5856.2559, Time/batch_file : 2.2981, Training time: 5833.1789\n",
      "Epoch : 502/2000 data_batch_3,  Train_loss : 5526.9233  Test_loss : 5988.5825, Time/batch_file : 2.2895, Training time: 5835.4685\n",
      "Epoch : 502/2000 data_batch_4,  Train_loss : 5588.6973  Test_loss : 5859.5942, Time/batch_file : 2.2887, Training time: 5837.7574\n",
      "Epoch : 502/2000 data_batch_5,  Train_loss : 5513.4072  Test_loss : 5954.7607, Time/batch_file : 2.2705, Training time: 5840.0281\n",
      "Epoch : 503/2000 data_batch_1,  Train_loss : 5429.8418  Test_loss : 5821.1099, Time/batch_file : 2.2790, Training time: 5842.3073\n",
      "Epoch : 503/2000 data_batch_2,  Train_loss : 5607.7529  Test_loss : 5896.4346, Time/batch_file : 2.3207, Training time: 5844.6282\n",
      "Epoch : 503/2000 data_batch_3,  Train_loss : 5156.8672  Test_loss : 6124.6401, Time/batch_file : 2.2911, Training time: 5846.9196\n",
      "Epoch : 503/2000 data_batch_4,  Train_loss : 5369.9058  Test_loss : 5917.8936, Time/batch_file : 2.3141, Training time: 5849.2338\n",
      "Epoch : 503/2000 data_batch_5,  Train_loss : 5330.2607  Test_loss : 6043.5879, Time/batch_file : 2.2958, Training time: 5851.5298\n",
      "Epoch : 504/2000 data_batch_1,  Train_loss : 5539.0347  Test_loss : 4959.2012, Time/batch_file : 2.2949, Training time: 5853.8249\n",
      "Epoch : 504/2000 data_batch_2,  Train_loss : 5682.0068  Test_loss : 5004.8926, Time/batch_file : 2.2827, Training time: 5856.1077\n",
      "Epoch : 504/2000 data_batch_3,  Train_loss : 5405.8501  Test_loss : 5168.9771, Time/batch_file : 2.2998, Training time: 5858.4078\n",
      "Epoch : 504/2000 data_batch_4,  Train_loss : 5276.4170  Test_loss : 4973.5122, Time/batch_file : 2.2933, Training time: 5860.7013\n",
      "Epoch : 504/2000 data_batch_5,  Train_loss : 5365.9575  Test_loss : 4877.5610, Time/batch_file : 2.2980, Training time: 5862.9995\n",
      "Epoch : 505/2000 data_batch_1,  Train_loss : 4711.0635  Test_loss : 5502.9468, Time/batch_file : 2.2968, Training time: 5865.2965\n",
      "Epoch : 505/2000 data_batch_2,  Train_loss : 5091.1084  Test_loss : 5537.9277, Time/batch_file : 2.2915, Training time: 5867.5882\n",
      "Epoch : 505/2000 data_batch_3,  Train_loss : 5272.4639  Test_loss : 5820.9219, Time/batch_file : 2.3098, Training time: 5869.8981\n",
      "Epoch : 505/2000 data_batch_4,  Train_loss : 5128.7808  Test_loss : 5384.6641, Time/batch_file : 2.2910, Training time: 5872.1893\n",
      "Epoch : 505/2000 data_batch_5,  Train_loss : 5166.8354  Test_loss : 5601.9033, Time/batch_file : 2.3139, Training time: 5874.5033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 506/2000 data_batch_1,  Train_loss : 5305.7041  Test_loss : 5678.8169, Time/batch_file : 2.2863, Training time: 5876.7899\n",
      "Epoch : 506/2000 data_batch_2,  Train_loss : 5409.1909  Test_loss : 5716.2622, Time/batch_file : 2.3024, Training time: 5879.0925\n",
      "Epoch : 506/2000 data_batch_3,  Train_loss : 5433.8989  Test_loss : 5835.0464, Time/batch_file : 2.2903, Training time: 5881.3830\n",
      "Epoch : 506/2000 data_batch_4,  Train_loss : 5093.0684  Test_loss : 5786.5024, Time/batch_file : 2.2978, Training time: 5883.6810\n",
      "Epoch : 506/2000 data_batch_5,  Train_loss : 5132.0513  Test_loss : 5746.5874, Time/batch_file : 2.3088, Training time: 5885.9900\n",
      "Epoch : 507/2000 data_batch_1,  Train_loss : 5242.8735  Test_loss : 6253.3477, Time/batch_file : 2.3078, Training time: 5888.2979\n",
      "Epoch : 507/2000 data_batch_2,  Train_loss : 5366.2734  Test_loss : 6004.1060, Time/batch_file : 2.2959, Training time: 5890.5941\n",
      "Epoch : 507/2000 data_batch_3,  Train_loss : 5380.1450  Test_loss : 5992.5967, Time/batch_file : 2.2837, Training time: 5892.8780\n",
      "Epoch : 507/2000 data_batch_4,  Train_loss : 5573.4878  Test_loss : 6053.1729, Time/batch_file : 2.3043, Training time: 5895.1824\n",
      "Epoch : 507/2000 data_batch_5,  Train_loss : 5469.3613  Test_loss : 6120.1289, Time/batch_file : 2.2892, Training time: 5897.4718\n",
      "Epoch : 508/2000 data_batch_1,  Train_loss : 5751.0596  Test_loss : 5535.4087, Time/batch_file : 2.3024, Training time: 5899.7744\n",
      "Epoch : 508/2000 data_batch_2,  Train_loss : 5734.7539  Test_loss : 5759.0483, Time/batch_file : 2.2913, Training time: 5902.0659\n",
      "Epoch : 508/2000 data_batch_3,  Train_loss : 5565.3149  Test_loss : 5898.3467, Time/batch_file : 2.3176, Training time: 5904.3837\n",
      "Epoch : 508/2000 data_batch_4,  Train_loss : 5408.1006  Test_loss : 5708.2446, Time/batch_file : 2.2882, Training time: 5906.6722\n",
      "Epoch : 508/2000 data_batch_5,  Train_loss : 5853.6025  Test_loss : 5558.3975, Time/batch_file : 2.2928, Training time: 5908.9653\n",
      "Epoch : 509/2000 data_batch_1,  Train_loss : 4732.0215  Test_loss : 5544.9180, Time/batch_file : 2.3127, Training time: 5911.2783\n",
      "Epoch : 509/2000 data_batch_2,  Train_loss : 4826.1494  Test_loss : 5105.8940, Time/batch_file : 2.3232, Training time: 5913.6017\n",
      "Epoch : 509/2000 data_batch_3,  Train_loss : 4848.9614  Test_loss : 5355.7534, Time/batch_file : 2.2981, Training time: 5915.9000\n",
      "Epoch : 509/2000 data_batch_4,  Train_loss : 4781.8076  Test_loss : 5634.0459, Time/batch_file : 2.2928, Training time: 5918.1930\n",
      "Epoch : 509/2000 data_batch_5,  Train_loss : 4898.2832  Test_loss : 5694.8496, Time/batch_file : 2.2936, Training time: 5920.4867\n",
      "Epoch : 510/2000 data_batch_1,  Train_loss : 5353.8433  Test_loss : 5581.7397, Time/batch_file : 2.2746, Training time: 5922.7615\n",
      "Epoch : 510/2000 data_batch_2,  Train_loss : 5094.3989  Test_loss : 5762.4922, Time/batch_file : 2.3172, Training time: 5925.0788\n",
      "Epoch : 510/2000 data_batch_3,  Train_loss : 5192.9927  Test_loss : 5805.2607, Time/batch_file : 2.3008, Training time: 5927.3798\n",
      "Epoch : 510/2000 data_batch_4,  Train_loss : 5143.8516  Test_loss : 5693.8809, Time/batch_file : 2.2969, Training time: 5929.6769\n",
      "Epoch : 510/2000 data_batch_5,  Train_loss : 5531.0645  Test_loss : 5564.4512, Time/batch_file : 2.2719, Training time: 5931.9490\n",
      "[./nets/net-510.ckpt] SAVED\n",
      "Epoch : 511/2000 data_batch_1,  Train_loss : 5293.5557  Test_loss : 5736.7314, Time/batch_file : 2.3197, Training time: 5935.5622\n",
      "Epoch : 511/2000 data_batch_2,  Train_loss : 5211.8130  Test_loss : 5956.9312, Time/batch_file : 2.3123, Training time: 5937.8747\n",
      "Epoch : 511/2000 data_batch_3,  Train_loss : 5278.8682  Test_loss : 5683.9941, Time/batch_file : 2.2925, Training time: 5940.1674\n",
      "Epoch : 511/2000 data_batch_4,  Train_loss : 4928.4341  Test_loss : 5959.8589, Time/batch_file : 2.2873, Training time: 5942.4548\n",
      "Epoch : 511/2000 data_batch_5,  Train_loss : 5186.5562  Test_loss : 5621.3398, Time/batch_file : 2.3193, Training time: 5944.7742\n",
      "Epoch : 512/2000 data_batch_1,  Train_loss : 5651.3374  Test_loss : 5186.8086, Time/batch_file : 2.2925, Training time: 5947.0668\n",
      "Epoch : 512/2000 data_batch_2,  Train_loss : 5750.9561  Test_loss : 5296.0049, Time/batch_file : 2.2841, Training time: 5949.3512\n",
      "Epoch : 512/2000 data_batch_3,  Train_loss : 5774.2842  Test_loss : 5390.6240, Time/batch_file : 2.2667, Training time: 5951.6181\n",
      "Epoch : 512/2000 data_batch_4,  Train_loss : 5638.5156  Test_loss : 5108.6021, Time/batch_file : 2.2949, Training time: 5953.9133\n",
      "Epoch : 512/2000 data_batch_5,  Train_loss : 5479.6123  Test_loss : 5577.9487, Time/batch_file : 2.2888, Training time: 5956.2022\n",
      "Epoch : 513/2000 data_batch_1,  Train_loss : 5456.3711  Test_loss : 5370.0371, Time/batch_file : 2.2911, Training time: 5958.4935\n",
      "Epoch : 513/2000 data_batch_2,  Train_loss : 5669.3438  Test_loss : 5391.4922, Time/batch_file : 2.2768, Training time: 5960.7704\n",
      "Epoch : 513/2000 data_batch_3,  Train_loss : 5641.2002  Test_loss : 5462.6045, Time/batch_file : 2.3229, Training time: 5963.0935\n",
      "Epoch : 513/2000 data_batch_4,  Train_loss : 5804.7305  Test_loss : 5551.2373, Time/batch_file : 2.3028, Training time: 5965.3966\n",
      "Epoch : 513/2000 data_batch_5,  Train_loss : 5725.8804  Test_loss : 5918.8145, Time/batch_file : 2.2934, Training time: 5967.6902\n",
      "Epoch : 514/2000 data_batch_1,  Train_loss : 5521.4185  Test_loss : 5581.9385, Time/batch_file : 2.2837, Training time: 5969.9740\n",
      "Epoch : 514/2000 data_batch_2,  Train_loss : 5466.6841  Test_loss : 5262.9761, Time/batch_file : 2.2984, Training time: 5972.2727\n",
      "Epoch : 514/2000 data_batch_3,  Train_loss : 5791.6855  Test_loss : 5472.5098, Time/batch_file : 2.2920, Training time: 5974.5650\n",
      "Epoch : 514/2000 data_batch_4,  Train_loss : 5731.6885  Test_loss : 5045.5762, Time/batch_file : 2.2797, Training time: 5976.8449\n",
      "Epoch : 514/2000 data_batch_5,  Train_loss : 5472.8721  Test_loss : 5247.7090, Time/batch_file : 2.3034, Training time: 5979.1492\n",
      "Epoch : 515/2000 data_batch_1,  Train_loss : 5959.0420  Test_loss : 5058.1050, Time/batch_file : 2.3184, Training time: 5981.4678\n",
      "Epoch : 515/2000 data_batch_2,  Train_loss : 5516.3174  Test_loss : 5145.1533, Time/batch_file : 2.3078, Training time: 5983.7758\n",
      "Epoch : 515/2000 data_batch_3,  Train_loss : 5370.3511  Test_loss : 4917.5674, Time/batch_file : 2.2905, Training time: 5986.0666\n",
      "Epoch : 515/2000 data_batch_4,  Train_loss : 5371.6719  Test_loss : 4896.7163, Time/batch_file : 2.2884, Training time: 5988.3552\n",
      "Epoch : 515/2000 data_batch_5,  Train_loss : 5592.8589  Test_loss : 5335.5981, Time/batch_file : 2.3139, Training time: 5990.6693\n",
      "Epoch : 516/2000 data_batch_1,  Train_loss : 5504.4033  Test_loss : 5809.5698, Time/batch_file : 2.2892, Training time: 5992.9587\n",
      "Epoch : 516/2000 data_batch_2,  Train_loss : 5458.8799  Test_loss : 5748.0234, Time/batch_file : 2.2867, Training time: 5995.2457\n",
      "Epoch : 516/2000 data_batch_3,  Train_loss : 5524.6606  Test_loss : 5789.7314, Time/batch_file : 2.2674, Training time: 5997.5132\n",
      "Epoch : 516/2000 data_batch_4,  Train_loss : 5510.4858  Test_loss : 5503.9370, Time/batch_file : 2.2988, Training time: 5999.8124\n",
      "Epoch : 516/2000 data_batch_5,  Train_loss : 5286.8496  Test_loss : 5709.8145, Time/batch_file : 2.2878, Training time: 6002.1003\n",
      "Epoch : 517/2000 data_batch_1,  Train_loss : 5333.5776  Test_loss : 5635.0469, Time/batch_file : 2.2977, Training time: 6004.3982\n",
      "Epoch : 517/2000 data_batch_2,  Train_loss : 5547.5352  Test_loss : 5647.4258, Time/batch_file : 2.2792, Training time: 6006.6776\n",
      "Epoch : 517/2000 data_batch_3,  Train_loss : 5333.5762  Test_loss : 5400.8550, Time/batch_file : 2.3085, Training time: 6008.9863\n",
      "Epoch : 517/2000 data_batch_4,  Train_loss : 5346.8896  Test_loss : 5677.8823, Time/batch_file : 2.3009, Training time: 6011.2874\n",
      "Epoch : 517/2000 data_batch_5,  Train_loss : 5640.9810  Test_loss : 5663.1206, Time/batch_file : 2.2860, Training time: 6013.5736\n",
      "Epoch : 518/2000 data_batch_1,  Train_loss : 4834.6108  Test_loss : 5639.7432, Time/batch_file : 2.2765, Training time: 6015.8504\n",
      "Epoch : 518/2000 data_batch_2,  Train_loss : 4977.1543  Test_loss : 5769.4658, Time/batch_file : 2.3136, Training time: 6018.1643\n",
      "Epoch : 518/2000 data_batch_3,  Train_loss : 5114.1465  Test_loss : 5552.8906, Time/batch_file : 2.3315, Training time: 6020.4959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 518/2000 data_batch_4,  Train_loss : 4813.4102  Test_loss : 5963.8911, Time/batch_file : 2.2805, Training time: 6022.7766\n",
      "Epoch : 518/2000 data_batch_5,  Train_loss : 5087.8735  Test_loss : 5709.0537, Time/batch_file : 2.2771, Training time: 6025.0540\n",
      "Epoch : 519/2000 data_batch_1,  Train_loss : 5105.5361  Test_loss : 5454.4165, Time/batch_file : 2.3202, Training time: 6027.3743\n",
      "Epoch : 519/2000 data_batch_2,  Train_loss : 5182.3232  Test_loss : 5477.2300, Time/batch_file : 2.3107, Training time: 6029.6853\n",
      "Epoch : 519/2000 data_batch_3,  Train_loss : 5164.4365  Test_loss : 5628.3984, Time/batch_file : 2.2894, Training time: 6031.9748\n",
      "Epoch : 519/2000 data_batch_4,  Train_loss : 5110.6665  Test_loss : 5544.7690, Time/batch_file : 2.2884, Training time: 6034.2633\n",
      "Epoch : 519/2000 data_batch_5,  Train_loss : 5083.0361  Test_loss : 5359.7207, Time/batch_file : 2.3255, Training time: 6036.5890\n",
      "Epoch : 520/2000 data_batch_1,  Train_loss : 5597.2158  Test_loss : 5930.3066, Time/batch_file : 2.3021, Training time: 6038.8913\n",
      "Epoch : 520/2000 data_batch_2,  Train_loss : 5546.9712  Test_loss : 5995.9375, Time/batch_file : 2.2982, Training time: 6041.1897\n",
      "Epoch : 520/2000 data_batch_3,  Train_loss : 5546.0225  Test_loss : 5729.3506, Time/batch_file : 2.2912, Training time: 6043.4812\n",
      "Epoch : 520/2000 data_batch_4,  Train_loss : 5787.3867  Test_loss : 5830.5337, Time/batch_file : 2.3155, Training time: 6045.7968\n",
      "Epoch : 520/2000 data_batch_5,  Train_loss : 5499.9287  Test_loss : 5816.2773, Time/batch_file : 2.3072, Training time: 6048.1042\n",
      "[./nets/net-520.ckpt] SAVED\n",
      "Epoch : 521/2000 data_batch_1,  Train_loss : 5422.7109  Test_loss : 5622.9585, Time/batch_file : 2.2971, Training time: 6051.6881\n",
      "Epoch : 521/2000 data_batch_2,  Train_loss : 5423.8521  Test_loss : 5554.4541, Time/batch_file : 2.2900, Training time: 6053.9783\n",
      "Epoch : 521/2000 data_batch_3,  Train_loss : 5541.9941  Test_loss : 5660.3896, Time/batch_file : 2.3083, Training time: 6056.2869\n",
      "Epoch : 521/2000 data_batch_4,  Train_loss : 5292.2744  Test_loss : 5428.9712, Time/batch_file : 2.2804, Training time: 6058.5676\n",
      "Epoch : 521/2000 data_batch_5,  Train_loss : 5261.0400  Test_loss : 5707.6152, Time/batch_file : 2.2799, Training time: 6060.8477\n",
      "Epoch : 522/2000 data_batch_1,  Train_loss : 5512.6611  Test_loss : 6017.3179, Time/batch_file : 2.2856, Training time: 6063.1334\n",
      "Epoch : 522/2000 data_batch_2,  Train_loss : 5429.4805  Test_loss : 6118.4238, Time/batch_file : 2.2812, Training time: 6065.4148\n",
      "Epoch : 522/2000 data_batch_3,  Train_loss : 5720.0249  Test_loss : 5565.4653, Time/batch_file : 2.2870, Training time: 6067.7021\n",
      "Epoch : 522/2000 data_batch_4,  Train_loss : 5260.3779  Test_loss : 5925.9521, Time/batch_file : 2.2792, Training time: 6069.9814\n",
      "Epoch : 522/2000 data_batch_5,  Train_loss : 5395.5347  Test_loss : 6136.0298, Time/batch_file : 2.2752, Training time: 6072.2568\n",
      "Epoch : 523/2000 data_batch_1,  Train_loss : 5672.4258  Test_loss : 5843.9375, Time/batch_file : 2.2764, Training time: 6074.5334\n",
      "Epoch : 523/2000 data_batch_2,  Train_loss : 5745.3628  Test_loss : 5889.8350, Time/batch_file : 2.2824, Training time: 6076.8158\n",
      "Epoch : 523/2000 data_batch_3,  Train_loss : 5493.2632  Test_loss : 5826.2397, Time/batch_file : 2.2895, Training time: 6079.1055\n",
      "Epoch : 523/2000 data_batch_4,  Train_loss : 5574.8174  Test_loss : 5722.1040, Time/batch_file : 2.2941, Training time: 6081.3998\n",
      "Epoch : 523/2000 data_batch_5,  Train_loss : 5317.2324  Test_loss : 5856.7441, Time/batch_file : 2.2871, Training time: 6083.6871\n",
      "Epoch : 524/2000 data_batch_1,  Train_loss : 5150.8486  Test_loss : 5734.7876, Time/batch_file : 2.2766, Training time: 6085.9639\n",
      "Epoch : 524/2000 data_batch_2,  Train_loss : 5646.8047  Test_loss : 5454.5698, Time/batch_file : 2.2828, Training time: 6088.2468\n",
      "Epoch : 524/2000 data_batch_3,  Train_loss : 5554.0488  Test_loss : 5457.2412, Time/batch_file : 2.2837, Training time: 6090.5308\n",
      "Epoch : 524/2000 data_batch_4,  Train_loss : 5355.1685  Test_loss : 5649.5068, Time/batch_file : 2.2807, Training time: 6092.8118\n",
      "Epoch : 524/2000 data_batch_5,  Train_loss : 5224.6846  Test_loss : 5789.0010, Time/batch_file : 2.2778, Training time: 6095.0898\n",
      "Epoch : 525/2000 data_batch_1,  Train_loss : 5528.1177  Test_loss : 5779.4658, Time/batch_file : 2.2918, Training time: 6097.3817\n",
      "Epoch : 525/2000 data_batch_2,  Train_loss : 5717.6182  Test_loss : 5996.7832, Time/batch_file : 2.2904, Training time: 6099.6725\n",
      "Epoch : 525/2000 data_batch_3,  Train_loss : 5574.7720  Test_loss : 5566.6172, Time/batch_file : 2.2949, Training time: 6101.9676\n",
      "Epoch : 525/2000 data_batch_4,  Train_loss : 5843.5649  Test_loss : 5786.2314, Time/batch_file : 2.2975, Training time: 6104.2652\n",
      "Epoch : 525/2000 data_batch_5,  Train_loss : 5647.5244  Test_loss : 5735.2070, Time/batch_file : 2.2885, Training time: 6106.5539\n",
      "Epoch : 526/2000 data_batch_1,  Train_loss : 5374.7085  Test_loss : 5408.1255, Time/batch_file : 2.2804, Training time: 6108.8345\n",
      "Epoch : 526/2000 data_batch_2,  Train_loss : 5428.7778  Test_loss : 5683.2842, Time/batch_file : 2.2899, Training time: 6111.1246\n",
      "Epoch : 526/2000 data_batch_3,  Train_loss : 5485.1367  Test_loss : 5439.5889, Time/batch_file : 2.2883, Training time: 6113.4131\n",
      "Epoch : 526/2000 data_batch_4,  Train_loss : 5559.5327  Test_loss : 5368.8721, Time/batch_file : 2.2880, Training time: 6115.7012\n",
      "Epoch : 526/2000 data_batch_5,  Train_loss : 5369.1768  Test_loss : 5288.2573, Time/batch_file : 2.2934, Training time: 6117.9948\n",
      "Epoch : 527/2000 data_batch_1,  Train_loss : 5185.2749  Test_loss : 5729.8584, Time/batch_file : 2.2848, Training time: 6120.2800\n",
      "Epoch : 527/2000 data_batch_2,  Train_loss : 5461.0293  Test_loss : 5836.7939, Time/batch_file : 2.2776, Training time: 6122.5577\n",
      "Epoch : 527/2000 data_batch_3,  Train_loss : 5312.2466  Test_loss : 5921.8389, Time/batch_file : 2.2849, Training time: 6124.8428\n",
      "Epoch : 527/2000 data_batch_4,  Train_loss : 5206.3262  Test_loss : 5900.1431, Time/batch_file : 2.2811, Training time: 6127.1241\n",
      "Epoch : 527/2000 data_batch_5,  Train_loss : 5749.1860  Test_loss : 5638.4019, Time/batch_file : 2.2875, Training time: 6129.4117\n",
      "Epoch : 528/2000 data_batch_1,  Train_loss : 5509.1841  Test_loss : 5602.9609, Time/batch_file : 2.2811, Training time: 6131.6930\n",
      "Epoch : 528/2000 data_batch_2,  Train_loss : 5607.7500  Test_loss : 5594.9214, Time/batch_file : 2.2753, Training time: 6133.9685\n",
      "Epoch : 528/2000 data_batch_3,  Train_loss : 5581.1621  Test_loss : 5615.2271, Time/batch_file : 2.2800, Training time: 6136.2487\n",
      "Epoch : 528/2000 data_batch_4,  Train_loss : 5351.7256  Test_loss : 5554.3521, Time/batch_file : 2.2729, Training time: 6138.5218\n",
      "Epoch : 528/2000 data_batch_5,  Train_loss : 5451.2285  Test_loss : 5967.2075, Time/batch_file : 2.2731, Training time: 6140.7951\n",
      "Epoch : 529/2000 data_batch_1,  Train_loss : 5630.6416  Test_loss : 5437.5298, Time/batch_file : 2.2888, Training time: 6143.0841\n",
      "Epoch : 529/2000 data_batch_2,  Train_loss : 5471.1621  Test_loss : 5892.4619, Time/batch_file : 2.2718, Training time: 6145.3561\n",
      "Epoch : 529/2000 data_batch_3,  Train_loss : 5474.1841  Test_loss : 5800.1968, Time/batch_file : 2.2791, Training time: 6147.6353\n",
      "Epoch : 529/2000 data_batch_4,  Train_loss : 5682.5732  Test_loss : 5665.3462, Time/batch_file : 2.2871, Training time: 6149.9225\n",
      "Epoch : 529/2000 data_batch_5,  Train_loss : 5566.5728  Test_loss : 5560.3564, Time/batch_file : 2.2784, Training time: 6152.2012\n",
      "Epoch : 530/2000 data_batch_1,  Train_loss : 5663.8730  Test_loss : 5701.9644, Time/batch_file : 2.2815, Training time: 6154.4829\n",
      "Epoch : 530/2000 data_batch_2,  Train_loss : 5569.9858  Test_loss : 5874.4971, Time/batch_file : 2.2707, Training time: 6156.7538\n",
      "Epoch : 530/2000 data_batch_3,  Train_loss : 5474.5752  Test_loss : 5669.5708, Time/batch_file : 2.2798, Training time: 6159.0337\n",
      "Epoch : 530/2000 data_batch_4,  Train_loss : 5458.0825  Test_loss : 5786.7354, Time/batch_file : 2.2792, Training time: 6161.3131\n",
      "Epoch : 530/2000 data_batch_5,  Train_loss : 5484.4214  Test_loss : 5888.1138, Time/batch_file : 2.2729, Training time: 6163.5863\n",
      "[./nets/net-530.ckpt] SAVED\n",
      "Epoch : 531/2000 data_batch_1,  Train_loss : 4928.2974  Test_loss : 5761.0015, Time/batch_file : 2.3070, Training time: 6167.1740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 531/2000 data_batch_2,  Train_loss : 5006.7427  Test_loss : 5548.1279, Time/batch_file : 2.2967, Training time: 6169.4709\n",
      "Epoch : 531/2000 data_batch_3,  Train_loss : 5204.5918  Test_loss : 5890.9600, Time/batch_file : 2.3071, Training time: 6171.7782\n",
      "Epoch : 531/2000 data_batch_4,  Train_loss : 5053.7002  Test_loss : 5386.5469, Time/batch_file : 2.3050, Training time: 6174.0833\n",
      "Epoch : 531/2000 data_batch_5,  Train_loss : 5060.8813  Test_loss : 5489.9287, Time/batch_file : 2.3097, Training time: 6176.3934\n",
      "Epoch : 532/2000 data_batch_1,  Train_loss : 5517.1650  Test_loss : 5616.8281, Time/batch_file : 2.2882, Training time: 6178.6818\n",
      "Epoch : 532/2000 data_batch_2,  Train_loss : 5483.2900  Test_loss : 5201.2905, Time/batch_file : 2.2714, Training time: 6180.9534\n",
      "Epoch : 532/2000 data_batch_3,  Train_loss : 5649.4463  Test_loss : 5707.6318, Time/batch_file : 2.2891, Training time: 6183.2427\n",
      "Epoch : 532/2000 data_batch_4,  Train_loss : 5680.6533  Test_loss : 5521.3794, Time/batch_file : 2.2971, Training time: 6185.5400\n",
      "Epoch : 532/2000 data_batch_5,  Train_loss : 5263.8389  Test_loss : 5727.0000, Time/batch_file : 2.2953, Training time: 6187.8355\n",
      "Epoch : 533/2000 data_batch_1,  Train_loss : 4858.4561  Test_loss : 6147.0303, Time/batch_file : 2.2796, Training time: 6190.1153\n",
      "Epoch : 533/2000 data_batch_2,  Train_loss : 4998.6206  Test_loss : 5948.0757, Time/batch_file : 2.2936, Training time: 6192.4092\n",
      "Epoch : 533/2000 data_batch_3,  Train_loss : 4957.4253  Test_loss : 6015.1240, Time/batch_file : 2.2668, Training time: 6194.6762\n",
      "Epoch : 533/2000 data_batch_4,  Train_loss : 4922.8691  Test_loss : 6397.9482, Time/batch_file : 2.3012, Training time: 6196.9775\n",
      "Epoch : 533/2000 data_batch_5,  Train_loss : 4702.0405  Test_loss : 6246.8232, Time/batch_file : 2.2904, Training time: 6199.2680\n",
      "Epoch : 534/2000 data_batch_1,  Train_loss : 5546.2983  Test_loss : 5725.9199, Time/batch_file : 2.3077, Training time: 6201.5759\n",
      "Epoch : 534/2000 data_batch_2,  Train_loss : 5082.5439  Test_loss : 5732.4253, Time/batch_file : 2.2834, Training time: 6203.8594\n",
      "Epoch : 534/2000 data_batch_3,  Train_loss : 5339.2695  Test_loss : 5695.4507, Time/batch_file : 2.2995, Training time: 6206.1591\n",
      "Epoch : 534/2000 data_batch_4,  Train_loss : 5116.9185  Test_loss : 5634.7744, Time/batch_file : 2.2727, Training time: 6208.4320\n",
      "Epoch : 534/2000 data_batch_5,  Train_loss : 5331.5103  Test_loss : 5770.6548, Time/batch_file : 2.2898, Training time: 6210.7220\n",
      "Epoch : 535/2000 data_batch_1,  Train_loss : 5224.1470  Test_loss : 5340.7139, Time/batch_file : 2.2958, Training time: 6213.0180\n",
      "Epoch : 535/2000 data_batch_2,  Train_loss : 5310.7656  Test_loss : 5394.7920, Time/batch_file : 2.3025, Training time: 6215.3207\n",
      "Epoch : 535/2000 data_batch_3,  Train_loss : 5434.2197  Test_loss : 5763.0298, Time/batch_file : 2.2824, Training time: 6217.6033\n",
      "Epoch : 535/2000 data_batch_4,  Train_loss : 5698.3608  Test_loss : 5526.9038, Time/batch_file : 2.2913, Training time: 6219.8948\n",
      "Epoch : 535/2000 data_batch_5,  Train_loss : 5406.6167  Test_loss : 5436.7490, Time/batch_file : 2.2846, Training time: 6222.1797\n",
      "Epoch : 536/2000 data_batch_1,  Train_loss : 5506.3179  Test_loss : 5417.6167, Time/batch_file : 2.3022, Training time: 6224.4821\n",
      "Epoch : 536/2000 data_batch_2,  Train_loss : 5552.7466  Test_loss : 5737.9194, Time/batch_file : 2.3156, Training time: 6226.7979\n",
      "Epoch : 536/2000 data_batch_3,  Train_loss : 5341.6436  Test_loss : 5551.6450, Time/batch_file : 2.2852, Training time: 6229.0833\n",
      "Epoch : 536/2000 data_batch_4,  Train_loss : 5357.9102  Test_loss : 5545.9604, Time/batch_file : 2.3001, Training time: 6231.3835\n",
      "Epoch : 536/2000 data_batch_5,  Train_loss : 4982.0820  Test_loss : 5500.3071, Time/batch_file : 2.3173, Training time: 6233.7010\n",
      "Epoch : 537/2000 data_batch_1,  Train_loss : 5891.8062  Test_loss : 5915.2617, Time/batch_file : 2.2850, Training time: 6235.9862\n",
      "Epoch : 537/2000 data_batch_2,  Train_loss : 5744.5532  Test_loss : 6023.5176, Time/batch_file : 2.2814, Training time: 6238.2678\n",
      "Epoch : 537/2000 data_batch_3,  Train_loss : 5600.4604  Test_loss : 6132.4707, Time/batch_file : 2.2732, Training time: 6240.5412\n",
      "Epoch : 537/2000 data_batch_4,  Train_loss : 5911.7900  Test_loss : 6303.7539, Time/batch_file : 2.2900, Training time: 6242.8314\n",
      "Epoch : 537/2000 data_batch_5,  Train_loss : 5877.1758  Test_loss : 5932.1602, Time/batch_file : 2.2906, Training time: 6245.1221\n",
      "Epoch : 538/2000 data_batch_1,  Train_loss : 5205.1895  Test_loss : 5327.9600, Time/batch_file : 2.2955, Training time: 6247.4178\n",
      "Epoch : 538/2000 data_batch_2,  Train_loss : 5360.5049  Test_loss : 5348.8892, Time/batch_file : 2.2702, Training time: 6249.6882\n",
      "Epoch : 538/2000 data_batch_3,  Train_loss : 4912.6299  Test_loss : 5186.5156, Time/batch_file : 2.2803, Training time: 6251.9687\n",
      "Epoch : 538/2000 data_batch_4,  Train_loss : 5275.0928  Test_loss : 5505.9922, Time/batch_file : 2.2749, Training time: 6254.2439\n",
      "Epoch : 538/2000 data_batch_5,  Train_loss : 5214.5669  Test_loss : 5398.4683, Time/batch_file : 2.2798, Training time: 6256.5239\n",
      "Epoch : 539/2000 data_batch_1,  Train_loss : 5404.7739  Test_loss : 5373.6592, Time/batch_file : 2.3062, Training time: 6258.8303\n",
      "Epoch : 539/2000 data_batch_2,  Train_loss : 5459.0864  Test_loss : 5320.4473, Time/batch_file : 2.2732, Training time: 6261.1037\n",
      "Epoch : 539/2000 data_batch_3,  Train_loss : 5535.6050  Test_loss : 5326.7578, Time/batch_file : 2.2851, Training time: 6263.3891\n",
      "Epoch : 539/2000 data_batch_4,  Train_loss : 5337.1323  Test_loss : 5180.0054, Time/batch_file : 2.2885, Training time: 6265.6778\n",
      "Epoch : 539/2000 data_batch_5,  Train_loss : 5467.7251  Test_loss : 5421.0024, Time/batch_file : 2.2827, Training time: 6267.9609\n",
      "Epoch : 540/2000 data_batch_1,  Train_loss : 5177.3477  Test_loss : 5446.7334, Time/batch_file : 2.2756, Training time: 6270.2367\n",
      "Epoch : 540/2000 data_batch_2,  Train_loss : 4979.9385  Test_loss : 5652.7520, Time/batch_file : 2.2715, Training time: 6272.5084\n",
      "Epoch : 540/2000 data_batch_3,  Train_loss : 5160.8169  Test_loss : 5504.7539, Time/batch_file : 2.2886, Training time: 6274.7971\n",
      "Epoch : 540/2000 data_batch_4,  Train_loss : 5135.0762  Test_loss : 5768.3940, Time/batch_file : 2.2972, Training time: 6277.0945\n",
      "Epoch : 540/2000 data_batch_5,  Train_loss : 5388.0933  Test_loss : 5942.1147, Time/batch_file : 2.2985, Training time: 6279.3931\n",
      "[./nets/net-540.ckpt] SAVED\n",
      "Epoch : 541/2000 data_batch_1,  Train_loss : 5529.2808  Test_loss : 5763.0093, Time/batch_file : 2.3002, Training time: 6282.9838\n",
      "Epoch : 541/2000 data_batch_2,  Train_loss : 5494.7192  Test_loss : 5373.4482, Time/batch_file : 2.3259, Training time: 6285.3099\n",
      "Epoch : 541/2000 data_batch_3,  Train_loss : 5477.9878  Test_loss : 5749.5186, Time/batch_file : 2.2838, Training time: 6287.5940\n",
      "Epoch : 541/2000 data_batch_4,  Train_loss : 5150.5303  Test_loss : 5768.5527, Time/batch_file : 2.3236, Training time: 6289.9178\n",
      "Epoch : 541/2000 data_batch_5,  Train_loss : 5457.9795  Test_loss : 5399.5137, Time/batch_file : 2.3063, Training time: 6292.2243\n",
      "Epoch : 542/2000 data_batch_1,  Train_loss : 4769.1562  Test_loss : 5761.1528, Time/batch_file : 2.3142, Training time: 6294.5386\n",
      "Epoch : 542/2000 data_batch_2,  Train_loss : 5055.6514  Test_loss : 5911.9468, Time/batch_file : 2.3307, Training time: 6296.8696\n",
      "Epoch : 542/2000 data_batch_3,  Train_loss : 4977.3105  Test_loss : 6145.2622, Time/batch_file : 2.3103, Training time: 6299.1800\n",
      "Epoch : 542/2000 data_batch_4,  Train_loss : 5112.2910  Test_loss : 5579.4365, Time/batch_file : 2.3130, Training time: 6301.4933\n",
      "Epoch : 542/2000 data_batch_5,  Train_loss : 4979.2109  Test_loss : 5835.6279, Time/batch_file : 2.3130, Training time: 6303.8066\n",
      "Epoch : 543/2000 data_batch_1,  Train_loss : 5164.7158  Test_loss : 4999.8638, Time/batch_file : 2.3183, Training time: 6306.1251\n",
      "Epoch : 543/2000 data_batch_2,  Train_loss : 5023.7900  Test_loss : 5351.4194, Time/batch_file : 2.3181, Training time: 6308.4435\n",
      "Epoch : 543/2000 data_batch_3,  Train_loss : 5068.3984  Test_loss : 5138.0688, Time/batch_file : 2.3150, Training time: 6310.7588\n",
      "Epoch : 543/2000 data_batch_4,  Train_loss : 5177.7217  Test_loss : 5002.3706, Time/batch_file : 2.3166, Training time: 6313.0756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 543/2000 data_batch_5,  Train_loss : 4960.8936  Test_loss : 5336.6079, Time/batch_file : 2.3165, Training time: 6315.3923\n",
      "Epoch : 544/2000 data_batch_1,  Train_loss : 5549.3921  Test_loss : 5167.3076, Time/batch_file : 2.3180, Training time: 6317.7105\n",
      "Epoch : 544/2000 data_batch_2,  Train_loss : 5420.8818  Test_loss : 5155.4966, Time/batch_file : 2.3392, Training time: 6320.0499\n",
      "Epoch : 544/2000 data_batch_3,  Train_loss : 5667.8794  Test_loss : 5055.5674, Time/batch_file : 2.3176, Training time: 6322.3676\n",
      "Epoch : 544/2000 data_batch_4,  Train_loss : 5406.6328  Test_loss : 5099.8169, Time/batch_file : 2.3211, Training time: 6324.6890\n",
      "Epoch : 544/2000 data_batch_5,  Train_loss : 5270.0713  Test_loss : 5336.7915, Time/batch_file : 2.3234, Training time: 6327.0127\n",
      "Epoch : 545/2000 data_batch_1,  Train_loss : 5812.8652  Test_loss : 5954.4512, Time/batch_file : 2.3296, Training time: 6329.3425\n",
      "Epoch : 545/2000 data_batch_2,  Train_loss : 5878.5967  Test_loss : 5829.9111, Time/batch_file : 2.3062, Training time: 6331.6489\n",
      "Epoch : 545/2000 data_batch_3,  Train_loss : 5779.9541  Test_loss : 5784.6416, Time/batch_file : 2.3152, Training time: 6333.9642\n",
      "Epoch : 545/2000 data_batch_4,  Train_loss : 5753.8354  Test_loss : 5480.1782, Time/batch_file : 2.3101, Training time: 6336.2745\n",
      "Epoch : 545/2000 data_batch_5,  Train_loss : 5652.0967  Test_loss : 5744.0776, Time/batch_file : 2.3032, Training time: 6338.5778\n",
      "Epoch : 546/2000 data_batch_1,  Train_loss : 5179.7744  Test_loss : 4960.7896, Time/batch_file : 2.3090, Training time: 6340.8871\n",
      "Epoch : 546/2000 data_batch_2,  Train_loss : 5492.0967  Test_loss : 5320.5073, Time/batch_file : 2.3189, Training time: 6343.2062\n",
      "Epoch : 546/2000 data_batch_3,  Train_loss : 5330.9829  Test_loss : 5217.7109, Time/batch_file : 2.3135, Training time: 6345.5199\n",
      "Epoch : 546/2000 data_batch_4,  Train_loss : 5152.6724  Test_loss : 5046.0732, Time/batch_file : 2.3107, Training time: 6347.8308\n",
      "Epoch : 546/2000 data_batch_5,  Train_loss : 4904.9478  Test_loss : 5379.1025, Time/batch_file : 2.3070, Training time: 6350.1380\n",
      "Epoch : 547/2000 data_batch_1,  Train_loss : 5366.2744  Test_loss : 5537.0322, Time/batch_file : 2.3186, Training time: 6352.4569\n",
      "Epoch : 547/2000 data_batch_2,  Train_loss : 5243.3999  Test_loss : 5463.0479, Time/batch_file : 2.3291, Training time: 6354.7862\n",
      "Epoch : 547/2000 data_batch_3,  Train_loss : 5187.1138  Test_loss : 5518.8584, Time/batch_file : 2.3162, Training time: 6357.1026\n",
      "Epoch : 547/2000 data_batch_4,  Train_loss : 5434.9067  Test_loss : 5438.8833, Time/batch_file : 2.3264, Training time: 6359.4292\n",
      "Epoch : 547/2000 data_batch_5,  Train_loss : 5250.2954  Test_loss : 5393.4775, Time/batch_file : 2.3129, Training time: 6361.7423\n",
      "Epoch : 548/2000 data_batch_1,  Train_loss : 4899.1357  Test_loss : 5017.3076, Time/batch_file : 2.3122, Training time: 6364.0547\n",
      "Epoch : 548/2000 data_batch_2,  Train_loss : 5283.1846  Test_loss : 4862.4570, Time/batch_file : 2.3105, Training time: 6366.3654\n",
      "Epoch : 548/2000 data_batch_3,  Train_loss : 5258.8101  Test_loss : 5045.5303, Time/batch_file : 2.3272, Training time: 6368.6927\n",
      "Epoch : 548/2000 data_batch_4,  Train_loss : 5128.3154  Test_loss : 5132.0449, Time/batch_file : 2.3146, Training time: 6371.0077\n",
      "Epoch : 548/2000 data_batch_5,  Train_loss : 5257.3223  Test_loss : 5137.2314, Time/batch_file : 2.3203, Training time: 6373.3281\n",
      "Epoch : 549/2000 data_batch_1,  Train_loss : 5292.0283  Test_loss : 5145.5562, Time/batch_file : 2.3176, Training time: 6375.6459\n",
      "Epoch : 549/2000 data_batch_2,  Train_loss : 5458.7329  Test_loss : 5361.9150, Time/batch_file : 2.3141, Training time: 6377.9602\n",
      "Epoch : 549/2000 data_batch_3,  Train_loss : 5590.3862  Test_loss : 5410.4272, Time/batch_file : 2.3174, Training time: 6380.2777\n",
      "Epoch : 549/2000 data_batch_4,  Train_loss : 5504.1172  Test_loss : 5276.5010, Time/batch_file : 2.3125, Training time: 6382.5905\n",
      "Epoch : 549/2000 data_batch_5,  Train_loss : 5431.6582  Test_loss : 4964.3008, Time/batch_file : 2.3096, Training time: 6384.9003\n",
      "Epoch : 550/2000 data_batch_1,  Train_loss : 5687.9009  Test_loss : 5954.0410, Time/batch_file : 2.3051, Training time: 6387.2057\n",
      "Epoch : 550/2000 data_batch_2,  Train_loss : 5822.4194  Test_loss : 5517.2305, Time/batch_file : 2.3041, Training time: 6389.5100\n",
      "Epoch : 550/2000 data_batch_3,  Train_loss : 5805.3232  Test_loss : 5771.0605, Time/batch_file : 2.3250, Training time: 6391.8351\n",
      "Epoch : 550/2000 data_batch_4,  Train_loss : 5612.3799  Test_loss : 6137.7051, Time/batch_file : 2.3095, Training time: 6394.1448\n",
      "Epoch : 550/2000 data_batch_5,  Train_loss : 5913.8164  Test_loss : 5974.4893, Time/batch_file : 2.3144, Training time: 6396.4594\n",
      "[./nets/net-550.ckpt] SAVED\n",
      "Epoch : 551/2000 data_batch_1,  Train_loss : 5310.2393  Test_loss : 5492.6318, Time/batch_file : 2.3070, Training time: 6400.0642\n",
      "Epoch : 551/2000 data_batch_2,  Train_loss : 5211.7607  Test_loss : 6071.3813, Time/batch_file : 2.3056, Training time: 6402.3701\n",
      "Epoch : 551/2000 data_batch_3,  Train_loss : 5318.1396  Test_loss : 5695.2168, Time/batch_file : 2.3090, Training time: 6404.6793\n",
      "Epoch : 551/2000 data_batch_4,  Train_loss : 5313.4282  Test_loss : 5449.9512, Time/batch_file : 2.2979, Training time: 6406.9773\n",
      "Epoch : 551/2000 data_batch_5,  Train_loss : 5383.3853  Test_loss : 5640.1631, Time/batch_file : 2.2975, Training time: 6409.2750\n",
      "Epoch : 552/2000 data_batch_1,  Train_loss : 5078.1719  Test_loss : 5893.3936, Time/batch_file : 2.3106, Training time: 6411.5858\n",
      "Epoch : 552/2000 data_batch_2,  Train_loss : 5115.3418  Test_loss : 5742.8438, Time/batch_file : 2.2976, Training time: 6413.8836\n",
      "Epoch : 552/2000 data_batch_3,  Train_loss : 5302.4131  Test_loss : 5650.9150, Time/batch_file : 2.3115, Training time: 6416.1954\n",
      "Epoch : 552/2000 data_batch_4,  Train_loss : 4951.6997  Test_loss : 6010.5898, Time/batch_file : 2.3134, Training time: 6418.5089\n",
      "Epoch : 552/2000 data_batch_5,  Train_loss : 5086.3052  Test_loss : 5724.1455, Time/batch_file : 2.3008, Training time: 6420.8099\n",
      "Epoch : 553/2000 data_batch_1,  Train_loss : 5053.3188  Test_loss : 5425.2256, Time/batch_file : 2.2963, Training time: 6423.1064\n",
      "Epoch : 553/2000 data_batch_2,  Train_loss : 5148.1270  Test_loss : 5311.9707, Time/batch_file : 2.3085, Training time: 6425.4151\n",
      "Epoch : 553/2000 data_batch_3,  Train_loss : 5353.1309  Test_loss : 5045.8589, Time/batch_file : 2.3152, Training time: 6427.7305\n",
      "Epoch : 553/2000 data_batch_4,  Train_loss : 5590.5898  Test_loss : 5361.2939, Time/batch_file : 2.3056, Training time: 6430.0363\n",
      "Epoch : 553/2000 data_batch_5,  Train_loss : 5241.8223  Test_loss : 5365.4878, Time/batch_file : 2.3072, Training time: 6432.3437\n",
      "Epoch : 554/2000 data_batch_1,  Train_loss : 5220.5181  Test_loss : 5290.8672, Time/batch_file : 2.2974, Training time: 6434.6413\n",
      "Epoch : 554/2000 data_batch_2,  Train_loss : 5048.1689  Test_loss : 5114.4712, Time/batch_file : 2.2843, Training time: 6436.9257\n",
      "Epoch : 554/2000 data_batch_3,  Train_loss : 5214.8857  Test_loss : 5635.5312, Time/batch_file : 2.2938, Training time: 6439.2197\n",
      "Epoch : 554/2000 data_batch_4,  Train_loss : 5240.6890  Test_loss : 5391.8892, Time/batch_file : 2.2955, Training time: 6441.5154\n",
      "Epoch : 554/2000 data_batch_5,  Train_loss : 5143.8584  Test_loss : 5486.0908, Time/batch_file : 2.2924, Training time: 6443.8080\n",
      "Epoch : 555/2000 data_batch_1,  Train_loss : 5053.5879  Test_loss : 5854.6152, Time/batch_file : 2.2788, Training time: 6446.0871\n",
      "Epoch : 555/2000 data_batch_2,  Train_loss : 5404.4824  Test_loss : 5758.7949, Time/batch_file : 2.3183, Training time: 6448.4056\n",
      "Epoch : 555/2000 data_batch_3,  Train_loss : 5249.5605  Test_loss : 6234.7588, Time/batch_file : 2.2906, Training time: 6450.6964\n",
      "Epoch : 555/2000 data_batch_4,  Train_loss : 5403.4897  Test_loss : 5838.4341, Time/batch_file : 2.3093, Training time: 6453.0059\n",
      "Epoch : 555/2000 data_batch_5,  Train_loss : 5386.9165  Test_loss : 6052.9707, Time/batch_file : 2.3002, Training time: 6455.3063\n",
      "Epoch : 556/2000 data_batch_1,  Train_loss : 5091.6729  Test_loss : 5585.2432, Time/batch_file : 2.2867, Training time: 6457.5932\n",
      "Epoch : 556/2000 data_batch_2,  Train_loss : 5170.2925  Test_loss : 5841.7808, Time/batch_file : 2.2894, Training time: 6459.8829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 556/2000 data_batch_3,  Train_loss : 5310.9097  Test_loss : 5856.1523, Time/batch_file : 2.2964, Training time: 6462.1795\n",
      "Epoch : 556/2000 data_batch_4,  Train_loss : 5385.2163  Test_loss : 5834.6284, Time/batch_file : 2.3046, Training time: 6464.4843\n",
      "Epoch : 556/2000 data_batch_5,  Train_loss : 5169.3066  Test_loss : 6028.2651, Time/batch_file : 2.2988, Training time: 6466.7833\n",
      "Epoch : 557/2000 data_batch_1,  Train_loss : 5370.5713  Test_loss : 5795.9229, Time/batch_file : 2.2861, Training time: 6469.0696\n",
      "Epoch : 557/2000 data_batch_2,  Train_loss : 5539.9395  Test_loss : 6234.5234, Time/batch_file : 2.2933, Training time: 6471.3630\n",
      "Epoch : 557/2000 data_batch_3,  Train_loss : 5486.1260  Test_loss : 5943.4980, Time/batch_file : 2.3089, Training time: 6473.6721\n",
      "Epoch : 557/2000 data_batch_4,  Train_loss : 5810.1763  Test_loss : 6001.9209, Time/batch_file : 2.2833, Training time: 6475.9557\n",
      "Epoch : 557/2000 data_batch_5,  Train_loss : 5606.8896  Test_loss : 6038.6074, Time/batch_file : 2.3306, Training time: 6478.2865\n",
      "Epoch : 558/2000 data_batch_1,  Train_loss : 5319.6250  Test_loss : 5121.5669, Time/batch_file : 2.2754, Training time: 6480.5622\n",
      "Epoch : 558/2000 data_batch_2,  Train_loss : 4764.0151  Test_loss : 4921.4756, Time/batch_file : 2.2966, Training time: 6482.8590\n",
      "Epoch : 558/2000 data_batch_3,  Train_loss : 5241.5259  Test_loss : 5242.6108, Time/batch_file : 2.2900, Training time: 6485.1492\n",
      "Epoch : 558/2000 data_batch_4,  Train_loss : 4954.2803  Test_loss : 5222.6328, Time/batch_file : 2.2868, Training time: 6487.4361\n",
      "Epoch : 558/2000 data_batch_5,  Train_loss : 5081.6841  Test_loss : 5213.5762, Time/batch_file : 2.2817, Training time: 6489.7179\n",
      "Epoch : 559/2000 data_batch_1,  Train_loss : 5191.8242  Test_loss : 5079.6118, Time/batch_file : 2.2841, Training time: 6492.0023\n",
      "Epoch : 559/2000 data_batch_2,  Train_loss : 4979.9854  Test_loss : 5362.7783, Time/batch_file : 2.3040, Training time: 6494.3066\n",
      "Epoch : 559/2000 data_batch_3,  Train_loss : 5152.7451  Test_loss : 5422.6304, Time/batch_file : 2.2817, Training time: 6496.5885\n",
      "Epoch : 559/2000 data_batch_4,  Train_loss : 5108.3594  Test_loss : 5375.8037, Time/batch_file : 2.3107, Training time: 6498.8995\n",
      "Epoch : 559/2000 data_batch_5,  Train_loss : 5081.3281  Test_loss : 5259.3193, Time/batch_file : 2.3064, Training time: 6501.2062\n",
      "Epoch : 560/2000 data_batch_1,  Train_loss : 5427.4121  Test_loss : 5619.3389, Time/batch_file : 2.3171, Training time: 6503.5236\n",
      "Epoch : 560/2000 data_batch_2,  Train_loss : 5350.8955  Test_loss : 5419.6885, Time/batch_file : 2.3319, Training time: 6505.8556\n",
      "Epoch : 560/2000 data_batch_3,  Train_loss : 5578.1255  Test_loss : 5668.3213, Time/batch_file : 2.3161, Training time: 6508.1720\n",
      "Epoch : 560/2000 data_batch_4,  Train_loss : 5416.7778  Test_loss : 5719.4287, Time/batch_file : 2.3029, Training time: 6510.4751\n",
      "Epoch : 560/2000 data_batch_5,  Train_loss : 5330.1387  Test_loss : 5803.1748, Time/batch_file : 2.3198, Training time: 6512.7951\n",
      "[./nets/net-560.ckpt] SAVED\n",
      "Epoch : 561/2000 data_batch_1,  Train_loss : 5396.3892  Test_loss : 6296.0420, Time/batch_file : 2.3234, Training time: 6518.0917\n",
      "Epoch : 561/2000 data_batch_2,  Train_loss : 5858.8247  Test_loss : 5927.6626, Time/batch_file : 2.3249, Training time: 6520.4168\n",
      "Epoch : 561/2000 data_batch_3,  Train_loss : 5190.5410  Test_loss : 5628.0605, Time/batch_file : 2.3177, Training time: 6522.7348\n",
      "Epoch : 561/2000 data_batch_4,  Train_loss : 5445.5386  Test_loss : 5641.9424, Time/batch_file : 2.3353, Training time: 6525.0703\n",
      "Epoch : 561/2000 data_batch_5,  Train_loss : 5430.3589  Test_loss : 6034.0225, Time/batch_file : 2.3214, Training time: 6527.3919\n",
      "Epoch : 562/2000 data_batch_1,  Train_loss : 5807.6582  Test_loss : 5021.4590, Time/batch_file : 2.3126, Training time: 6529.7046\n",
      "Epoch : 562/2000 data_batch_2,  Train_loss : 5759.8135  Test_loss : 5135.5654, Time/batch_file : 2.2876, Training time: 6531.9925\n",
      "Epoch : 562/2000 data_batch_3,  Train_loss : 5281.6304  Test_loss : 5347.3418, Time/batch_file : 2.3257, Training time: 6534.3185\n",
      "Epoch : 562/2000 data_batch_4,  Train_loss : 5691.8193  Test_loss : 5169.8110, Time/batch_file : 2.3071, Training time: 6536.6258\n",
      "Epoch : 562/2000 data_batch_5,  Train_loss : 5346.0781  Test_loss : 5474.3652, Time/batch_file : 2.3135, Training time: 6538.9394\n",
      "Epoch : 563/2000 data_batch_1,  Train_loss : 5358.3379  Test_loss : 5257.7646, Time/batch_file : 2.3150, Training time: 6541.2546\n",
      "Epoch : 563/2000 data_batch_2,  Train_loss : 5848.1104  Test_loss : 5381.8218, Time/batch_file : 2.3206, Training time: 6543.5755\n",
      "Epoch : 563/2000 data_batch_3,  Train_loss : 5531.6494  Test_loss : 5434.7295, Time/batch_file : 2.3352, Training time: 6545.9107\n",
      "Epoch : 563/2000 data_batch_4,  Train_loss : 5271.0205  Test_loss : 5191.6299, Time/batch_file : 2.3222, Training time: 6548.2332\n",
      "Epoch : 563/2000 data_batch_5,  Train_loss : 5589.9990  Test_loss : 5416.7876, Time/batch_file : 2.2969, Training time: 6550.5303\n",
      "Epoch : 564/2000 data_batch_1,  Train_loss : 4967.5415  Test_loss : 5594.5723, Time/batch_file : 2.3147, Training time: 6552.8451\n",
      "Epoch : 564/2000 data_batch_2,  Train_loss : 4641.6602  Test_loss : 5738.3931, Time/batch_file : 2.2933, Training time: 6555.1386\n",
      "Epoch : 564/2000 data_batch_3,  Train_loss : 4739.8896  Test_loss : 5552.3257, Time/batch_file : 2.3114, Training time: 6557.4502\n",
      "Epoch : 564/2000 data_batch_4,  Train_loss : 4823.3950  Test_loss : 5800.6860, Time/batch_file : 2.3101, Training time: 6559.7605\n",
      "Epoch : 564/2000 data_batch_5,  Train_loss : 4791.2144  Test_loss : 5722.9629, Time/batch_file : 2.3158, Training time: 6562.0764\n",
      "Epoch : 565/2000 data_batch_1,  Train_loss : 5382.0527  Test_loss : 6088.5039, Time/batch_file : 2.3140, Training time: 6564.3906\n",
      "Epoch : 565/2000 data_batch_2,  Train_loss : 5658.8008  Test_loss : 5867.8486, Time/batch_file : 2.3174, Training time: 6566.7081\n",
      "Epoch : 565/2000 data_batch_3,  Train_loss : 5601.4766  Test_loss : 5829.6807, Time/batch_file : 2.2888, Training time: 6568.9971\n",
      "Epoch : 565/2000 data_batch_4,  Train_loss : 5528.7188  Test_loss : 6202.6099, Time/batch_file : 2.3159, Training time: 6571.3133\n",
      "Epoch : 565/2000 data_batch_5,  Train_loss : 5387.6172  Test_loss : 6031.7246, Time/batch_file : 2.2886, Training time: 6573.6021\n",
      "Epoch : 566/2000 data_batch_1,  Train_loss : 5486.0459  Test_loss : 5768.3428, Time/batch_file : 2.3188, Training time: 6575.9212\n",
      "Epoch : 566/2000 data_batch_2,  Train_loss : 5358.0864  Test_loss : 5478.1714, Time/batch_file : 2.3263, Training time: 6578.2477\n",
      "Epoch : 566/2000 data_batch_3,  Train_loss : 5187.1367  Test_loss : 5377.3423, Time/batch_file : 2.3152, Training time: 6580.5632\n",
      "Epoch : 566/2000 data_batch_4,  Train_loss : 5365.6475  Test_loss : 5668.9795, Time/batch_file : 2.3115, Training time: 6582.8748\n",
      "Epoch : 566/2000 data_batch_5,  Train_loss : 5420.2715  Test_loss : 6045.0469, Time/batch_file : 2.3165, Training time: 6585.1916\n",
      "Epoch : 567/2000 data_batch_1,  Train_loss : 5463.2290  Test_loss : 5535.9844, Time/batch_file : 2.2787, Training time: 6587.4705\n",
      "Epoch : 567/2000 data_batch_2,  Train_loss : 5371.1943  Test_loss : 5093.6772, Time/batch_file : 2.3088, Training time: 6589.7795\n",
      "Epoch : 567/2000 data_batch_3,  Train_loss : 5274.5474  Test_loss : 5151.5762, Time/batch_file : 2.2821, Training time: 6592.0618\n",
      "Epoch : 567/2000 data_batch_4,  Train_loss : 5022.8003  Test_loss : 5402.8027, Time/batch_file : 2.3241, Training time: 6594.3862\n",
      "Epoch : 567/2000 data_batch_5,  Train_loss : 5246.0811  Test_loss : 5773.4917, Time/batch_file : 2.3021, Training time: 6596.6884\n",
      "Epoch : 568/2000 data_batch_1,  Train_loss : 4704.0410  Test_loss : 5475.0840, Time/batch_file : 2.3133, Training time: 6599.0019\n",
      "Epoch : 568/2000 data_batch_2,  Train_loss : 5011.8779  Test_loss : 5379.0762, Time/batch_file : 2.3043, Training time: 6601.3065\n",
      "Epoch : 568/2000 data_batch_3,  Train_loss : 4767.5400  Test_loss : 5488.1968, Time/batch_file : 2.3066, Training time: 6603.6134\n",
      "Epoch : 568/2000 data_batch_4,  Train_loss : 4895.0723  Test_loss : 5357.7456, Time/batch_file : 2.2795, Training time: 6605.8931\n",
      "Epoch : 568/2000 data_batch_5,  Train_loss : 4907.7178  Test_loss : 5563.7539, Time/batch_file : 2.3263, Training time: 6608.2196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 569/2000 data_batch_1,  Train_loss : 4922.9985  Test_loss : 5195.8369, Time/batch_file : 2.2877, Training time: 6610.5075\n",
      "Epoch : 569/2000 data_batch_2,  Train_loss : 4996.9316  Test_loss : 4922.3286, Time/batch_file : 2.3152, Training time: 6612.8229\n",
      "Epoch : 569/2000 data_batch_3,  Train_loss : 4919.4375  Test_loss : 5115.5010, Time/batch_file : 2.3193, Training time: 6615.1424\n",
      "Epoch : 569/2000 data_batch_4,  Train_loss : 5172.3428  Test_loss : 5055.5278, Time/batch_file : 2.3191, Training time: 6617.4617\n",
      "Epoch : 569/2000 data_batch_5,  Train_loss : 4923.3291  Test_loss : 4872.4102, Time/batch_file : 2.3294, Training time: 6619.7912\n",
      "Epoch : 570/2000 data_batch_1,  Train_loss : 5077.7236  Test_loss : 5811.2368, Time/batch_file : 2.3209, Training time: 6622.1124\n",
      "Epoch : 570/2000 data_batch_2,  Train_loss : 5099.3521  Test_loss : 5426.3462, Time/batch_file : 2.3013, Training time: 6624.4138\n",
      "Epoch : 570/2000 data_batch_3,  Train_loss : 5067.9106  Test_loss : 5701.3867, Time/batch_file : 2.3198, Training time: 6626.7337\n",
      "Epoch : 570/2000 data_batch_4,  Train_loss : 5292.4302  Test_loss : 5791.7710, Time/batch_file : 2.3003, Training time: 6629.0342\n",
      "Epoch : 570/2000 data_batch_5,  Train_loss : 5210.8765  Test_loss : 5736.7798, Time/batch_file : 2.3126, Training time: 6631.3470\n",
      "[./nets/net-570.ckpt] SAVED\n",
      "Epoch : 571/2000 data_batch_1,  Train_loss : 5168.9014  Test_loss : 5262.4795, Time/batch_file : 2.3485, Training time: 6634.9887\n",
      "Epoch : 571/2000 data_batch_2,  Train_loss : 5363.8027  Test_loss : 5938.2139, Time/batch_file : 2.3209, Training time: 6637.3098\n",
      "Epoch : 571/2000 data_batch_3,  Train_loss : 5443.5132  Test_loss : 5815.9697, Time/batch_file : 2.2956, Training time: 6639.6056\n",
      "Epoch : 571/2000 data_batch_4,  Train_loss : 5295.4209  Test_loss : 5413.2549, Time/batch_file : 2.3230, Training time: 6641.9288\n",
      "Epoch : 571/2000 data_batch_5,  Train_loss : 5200.9419  Test_loss : 5494.9570, Time/batch_file : 2.3070, Training time: 6644.2360\n",
      "Epoch : 572/2000 data_batch_1,  Train_loss : 5073.2520  Test_loss : 5199.6172, Time/batch_file : 2.2912, Training time: 6646.5275\n",
      "Epoch : 572/2000 data_batch_2,  Train_loss : 5311.9229  Test_loss : 5403.5469, Time/batch_file : 2.2908, Training time: 6648.8186\n",
      "Epoch : 572/2000 data_batch_3,  Train_loss : 5144.4282  Test_loss : 5538.8462, Time/batch_file : 2.3041, Training time: 6651.1229\n",
      "Epoch : 572/2000 data_batch_4,  Train_loss : 5272.4229  Test_loss : 5585.0752, Time/batch_file : 2.2782, Training time: 6653.4014\n",
      "Epoch : 572/2000 data_batch_5,  Train_loss : 5118.3535  Test_loss : 5529.3643, Time/batch_file : 2.3014, Training time: 6655.7030\n",
      "Epoch : 573/2000 data_batch_1,  Train_loss : 5460.1934  Test_loss : 5329.7969, Time/batch_file : 2.3105, Training time: 6658.0137\n",
      "Epoch : 573/2000 data_batch_2,  Train_loss : 5416.3989  Test_loss : 5699.6279, Time/batch_file : 2.2932, Training time: 6660.3071\n",
      "Epoch : 573/2000 data_batch_3,  Train_loss : 5330.4229  Test_loss : 5668.3564, Time/batch_file : 2.3005, Training time: 6662.6078\n",
      "Epoch : 573/2000 data_batch_4,  Train_loss : 5534.9902  Test_loss : 5538.0107, Time/batch_file : 2.3188, Training time: 6664.9268\n",
      "Epoch : 573/2000 data_batch_5,  Train_loss : 5593.9492  Test_loss : 5280.4517, Time/batch_file : 2.3044, Training time: 6667.2314\n",
      "Epoch : 574/2000 data_batch_1,  Train_loss : 5303.9307  Test_loss : 5210.4409, Time/batch_file : 2.3119, Training time: 6669.5434\n",
      "Epoch : 574/2000 data_batch_2,  Train_loss : 5244.6494  Test_loss : 5350.1914, Time/batch_file : 2.3038, Training time: 6671.8474\n",
      "Epoch : 574/2000 data_batch_3,  Train_loss : 5140.9365  Test_loss : 5212.6025, Time/batch_file : 2.3203, Training time: 6674.1679\n",
      "Epoch : 574/2000 data_batch_4,  Train_loss : 4825.8091  Test_loss : 5022.9429, Time/batch_file : 2.3276, Training time: 6676.4956\n",
      "Epoch : 574/2000 data_batch_5,  Train_loss : 5001.2275  Test_loss : 5159.1719, Time/batch_file : 2.2991, Training time: 6678.7949\n",
      "Epoch : 575/2000 data_batch_1,  Train_loss : 5529.4497  Test_loss : 5481.0957, Time/batch_file : 2.2988, Training time: 6681.0938\n",
      "Epoch : 575/2000 data_batch_2,  Train_loss : 5509.0327  Test_loss : 5373.4077, Time/batch_file : 2.2777, Training time: 6683.3717\n",
      "Epoch : 575/2000 data_batch_3,  Train_loss : 5386.3452  Test_loss : 5493.2412, Time/batch_file : 2.2786, Training time: 6685.6506\n",
      "Epoch : 575/2000 data_batch_4,  Train_loss : 5334.8667  Test_loss : 5368.4526, Time/batch_file : 2.2730, Training time: 6687.9238\n",
      "Epoch : 575/2000 data_batch_5,  Train_loss : 5175.5991  Test_loss : 5896.6934, Time/batch_file : 2.2978, Training time: 6690.2218\n",
      "Epoch : 576/2000 data_batch_1,  Train_loss : 5759.6187  Test_loss : 5582.2339, Time/batch_file : 2.2673, Training time: 6692.4893\n",
      "Epoch : 576/2000 data_batch_2,  Train_loss : 5757.1162  Test_loss : 5620.9443, Time/batch_file : 2.2740, Training time: 6694.7634\n",
      "Epoch : 576/2000 data_batch_3,  Train_loss : 5455.6768  Test_loss : 5467.5947, Time/batch_file : 2.2895, Training time: 6697.0531\n",
      "Epoch : 576/2000 data_batch_4,  Train_loss : 5582.2764  Test_loss : 5255.8491, Time/batch_file : 2.2749, Training time: 6699.3282\n",
      "Epoch : 576/2000 data_batch_5,  Train_loss : 5573.7256  Test_loss : 5586.3833, Time/batch_file : 2.2742, Training time: 6701.6026\n",
      "Epoch : 577/2000 data_batch_1,  Train_loss : 5240.7378  Test_loss : 5601.9570, Time/batch_file : 2.3042, Training time: 6703.9070\n",
      "Epoch : 577/2000 data_batch_2,  Train_loss : 5403.6895  Test_loss : 5596.7515, Time/batch_file : 2.2559, Training time: 6706.1632\n",
      "Epoch : 577/2000 data_batch_3,  Train_loss : 5078.5063  Test_loss : 5403.7666, Time/batch_file : 2.2698, Training time: 6708.4332\n",
      "Epoch : 577/2000 data_batch_4,  Train_loss : 5336.5923  Test_loss : 5598.9595, Time/batch_file : 2.3016, Training time: 6710.7351\n",
      "Epoch : 577/2000 data_batch_5,  Train_loss : 4976.9849  Test_loss : 5454.8164, Time/batch_file : 2.2697, Training time: 6713.0050\n",
      "Epoch : 578/2000 data_batch_1,  Train_loss : 5156.1611  Test_loss : 5303.9116, Time/batch_file : 2.2819, Training time: 6715.2871\n",
      "Epoch : 578/2000 data_batch_2,  Train_loss : 5338.2490  Test_loss : 5374.6348, Time/batch_file : 2.3077, Training time: 6717.5950\n",
      "Epoch : 578/2000 data_batch_3,  Train_loss : 5145.4912  Test_loss : 5103.0977, Time/batch_file : 2.2877, Training time: 6719.8830\n",
      "Epoch : 578/2000 data_batch_4,  Train_loss : 5086.8975  Test_loss : 5399.8867, Time/batch_file : 2.2896, Training time: 6722.1728\n",
      "Epoch : 578/2000 data_batch_5,  Train_loss : 5275.3330  Test_loss : 5007.9990, Time/batch_file : 2.3143, Training time: 6724.4873\n",
      "Epoch : 579/2000 data_batch_1,  Train_loss : 4822.6621  Test_loss : 5337.9590, Time/batch_file : 2.2801, Training time: 6726.7677\n",
      "Epoch : 579/2000 data_batch_2,  Train_loss : 5225.1406  Test_loss : 5424.8037, Time/batch_file : 2.2865, Training time: 6729.0544\n",
      "Epoch : 579/2000 data_batch_3,  Train_loss : 5162.3862  Test_loss : 5315.2051, Time/batch_file : 2.3127, Training time: 6731.3674\n",
      "Epoch : 579/2000 data_batch_4,  Train_loss : 5137.1411  Test_loss : 5682.9795, Time/batch_file : 2.2855, Training time: 6733.6530\n",
      "Epoch : 579/2000 data_batch_5,  Train_loss : 4920.8643  Test_loss : 5265.7988, Time/batch_file : 2.2793, Training time: 6735.9326\n",
      "Epoch : 580/2000 data_batch_1,  Train_loss : 5203.5605  Test_loss : 5381.8828, Time/batch_file : 2.2977, Training time: 6738.2305\n",
      "Epoch : 580/2000 data_batch_2,  Train_loss : 5580.9473  Test_loss : 5283.2837, Time/batch_file : 2.2795, Training time: 6740.5101\n",
      "Epoch : 580/2000 data_batch_3,  Train_loss : 5437.3955  Test_loss : 5523.3071, Time/batch_file : 2.2832, Training time: 6742.7936\n",
      "Epoch : 580/2000 data_batch_4,  Train_loss : 5418.6084  Test_loss : 5153.9873, Time/batch_file : 2.3235, Training time: 6745.1173\n",
      "Epoch : 580/2000 data_batch_5,  Train_loss : 5634.1167  Test_loss : 4968.3770, Time/batch_file : 2.2735, Training time: 6747.3911\n",
      "[./nets/net-580.ckpt] SAVED\n",
      "Epoch : 581/2000 data_batch_1,  Train_loss : 5153.4146  Test_loss : 5536.9932, Time/batch_file : 2.2799, Training time: 6750.9658\n",
      "Epoch : 581/2000 data_batch_2,  Train_loss : 5410.0376  Test_loss : 5352.5166, Time/batch_file : 2.2763, Training time: 6753.2423\n",
      "Epoch : 581/2000 data_batch_3,  Train_loss : 5354.9731  Test_loss : 5271.8457, Time/batch_file : 2.2601, Training time: 6755.5026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 581/2000 data_batch_4,  Train_loss : 5320.0898  Test_loss : 5270.9854, Time/batch_file : 2.2731, Training time: 6757.7758\n",
      "Epoch : 581/2000 data_batch_5,  Train_loss : 5455.1631  Test_loss : 5623.1465, Time/batch_file : 2.2681, Training time: 6760.0442\n",
      "Epoch : 582/2000 data_batch_1,  Train_loss : 5234.7295  Test_loss : 5099.1494, Time/batch_file : 2.2908, Training time: 6762.3352\n",
      "Epoch : 582/2000 data_batch_2,  Train_loss : 5468.5439  Test_loss : 5420.2197, Time/batch_file : 2.2827, Training time: 6764.6182\n",
      "Epoch : 582/2000 data_batch_3,  Train_loss : 5761.9585  Test_loss : 5602.1387, Time/batch_file : 2.2800, Training time: 6766.8984\n",
      "Epoch : 582/2000 data_batch_4,  Train_loss : 5460.8501  Test_loss : 5037.2363, Time/batch_file : 2.2815, Training time: 6769.1801\n",
      "Epoch : 582/2000 data_batch_5,  Train_loss : 5605.5010  Test_loss : 4926.8359, Time/batch_file : 2.2799, Training time: 6771.4602\n",
      "Epoch : 583/2000 data_batch_1,  Train_loss : 5200.7915  Test_loss : 5919.8657, Time/batch_file : 2.2840, Training time: 6773.7444\n",
      "Epoch : 583/2000 data_batch_2,  Train_loss : 5114.6714  Test_loss : 5707.7266, Time/batch_file : 2.2858, Training time: 6776.0305\n",
      "Epoch : 583/2000 data_batch_3,  Train_loss : 5070.8730  Test_loss : 5640.9966, Time/batch_file : 2.2931, Training time: 6778.3237\n",
      "Epoch : 583/2000 data_batch_4,  Train_loss : 5337.9077  Test_loss : 5834.5508, Time/batch_file : 2.2757, Training time: 6780.5996\n",
      "Epoch : 583/2000 data_batch_5,  Train_loss : 5115.2329  Test_loss : 5707.6401, Time/batch_file : 2.2895, Training time: 6782.8892\n",
      "Epoch : 584/2000 data_batch_1,  Train_loss : 5063.7539  Test_loss : 5290.9336, Time/batch_file : 2.2727, Training time: 6785.1621\n",
      "Epoch : 584/2000 data_batch_2,  Train_loss : 4771.8594  Test_loss : 5586.5913, Time/batch_file : 2.2758, Training time: 6787.4381\n",
      "Epoch : 584/2000 data_batch_3,  Train_loss : 5267.6211  Test_loss : 5523.5371, Time/batch_file : 2.2832, Training time: 6789.7215\n",
      "Epoch : 584/2000 data_batch_4,  Train_loss : 5104.6938  Test_loss : 5524.8960, Time/batch_file : 2.2795, Training time: 6792.0013\n",
      "Epoch : 584/2000 data_batch_5,  Train_loss : 5122.5684  Test_loss : 5611.4756, Time/batch_file : 2.2825, Training time: 6794.2840\n",
      "Epoch : 585/2000 data_batch_1,  Train_loss : 5649.5171  Test_loss : 5751.6621, Time/batch_file : 2.2766, Training time: 6796.5608\n",
      "Epoch : 585/2000 data_batch_2,  Train_loss : 4977.6592  Test_loss : 5550.0527, Time/batch_file : 2.2776, Training time: 6798.8387\n",
      "Epoch : 585/2000 data_batch_3,  Train_loss : 5662.9395  Test_loss : 5635.2075, Time/batch_file : 2.2778, Training time: 6801.1166\n",
      "Epoch : 585/2000 data_batch_4,  Train_loss : 5365.6650  Test_loss : 5584.3105, Time/batch_file : 2.2779, Training time: 6803.3947\n",
      "Epoch : 585/2000 data_batch_5,  Train_loss : 5350.6064  Test_loss : 5351.1006, Time/batch_file : 2.2792, Training time: 6805.6740\n",
      "Epoch : 586/2000 data_batch_1,  Train_loss : 5161.4536  Test_loss : 5496.5474, Time/batch_file : 2.2651, Training time: 6807.9393\n",
      "Epoch : 586/2000 data_batch_2,  Train_loss : 5572.4214  Test_loss : 5713.2822, Time/batch_file : 2.2740, Training time: 6810.2135\n",
      "Epoch : 586/2000 data_batch_3,  Train_loss : 5190.6973  Test_loss : 5974.8403, Time/batch_file : 2.2676, Training time: 6812.4813\n",
      "Epoch : 586/2000 data_batch_4,  Train_loss : 5243.0332  Test_loss : 5468.7866, Time/batch_file : 2.2657, Training time: 6814.7472\n",
      "Epoch : 586/2000 data_batch_5,  Train_loss : 5267.8633  Test_loss : 5453.9888, Time/batch_file : 2.2720, Training time: 6817.0193\n",
      "Epoch : 587/2000 data_batch_1,  Train_loss : 5125.5986  Test_loss : 5948.5693, Time/batch_file : 2.2821, Training time: 6819.3016\n",
      "Epoch : 587/2000 data_batch_2,  Train_loss : 5011.9902  Test_loss : 6107.4644, Time/batch_file : 2.2724, Training time: 6821.5743\n",
      "Epoch : 587/2000 data_batch_3,  Train_loss : 5022.3564  Test_loss : 5982.4082, Time/batch_file : 2.2971, Training time: 6823.8716\n",
      "Epoch : 587/2000 data_batch_4,  Train_loss : 5058.3047  Test_loss : 6572.6289, Time/batch_file : 2.2818, Training time: 6826.1536\n",
      "Epoch : 587/2000 data_batch_5,  Train_loss : 5133.6650  Test_loss : 6131.2686, Time/batch_file : 2.2804, Training time: 6828.4343\n",
      "Epoch : 588/2000 data_batch_1,  Train_loss : 5419.8174  Test_loss : 5325.2295, Time/batch_file : 2.2673, Training time: 6830.7019\n",
      "Epoch : 588/2000 data_batch_2,  Train_loss : 5446.1846  Test_loss : 4896.5269, Time/batch_file : 2.2678, Training time: 6832.9698\n",
      "Epoch : 588/2000 data_batch_3,  Train_loss : 5652.2168  Test_loss : 5100.5566, Time/batch_file : 2.2667, Training time: 6835.2367\n",
      "Epoch : 588/2000 data_batch_4,  Train_loss : 5190.1499  Test_loss : 5548.1724, Time/batch_file : 2.2682, Training time: 6837.5051\n",
      "Epoch : 588/2000 data_batch_5,  Train_loss : 5266.9219  Test_loss : 4940.0156, Time/batch_file : 2.2725, Training time: 6839.7778\n",
      "Epoch : 589/2000 data_batch_1,  Train_loss : 5269.6045  Test_loss : 5898.5444, Time/batch_file : 2.2724, Training time: 6842.0505\n",
      "Epoch : 589/2000 data_batch_2,  Train_loss : 5380.2998  Test_loss : 5940.4824, Time/batch_file : 2.2726, Training time: 6844.3233\n",
      "Epoch : 589/2000 data_batch_3,  Train_loss : 5260.3950  Test_loss : 5854.8306, Time/batch_file : 2.2614, Training time: 6846.5849\n",
      "Epoch : 589/2000 data_batch_4,  Train_loss : 5123.4512  Test_loss : 5725.3169, Time/batch_file : 2.2757, Training time: 6848.8608\n",
      "Epoch : 589/2000 data_batch_5,  Train_loss : 5218.2217  Test_loss : 5803.3921, Time/batch_file : 2.2648, Training time: 6851.1259\n",
      "Epoch : 590/2000 data_batch_1,  Train_loss : 5079.1860  Test_loss : 5814.9590, Time/batch_file : 2.2789, Training time: 6853.4050\n",
      "Epoch : 590/2000 data_batch_2,  Train_loss : 5241.8804  Test_loss : 5550.3398, Time/batch_file : 2.2856, Training time: 6855.6908\n",
      "Epoch : 590/2000 data_batch_3,  Train_loss : 4954.6260  Test_loss : 5671.8828, Time/batch_file : 2.2696, Training time: 6857.9605\n",
      "Epoch : 590/2000 data_batch_4,  Train_loss : 5110.0737  Test_loss : 5672.8066, Time/batch_file : 2.2774, Training time: 6860.2382\n",
      "Epoch : 590/2000 data_batch_5,  Train_loss : 5054.5986  Test_loss : 5558.3975, Time/batch_file : 2.2751, Training time: 6862.5136\n",
      "[./nets/net-590.ckpt] SAVED\n",
      "Epoch : 591/2000 data_batch_1,  Train_loss : 4860.0752  Test_loss : 5073.7021, Time/batch_file : 2.3361, Training time: 6866.1467\n",
      "Epoch : 591/2000 data_batch_2,  Train_loss : 4591.5068  Test_loss : 4808.5942, Time/batch_file : 2.2876, Training time: 6868.4345\n",
      "Epoch : 591/2000 data_batch_3,  Train_loss : 4759.7290  Test_loss : 4527.2637, Time/batch_file : 2.2957, Training time: 6870.7304\n",
      "Epoch : 591/2000 data_batch_4,  Train_loss : 4849.2739  Test_loss : 4886.8477, Time/batch_file : 2.2973, Training time: 6873.0280\n",
      "Epoch : 591/2000 data_batch_5,  Train_loss : 4845.4482  Test_loss : 4690.5620, Time/batch_file : 2.2823, Training time: 6875.3105\n",
      "Epoch : 592/2000 data_batch_1,  Train_loss : 5221.0596  Test_loss : 5580.9824, Time/batch_file : 2.2837, Training time: 6877.5944\n",
      "Epoch : 592/2000 data_batch_2,  Train_loss : 5460.6851  Test_loss : 5517.0615, Time/batch_file : 2.2848, Training time: 6879.8795\n",
      "Epoch : 592/2000 data_batch_3,  Train_loss : 5203.6597  Test_loss : 5343.7588, Time/batch_file : 2.2910, Training time: 6882.1708\n",
      "Epoch : 592/2000 data_batch_4,  Train_loss : 5181.3154  Test_loss : 6001.4644, Time/batch_file : 2.2983, Training time: 6884.4693\n",
      "Epoch : 592/2000 data_batch_5,  Train_loss : 5467.7212  Test_loss : 5804.5044, Time/batch_file : 2.2990, Training time: 6886.7686\n",
      "Epoch : 593/2000 data_batch_1,  Train_loss : 5049.2710  Test_loss : 5400.9067, Time/batch_file : 2.3175, Training time: 6889.0864\n",
      "Epoch : 593/2000 data_batch_2,  Train_loss : 5232.1470  Test_loss : 6130.0098, Time/batch_file : 2.3096, Training time: 6891.3962\n",
      "Epoch : 593/2000 data_batch_3,  Train_loss : 5110.0005  Test_loss : 5454.3599, Time/batch_file : 2.2950, Training time: 6893.6915\n",
      "Epoch : 593/2000 data_batch_4,  Train_loss : 5020.1538  Test_loss : 5719.1924, Time/batch_file : 2.3145, Training time: 6896.0061\n",
      "Epoch : 593/2000 data_batch_5,  Train_loss : 4955.2905  Test_loss : 5712.7764, Time/batch_file : 2.2960, Training time: 6898.3023\n",
      "Epoch : 594/2000 data_batch_1,  Train_loss : 5697.6567  Test_loss : 5407.6270, Time/batch_file : 2.2852, Training time: 6900.5878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 594/2000 data_batch_2,  Train_loss : 5378.9619  Test_loss : 5549.8491, Time/batch_file : 2.2790, Training time: 6902.8671\n",
      "Epoch : 594/2000 data_batch_3,  Train_loss : 5505.6265  Test_loss : 5589.1943, Time/batch_file : 2.3000, Training time: 6905.1672\n",
      "Epoch : 594/2000 data_batch_4,  Train_loss : 5326.6782  Test_loss : 5406.2500, Time/batch_file : 2.3064, Training time: 6907.4738\n",
      "Epoch : 594/2000 data_batch_5,  Train_loss : 5567.3926  Test_loss : 5878.2041, Time/batch_file : 2.2867, Training time: 6909.7607\n",
      "Epoch : 595/2000 data_batch_1,  Train_loss : 5465.6279  Test_loss : 5058.9014, Time/batch_file : 2.2963, Training time: 6912.0573\n",
      "Epoch : 595/2000 data_batch_2,  Train_loss : 5802.3979  Test_loss : 5009.6758, Time/batch_file : 2.2979, Training time: 6914.3552\n",
      "Epoch : 595/2000 data_batch_3,  Train_loss : 5657.4263  Test_loss : 5119.9058, Time/batch_file : 2.2947, Training time: 6916.6500\n",
      "Epoch : 595/2000 data_batch_4,  Train_loss : 5810.0508  Test_loss : 5168.0117, Time/batch_file : 2.3008, Training time: 6918.9510\n",
      "Epoch : 595/2000 data_batch_5,  Train_loss : 5496.4424  Test_loss : 5493.4175, Time/batch_file : 2.3229, Training time: 6921.2742\n",
      "Epoch : 596/2000 data_batch_1,  Train_loss : 4926.5645  Test_loss : 5533.1592, Time/batch_file : 2.3023, Training time: 6923.5767\n",
      "Epoch : 596/2000 data_batch_2,  Train_loss : 4731.1147  Test_loss : 5592.3081, Time/batch_file : 2.3111, Training time: 6925.8879\n",
      "Epoch : 596/2000 data_batch_3,  Train_loss : 5258.0933  Test_loss : 5989.9194, Time/batch_file : 2.3154, Training time: 6928.2036\n",
      "Epoch : 596/2000 data_batch_4,  Train_loss : 4957.3804  Test_loss : 5627.0215, Time/batch_file : 2.2979, Training time: 6930.5017\n",
      "Epoch : 596/2000 data_batch_5,  Train_loss : 4732.9429  Test_loss : 5663.4941, Time/batch_file : 2.2975, Training time: 6932.7995\n",
      "Epoch : 597/2000 data_batch_1,  Train_loss : 4945.4873  Test_loss : 6392.7764, Time/batch_file : 2.2897, Training time: 6935.0893\n",
      "Epoch : 597/2000 data_batch_2,  Train_loss : 5115.3940  Test_loss : 6455.7656, Time/batch_file : 2.2905, Training time: 6937.3800\n",
      "Epoch : 597/2000 data_batch_3,  Train_loss : 5105.4810  Test_loss : 6367.3340, Time/batch_file : 2.2840, Training time: 6939.6642\n",
      "Epoch : 597/2000 data_batch_4,  Train_loss : 5005.7041  Test_loss : 6327.7217, Time/batch_file : 2.2989, Training time: 6941.9633\n",
      "Epoch : 597/2000 data_batch_5,  Train_loss : 5244.1201  Test_loss : 6271.4131, Time/batch_file : 2.3005, Training time: 6944.2640\n",
      "Epoch : 598/2000 data_batch_1,  Train_loss : 5493.3828  Test_loss : 5865.7266, Time/batch_file : 2.3020, Training time: 6946.5662\n",
      "Epoch : 598/2000 data_batch_2,  Train_loss : 5608.7036  Test_loss : 5507.1680, Time/batch_file : 2.3058, Training time: 6948.8724\n",
      "Epoch : 598/2000 data_batch_3,  Train_loss : 5565.8408  Test_loss : 5756.6138, Time/batch_file : 2.2995, Training time: 6951.1721\n",
      "Epoch : 598/2000 data_batch_4,  Train_loss : 5360.7432  Test_loss : 5674.9209, Time/batch_file : 2.3027, Training time: 6953.4750\n",
      "Epoch : 598/2000 data_batch_5,  Train_loss : 5392.2148  Test_loss : 5858.1836, Time/batch_file : 2.2897, Training time: 6955.7648\n",
      "Epoch : 599/2000 data_batch_1,  Train_loss : 4983.4644  Test_loss : 5508.1714, Time/batch_file : 2.2981, Training time: 6958.0631\n",
      "Epoch : 599/2000 data_batch_2,  Train_loss : 4960.1880  Test_loss : 5539.4185, Time/batch_file : 2.3183, Training time: 6960.3816\n",
      "Epoch : 599/2000 data_batch_3,  Train_loss : 5196.1553  Test_loss : 5625.8555, Time/batch_file : 2.3191, Training time: 6962.7010\n",
      "Epoch : 599/2000 data_batch_4,  Train_loss : 4952.5234  Test_loss : 5798.9268, Time/batch_file : 2.3151, Training time: 6965.0163\n",
      "Epoch : 599/2000 data_batch_5,  Train_loss : 4991.3340  Test_loss : 5581.4902, Time/batch_file : 2.3007, Training time: 6967.3171\n",
      "Epoch : 600/2000 data_batch_1,  Train_loss : 5280.1602  Test_loss : 4788.0518, Time/batch_file : 2.3061, Training time: 6969.6234\n",
      "Epoch : 600/2000 data_batch_2,  Train_loss : 5329.3633  Test_loss : 5222.1348, Time/batch_file : 2.2974, Training time: 6971.9210\n",
      "Epoch : 600/2000 data_batch_3,  Train_loss : 5166.9277  Test_loss : 4926.5835, Time/batch_file : 2.3086, Training time: 6974.2298\n",
      "Epoch : 600/2000 data_batch_4,  Train_loss : 5454.5264  Test_loss : 5307.4263, Time/batch_file : 2.2894, Training time: 6976.5194\n",
      "Epoch : 600/2000 data_batch_5,  Train_loss : 5228.1216  Test_loss : 4968.4082, Time/batch_file : 2.3145, Training time: 6978.8340\n",
      "[./nets/net-600.ckpt] SAVED\n",
      "Epoch : 601/2000 data_batch_1,  Train_loss : 4998.7539  Test_loss : 4981.3955, Time/batch_file : 2.3340, Training time: 6982.4625\n",
      "Epoch : 601/2000 data_batch_2,  Train_loss : 5330.8740  Test_loss : 5000.5854, Time/batch_file : 2.3214, Training time: 6984.7841\n",
      "Epoch : 601/2000 data_batch_3,  Train_loss : 5294.8252  Test_loss : 4909.5835, Time/batch_file : 2.2846, Training time: 6987.0690\n",
      "Epoch : 601/2000 data_batch_4,  Train_loss : 5158.2437  Test_loss : 4985.1006, Time/batch_file : 2.3119, Training time: 6989.3811\n",
      "Epoch : 601/2000 data_batch_5,  Train_loss : 5117.5684  Test_loss : 5221.2471, Time/batch_file : 2.2815, Training time: 6991.6626\n",
      "Epoch : 602/2000 data_batch_1,  Train_loss : 5843.5146  Test_loss : 5261.2827, Time/batch_file : 2.2955, Training time: 6993.9584\n",
      "Epoch : 602/2000 data_batch_2,  Train_loss : 5712.2412  Test_loss : 5145.9639, Time/batch_file : 2.2638, Training time: 6996.2224\n",
      "Epoch : 602/2000 data_batch_3,  Train_loss : 5497.6260  Test_loss : 5467.5103, Time/batch_file : 2.3211, Training time: 6998.5438\n",
      "Epoch : 602/2000 data_batch_4,  Train_loss : 5917.7241  Test_loss : 5050.9453, Time/batch_file : 2.2696, Training time: 7000.8137\n",
      "Epoch : 602/2000 data_batch_5,  Train_loss : 5693.2007  Test_loss : 4810.0693, Time/batch_file : 2.3144, Training time: 7003.1282\n",
      "Epoch : 603/2000 data_batch_1,  Train_loss : 5285.2749  Test_loss : 5422.4204, Time/batch_file : 2.2900, Training time: 7005.4184\n",
      "Epoch : 603/2000 data_batch_2,  Train_loss : 5147.5728  Test_loss : 5321.9053, Time/batch_file : 2.3111, Training time: 7007.7297\n",
      "Epoch : 603/2000 data_batch_3,  Train_loss : 5394.7275  Test_loss : 5189.0063, Time/batch_file : 2.3018, Training time: 7010.0316\n",
      "Epoch : 603/2000 data_batch_4,  Train_loss : 5299.2656  Test_loss : 5491.0327, Time/batch_file : 2.3081, Training time: 7012.3399\n",
      "Epoch : 603/2000 data_batch_5,  Train_loss : 5041.9238  Test_loss : 5584.8564, Time/batch_file : 2.2764, Training time: 7014.6164\n",
      "Epoch : 604/2000 data_batch_1,  Train_loss : 4788.9185  Test_loss : 5480.1230, Time/batch_file : 2.3422, Training time: 7016.9586\n",
      "Epoch : 604/2000 data_batch_2,  Train_loss : 5273.4268  Test_loss : 5333.0625, Time/batch_file : 2.2722, Training time: 7019.2312\n",
      "Epoch : 604/2000 data_batch_3,  Train_loss : 4950.6514  Test_loss : 5421.5771, Time/batch_file : 2.3017, Training time: 7021.5331\n",
      "Epoch : 604/2000 data_batch_4,  Train_loss : 5161.5684  Test_loss : 5449.1221, Time/batch_file : 2.2785, Training time: 7023.8117\n",
      "Epoch : 604/2000 data_batch_5,  Train_loss : 4913.2109  Test_loss : 5675.7432, Time/batch_file : 2.3096, Training time: 7026.1215\n",
      "Epoch : 605/2000 data_batch_1,  Train_loss : 5416.5903  Test_loss : 5733.0527, Time/batch_file : 2.2780, Training time: 7028.3997\n",
      "Epoch : 605/2000 data_batch_2,  Train_loss : 5766.3691  Test_loss : 5634.2393, Time/batch_file : 2.3187, Training time: 7030.7187\n",
      "Epoch : 605/2000 data_batch_3,  Train_loss : 5755.2271  Test_loss : 5569.9395, Time/batch_file : 2.2762, Training time: 7032.9950\n",
      "Epoch : 605/2000 data_batch_4,  Train_loss : 5367.4863  Test_loss : 5354.4482, Time/batch_file : 2.3164, Training time: 7035.3116\n",
      "Epoch : 605/2000 data_batch_5,  Train_loss : 5465.8389  Test_loss : 5539.6528, Time/batch_file : 2.2698, Training time: 7037.5817\n",
      "Epoch : 606/2000 data_batch_1,  Train_loss : 5056.4204  Test_loss : 5517.0977, Time/batch_file : 2.3060, Training time: 7039.8879\n",
      "Epoch : 606/2000 data_batch_2,  Train_loss : 5456.8569  Test_loss : 5763.5601, Time/batch_file : 2.2903, Training time: 7042.1784\n",
      "Epoch : 606/2000 data_batch_3,  Train_loss : 5038.4766  Test_loss : 5448.0562, Time/batch_file : 2.3240, Training time: 7044.5026\n",
      "Epoch : 606/2000 data_batch_4,  Train_loss : 5279.9253  Test_loss : 5203.8604, Time/batch_file : 2.2799, Training time: 7046.7828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 606/2000 data_batch_5,  Train_loss : 5243.4033  Test_loss : 5647.7129, Time/batch_file : 2.3017, Training time: 7049.0847\n",
      "Epoch : 607/2000 data_batch_1,  Train_loss : 5188.1050  Test_loss : 5817.2061, Time/batch_file : 2.2691, Training time: 7051.3540\n",
      "Epoch : 607/2000 data_batch_2,  Train_loss : 5171.9219  Test_loss : 5761.9243, Time/batch_file : 2.3099, Training time: 7053.6641\n",
      "Epoch : 607/2000 data_batch_3,  Train_loss : 5300.0903  Test_loss : 5600.6221, Time/batch_file : 2.2805, Training time: 7055.9448\n",
      "Epoch : 607/2000 data_batch_4,  Train_loss : 5126.1694  Test_loss : 5634.0181, Time/batch_file : 2.3150, Training time: 7058.2599\n",
      "Epoch : 607/2000 data_batch_5,  Train_loss : 5093.4795  Test_loss : 5488.0835, Time/batch_file : 2.2668, Training time: 7060.5269\n",
      "Epoch : 608/2000 data_batch_1,  Train_loss : 5153.5771  Test_loss : 5950.7720, Time/batch_file : 2.2987, Training time: 7062.8258\n",
      "Epoch : 608/2000 data_batch_2,  Train_loss : 5093.1431  Test_loss : 5687.8560, Time/batch_file : 2.2865, Training time: 7065.1126\n",
      "Epoch : 608/2000 data_batch_3,  Train_loss : 4973.6494  Test_loss : 5676.9561, Time/batch_file : 2.3095, Training time: 7067.4222\n",
      "Epoch : 608/2000 data_batch_4,  Train_loss : 5037.6191  Test_loss : 5926.2676, Time/batch_file : 2.2677, Training time: 7069.6902\n",
      "Epoch : 608/2000 data_batch_5,  Train_loss : 5049.3857  Test_loss : 5614.6235, Time/batch_file : 2.3029, Training time: 7071.9933\n",
      "Epoch : 609/2000 data_batch_1,  Train_loss : 5465.0171  Test_loss : 5563.0166, Time/batch_file : 2.2719, Training time: 7074.2653\n",
      "Epoch : 609/2000 data_batch_2,  Train_loss : 5295.6240  Test_loss : 5607.7373, Time/batch_file : 2.2975, Training time: 7076.5630\n",
      "Epoch : 609/2000 data_batch_3,  Train_loss : 5274.3223  Test_loss : 5662.9092, Time/batch_file : 2.2637, Training time: 7078.8269\n",
      "Epoch : 609/2000 data_batch_4,  Train_loss : 5263.7100  Test_loss : 5393.9619, Time/batch_file : 2.3002, Training time: 7081.1273\n",
      "Epoch : 609/2000 data_batch_5,  Train_loss : 5459.5864  Test_loss : 5542.7705, Time/batch_file : 2.2640, Training time: 7083.3915\n",
      "Epoch : 610/2000 data_batch_1,  Train_loss : 4853.9160  Test_loss : 5264.2695, Time/batch_file : 2.3352, Training time: 7085.7268\n",
      "Epoch : 610/2000 data_batch_2,  Train_loss : 5105.4346  Test_loss : 5375.7754, Time/batch_file : 2.2883, Training time: 7088.0154\n",
      "Epoch : 610/2000 data_batch_3,  Train_loss : 5025.3301  Test_loss : 5274.3672, Time/batch_file : 2.3083, Training time: 7090.3239\n",
      "Epoch : 610/2000 data_batch_4,  Train_loss : 4985.0098  Test_loss : 5280.3589, Time/batch_file : 2.2843, Training time: 7092.6085\n",
      "Epoch : 610/2000 data_batch_5,  Train_loss : 4990.7310  Test_loss : 5424.6011, Time/batch_file : 2.3130, Training time: 7094.9216\n",
      "[./nets/net-610.ckpt] SAVED\n",
      "Epoch : 611/2000 data_batch_1,  Train_loss : 4877.4688  Test_loss : 5463.0537, Time/batch_file : 2.2878, Training time: 7098.4888\n",
      "Epoch : 611/2000 data_batch_2,  Train_loss : 4945.7363  Test_loss : 5705.3999, Time/batch_file : 2.2976, Training time: 7100.7866\n",
      "Epoch : 611/2000 data_batch_3,  Train_loss : 5152.9043  Test_loss : 5045.8037, Time/batch_file : 2.2673, Training time: 7103.0541\n",
      "Epoch : 611/2000 data_batch_4,  Train_loss : 5221.2793  Test_loss : 5532.5342, Time/batch_file : 2.2977, Training time: 7105.3521\n",
      "Epoch : 611/2000 data_batch_5,  Train_loss : 4883.3457  Test_loss : 5587.6919, Time/batch_file : 2.2950, Training time: 7107.6473\n",
      "Epoch : 612/2000 data_batch_1,  Train_loss : 5306.5811  Test_loss : 5498.6216, Time/batch_file : 2.2978, Training time: 7109.9454\n",
      "Epoch : 612/2000 data_batch_2,  Train_loss : 5364.8447  Test_loss : 5362.0986, Time/batch_file : 2.2688, Training time: 7112.2145\n",
      "Epoch : 612/2000 data_batch_3,  Train_loss : 5559.6943  Test_loss : 5335.0254, Time/batch_file : 2.2986, Training time: 7114.5132\n",
      "Epoch : 612/2000 data_batch_4,  Train_loss : 5476.6411  Test_loss : 5632.8057, Time/batch_file : 2.2966, Training time: 7116.8100\n",
      "Epoch : 612/2000 data_batch_5,  Train_loss : 5428.6758  Test_loss : 5598.7578, Time/batch_file : 2.2980, Training time: 7119.1082\n",
      "Epoch : 613/2000 data_batch_1,  Train_loss : 5564.0073  Test_loss : 5952.9434, Time/batch_file : 2.2753, Training time: 7121.3837\n",
      "Epoch : 613/2000 data_batch_2,  Train_loss : 5131.9395  Test_loss : 5400.0420, Time/batch_file : 2.2641, Training time: 7123.6480\n",
      "Epoch : 613/2000 data_batch_3,  Train_loss : 4790.2808  Test_loss : 5496.2070, Time/batch_file : 2.2792, Training time: 7125.9273\n",
      "Epoch : 613/2000 data_batch_4,  Train_loss : 5274.2192  Test_loss : 5571.3286, Time/batch_file : 2.2671, Training time: 7128.1946\n",
      "Epoch : 613/2000 data_batch_5,  Train_loss : 4962.3481  Test_loss : 5588.2222, Time/batch_file : 2.2788, Training time: 7130.4735\n",
      "Epoch : 614/2000 data_batch_1,  Train_loss : 4610.6562  Test_loss : 5079.3223, Time/batch_file : 2.2834, Training time: 7132.7571\n",
      "Epoch : 614/2000 data_batch_2,  Train_loss : 4762.5742  Test_loss : 5321.8105, Time/batch_file : 2.2887, Training time: 7135.0460\n",
      "Epoch : 614/2000 data_batch_3,  Train_loss : 4923.5063  Test_loss : 4840.5566, Time/batch_file : 2.3053, Training time: 7137.3515\n",
      "Epoch : 614/2000 data_batch_4,  Train_loss : 4708.3623  Test_loss : 5220.5244, Time/batch_file : 2.2980, Training time: 7139.6498\n",
      "Epoch : 614/2000 data_batch_5,  Train_loss : 4519.5747  Test_loss : 4948.5249, Time/batch_file : 2.2793, Training time: 7141.9293\n",
      "Epoch : 615/2000 data_batch_1,  Train_loss : 5041.5142  Test_loss : 5879.4971, Time/batch_file : 2.3046, Training time: 7144.2343\n",
      "Epoch : 615/2000 data_batch_2,  Train_loss : 5158.1846  Test_loss : 5721.9785, Time/batch_file : 2.2790, Training time: 7146.5134\n",
      "Epoch : 615/2000 data_batch_3,  Train_loss : 5064.5000  Test_loss : 5394.1670, Time/batch_file : 2.2898, Training time: 7148.8033\n",
      "Epoch : 615/2000 data_batch_4,  Train_loss : 5312.3979  Test_loss : 5462.5640, Time/batch_file : 2.2816, Training time: 7151.0851\n",
      "Epoch : 615/2000 data_batch_5,  Train_loss : 5133.9839  Test_loss : 5390.7280, Time/batch_file : 2.2985, Training time: 7153.3838\n",
      "Epoch : 616/2000 data_batch_1,  Train_loss : 5497.4629  Test_loss : 4921.6948, Time/batch_file : 2.2904, Training time: 7155.6744\n",
      "Epoch : 616/2000 data_batch_2,  Train_loss : 5358.4897  Test_loss : 5400.0239, Time/batch_file : 2.3033, Training time: 7157.9779\n",
      "Epoch : 616/2000 data_batch_3,  Train_loss : 5344.7998  Test_loss : 5219.0610, Time/batch_file : 2.2992, Training time: 7160.2772\n",
      "Epoch : 616/2000 data_batch_4,  Train_loss : 5717.9092  Test_loss : 5027.4912, Time/batch_file : 2.3190, Training time: 7162.5964\n",
      "Epoch : 616/2000 data_batch_5,  Train_loss : 5357.1362  Test_loss : 5037.2217, Time/batch_file : 2.2930, Training time: 7164.8896\n",
      "Epoch : 617/2000 data_batch_1,  Train_loss : 5189.6934  Test_loss : 5363.8882, Time/batch_file : 2.2903, Training time: 7167.1801\n",
      "Epoch : 617/2000 data_batch_2,  Train_loss : 5304.1338  Test_loss : 5611.5981, Time/batch_file : 2.2791, Training time: 7169.4594\n",
      "Epoch : 617/2000 data_batch_3,  Train_loss : 5054.6333  Test_loss : 5829.8203, Time/batch_file : 2.2939, Training time: 7171.7535\n",
      "Epoch : 617/2000 data_batch_4,  Train_loss : 5096.6118  Test_loss : 5478.6313, Time/batch_file : 2.2720, Training time: 7174.0258\n",
      "Epoch : 617/2000 data_batch_5,  Train_loss : 4945.0791  Test_loss : 5876.3291, Time/batch_file : 2.2858, Training time: 7176.3117\n",
      "Epoch : 618/2000 data_batch_1,  Train_loss : 4601.5737  Test_loss : 5347.9346, Time/batch_file : 2.2751, Training time: 7178.5871\n",
      "Epoch : 618/2000 data_batch_2,  Train_loss : 4881.2349  Test_loss : 6073.3867, Time/batch_file : 2.3001, Training time: 7180.8874\n",
      "Epoch : 618/2000 data_batch_3,  Train_loss : 4788.4619  Test_loss : 5440.7637, Time/batch_file : 2.2803, Training time: 7183.1679\n",
      "Epoch : 618/2000 data_batch_4,  Train_loss : 4583.1133  Test_loss : 5675.1885, Time/batch_file : 2.2863, Training time: 7185.4544\n",
      "Epoch : 618/2000 data_batch_5,  Train_loss : 4730.4102  Test_loss : 5888.8525, Time/batch_file : 2.2743, Training time: 7187.7288\n",
      "Epoch : 619/2000 data_batch_1,  Train_loss : 5334.1909  Test_loss : 5845.3257, Time/batch_file : 2.3082, Training time: 7190.0372\n",
      "Epoch : 619/2000 data_batch_2,  Train_loss : 5518.7476  Test_loss : 5861.5059, Time/batch_file : 2.2793, Training time: 7192.3168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 619/2000 data_batch_3,  Train_loss : 5112.2896  Test_loss : 5723.2427, Time/batch_file : 2.2996, Training time: 7194.6166\n",
      "Epoch : 619/2000 data_batch_4,  Train_loss : 5564.2671  Test_loss : 5878.7729, Time/batch_file : 2.2887, Training time: 7196.9056\n",
      "Epoch : 619/2000 data_batch_5,  Train_loss : 5340.8193  Test_loss : 5697.1982, Time/batch_file : 2.3091, Training time: 7199.2149\n",
      "Epoch : 620/2000 data_batch_1,  Train_loss : 5187.8862  Test_loss : 4740.0908, Time/batch_file : 2.2770, Training time: 7201.4923\n",
      "Epoch : 620/2000 data_batch_2,  Train_loss : 5142.0791  Test_loss : 4653.4565, Time/batch_file : 2.2911, Training time: 7203.7836\n",
      "Epoch : 620/2000 data_batch_3,  Train_loss : 5195.8330  Test_loss : 5094.8423, Time/batch_file : 2.2803, Training time: 7206.0640\n",
      "Epoch : 620/2000 data_batch_4,  Train_loss : 5183.4609  Test_loss : 4896.9756, Time/batch_file : 2.3030, Training time: 7208.3673\n",
      "Epoch : 620/2000 data_batch_5,  Train_loss : 5317.0273  Test_loss : 4712.6094, Time/batch_file : 2.2752, Training time: 7210.6426\n",
      "[./nets/net-620.ckpt] SAVED\n",
      "Epoch : 621/2000 data_batch_1,  Train_loss : 4717.0605  Test_loss : 5334.8115, Time/batch_file : 2.2823, Training time: 7214.2253\n",
      "Epoch : 621/2000 data_batch_2,  Train_loss : 5280.1406  Test_loss : 5450.0928, Time/batch_file : 2.2554, Training time: 7216.4809\n",
      "Epoch : 621/2000 data_batch_3,  Train_loss : 5229.6318  Test_loss : 5201.9644, Time/batch_file : 2.2642, Training time: 7218.7453\n",
      "Epoch : 621/2000 data_batch_4,  Train_loss : 4897.6006  Test_loss : 5188.2114, Time/batch_file : 2.2949, Training time: 7221.0403\n",
      "Epoch : 621/2000 data_batch_5,  Train_loss : 5116.9082  Test_loss : 5331.4697, Time/batch_file : 2.2557, Training time: 7223.2962\n",
      "Epoch : 622/2000 data_batch_1,  Train_loss : 5244.2246  Test_loss : 5663.0918, Time/batch_file : 2.2865, Training time: 7225.5828\n",
      "Epoch : 622/2000 data_batch_2,  Train_loss : 5261.8257  Test_loss : 5619.3398, Time/batch_file : 2.3017, Training time: 7227.8847\n",
      "Epoch : 622/2000 data_batch_3,  Train_loss : 5095.6855  Test_loss : 5873.9575, Time/batch_file : 2.2872, Training time: 7230.1720\n",
      "Epoch : 622/2000 data_batch_4,  Train_loss : 5222.9019  Test_loss : 5814.8940, Time/batch_file : 2.2963, Training time: 7232.4685\n",
      "Epoch : 622/2000 data_batch_5,  Train_loss : 5136.7744  Test_loss : 5817.5127, Time/batch_file : 2.2753, Training time: 7234.7440\n",
      "Epoch : 623/2000 data_batch_1,  Train_loss : 5370.1802  Test_loss : 5556.2036, Time/batch_file : 2.3039, Training time: 7237.0481\n",
      "Epoch : 623/2000 data_batch_2,  Train_loss : 5283.5054  Test_loss : 5126.3276, Time/batch_file : 2.2688, Training time: 7239.3172\n",
      "Epoch : 623/2000 data_batch_3,  Train_loss : 5550.6851  Test_loss : 5319.7178, Time/batch_file : 2.2745, Training time: 7241.5919\n",
      "Epoch : 623/2000 data_batch_4,  Train_loss : 5688.8672  Test_loss : 5570.6436, Time/batch_file : 2.2833, Training time: 7243.8753\n",
      "Epoch : 623/2000 data_batch_5,  Train_loss : 5738.1646  Test_loss : 5656.5205, Time/batch_file : 2.2767, Training time: 7246.1522\n",
      "Epoch : 624/2000 data_batch_1,  Train_loss : 5254.5425  Test_loss : 5789.6968, Time/batch_file : 2.2981, Training time: 7248.4505\n",
      "Epoch : 624/2000 data_batch_2,  Train_loss : 5283.1875  Test_loss : 5879.6460, Time/batch_file : 2.3125, Training time: 7250.7632\n",
      "Epoch : 624/2000 data_batch_3,  Train_loss : 5140.7959  Test_loss : 5284.2666, Time/batch_file : 2.2876, Training time: 7253.0511\n",
      "Epoch : 624/2000 data_batch_4,  Train_loss : 5125.7007  Test_loss : 6037.0898, Time/batch_file : 2.2854, Training time: 7255.3366\n",
      "Epoch : 624/2000 data_batch_5,  Train_loss : 5114.7363  Test_loss : 5986.6367, Time/batch_file : 2.3114, Training time: 7257.6482\n",
      "Epoch : 625/2000 data_batch_1,  Train_loss : 5183.9043  Test_loss : 5789.8110, Time/batch_file : 2.2999, Training time: 7259.9484\n",
      "Epoch : 625/2000 data_batch_2,  Train_loss : 5265.8896  Test_loss : 5473.5439, Time/batch_file : 2.2915, Training time: 7262.2402\n",
      "Epoch : 625/2000 data_batch_3,  Train_loss : 5443.5757  Test_loss : 5625.1592, Time/batch_file : 2.2790, Training time: 7264.5194\n",
      "Epoch : 625/2000 data_batch_4,  Train_loss : 5203.3428  Test_loss : 5378.3423, Time/batch_file : 2.2804, Training time: 7266.7999\n",
      "Epoch : 625/2000 data_batch_5,  Train_loss : 5279.4458  Test_loss : 5558.4736, Time/batch_file : 2.2827, Training time: 7269.0829\n",
      "Epoch : 626/2000 data_batch_1,  Train_loss : 5632.3745  Test_loss : 4814.4375, Time/batch_file : 2.2862, Training time: 7271.3692\n",
      "Epoch : 626/2000 data_batch_2,  Train_loss : 5700.1289  Test_loss : 4768.1240, Time/batch_file : 2.2903, Training time: 7273.6604\n",
      "Epoch : 626/2000 data_batch_3,  Train_loss : 5681.1611  Test_loss : 4657.2412, Time/batch_file : 2.2789, Training time: 7275.9395\n",
      "Epoch : 626/2000 data_batch_4,  Train_loss : 5636.6025  Test_loss : 5064.0850, Time/batch_file : 2.3015, Training time: 7278.2412\n",
      "Epoch : 626/2000 data_batch_5,  Train_loss : 5038.6055  Test_loss : 5031.1265, Time/batch_file : 2.2805, Training time: 7280.5218\n",
      "Epoch : 627/2000 data_batch_1,  Train_loss : 5601.8237  Test_loss : 5122.1533, Time/batch_file : 2.2912, Training time: 7282.8133\n",
      "Epoch : 627/2000 data_batch_2,  Train_loss : 5481.4502  Test_loss : 4976.0381, Time/batch_file : 2.2967, Training time: 7285.1103\n",
      "Epoch : 627/2000 data_batch_3,  Train_loss : 5565.8672  Test_loss : 5201.2319, Time/batch_file : 2.2896, Training time: 7287.4001\n",
      "Epoch : 627/2000 data_batch_4,  Train_loss : 5359.9160  Test_loss : 5507.3203, Time/batch_file : 2.2782, Training time: 7289.6785\n",
      "Epoch : 627/2000 data_batch_5,  Train_loss : 5175.0830  Test_loss : 5196.6621, Time/batch_file : 2.2866, Training time: 7291.9653\n",
      "Epoch : 628/2000 data_batch_1,  Train_loss : 5417.9893  Test_loss : 4996.9238, Time/batch_file : 2.2727, Training time: 7294.2382\n",
      "Epoch : 628/2000 data_batch_2,  Train_loss : 5559.6226  Test_loss : 4951.6245, Time/batch_file : 2.2815, Training time: 7296.5198\n",
      "Epoch : 628/2000 data_batch_3,  Train_loss : 5541.4658  Test_loss : 4943.9331, Time/batch_file : 2.2798, Training time: 7298.7998\n",
      "Epoch : 628/2000 data_batch_4,  Train_loss : 5524.6128  Test_loss : 5026.8833, Time/batch_file : 2.2781, Training time: 7301.0781\n",
      "Epoch : 628/2000 data_batch_5,  Train_loss : 5114.2451  Test_loss : 4910.8066, Time/batch_file : 2.2702, Training time: 7303.3485\n",
      "Epoch : 629/2000 data_batch_1,  Train_loss : 4947.2568  Test_loss : 5413.2500, Time/batch_file : 2.2752, Training time: 7305.6240\n",
      "Epoch : 629/2000 data_batch_2,  Train_loss : 5113.4595  Test_loss : 5446.2607, Time/batch_file : 2.2808, Training time: 7307.9048\n",
      "Epoch : 629/2000 data_batch_3,  Train_loss : 4873.1299  Test_loss : 5013.2744, Time/batch_file : 2.2732, Training time: 7310.1782\n",
      "Epoch : 629/2000 data_batch_4,  Train_loss : 4794.0986  Test_loss : 5322.7197, Time/batch_file : 2.2758, Training time: 7312.4543\n",
      "Epoch : 629/2000 data_batch_5,  Train_loss : 4870.1611  Test_loss : 5120.6953, Time/batch_file : 2.2919, Training time: 7314.7464\n",
      "Epoch : 630/2000 data_batch_1,  Train_loss : 5270.5112  Test_loss : 5117.9614, Time/batch_file : 2.3025, Training time: 7317.0491\n",
      "Epoch : 630/2000 data_batch_2,  Train_loss : 5650.7290  Test_loss : 4718.6719, Time/batch_file : 2.3164, Training time: 7319.3657\n",
      "Epoch : 630/2000 data_batch_3,  Train_loss : 5373.0732  Test_loss : 4884.2651, Time/batch_file : 2.3007, Training time: 7321.6666\n",
      "Epoch : 630/2000 data_batch_4,  Train_loss : 5265.0913  Test_loss : 4818.7593, Time/batch_file : 2.2845, Training time: 7323.9513\n",
      "Epoch : 630/2000 data_batch_5,  Train_loss : 5088.2051  Test_loss : 5119.6621, Time/batch_file : 2.3076, Training time: 7326.2590\n",
      "[./nets/net-630.ckpt] SAVED\n",
      "Epoch : 631/2000 data_batch_1,  Train_loss : 5443.4683  Test_loss : 5803.9365, Time/batch_file : 2.2987, Training time: 7329.8469\n",
      "Epoch : 631/2000 data_batch_2,  Train_loss : 5350.0654  Test_loss : 5858.0166, Time/batch_file : 2.2849, Training time: 7332.1320\n",
      "Epoch : 631/2000 data_batch_3,  Train_loss : 5283.3647  Test_loss : 5470.8760, Time/batch_file : 2.2631, Training time: 7334.3953\n",
      "Epoch : 631/2000 data_batch_4,  Train_loss : 5234.6748  Test_loss : 5329.1509, Time/batch_file : 2.2770, Training time: 7336.6725\n",
      "Epoch : 631/2000 data_batch_5,  Train_loss : 5245.2285  Test_loss : 5852.4233, Time/batch_file : 2.2813, Training time: 7338.9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 632/2000 data_batch_1,  Train_loss : 5213.0063  Test_loss : 5357.1177, Time/batch_file : 2.2686, Training time: 7341.2229\n",
      "Epoch : 632/2000 data_batch_2,  Train_loss : 5124.9463  Test_loss : 5371.1094, Time/batch_file : 2.2840, Training time: 7343.5071\n",
      "Epoch : 632/2000 data_batch_3,  Train_loss : 5175.0596  Test_loss : 5348.8779, Time/batch_file : 2.3043, Training time: 7345.8116\n",
      "Epoch : 632/2000 data_batch_4,  Train_loss : 5074.9141  Test_loss : 5358.9199, Time/batch_file : 2.2554, Training time: 7348.0672\n",
      "Epoch : 632/2000 data_batch_5,  Train_loss : 5145.6650  Test_loss : 5713.1519, Time/batch_file : 2.2846, Training time: 7350.3520\n",
      "Epoch : 633/2000 data_batch_1,  Train_loss : 4834.1182  Test_loss : 5291.3120, Time/batch_file : 2.2827, Training time: 7352.6349\n",
      "Epoch : 633/2000 data_batch_2,  Train_loss : 4850.3086  Test_loss : 5460.9375, Time/batch_file : 2.2614, Training time: 7354.8965\n",
      "Epoch : 633/2000 data_batch_3,  Train_loss : 4785.5684  Test_loss : 5446.2241, Time/batch_file : 2.2703, Training time: 7357.1671\n",
      "Epoch : 633/2000 data_batch_4,  Train_loss : 4935.0742  Test_loss : 5195.5728, Time/batch_file : 2.2860, Training time: 7359.4533\n",
      "Epoch : 633/2000 data_batch_5,  Train_loss : 4710.6914  Test_loss : 5407.0527, Time/batch_file : 2.2560, Training time: 7361.7094\n",
      "Epoch : 634/2000 data_batch_1,  Train_loss : 5143.5615  Test_loss : 5171.3867, Time/batch_file : 2.2941, Training time: 7364.0038\n",
      "Epoch : 634/2000 data_batch_2,  Train_loss : 5343.6133  Test_loss : 5620.7988, Time/batch_file : 2.2927, Training time: 7366.2966\n",
      "Epoch : 634/2000 data_batch_3,  Train_loss : 4886.3027  Test_loss : 5601.3457, Time/batch_file : 2.2766, Training time: 7368.5734\n",
      "Epoch : 634/2000 data_batch_4,  Train_loss : 5018.8569  Test_loss : 5545.4214, Time/batch_file : 2.2891, Training time: 7370.8628\n",
      "Epoch : 634/2000 data_batch_5,  Train_loss : 5228.5557  Test_loss : 5501.4980, Time/batch_file : 2.3066, Training time: 7373.1695\n",
      "Epoch : 635/2000 data_batch_1,  Train_loss : 4807.0225  Test_loss : 5711.4844, Time/batch_file : 2.2828, Training time: 7375.4525\n",
      "Epoch : 635/2000 data_batch_2,  Train_loss : 5081.9482  Test_loss : 5607.9414, Time/batch_file : 2.3108, Training time: 7377.7636\n",
      "Epoch : 635/2000 data_batch_3,  Train_loss : 5336.1787  Test_loss : 5654.7666, Time/batch_file : 2.2854, Training time: 7380.0494\n",
      "Epoch : 635/2000 data_batch_4,  Train_loss : 5422.2324  Test_loss : 5686.5874, Time/batch_file : 2.2834, Training time: 7382.3330\n",
      "Epoch : 635/2000 data_batch_5,  Train_loss : 4656.9238  Test_loss : 5641.8633, Time/batch_file : 2.2879, Training time: 7384.6211\n",
      "Epoch : 636/2000 data_batch_1,  Train_loss : 5208.7275  Test_loss : 5341.2832, Time/batch_file : 2.3037, Training time: 7386.9249\n",
      "Epoch : 636/2000 data_batch_2,  Train_loss : 5170.6841  Test_loss : 5004.3438, Time/batch_file : 2.2677, Training time: 7389.1928\n",
      "Epoch : 636/2000 data_batch_3,  Train_loss : 5156.7246  Test_loss : 5400.3784, Time/batch_file : 2.2804, Training time: 7391.4734\n",
      "Epoch : 636/2000 data_batch_4,  Train_loss : 5010.4893  Test_loss : 5301.3398, Time/batch_file : 2.2795, Training time: 7393.7532\n",
      "Epoch : 636/2000 data_batch_5,  Train_loss : 5322.7104  Test_loss : 5257.1958, Time/batch_file : 2.2699, Training time: 7396.0232\n",
      "Epoch : 637/2000 data_batch_1,  Train_loss : 4927.7793  Test_loss : 5560.9873, Time/batch_file : 2.2976, Training time: 7398.3211\n",
      "Epoch : 637/2000 data_batch_2,  Train_loss : 5103.5200  Test_loss : 5388.5908, Time/batch_file : 2.3080, Training time: 7400.6293\n",
      "Epoch : 637/2000 data_batch_3,  Train_loss : 5040.2314  Test_loss : 5265.7031, Time/batch_file : 2.2705, Training time: 7402.9000\n",
      "Epoch : 637/2000 data_batch_4,  Train_loss : 5137.7251  Test_loss : 5381.2920, Time/batch_file : 2.2962, Training time: 7405.1965\n",
      "Epoch : 637/2000 data_batch_5,  Train_loss : 5118.9365  Test_loss : 5112.4302, Time/batch_file : 2.2875, Training time: 7407.4842\n",
      "Epoch : 638/2000 data_batch_1,  Train_loss : 5123.7632  Test_loss : 5722.2666, Time/batch_file : 2.2791, Training time: 7409.7636\n",
      "Epoch : 638/2000 data_batch_2,  Train_loss : 5132.1831  Test_loss : 5662.1562, Time/batch_file : 2.2861, Training time: 7412.0497\n",
      "Epoch : 638/2000 data_batch_3,  Train_loss : 4985.9453  Test_loss : 5635.1567, Time/batch_file : 2.3030, Training time: 7414.3529\n",
      "Epoch : 638/2000 data_batch_4,  Train_loss : 5061.9731  Test_loss : 5866.0918, Time/batch_file : 2.2628, Training time: 7416.6160\n",
      "Epoch : 638/2000 data_batch_5,  Train_loss : 4894.6035  Test_loss : 5690.7373, Time/batch_file : 2.2961, Training time: 7418.9123\n",
      "Epoch : 639/2000 data_batch_1,  Train_loss : 4933.1997  Test_loss : 5154.7012, Time/batch_file : 2.2957, Training time: 7421.2083\n",
      "Epoch : 639/2000 data_batch_2,  Train_loss : 5147.6704  Test_loss : 4742.3750, Time/batch_file : 2.2760, Training time: 7423.4845\n",
      "Epoch : 639/2000 data_batch_3,  Train_loss : 4858.6611  Test_loss : 4660.2070, Time/batch_file : 2.2893, Training time: 7425.7741\n",
      "Epoch : 639/2000 data_batch_4,  Train_loss : 5134.3823  Test_loss : 5145.2588, Time/batch_file : 2.3141, Training time: 7428.0883\n",
      "Epoch : 639/2000 data_batch_5,  Train_loss : 4813.1191  Test_loss : 4716.1201, Time/batch_file : 2.2671, Training time: 7430.3556\n",
      "Epoch : 640/2000 data_batch_1,  Train_loss : 5426.5547  Test_loss : 4381.0137, Time/batch_file : 2.2834, Training time: 7432.6392\n",
      "Epoch : 640/2000 data_batch_2,  Train_loss : 5306.9912  Test_loss : 4497.2310, Time/batch_file : 2.2786, Training time: 7434.9179\n",
      "Epoch : 640/2000 data_batch_3,  Train_loss : 5427.8057  Test_loss : 4531.4028, Time/batch_file : 2.2692, Training time: 7437.1873\n",
      "Epoch : 640/2000 data_batch_4,  Train_loss : 4955.4644  Test_loss : 4744.0942, Time/batch_file : 2.2746, Training time: 7439.4621\n",
      "Epoch : 640/2000 data_batch_5,  Train_loss : 5213.0112  Test_loss : 4563.8760, Time/batch_file : 2.3004, Training time: 7441.7627\n",
      "[./nets/net-640.ckpt] SAVED\n",
      "Epoch : 641/2000 data_batch_1,  Train_loss : 4705.3086  Test_loss : 6148.4639, Time/batch_file : 2.3135, Training time: 7445.3631\n",
      "Epoch : 641/2000 data_batch_2,  Train_loss : 4666.3413  Test_loss : 6053.7505, Time/batch_file : 2.2887, Training time: 7447.6519\n",
      "Epoch : 641/2000 data_batch_3,  Train_loss : 4920.0283  Test_loss : 6039.6348, Time/batch_file : 2.2991, Training time: 7449.9511\n",
      "Epoch : 641/2000 data_batch_4,  Train_loss : 4573.3242  Test_loss : 6113.3242, Time/batch_file : 2.2784, Training time: 7452.2297\n",
      "Epoch : 641/2000 data_batch_5,  Train_loss : 4660.3477  Test_loss : 5717.7744, Time/batch_file : 2.2827, Training time: 7454.5126\n",
      "Epoch : 642/2000 data_batch_1,  Train_loss : 5623.8789  Test_loss : 5139.8926, Time/batch_file : 2.2829, Training time: 7456.7957\n",
      "Epoch : 642/2000 data_batch_2,  Train_loss : 5118.1084  Test_loss : 4521.9639, Time/batch_file : 2.2730, Training time: 7459.0689\n",
      "Epoch : 642/2000 data_batch_3,  Train_loss : 5195.0859  Test_loss : 5091.1133, Time/batch_file : 2.2773, Training time: 7461.3464\n",
      "Epoch : 642/2000 data_batch_4,  Train_loss : 5329.6768  Test_loss : 5109.8110, Time/batch_file : 2.2744, Training time: 7463.6211\n",
      "Epoch : 642/2000 data_batch_5,  Train_loss : 5222.8047  Test_loss : 4828.4316, Time/batch_file : 2.2750, Training time: 7465.8963\n",
      "Epoch : 643/2000 data_batch_1,  Train_loss : 5222.3574  Test_loss : 5413.0811, Time/batch_file : 2.2785, Training time: 7468.1750\n",
      "Epoch : 643/2000 data_batch_2,  Train_loss : 5438.6914  Test_loss : 5547.7231, Time/batch_file : 2.2760, Training time: 7470.4512\n",
      "Epoch : 643/2000 data_batch_3,  Train_loss : 5468.9092  Test_loss : 5329.3042, Time/batch_file : 2.2838, Training time: 7472.7353\n",
      "Epoch : 643/2000 data_batch_4,  Train_loss : 5318.8843  Test_loss : 5062.0156, Time/batch_file : 2.2980, Training time: 7475.0336\n",
      "Epoch : 643/2000 data_batch_5,  Train_loss : 5436.1816  Test_loss : 5615.9937, Time/batch_file : 2.2788, Training time: 7477.3126\n",
      "Epoch : 644/2000 data_batch_1,  Train_loss : 4543.8193  Test_loss : 4935.7646, Time/batch_file : 2.2818, Training time: 7479.5945\n",
      "Epoch : 644/2000 data_batch_2,  Train_loss : 4608.0723  Test_loss : 5198.3208, Time/batch_file : 2.2856, Training time: 7481.8804\n",
      "Epoch : 644/2000 data_batch_3,  Train_loss : 4365.9502  Test_loss : 4899.4170, Time/batch_file : 2.2966, Training time: 7484.1771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 644/2000 data_batch_4,  Train_loss : 4868.9702  Test_loss : 5068.4697, Time/batch_file : 2.2804, Training time: 7486.4578\n",
      "Epoch : 644/2000 data_batch_5,  Train_loss : 4906.9229  Test_loss : 4999.5078, Time/batch_file : 2.2886, Training time: 7488.7465\n",
      "Epoch : 645/2000 data_batch_1,  Train_loss : 4597.4102  Test_loss : 5590.2559, Time/batch_file : 2.2792, Training time: 7491.0260\n",
      "Epoch : 645/2000 data_batch_2,  Train_loss : 4930.5059  Test_loss : 5032.6562, Time/batch_file : 2.2704, Training time: 7493.2967\n",
      "Epoch : 645/2000 data_batch_3,  Train_loss : 4604.6445  Test_loss : 5232.5713, Time/batch_file : 2.2685, Training time: 7495.5654\n",
      "Epoch : 645/2000 data_batch_4,  Train_loss : 4684.8623  Test_loss : 5301.6558, Time/batch_file : 2.2932, Training time: 7497.8590\n",
      "Epoch : 645/2000 data_batch_5,  Train_loss : 4847.8867  Test_loss : 5211.9219, Time/batch_file : 2.2743, Training time: 7500.1335\n",
      "Epoch : 646/2000 data_batch_1,  Train_loss : 5496.9224  Test_loss : 5203.8584, Time/batch_file : 2.2928, Training time: 7502.4265\n",
      "Epoch : 646/2000 data_batch_2,  Train_loss : 5532.5073  Test_loss : 5094.6533, Time/batch_file : 2.2955, Training time: 7504.7221\n",
      "Epoch : 646/2000 data_batch_3,  Train_loss : 5666.2202  Test_loss : 5034.7319, Time/batch_file : 2.2933, Training time: 7507.0157\n",
      "Epoch : 646/2000 data_batch_4,  Train_loss : 5521.5449  Test_loss : 5170.7856, Time/batch_file : 2.2843, Training time: 7509.3002\n",
      "Epoch : 646/2000 data_batch_5,  Train_loss : 5454.6538  Test_loss : 5023.3569, Time/batch_file : 2.2853, Training time: 7511.5857\n",
      "Epoch : 647/2000 data_batch_1,  Train_loss : 4829.1587  Test_loss : 5236.4980, Time/batch_file : 2.2730, Training time: 7513.8589\n",
      "Epoch : 647/2000 data_batch_2,  Train_loss : 4967.8169  Test_loss : 5511.8174, Time/batch_file : 2.2744, Training time: 7516.1335\n",
      "Epoch : 647/2000 data_batch_3,  Train_loss : 4797.3896  Test_loss : 5539.3633, Time/batch_file : 2.2733, Training time: 7518.4069\n",
      "Epoch : 647/2000 data_batch_4,  Train_loss : 4722.9873  Test_loss : 5282.5024, Time/batch_file : 2.3046, Training time: 7520.7117\n",
      "Epoch : 647/2000 data_batch_5,  Train_loss : 4709.0127  Test_loss : 5489.1216, Time/batch_file : 2.3111, Training time: 7523.0231\n",
      "Epoch : 648/2000 data_batch_1,  Train_loss : 4930.7793  Test_loss : 5213.3164, Time/batch_file : 2.2859, Training time: 7525.3092\n",
      "Epoch : 648/2000 data_batch_2,  Train_loss : 5055.9883  Test_loss : 5079.6328, Time/batch_file : 2.2721, Training time: 7527.5815\n",
      "Epoch : 648/2000 data_batch_3,  Train_loss : 4707.6021  Test_loss : 5190.5967, Time/batch_file : 2.2743, Training time: 7529.8561\n",
      "Epoch : 648/2000 data_batch_4,  Train_loss : 5033.8442  Test_loss : 5282.8545, Time/batch_file : 2.2727, Training time: 7532.1290\n",
      "Epoch : 648/2000 data_batch_5,  Train_loss : 5227.3677  Test_loss : 5209.0693, Time/batch_file : 2.2886, Training time: 7534.4179\n",
      "Epoch : 649/2000 data_batch_1,  Train_loss : 5153.1387  Test_loss : 5802.3657, Time/batch_file : 2.2751, Training time: 7536.6931\n",
      "Epoch : 649/2000 data_batch_2,  Train_loss : 5177.3281  Test_loss : 5544.3345, Time/batch_file : 2.2752, Training time: 7538.9684\n",
      "Epoch : 649/2000 data_batch_3,  Train_loss : 5107.9170  Test_loss : 5434.1523, Time/batch_file : 2.2748, Training time: 7541.2434\n",
      "Epoch : 649/2000 data_batch_4,  Train_loss : 4950.9111  Test_loss : 5750.9551, Time/batch_file : 2.2696, Training time: 7543.5132\n",
      "Epoch : 649/2000 data_batch_5,  Train_loss : 5015.6416  Test_loss : 5762.5439, Time/batch_file : 2.2680, Training time: 7545.7815\n",
      "Epoch : 650/2000 data_batch_1,  Train_loss : 5065.6074  Test_loss : 5700.0137, Time/batch_file : 2.2612, Training time: 7548.0430\n",
      "Epoch : 650/2000 data_batch_2,  Train_loss : 5074.4277  Test_loss : 6035.0254, Time/batch_file : 2.2620, Training time: 7550.3051\n",
      "Epoch : 650/2000 data_batch_3,  Train_loss : 5282.9512  Test_loss : 5907.6953, Time/batch_file : 2.2701, Training time: 7552.5755\n",
      "Epoch : 650/2000 data_batch_4,  Train_loss : 5383.3530  Test_loss : 5856.5605, Time/batch_file : 2.2642, Training time: 7554.8398\n",
      "Epoch : 650/2000 data_batch_5,  Train_loss : 5009.3013  Test_loss : 5825.1758, Time/batch_file : 2.2710, Training time: 7557.1110\n",
      "[./nets/net-650.ckpt] SAVED\n",
      "Epoch : 651/2000 data_batch_1,  Train_loss : 5063.0928  Test_loss : 6021.4912, Time/batch_file : 2.2914, Training time: 7560.6780\n",
      "Epoch : 651/2000 data_batch_2,  Train_loss : 5182.7300  Test_loss : 5800.8447, Time/batch_file : 2.2834, Training time: 7562.9615\n",
      "Epoch : 651/2000 data_batch_3,  Train_loss : 5003.8813  Test_loss : 5955.1504, Time/batch_file : 2.2700, Training time: 7565.2317\n",
      "Epoch : 651/2000 data_batch_4,  Train_loss : 5075.0801  Test_loss : 5850.0332, Time/batch_file : 2.2914, Training time: 7567.5233\n",
      "Epoch : 651/2000 data_batch_5,  Train_loss : 5254.2427  Test_loss : 5678.2012, Time/batch_file : 2.2925, Training time: 7569.8160\n",
      "Epoch : 652/2000 data_batch_1,  Train_loss : 5600.1406  Test_loss : 5919.1211, Time/batch_file : 2.2803, Training time: 7572.0965\n",
      "Epoch : 652/2000 data_batch_2,  Train_loss : 5503.8828  Test_loss : 5749.7930, Time/batch_file : 2.2872, Training time: 7574.3839\n",
      "Epoch : 652/2000 data_batch_3,  Train_loss : 5249.6084  Test_loss : 5240.2622, Time/batch_file : 2.2782, Training time: 7576.6622\n",
      "Epoch : 652/2000 data_batch_4,  Train_loss : 5634.2427  Test_loss : 5526.6548, Time/batch_file : 2.2885, Training time: 7578.9509\n",
      "Epoch : 652/2000 data_batch_5,  Train_loss : 5266.2422  Test_loss : 5333.4600, Time/batch_file : 2.2646, Training time: 7581.2157\n",
      "Epoch : 653/2000 data_batch_1,  Train_loss : 4836.1543  Test_loss : 5411.0200, Time/batch_file : 2.2891, Training time: 7583.5051\n",
      "Epoch : 653/2000 data_batch_2,  Train_loss : 5077.1416  Test_loss : 5144.5859, Time/batch_file : 2.2750, Training time: 7585.7802\n",
      "Epoch : 653/2000 data_batch_3,  Train_loss : 4976.7861  Test_loss : 5326.0444, Time/batch_file : 2.2801, Training time: 7588.0605\n",
      "Epoch : 653/2000 data_batch_4,  Train_loss : 5119.6802  Test_loss : 5742.6724, Time/batch_file : 2.2917, Training time: 7590.3525\n",
      "Epoch : 653/2000 data_batch_5,  Train_loss : 5033.9761  Test_loss : 5234.1030, Time/batch_file : 2.2778, Training time: 7592.6305\n",
      "Epoch : 654/2000 data_batch_1,  Train_loss : 4870.7271  Test_loss : 5682.5376, Time/batch_file : 2.3219, Training time: 7594.9526\n",
      "Epoch : 654/2000 data_batch_2,  Train_loss : 4923.3623  Test_loss : 5926.9668, Time/batch_file : 2.2881, Training time: 7597.2409\n",
      "Epoch : 654/2000 data_batch_3,  Train_loss : 5034.7432  Test_loss : 5920.3838, Time/batch_file : 2.3243, Training time: 7599.5653\n",
      "Epoch : 654/2000 data_batch_4,  Train_loss : 5186.6021  Test_loss : 5633.4209, Time/batch_file : 2.3162, Training time: 7601.8816\n",
      "Epoch : 654/2000 data_batch_5,  Train_loss : 5299.4600  Test_loss : 5600.8975, Time/batch_file : 2.2992, Training time: 7604.1810\n",
      "Epoch : 655/2000 data_batch_1,  Train_loss : 4913.5962  Test_loss : 5057.2227, Time/batch_file : 2.2762, Training time: 7606.4575\n",
      "Epoch : 655/2000 data_batch_2,  Train_loss : 4841.6929  Test_loss : 5194.2432, Time/batch_file : 2.2780, Training time: 7608.7357\n",
      "Epoch : 655/2000 data_batch_3,  Train_loss : 4918.4912  Test_loss : 5278.1631, Time/batch_file : 2.3021, Training time: 7611.0380\n",
      "Epoch : 655/2000 data_batch_4,  Train_loss : 5157.4863  Test_loss : 5476.5396, Time/batch_file : 2.2981, Training time: 7613.3364\n",
      "Epoch : 655/2000 data_batch_5,  Train_loss : 4876.1484  Test_loss : 5285.7876, Time/batch_file : 2.2788, Training time: 7615.6155\n",
      "Epoch : 656/2000 data_batch_1,  Train_loss : 5352.5376  Test_loss : 5934.9697, Time/batch_file : 2.2967, Training time: 7617.9124\n",
      "Epoch : 656/2000 data_batch_2,  Train_loss : 5032.7778  Test_loss : 5702.0425, Time/batch_file : 2.2735, Training time: 7620.1862\n",
      "Epoch : 656/2000 data_batch_3,  Train_loss : 5204.2285  Test_loss : 5619.7920, Time/batch_file : 2.3081, Training time: 7622.4945\n",
      "Epoch : 656/2000 data_batch_4,  Train_loss : 5126.7617  Test_loss : 5742.3633, Time/batch_file : 2.2923, Training time: 7624.7871\n",
      "Epoch : 656/2000 data_batch_5,  Train_loss : 5127.4502  Test_loss : 5664.9409, Time/batch_file : 2.2989, Training time: 7627.0862\n",
      "Epoch : 657/2000 data_batch_1,  Train_loss : 5305.8770  Test_loss : 6152.3594, Time/batch_file : 2.2909, Training time: 7629.3773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 657/2000 data_batch_2,  Train_loss : 5192.7373  Test_loss : 5704.6094, Time/batch_file : 2.2827, Training time: 7631.6602\n",
      "Epoch : 657/2000 data_batch_3,  Train_loss : 5253.4658  Test_loss : 5870.1055, Time/batch_file : 2.2912, Training time: 7633.9515\n",
      "Epoch : 657/2000 data_batch_4,  Train_loss : 5242.9380  Test_loss : 5613.0557, Time/batch_file : 2.2833, Training time: 7636.2350\n",
      "Epoch : 657/2000 data_batch_5,  Train_loss : 5283.6558  Test_loss : 5894.3716, Time/batch_file : 2.2900, Training time: 7638.5252\n",
      "Epoch : 658/2000 data_batch_1,  Train_loss : 5347.1484  Test_loss : 5557.5322, Time/batch_file : 2.3018, Training time: 7640.8273\n",
      "Epoch : 658/2000 data_batch_2,  Train_loss : 5326.4805  Test_loss : 5709.9702, Time/batch_file : 2.2863, Training time: 7643.1138\n",
      "Epoch : 658/2000 data_batch_3,  Train_loss : 4941.4707  Test_loss : 5944.7334, Time/batch_file : 2.3012, Training time: 7645.4153\n",
      "Epoch : 658/2000 data_batch_4,  Train_loss : 5256.0264  Test_loss : 5711.9365, Time/batch_file : 2.2958, Training time: 7647.7112\n",
      "Epoch : 658/2000 data_batch_5,  Train_loss : 5069.9121  Test_loss : 5563.0747, Time/batch_file : 2.3292, Training time: 7650.0406\n",
      "Epoch : 659/2000 data_batch_1,  Train_loss : 5263.1255  Test_loss : 5548.3047, Time/batch_file : 2.2696, Training time: 7652.3105\n",
      "Epoch : 659/2000 data_batch_2,  Train_loss : 4957.0586  Test_loss : 5528.6572, Time/batch_file : 2.2825, Training time: 7654.5932\n",
      "Epoch : 659/2000 data_batch_3,  Train_loss : 5214.9014  Test_loss : 5802.9111, Time/batch_file : 2.2892, Training time: 7656.8826\n",
      "Epoch : 659/2000 data_batch_4,  Train_loss : 5246.5562  Test_loss : 5525.5034, Time/batch_file : 2.2850, Training time: 7659.1677\n",
      "Epoch : 659/2000 data_batch_5,  Train_loss : 5547.1079  Test_loss : 5534.1064, Time/batch_file : 2.3016, Training time: 7661.4694\n",
      "Epoch : 660/2000 data_batch_1,  Train_loss : 4996.6836  Test_loss : 5155.7930, Time/batch_file : 2.2649, Training time: 7663.7345\n",
      "Epoch : 660/2000 data_batch_2,  Train_loss : 5238.7144  Test_loss : 5489.8838, Time/batch_file : 2.2888, Training time: 7666.0236\n",
      "Epoch : 660/2000 data_batch_3,  Train_loss : 5211.9883  Test_loss : 5404.4458, Time/batch_file : 2.2805, Training time: 7668.3043\n",
      "Epoch : 660/2000 data_batch_4,  Train_loss : 5171.0439  Test_loss : 5310.6313, Time/batch_file : 2.2620, Training time: 7670.5665\n",
      "Epoch : 660/2000 data_batch_5,  Train_loss : 5385.1230  Test_loss : 5160.2041, Time/batch_file : 2.2754, Training time: 7672.8421\n",
      "[./nets/net-660.ckpt] SAVED\n",
      "Epoch : 661/2000 data_batch_1,  Train_loss : 5063.5391  Test_loss : 5317.1611, Time/batch_file : 2.2869, Training time: 7676.4097\n",
      "Epoch : 661/2000 data_batch_2,  Train_loss : 4987.0713  Test_loss : 5609.3076, Time/batch_file : 2.2819, Training time: 7678.6918\n",
      "Epoch : 661/2000 data_batch_3,  Train_loss : 4999.5698  Test_loss : 5513.0161, Time/batch_file : 2.2803, Training time: 7680.9722\n",
      "Epoch : 661/2000 data_batch_4,  Train_loss : 4799.8862  Test_loss : 5293.9434, Time/batch_file : 2.2640, Training time: 7683.2363\n",
      "Epoch : 661/2000 data_batch_5,  Train_loss : 4824.9839  Test_loss : 5427.8345, Time/batch_file : 2.2661, Training time: 7685.5026\n",
      "Epoch : 662/2000 data_batch_1,  Train_loss : 5296.3320  Test_loss : 5216.8081, Time/batch_file : 2.2896, Training time: 7687.7923\n",
      "Epoch : 662/2000 data_batch_2,  Train_loss : 5078.9531  Test_loss : 4918.6045, Time/batch_file : 2.2609, Training time: 7690.0534\n",
      "Epoch : 662/2000 data_batch_3,  Train_loss : 5364.3633  Test_loss : 5046.3257, Time/batch_file : 2.2805, Training time: 7692.3340\n",
      "Epoch : 662/2000 data_batch_4,  Train_loss : 5285.5854  Test_loss : 5209.7148, Time/batch_file : 2.2582, Training time: 7694.5924\n",
      "Epoch : 662/2000 data_batch_5,  Train_loss : 5310.2422  Test_loss : 5129.3076, Time/batch_file : 2.2727, Training time: 7696.8654\n",
      "Epoch : 663/2000 data_batch_1,  Train_loss : 5272.8652  Test_loss : 5210.9761, Time/batch_file : 2.2535, Training time: 7699.1192\n",
      "Epoch : 663/2000 data_batch_2,  Train_loss : 5106.3721  Test_loss : 5044.6885, Time/batch_file : 2.2853, Training time: 7701.4046\n",
      "Epoch : 663/2000 data_batch_3,  Train_loss : 4907.8516  Test_loss : 5408.8369, Time/batch_file : 2.2598, Training time: 7703.6646\n",
      "Epoch : 663/2000 data_batch_4,  Train_loss : 4905.7871  Test_loss : 5085.6655, Time/batch_file : 2.2755, Training time: 7705.9403\n",
      "Epoch : 663/2000 data_batch_5,  Train_loss : 5155.6963  Test_loss : 5075.2363, Time/batch_file : 2.2648, Training time: 7708.2055\n",
      "Epoch : 664/2000 data_batch_1,  Train_loss : 5161.1011  Test_loss : 5533.3989, Time/batch_file : 2.2717, Training time: 7710.4774\n",
      "Epoch : 664/2000 data_batch_2,  Train_loss : 5127.3813  Test_loss : 5478.1440, Time/batch_file : 2.2565, Training time: 7712.7342\n",
      "Epoch : 664/2000 data_batch_3,  Train_loss : 5261.7861  Test_loss : 5306.3545, Time/batch_file : 2.2846, Training time: 7715.0189\n",
      "Epoch : 664/2000 data_batch_4,  Train_loss : 5251.3066  Test_loss : 5108.0137, Time/batch_file : 2.2553, Training time: 7717.2744\n",
      "Epoch : 664/2000 data_batch_5,  Train_loss : 5160.9619  Test_loss : 5420.4966, Time/batch_file : 2.2767, Training time: 7719.5513\n",
      "Epoch : 665/2000 data_batch_1,  Train_loss : 5083.4590  Test_loss : 5864.1357, Time/batch_file : 2.2613, Training time: 7721.8128\n",
      "Epoch : 665/2000 data_batch_2,  Train_loss : 4997.2842  Test_loss : 5749.4175, Time/batch_file : 2.2912, Training time: 7724.1043\n",
      "Epoch : 665/2000 data_batch_3,  Train_loss : 5388.7578  Test_loss : 5587.3105, Time/batch_file : 2.2625, Training time: 7726.3670\n",
      "Epoch : 665/2000 data_batch_4,  Train_loss : 4912.8521  Test_loss : 5674.0874, Time/batch_file : 2.2777, Training time: 7728.6449\n",
      "Epoch : 665/2000 data_batch_5,  Train_loss : 5114.0640  Test_loss : 5833.2158, Time/batch_file : 2.2590, Training time: 7730.9041\n",
      "Epoch : 666/2000 data_batch_1,  Train_loss : 5136.7158  Test_loss : 5395.4775, Time/batch_file : 2.2628, Training time: 7733.1670\n",
      "Epoch : 666/2000 data_batch_2,  Train_loss : 4899.3828  Test_loss : 5313.1641, Time/batch_file : 2.2585, Training time: 7735.4258\n",
      "Epoch : 666/2000 data_batch_3,  Train_loss : 5082.3550  Test_loss : 5558.0693, Time/batch_file : 2.3007, Training time: 7737.7268\n",
      "Epoch : 666/2000 data_batch_4,  Train_loss : 4848.8760  Test_loss : 5428.0513, Time/batch_file : 2.2572, Training time: 7739.9842\n",
      "Epoch : 666/2000 data_batch_5,  Train_loss : 4810.5293  Test_loss : 5432.2646, Time/batch_file : 2.2682, Training time: 7742.2526\n",
      "Epoch : 667/2000 data_batch_1,  Train_loss : 4910.2300  Test_loss : 4784.8677, Time/batch_file : 2.2608, Training time: 7744.5135\n",
      "Epoch : 667/2000 data_batch_2,  Train_loss : 5205.4556  Test_loss : 5015.7153, Time/batch_file : 2.2763, Training time: 7746.7900\n",
      "Epoch : 667/2000 data_batch_3,  Train_loss : 4888.4297  Test_loss : 4837.5020, Time/batch_file : 2.2670, Training time: 7749.0573\n",
      "Epoch : 667/2000 data_batch_4,  Train_loss : 5099.8330  Test_loss : 5325.4038, Time/batch_file : 2.2644, Training time: 7751.3219\n",
      "Epoch : 667/2000 data_batch_5,  Train_loss : 4970.2793  Test_loss : 4734.4697, Time/batch_file : 2.2686, Training time: 7753.5905\n",
      "Epoch : 668/2000 data_batch_1,  Train_loss : 5359.2573  Test_loss : 5395.9678, Time/batch_file : 2.2695, Training time: 7755.8603\n",
      "Epoch : 668/2000 data_batch_2,  Train_loss : 5045.9282  Test_loss : 5066.0635, Time/batch_file : 2.2591, Training time: 7758.1196\n",
      "Epoch : 668/2000 data_batch_3,  Train_loss : 5322.3911  Test_loss : 5269.7070, Time/batch_file : 2.2694, Training time: 7760.3891\n",
      "Epoch : 668/2000 data_batch_4,  Train_loss : 5410.7759  Test_loss : 5114.8618, Time/batch_file : 2.2578, Training time: 7762.6471\n",
      "Epoch : 668/2000 data_batch_5,  Train_loss : 4974.7490  Test_loss : 5064.4844, Time/batch_file : 2.2746, Training time: 7764.9219\n",
      "Epoch : 669/2000 data_batch_1,  Train_loss : 5238.5156  Test_loss : 5922.0586, Time/batch_file : 2.2601, Training time: 7767.1821\n",
      "Epoch : 669/2000 data_batch_2,  Train_loss : 5133.7646  Test_loss : 5917.7295, Time/batch_file : 2.2683, Training time: 7769.4506\n",
      "Epoch : 669/2000 data_batch_3,  Train_loss : 5379.3545  Test_loss : 5875.3604, Time/batch_file : 2.2684, Training time: 7771.7191\n",
      "Epoch : 669/2000 data_batch_4,  Train_loss : 5233.0615  Test_loss : 5645.6797, Time/batch_file : 2.2899, Training time: 7774.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 669/2000 data_batch_5,  Train_loss : 5140.2686  Test_loss : 5792.3188, Time/batch_file : 2.2588, Training time: 7776.2682\n",
      "Epoch : 670/2000 data_batch_1,  Train_loss : 5498.8760  Test_loss : 5237.7212, Time/batch_file : 2.2813, Training time: 7778.5497\n",
      "Epoch : 670/2000 data_batch_2,  Train_loss : 5449.5449  Test_loss : 5330.4854, Time/batch_file : 2.2603, Training time: 7780.8102\n",
      "Epoch : 670/2000 data_batch_3,  Train_loss : 5156.8701  Test_loss : 5121.7686, Time/batch_file : 2.2894, Training time: 7783.0998\n",
      "Epoch : 670/2000 data_batch_4,  Train_loss : 5433.3032  Test_loss : 5498.4854, Time/batch_file : 2.2701, Training time: 7785.3702\n",
      "Epoch : 670/2000 data_batch_5,  Train_loss : 5214.3877  Test_loss : 5407.8877, Time/batch_file : 2.2832, Training time: 7787.6535\n",
      "[./nets/net-670.ckpt] SAVED\n",
      "Epoch : 671/2000 data_batch_1,  Train_loss : 5436.0742  Test_loss : 5474.7197, Time/batch_file : 2.3173, Training time: 7791.2364\n",
      "Epoch : 671/2000 data_batch_2,  Train_loss : 5715.0869  Test_loss : 5187.0850, Time/batch_file : 2.2769, Training time: 7793.5134\n",
      "Epoch : 671/2000 data_batch_3,  Train_loss : 5746.4009  Test_loss : 5376.4805, Time/batch_file : 2.3064, Training time: 7795.8200\n",
      "Epoch : 671/2000 data_batch_4,  Train_loss : 5646.7983  Test_loss : 5388.4004, Time/batch_file : 2.2908, Training time: 7798.1111\n",
      "Epoch : 671/2000 data_batch_5,  Train_loss : 5530.5620  Test_loss : 5470.0117, Time/batch_file : 2.3097, Training time: 7800.4209\n",
      "Epoch : 672/2000 data_batch_1,  Train_loss : 5695.4307  Test_loss : 5365.9912, Time/batch_file : 2.2718, Training time: 7802.6929\n",
      "Epoch : 672/2000 data_batch_2,  Train_loss : 5771.9600  Test_loss : 5518.1343, Time/batch_file : 2.2906, Training time: 7804.9837\n",
      "Epoch : 672/2000 data_batch_3,  Train_loss : 5630.1885  Test_loss : 5612.8857, Time/batch_file : 2.2967, Training time: 7807.2807\n",
      "Epoch : 672/2000 data_batch_4,  Train_loss : 5699.5332  Test_loss : 5561.4795, Time/batch_file : 2.3009, Training time: 7809.5818\n",
      "Epoch : 672/2000 data_batch_5,  Train_loss : 5257.0449  Test_loss : 5970.2773, Time/batch_file : 2.2963, Training time: 7811.8783\n",
      "Epoch : 673/2000 data_batch_1,  Train_loss : 4875.2803  Test_loss : 5560.2427, Time/batch_file : 2.2687, Training time: 7814.1472\n",
      "Epoch : 673/2000 data_batch_2,  Train_loss : 5277.2134  Test_loss : 6167.3833, Time/batch_file : 2.2736, Training time: 7816.4210\n",
      "Epoch : 673/2000 data_batch_3,  Train_loss : 5038.1572  Test_loss : 5621.7886, Time/batch_file : 2.2586, Training time: 7818.6797\n",
      "Epoch : 673/2000 data_batch_4,  Train_loss : 5014.0972  Test_loss : 5883.1572, Time/batch_file : 2.3037, Training time: 7820.9836\n",
      "Epoch : 673/2000 data_batch_5,  Train_loss : 4687.2490  Test_loss : 6025.6162, Time/batch_file : 2.2963, Training time: 7823.2801\n",
      "Epoch : 674/2000 data_batch_1,  Train_loss : 5526.6963  Test_loss : 4416.7168, Time/batch_file : 2.2631, Training time: 7825.5434\n",
      "Epoch : 674/2000 data_batch_2,  Train_loss : 5545.0400  Test_loss : 4512.3853, Time/batch_file : 2.2754, Training time: 7827.8189\n",
      "Epoch : 674/2000 data_batch_3,  Train_loss : 5433.0439  Test_loss : 4636.8271, Time/batch_file : 2.2698, Training time: 7830.0890\n",
      "Epoch : 674/2000 data_batch_4,  Train_loss : 5405.4258  Test_loss : 4466.6895, Time/batch_file : 2.2977, Training time: 7832.3869\n",
      "Epoch : 674/2000 data_batch_5,  Train_loss : 5307.8159  Test_loss : 4575.1123, Time/batch_file : 2.2797, Training time: 7834.6668\n",
      "Epoch : 675/2000 data_batch_1,  Train_loss : 5036.3872  Test_loss : 5312.4072, Time/batch_file : 2.2880, Training time: 7836.9550\n",
      "Epoch : 675/2000 data_batch_2,  Train_loss : 5186.6538  Test_loss : 5432.6284, Time/batch_file : 2.2763, Training time: 7839.2315\n",
      "Epoch : 675/2000 data_batch_3,  Train_loss : 5154.0259  Test_loss : 5395.2202, Time/batch_file : 2.2719, Training time: 7841.5036\n",
      "Epoch : 675/2000 data_batch_4,  Train_loss : 4896.1777  Test_loss : 5334.8979, Time/batch_file : 2.2963, Training time: 7843.8000\n",
      "Epoch : 675/2000 data_batch_5,  Train_loss : 4897.9150  Test_loss : 5484.7134, Time/batch_file : 2.2668, Training time: 7846.0671\n",
      "Epoch : 676/2000 data_batch_1,  Train_loss : 5328.1870  Test_loss : 5706.8350, Time/batch_file : 2.2852, Training time: 7848.3525\n",
      "Epoch : 676/2000 data_batch_2,  Train_loss : 6052.3135  Test_loss : 5604.9429, Time/batch_file : 2.2859, Training time: 7850.6386\n",
      "Epoch : 676/2000 data_batch_3,  Train_loss : 5572.0117  Test_loss : 5669.8652, Time/batch_file : 2.3028, Training time: 7852.9416\n",
      "Epoch : 676/2000 data_batch_4,  Train_loss : 5712.8047  Test_loss : 5481.5234, Time/batch_file : 2.2826, Training time: 7855.2244\n",
      "Epoch : 676/2000 data_batch_5,  Train_loss : 5433.7979  Test_loss : 5620.8062, Time/batch_file : 2.2984, Training time: 7857.5230\n",
      "Epoch : 677/2000 data_batch_1,  Train_loss : 5090.2754  Test_loss : 5066.6279, Time/batch_file : 2.2760, Training time: 7859.7991\n",
      "Epoch : 677/2000 data_batch_2,  Train_loss : 4944.5190  Test_loss : 5273.0713, Time/batch_file : 2.2652, Training time: 7862.0645\n",
      "Epoch : 677/2000 data_batch_3,  Train_loss : 4954.3711  Test_loss : 5212.4434, Time/batch_file : 2.2989, Training time: 7864.3636\n",
      "Epoch : 677/2000 data_batch_4,  Train_loss : 5179.9619  Test_loss : 5247.7139, Time/batch_file : 2.2840, Training time: 7866.6478\n",
      "Epoch : 677/2000 data_batch_5,  Train_loss : 5023.6899  Test_loss : 5154.2041, Time/batch_file : 2.2953, Training time: 7868.9434\n",
      "Epoch : 678/2000 data_batch_1,  Train_loss : 5231.4033  Test_loss : 5662.5361, Time/batch_file : 2.2618, Training time: 7871.2053\n",
      "Epoch : 678/2000 data_batch_2,  Train_loss : 5052.2241  Test_loss : 5304.9829, Time/batch_file : 2.2927, Training time: 7873.4982\n",
      "Epoch : 678/2000 data_batch_3,  Train_loss : 5047.9292  Test_loss : 5703.2231, Time/batch_file : 2.2577, Training time: 7875.7561\n",
      "Epoch : 678/2000 data_batch_4,  Train_loss : 5252.6543  Test_loss : 5501.7695, Time/batch_file : 2.2711, Training time: 7878.0274\n",
      "Epoch : 678/2000 data_batch_5,  Train_loss : 5115.3867  Test_loss : 5725.9053, Time/batch_file : 2.2545, Training time: 7880.2821\n",
      "Epoch : 679/2000 data_batch_1,  Train_loss : 5141.1436  Test_loss : 5228.0488, Time/batch_file : 2.2793, Training time: 7882.5616\n",
      "Epoch : 679/2000 data_batch_2,  Train_loss : 4937.8340  Test_loss : 5428.8975, Time/batch_file : 2.3080, Training time: 7884.8698\n",
      "Epoch : 679/2000 data_batch_3,  Train_loss : 5075.7734  Test_loss : 5219.0742, Time/batch_file : 2.2702, Training time: 7887.1403\n",
      "Epoch : 679/2000 data_batch_4,  Train_loss : 5362.0645  Test_loss : 5394.5146, Time/batch_file : 2.2702, Training time: 7889.4106\n",
      "Epoch : 679/2000 data_batch_5,  Train_loss : 5117.5210  Test_loss : 5154.6328, Time/batch_file : 2.2632, Training time: 7891.6739\n",
      "Epoch : 680/2000 data_batch_1,  Train_loss : 5021.9326  Test_loss : 5168.1240, Time/batch_file : 2.2891, Training time: 7893.9632\n",
      "Epoch : 680/2000 data_batch_2,  Train_loss : 4992.2261  Test_loss : 5083.1997, Time/batch_file : 2.2821, Training time: 7896.2455\n",
      "Epoch : 680/2000 data_batch_3,  Train_loss : 5128.4170  Test_loss : 4980.3511, Time/batch_file : 2.3085, Training time: 7898.5542\n",
      "Epoch : 680/2000 data_batch_4,  Train_loss : 5431.7266  Test_loss : 4899.7871, Time/batch_file : 2.2986, Training time: 7900.8530\n",
      "Epoch : 680/2000 data_batch_5,  Train_loss : 5211.1084  Test_loss : 4866.3843, Time/batch_file : 2.2952, Training time: 7903.1484\n",
      "[./nets/net-680.ckpt] SAVED\n",
      "Epoch : 681/2000 data_batch_1,  Train_loss : 5085.3477  Test_loss : 5646.3423, Time/batch_file : 2.3073, Training time: 7908.7252\n",
      "Epoch : 681/2000 data_batch_2,  Train_loss : 5301.5386  Test_loss : 5614.9048, Time/batch_file : 2.3044, Training time: 7911.0298\n",
      "Epoch : 681/2000 data_batch_3,  Train_loss : 5019.3647  Test_loss : 5597.2744, Time/batch_file : 2.3079, Training time: 7913.3380\n",
      "Epoch : 681/2000 data_batch_4,  Train_loss : 5019.1763  Test_loss : 5682.0400, Time/batch_file : 2.2737, Training time: 7915.6119\n",
      "Epoch : 681/2000 data_batch_5,  Train_loss : 5059.4180  Test_loss : 5940.6436, Time/batch_file : 2.2764, Training time: 7917.8886\n",
      "Epoch : 682/2000 data_batch_1,  Train_loss : 5507.4629  Test_loss : 5621.4131, Time/batch_file : 2.2826, Training time: 7920.1715\n",
      "Epoch : 682/2000 data_batch_2,  Train_loss : 5455.9258  Test_loss : 5375.2920, Time/batch_file : 2.2788, Training time: 7922.4504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 682/2000 data_batch_3,  Train_loss : 5165.2964  Test_loss : 5291.6943, Time/batch_file : 2.2746, Training time: 7924.7251\n",
      "Epoch : 682/2000 data_batch_4,  Train_loss : 5103.6523  Test_loss : 5312.4639, Time/batch_file : 2.2713, Training time: 7926.9966\n",
      "Epoch : 682/2000 data_batch_5,  Train_loss : 5150.2217  Test_loss : 5336.9683, Time/batch_file : 2.2731, Training time: 7929.2699\n",
      "Epoch : 683/2000 data_batch_1,  Train_loss : 5365.4189  Test_loss : 4885.6738, Time/batch_file : 2.2746, Training time: 7931.5447\n",
      "Epoch : 683/2000 data_batch_2,  Train_loss : 5210.8535  Test_loss : 4885.6040, Time/batch_file : 2.2802, Training time: 7933.8251\n",
      "Epoch : 683/2000 data_batch_3,  Train_loss : 5282.3740  Test_loss : 5105.0249, Time/batch_file : 2.2739, Training time: 7936.0993\n",
      "Epoch : 683/2000 data_batch_4,  Train_loss : 4969.7026  Test_loss : 5243.2363, Time/batch_file : 2.2815, Training time: 7938.3810\n",
      "Epoch : 683/2000 data_batch_5,  Train_loss : 5121.1670  Test_loss : 5097.2373, Time/batch_file : 2.2918, Training time: 7940.6730\n",
      "Epoch : 684/2000 data_batch_1,  Train_loss : 5069.4868  Test_loss : 5535.0503, Time/batch_file : 2.2658, Training time: 7942.9391\n",
      "Epoch : 684/2000 data_batch_2,  Train_loss : 5057.0786  Test_loss : 5841.0874, Time/batch_file : 2.2715, Training time: 7945.2108\n",
      "Epoch : 684/2000 data_batch_3,  Train_loss : 4805.5073  Test_loss : 5821.3906, Time/batch_file : 2.2617, Training time: 7947.4727\n",
      "Epoch : 684/2000 data_batch_4,  Train_loss : 4987.1724  Test_loss : 5772.5518, Time/batch_file : 2.2830, Training time: 7949.7559\n",
      "Epoch : 684/2000 data_batch_5,  Train_loss : 4783.5366  Test_loss : 5509.3994, Time/batch_file : 2.2613, Training time: 7952.0174\n",
      "Epoch : 685/2000 data_batch_1,  Train_loss : 5265.1665  Test_loss : 5540.1406, Time/batch_file : 2.2712, Training time: 7954.2888\n",
      "Epoch : 685/2000 data_batch_2,  Train_loss : 5240.1533  Test_loss : 5741.1938, Time/batch_file : 2.2549, Training time: 7956.5439\n",
      "Epoch : 685/2000 data_batch_3,  Train_loss : 5316.2124  Test_loss : 5320.5151, Time/batch_file : 2.2634, Training time: 7958.8075\n",
      "Epoch : 685/2000 data_batch_4,  Train_loss : 5088.4160  Test_loss : 5684.6172, Time/batch_file : 2.2492, Training time: 7961.0569\n",
      "Epoch : 685/2000 data_batch_5,  Train_loss : 5052.2129  Test_loss : 5855.7373, Time/batch_file : 2.2594, Training time: 7963.3165\n",
      "Epoch : 686/2000 data_batch_1,  Train_loss : 5709.5293  Test_loss : 5330.4395, Time/batch_file : 2.2592, Training time: 7965.5758\n",
      "Epoch : 686/2000 data_batch_2,  Train_loss : 5603.9312  Test_loss : 4913.9414, Time/batch_file : 2.2599, Training time: 7967.8359\n",
      "Epoch : 686/2000 data_batch_3,  Train_loss : 5505.9551  Test_loss : 5012.5566, Time/batch_file : 2.2490, Training time: 7970.0850\n",
      "Epoch : 686/2000 data_batch_4,  Train_loss : 5184.9482  Test_loss : 4891.2305, Time/batch_file : 2.2657, Training time: 7972.3510\n",
      "Epoch : 686/2000 data_batch_5,  Train_loss : 5606.0830  Test_loss : 4933.9590, Time/batch_file : 2.2632, Training time: 7974.6143\n",
      "Epoch : 687/2000 data_batch_1,  Train_loss : 4925.4839  Test_loss : 5914.3887, Time/batch_file : 2.2777, Training time: 7976.8923\n",
      "Epoch : 687/2000 data_batch_2,  Train_loss : 4772.6201  Test_loss : 5560.3091, Time/batch_file : 2.2776, Training time: 7979.1702\n",
      "Epoch : 687/2000 data_batch_3,  Train_loss : 4737.5088  Test_loss : 5877.3125, Time/batch_file : 2.2692, Training time: 7981.4396\n",
      "Epoch : 687/2000 data_batch_4,  Train_loss : 4824.9634  Test_loss : 5677.3765, Time/batch_file : 2.2702, Training time: 7983.7100\n",
      "Epoch : 687/2000 data_batch_5,  Train_loss : 4827.6152  Test_loss : 5916.4883, Time/batch_file : 2.2834, Training time: 7985.9937\n",
      "Epoch : 688/2000 data_batch_1,  Train_loss : 5226.2998  Test_loss : 5508.0903, Time/batch_file : 2.2708, Training time: 7988.2648\n",
      "Epoch : 688/2000 data_batch_2,  Train_loss : 5226.2930  Test_loss : 5631.3096, Time/batch_file : 2.2794, Training time: 7990.5443\n",
      "Epoch : 688/2000 data_batch_3,  Train_loss : 5165.4985  Test_loss : 5350.8657, Time/batch_file : 2.2668, Training time: 7992.8114\n",
      "Epoch : 688/2000 data_batch_4,  Train_loss : 5153.9146  Test_loss : 5421.2061, Time/batch_file : 2.2742, Training time: 7995.0858\n",
      "Epoch : 688/2000 data_batch_5,  Train_loss : 4945.8550  Test_loss : 5592.9922, Time/batch_file : 2.2764, Training time: 7997.3625\n",
      "Epoch : 689/2000 data_batch_1,  Train_loss : 5348.3203  Test_loss : 5906.8223, Time/batch_file : 2.2737, Training time: 7999.6364\n",
      "Epoch : 689/2000 data_batch_2,  Train_loss : 5391.2520  Test_loss : 5644.0435, Time/batch_file : 2.2646, Training time: 8001.9011\n",
      "Epoch : 689/2000 data_batch_3,  Train_loss : 5300.8213  Test_loss : 5709.9551, Time/batch_file : 2.2794, Training time: 8004.1807\n",
      "Epoch : 689/2000 data_batch_4,  Train_loss : 5353.3047  Test_loss : 5949.1416, Time/batch_file : 2.2637, Training time: 8006.4445\n",
      "Epoch : 689/2000 data_batch_5,  Train_loss : 5420.5269  Test_loss : 5560.7285, Time/batch_file : 2.2747, Training time: 8008.7195\n",
      "Epoch : 690/2000 data_batch_1,  Train_loss : 5143.5020  Test_loss : 5574.4189, Time/batch_file : 2.2578, Training time: 8010.9774\n",
      "Epoch : 690/2000 data_batch_2,  Train_loss : 4966.5752  Test_loss : 5475.2500, Time/batch_file : 2.2712, Training time: 8013.2488\n",
      "Epoch : 690/2000 data_batch_3,  Train_loss : 4929.1597  Test_loss : 5515.5557, Time/batch_file : 2.2646, Training time: 8015.5136\n",
      "Epoch : 690/2000 data_batch_4,  Train_loss : 5177.3921  Test_loss : 5585.6250, Time/batch_file : 2.2746, Training time: 8017.7884\n",
      "Epoch : 690/2000 data_batch_5,  Train_loss : 5116.2134  Test_loss : 5430.9976, Time/batch_file : 2.2684, Training time: 8020.0571\n",
      "[./nets/net-690.ckpt] SAVED\n",
      "Epoch : 691/2000 data_batch_1,  Train_loss : 4249.6875  Test_loss : 5209.5127, Time/batch_file : 2.2929, Training time: 8023.6345\n",
      "Epoch : 691/2000 data_batch_2,  Train_loss : 4569.5283  Test_loss : 5461.8628, Time/batch_file : 2.2800, Training time: 8025.9146\n",
      "Epoch : 691/2000 data_batch_3,  Train_loss : 4657.2876  Test_loss : 5090.4863, Time/batch_file : 2.3028, Training time: 8028.2176\n",
      "Epoch : 691/2000 data_batch_4,  Train_loss : 4558.5088  Test_loss : 5412.1318, Time/batch_file : 2.2939, Training time: 8030.5116\n",
      "Epoch : 691/2000 data_batch_5,  Train_loss : 4567.0371  Test_loss : 5286.6543, Time/batch_file : 2.2846, Training time: 8032.7965\n",
      "Epoch : 692/2000 data_batch_1,  Train_loss : 4953.9668  Test_loss : 5148.2617, Time/batch_file : 2.2915, Training time: 8035.0883\n",
      "Epoch : 692/2000 data_batch_2,  Train_loss : 5234.0957  Test_loss : 5342.2183, Time/batch_file : 2.2785, Training time: 8037.3670\n",
      "Epoch : 692/2000 data_batch_3,  Train_loss : 5159.5479  Test_loss : 5497.9229, Time/batch_file : 2.2957, Training time: 8039.6630\n",
      "Epoch : 692/2000 data_batch_4,  Train_loss : 5401.7100  Test_loss : 5421.1309, Time/batch_file : 2.3098, Training time: 8041.9731\n",
      "Epoch : 692/2000 data_batch_5,  Train_loss : 5236.3984  Test_loss : 5509.1943, Time/batch_file : 2.2850, Training time: 8044.2583\n",
      "Epoch : 693/2000 data_batch_1,  Train_loss : 4810.7803  Test_loss : 5538.2407, Time/batch_file : 2.3025, Training time: 8046.5611\n",
      "Epoch : 693/2000 data_batch_2,  Train_loss : 4946.8877  Test_loss : 5310.4102, Time/batch_file : 2.2992, Training time: 8048.8605\n",
      "Epoch : 693/2000 data_batch_3,  Train_loss : 4659.3604  Test_loss : 5420.8389, Time/batch_file : 2.2892, Training time: 8051.1499\n",
      "Epoch : 693/2000 data_batch_4,  Train_loss : 4567.8105  Test_loss : 5284.5488, Time/batch_file : 2.2743, Training time: 8053.4245\n",
      "Epoch : 693/2000 data_batch_5,  Train_loss : 4975.9126  Test_loss : 5368.5938, Time/batch_file : 2.2857, Training time: 8055.7103\n",
      "Epoch : 694/2000 data_batch_1,  Train_loss : 4928.3789  Test_loss : 5282.7881, Time/batch_file : 2.2795, Training time: 8057.9900\n",
      "Epoch : 694/2000 data_batch_2,  Train_loss : 4963.5518  Test_loss : 5162.3569, Time/batch_file : 2.2644, Training time: 8060.2546\n",
      "Epoch : 694/2000 data_batch_3,  Train_loss : 5107.5654  Test_loss : 5608.1123, Time/batch_file : 2.2823, Training time: 8062.5371\n",
      "Epoch : 694/2000 data_batch_4,  Train_loss : 5088.0044  Test_loss : 5493.4854, Time/batch_file : 2.2868, Training time: 8064.8241\n",
      "Epoch : 694/2000 data_batch_5,  Train_loss : 4927.7715  Test_loss : 5291.7881, Time/batch_file : 2.2968, Training time: 8067.1211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 695/2000 data_batch_1,  Train_loss : 5628.6870  Test_loss : 5013.9775, Time/batch_file : 2.3023, Training time: 8069.4236\n",
      "Epoch : 695/2000 data_batch_2,  Train_loss : 5704.6138  Test_loss : 4805.0684, Time/batch_file : 2.2989, Training time: 8071.7226\n",
      "Epoch : 695/2000 data_batch_3,  Train_loss : 5577.3335  Test_loss : 4998.6128, Time/batch_file : 2.2965, Training time: 8074.0194\n",
      "Epoch : 695/2000 data_batch_4,  Train_loss : 5362.8291  Test_loss : 5094.6050, Time/batch_file : 2.2851, Training time: 8076.3048\n",
      "Epoch : 695/2000 data_batch_5,  Train_loss : 5410.2275  Test_loss : 5019.0811, Time/batch_file : 2.3066, Training time: 8078.6116\n",
      "Epoch : 696/2000 data_batch_1,  Train_loss : 5258.0137  Test_loss : 5267.1177, Time/batch_file : 2.2875, Training time: 8080.8993\n",
      "Epoch : 696/2000 data_batch_2,  Train_loss : 5383.8574  Test_loss : 5296.4204, Time/batch_file : 2.3174, Training time: 8083.2168\n",
      "Epoch : 696/2000 data_batch_3,  Train_loss : 5176.8008  Test_loss : 4866.5142, Time/batch_file : 2.2706, Training time: 8085.4876\n",
      "Epoch : 696/2000 data_batch_4,  Train_loss : 5205.7197  Test_loss : 5029.3311, Time/batch_file : 2.2841, Training time: 8087.7719\n",
      "Epoch : 696/2000 data_batch_5,  Train_loss : 5443.9561  Test_loss : 5562.0244, Time/batch_file : 2.2593, Training time: 8090.0314\n",
      "Epoch : 697/2000 data_batch_1,  Train_loss : 4981.2939  Test_loss : 5616.5537, Time/batch_file : 2.2728, Training time: 8092.3044\n",
      "Epoch : 697/2000 data_batch_2,  Train_loss : 5181.3994  Test_loss : 5321.7939, Time/batch_file : 2.2673, Training time: 8094.5719\n",
      "Epoch : 697/2000 data_batch_3,  Train_loss : 5199.1211  Test_loss : 5334.5146, Time/batch_file : 2.2985, Training time: 8096.8705\n",
      "Epoch : 697/2000 data_batch_4,  Train_loss : 5158.1499  Test_loss : 5339.7446, Time/batch_file : 2.2820, Training time: 8099.1527\n",
      "Epoch : 697/2000 data_batch_5,  Train_loss : 5362.5161  Test_loss : 5697.5957, Time/batch_file : 2.2879, Training time: 8101.4408\n",
      "Epoch : 698/2000 data_batch_1,  Train_loss : 4878.4844  Test_loss : 5385.9688, Time/batch_file : 2.2808, Training time: 8103.7219\n",
      "Epoch : 698/2000 data_batch_2,  Train_loss : 4791.5381  Test_loss : 5516.1191, Time/batch_file : 2.2936, Training time: 8106.0158\n",
      "Epoch : 698/2000 data_batch_3,  Train_loss : 5077.4146  Test_loss : 5551.6411, Time/batch_file : 2.2871, Training time: 8108.3031\n",
      "Epoch : 698/2000 data_batch_4,  Train_loss : 5009.0068  Test_loss : 5542.5112, Time/batch_file : 2.2731, Training time: 8110.5764\n",
      "Epoch : 698/2000 data_batch_5,  Train_loss : 5009.4087  Test_loss : 5321.8350, Time/batch_file : 2.2970, Training time: 8112.8736\n",
      "Epoch : 699/2000 data_batch_1,  Train_loss : 4897.4272  Test_loss : 5429.5400, Time/batch_file : 2.2954, Training time: 8115.1691\n",
      "Epoch : 699/2000 data_batch_2,  Train_loss : 4758.6201  Test_loss : 5510.9795, Time/batch_file : 2.3232, Training time: 8117.4925\n",
      "Epoch : 699/2000 data_batch_3,  Train_loss : 4891.6113  Test_loss : 5577.8452, Time/batch_file : 2.2990, Training time: 8119.7918\n",
      "Epoch : 699/2000 data_batch_4,  Train_loss : 4783.8159  Test_loss : 5732.9092, Time/batch_file : 2.3159, Training time: 8122.1079\n",
      "Epoch : 699/2000 data_batch_5,  Train_loss : 4616.7266  Test_loss : 5438.0576, Time/batch_file : 2.2784, Training time: 8124.3865\n",
      "Epoch : 700/2000 data_batch_1,  Train_loss : 5753.0469  Test_loss : 5533.2798, Time/batch_file : 2.2947, Training time: 8126.6814\n",
      "Epoch : 700/2000 data_batch_2,  Train_loss : 5473.0576  Test_loss : 5778.4385, Time/batch_file : 2.2855, Training time: 8128.9671\n",
      "Epoch : 700/2000 data_batch_3,  Train_loss : 5683.0225  Test_loss : 5784.8843, Time/batch_file : 2.3064, Training time: 8131.2737\n",
      "Epoch : 700/2000 data_batch_4,  Train_loss : 5674.0273  Test_loss : 5150.4995, Time/batch_file : 2.2895, Training time: 8133.5634\n",
      "Epoch : 700/2000 data_batch_5,  Train_loss : 5214.5708  Test_loss : 5798.8486, Time/batch_file : 2.3024, Training time: 8135.8660\n",
      "[./nets/net-700.ckpt] SAVED\n",
      "Epoch : 701/2000 data_batch_1,  Train_loss : 5314.1436  Test_loss : 5603.6260, Time/batch_file : 2.2957, Training time: 8139.4377\n",
      "Epoch : 701/2000 data_batch_2,  Train_loss : 5828.7700  Test_loss : 5374.0674, Time/batch_file : 2.2956, Training time: 8141.7335\n",
      "Epoch : 701/2000 data_batch_3,  Train_loss : 5492.5317  Test_loss : 5253.3564, Time/batch_file : 2.2971, Training time: 8144.0307\n",
      "Epoch : 701/2000 data_batch_4,  Train_loss : 5421.2432  Test_loss : 5512.4395, Time/batch_file : 2.2828, Training time: 8146.3138\n",
      "Epoch : 701/2000 data_batch_5,  Train_loss : 5369.8662  Test_loss : 5681.3413, Time/batch_file : 2.2744, Training time: 8148.5884\n",
      "Epoch : 702/2000 data_batch_1,  Train_loss : 4685.0801  Test_loss : 5386.9028, Time/batch_file : 2.2536, Training time: 8150.8421\n",
      "Epoch : 702/2000 data_batch_2,  Train_loss : 4770.3228  Test_loss : 5366.4258, Time/batch_file : 2.2635, Training time: 8153.1058\n",
      "Epoch : 702/2000 data_batch_3,  Train_loss : 4766.2319  Test_loss : 5460.3955, Time/batch_file : 2.2658, Training time: 8155.3717\n",
      "Epoch : 702/2000 data_batch_4,  Train_loss : 4467.0796  Test_loss : 5466.1494, Time/batch_file : 2.2771, Training time: 8157.6490\n",
      "Epoch : 702/2000 data_batch_5,  Train_loss : 4513.9561  Test_loss : 5585.7188, Time/batch_file : 2.2542, Training time: 8159.9034\n",
      "Epoch : 703/2000 data_batch_1,  Train_loss : 5536.3784  Test_loss : 5757.1216, Time/batch_file : 2.2916, Training time: 8162.1952\n",
      "Epoch : 703/2000 data_batch_2,  Train_loss : 5249.8281  Test_loss : 5489.8604, Time/batch_file : 2.2634, Training time: 8164.4587\n",
      "Epoch : 703/2000 data_batch_3,  Train_loss : 5130.0059  Test_loss : 5078.3398, Time/batch_file : 2.2796, Training time: 8166.7385\n",
      "Epoch : 703/2000 data_batch_4,  Train_loss : 5354.7778  Test_loss : 5596.2271, Time/batch_file : 2.2748, Training time: 8169.0136\n",
      "Epoch : 703/2000 data_batch_5,  Train_loss : 5449.0029  Test_loss : 5438.6206, Time/batch_file : 2.2761, Training time: 8171.2898\n",
      "Epoch : 704/2000 data_batch_1,  Train_loss : 4860.1069  Test_loss : 5722.9087, Time/batch_file : 2.2813, Training time: 8173.5713\n",
      "Epoch : 704/2000 data_batch_2,  Train_loss : 4745.2236  Test_loss : 5439.0352, Time/batch_file : 2.2942, Training time: 8175.8657\n",
      "Epoch : 704/2000 data_batch_3,  Train_loss : 4808.9414  Test_loss : 5384.8379, Time/batch_file : 2.2698, Training time: 8178.1357\n",
      "Epoch : 704/2000 data_batch_4,  Train_loss : 4871.7974  Test_loss : 5454.9258, Time/batch_file : 2.2824, Training time: 8180.4183\n",
      "Epoch : 704/2000 data_batch_5,  Train_loss : 4719.8398  Test_loss : 5513.6338, Time/batch_file : 2.2845, Training time: 8182.7030\n",
      "Epoch : 705/2000 data_batch_1,  Train_loss : 5520.5977  Test_loss : 4912.4082, Time/batch_file : 2.2805, Training time: 8184.9837\n",
      "Epoch : 705/2000 data_batch_2,  Train_loss : 5452.6357  Test_loss : 4832.5449, Time/batch_file : 2.2735, Training time: 8187.2573\n",
      "Epoch : 705/2000 data_batch_3,  Train_loss : 5661.8252  Test_loss : 4607.7148, Time/batch_file : 2.2879, Training time: 8189.5454\n",
      "Epoch : 705/2000 data_batch_4,  Train_loss : 5541.3496  Test_loss : 4884.1299, Time/batch_file : 2.3041, Training time: 8191.8497\n",
      "Epoch : 705/2000 data_batch_5,  Train_loss : 5831.9092  Test_loss : 5038.5649, Time/batch_file : 2.2876, Training time: 8194.1375\n",
      "Epoch : 706/2000 data_batch_1,  Train_loss : 5132.9917  Test_loss : 5425.5972, Time/batch_file : 2.2772, Training time: 8196.4150\n",
      "Epoch : 706/2000 data_batch_2,  Train_loss : 5165.2300  Test_loss : 5425.8701, Time/batch_file : 2.2916, Training time: 8198.7069\n",
      "Epoch : 706/2000 data_batch_3,  Train_loss : 5469.0259  Test_loss : 4976.9766, Time/batch_file : 2.2807, Training time: 8200.9877\n",
      "Epoch : 706/2000 data_batch_4,  Train_loss : 5185.9121  Test_loss : 5141.9482, Time/batch_file : 2.2713, Training time: 8203.2591\n",
      "Epoch : 706/2000 data_batch_5,  Train_loss : 5510.5859  Test_loss : 5316.0605, Time/batch_file : 2.2729, Training time: 8205.5323\n",
      "Epoch : 707/2000 data_batch_1,  Train_loss : 5457.0908  Test_loss : 5112.9956, Time/batch_file : 2.2983, Training time: 8207.8308\n",
      "Epoch : 707/2000 data_batch_2,  Train_loss : 5688.2842  Test_loss : 5006.4390, Time/batch_file : 2.2634, Training time: 8210.0943\n",
      "Epoch : 707/2000 data_batch_3,  Train_loss : 5506.9302  Test_loss : 4936.7627, Time/batch_file : 2.3008, Training time: 8212.3953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 707/2000 data_batch_4,  Train_loss : 5354.3887  Test_loss : 5456.2715, Time/batch_file : 2.2616, Training time: 8214.6571\n",
      "Epoch : 707/2000 data_batch_5,  Train_loss : 5418.2529  Test_loss : 5031.0522, Time/batch_file : 2.2862, Training time: 8216.9436\n",
      "Epoch : 708/2000 data_batch_1,  Train_loss : 5086.0693  Test_loss : 5201.6094, Time/batch_file : 2.2853, Training time: 8219.2290\n",
      "Epoch : 708/2000 data_batch_2,  Train_loss : 4751.5439  Test_loss : 5185.9980, Time/batch_file : 2.2751, Training time: 8221.5043\n",
      "Epoch : 708/2000 data_batch_3,  Train_loss : 4870.9795  Test_loss : 4990.4268, Time/batch_file : 2.2842, Training time: 8223.7888\n",
      "Epoch : 708/2000 data_batch_4,  Train_loss : 4933.8022  Test_loss : 5185.9443, Time/batch_file : 2.2694, Training time: 8226.0584\n",
      "Epoch : 708/2000 data_batch_5,  Train_loss : 4798.9141  Test_loss : 5082.5830, Time/batch_file : 2.2782, Training time: 8228.3367\n",
      "Epoch : 709/2000 data_batch_1,  Train_loss : 4794.0830  Test_loss : 5294.9219, Time/batch_file : 2.2727, Training time: 8230.6097\n",
      "Epoch : 709/2000 data_batch_2,  Train_loss : 4680.2144  Test_loss : 5557.3154, Time/batch_file : 2.2793, Training time: 8232.8892\n",
      "Epoch : 709/2000 data_batch_3,  Train_loss : 4889.3750  Test_loss : 5191.3301, Time/batch_file : 2.2665, Training time: 8235.1559\n",
      "Epoch : 709/2000 data_batch_4,  Train_loss : 5009.3032  Test_loss : 5405.2178, Time/batch_file : 2.2911, Training time: 8237.4472\n",
      "Epoch : 709/2000 data_batch_5,  Train_loss : 4818.4785  Test_loss : 5650.6094, Time/batch_file : 2.2535, Training time: 8239.7009\n",
      "Epoch : 710/2000 data_batch_1,  Train_loss : 5614.7295  Test_loss : 5189.9414, Time/batch_file : 2.2965, Training time: 8241.9977\n",
      "Epoch : 710/2000 data_batch_2,  Train_loss : 5471.0439  Test_loss : 5320.1733, Time/batch_file : 2.2883, Training time: 8244.2862\n",
      "Epoch : 710/2000 data_batch_3,  Train_loss : 5580.0918  Test_loss : 5230.0586, Time/batch_file : 2.3049, Training time: 8246.5913\n",
      "Epoch : 710/2000 data_batch_4,  Train_loss : 5553.1465  Test_loss : 5350.8477, Time/batch_file : 2.2895, Training time: 8248.8810\n",
      "Epoch : 710/2000 data_batch_5,  Train_loss : 5421.4375  Test_loss : 5307.5444, Time/batch_file : 2.3108, Training time: 8251.1919\n",
      "[./nets/net-710.ckpt] SAVED\n",
      "Epoch : 711/2000 data_batch_1,  Train_loss : 5401.3550  Test_loss : 5380.1953, Time/batch_file : 2.3155, Training time: 8254.7858\n",
      "Epoch : 711/2000 data_batch_2,  Train_loss : 5407.3247  Test_loss : 5831.4980, Time/batch_file : 2.2934, Training time: 8257.0794\n",
      "Epoch : 711/2000 data_batch_3,  Train_loss : 5721.9043  Test_loss : 5258.1763, Time/batch_file : 2.3077, Training time: 8259.3873\n",
      "Epoch : 711/2000 data_batch_4,  Train_loss : 5246.3262  Test_loss : 5404.8828, Time/batch_file : 2.3107, Training time: 8261.6982\n",
      "Epoch : 711/2000 data_batch_5,  Train_loss : 5423.2031  Test_loss : 5247.9585, Time/batch_file : 2.3228, Training time: 8264.0212\n",
      "Epoch : 712/2000 data_batch_1,  Train_loss : 5342.4004  Test_loss : 5403.9434, Time/batch_file : 2.2893, Training time: 8266.3107\n",
      "Epoch : 712/2000 data_batch_2,  Train_loss : 5257.3325  Test_loss : 5373.4253, Time/batch_file : 2.2872, Training time: 8268.5982\n",
      "Epoch : 712/2000 data_batch_3,  Train_loss : 5088.6636  Test_loss : 4974.2383, Time/batch_file : 2.3047, Training time: 8270.9030\n",
      "Epoch : 712/2000 data_batch_4,  Train_loss : 5246.5088  Test_loss : 5300.3931, Time/batch_file : 2.2974, Training time: 8273.2006\n",
      "Epoch : 712/2000 data_batch_5,  Train_loss : 5122.8652  Test_loss : 5395.0820, Time/batch_file : 2.2816, Training time: 8275.4824\n",
      "Epoch : 713/2000 data_batch_1,  Train_loss : 5240.9775  Test_loss : 5696.3989, Time/batch_file : 2.2933, Training time: 8277.7759\n",
      "Epoch : 713/2000 data_batch_2,  Train_loss : 5113.5151  Test_loss : 5545.0098, Time/batch_file : 2.2851, Training time: 8280.0612\n",
      "Epoch : 713/2000 data_batch_3,  Train_loss : 5018.1812  Test_loss : 5898.6182, Time/batch_file : 2.2941, Training time: 8282.3555\n",
      "Epoch : 713/2000 data_batch_4,  Train_loss : 5085.6582  Test_loss : 5937.0894, Time/batch_file : 2.2884, Training time: 8284.6442\n",
      "Epoch : 713/2000 data_batch_5,  Train_loss : 5029.6167  Test_loss : 6138.4727, Time/batch_file : 2.2695, Training time: 8286.9139\n",
      "Epoch : 714/2000 data_batch_1,  Train_loss : 5092.4663  Test_loss : 4935.6328, Time/batch_file : 2.2879, Training time: 8289.2019\n",
      "Epoch : 714/2000 data_batch_2,  Train_loss : 4964.1670  Test_loss : 4792.9590, Time/batch_file : 2.2619, Training time: 8291.4640\n",
      "Epoch : 714/2000 data_batch_3,  Train_loss : 5008.6743  Test_loss : 4624.9907, Time/batch_file : 2.2733, Training time: 8293.7375\n",
      "Epoch : 714/2000 data_batch_4,  Train_loss : 5127.4482  Test_loss : 5149.4854, Time/batch_file : 2.2906, Training time: 8296.0284\n",
      "Epoch : 714/2000 data_batch_5,  Train_loss : 5200.8994  Test_loss : 4945.3125, Time/batch_file : 2.2942, Training time: 8298.3228\n",
      "Epoch : 715/2000 data_batch_1,  Train_loss : 5124.4385  Test_loss : 5461.8286, Time/batch_file : 2.2975, Training time: 8300.6205\n",
      "Epoch : 715/2000 data_batch_2,  Train_loss : 5174.1558  Test_loss : 5296.6343, Time/batch_file : 2.2746, Training time: 8302.8953\n",
      "Epoch : 715/2000 data_batch_3,  Train_loss : 5038.5732  Test_loss : 5496.5771, Time/batch_file : 2.2587, Training time: 8305.1543\n",
      "Epoch : 715/2000 data_batch_4,  Train_loss : 4914.9346  Test_loss : 4995.1582, Time/batch_file : 2.2697, Training time: 8307.4242\n",
      "Epoch : 715/2000 data_batch_5,  Train_loss : 5072.5923  Test_loss : 4901.4854, Time/batch_file : 2.2677, Training time: 8309.6920\n",
      "Epoch : 716/2000 data_batch_1,  Train_loss : 4877.8257  Test_loss : 5132.5991, Time/batch_file : 2.2984, Training time: 8311.9906\n",
      "Epoch : 716/2000 data_batch_2,  Train_loss : 5105.7314  Test_loss : 5292.6338, Time/batch_file : 2.2866, Training time: 8314.2774\n",
      "Epoch : 716/2000 data_batch_3,  Train_loss : 4944.5117  Test_loss : 5140.2490, Time/batch_file : 2.2900, Training time: 8316.5677\n",
      "Epoch : 716/2000 data_batch_4,  Train_loss : 4945.2754  Test_loss : 5125.1733, Time/batch_file : 2.2956, Training time: 8318.8635\n",
      "Epoch : 716/2000 data_batch_5,  Train_loss : 5155.8110  Test_loss : 5405.7285, Time/batch_file : 2.3006, Training time: 8321.1643\n",
      "Epoch : 717/2000 data_batch_1,  Train_loss : 4981.4858  Test_loss : 5610.3105, Time/batch_file : 2.2750, Training time: 8323.4396\n",
      "Epoch : 717/2000 data_batch_2,  Train_loss : 5060.4814  Test_loss : 5607.0947, Time/batch_file : 2.2760, Training time: 8325.7159\n",
      "Epoch : 717/2000 data_batch_3,  Train_loss : 4816.4951  Test_loss : 5380.4443, Time/batch_file : 2.2849, Training time: 8328.0011\n",
      "Epoch : 717/2000 data_batch_4,  Train_loss : 5155.5352  Test_loss : 5447.3735, Time/batch_file : 2.2878, Training time: 8330.2891\n",
      "Epoch : 717/2000 data_batch_5,  Train_loss : 5118.8872  Test_loss : 5362.3179, Time/batch_file : 2.2777, Training time: 8332.5670\n",
      "Epoch : 718/2000 data_batch_1,  Train_loss : 4872.5176  Test_loss : 5095.9292, Time/batch_file : 2.2903, Training time: 8334.8576\n",
      "Epoch : 718/2000 data_batch_2,  Train_loss : 4957.5840  Test_loss : 5371.4614, Time/batch_file : 2.2929, Training time: 8337.1506\n",
      "Epoch : 718/2000 data_batch_3,  Train_loss : 4841.1323  Test_loss : 5261.3530, Time/batch_file : 2.2817, Training time: 8339.4325\n",
      "Epoch : 718/2000 data_batch_4,  Train_loss : 4709.4595  Test_loss : 4954.3931, Time/batch_file : 2.2706, Training time: 8341.7034\n",
      "Epoch : 718/2000 data_batch_5,  Train_loss : 4986.5034  Test_loss : 4919.3359, Time/batch_file : 2.3038, Training time: 8344.0073\n",
      "Epoch : 719/2000 data_batch_1,  Train_loss : 4973.1807  Test_loss : 5703.5244, Time/batch_file : 2.2882, Training time: 8346.2957\n",
      "Epoch : 719/2000 data_batch_2,  Train_loss : 5072.6660  Test_loss : 5524.5796, Time/batch_file : 2.2943, Training time: 8348.5902\n",
      "Epoch : 719/2000 data_batch_3,  Train_loss : 4963.9351  Test_loss : 6100.5615, Time/batch_file : 2.2899, Training time: 8350.8802\n",
      "Epoch : 719/2000 data_batch_4,  Train_loss : 5092.0991  Test_loss : 5451.5557, Time/batch_file : 2.2858, Training time: 8353.1662\n",
      "Epoch : 719/2000 data_batch_5,  Train_loss : 5039.6948  Test_loss : 5591.9014, Time/batch_file : 2.2815, Training time: 8355.4479\n",
      "Epoch : 720/2000 data_batch_1,  Train_loss : 4838.2373  Test_loss : 5707.1865, Time/batch_file : 2.2932, Training time: 8357.7412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 720/2000 data_batch_2,  Train_loss : 4936.3872  Test_loss : 5827.6685, Time/batch_file : 2.2659, Training time: 8360.0072\n",
      "Epoch : 720/2000 data_batch_3,  Train_loss : 5101.5498  Test_loss : 5627.1650, Time/batch_file : 2.2774, Training time: 8362.2848\n",
      "Epoch : 720/2000 data_batch_4,  Train_loss : 5096.6025  Test_loss : 5857.6455, Time/batch_file : 2.2718, Training time: 8364.5567\n",
      "Epoch : 720/2000 data_batch_5,  Train_loss : 4814.9077  Test_loss : 4999.7510, Time/batch_file : 2.2571, Training time: 8366.8141\n",
      "[./nets/net-720.ckpt] SAVED\n",
      "Epoch : 721/2000 data_batch_1,  Train_loss : 5405.3994  Test_loss : 5369.7959, Time/batch_file : 2.2911, Training time: 8370.3779\n",
      "Epoch : 721/2000 data_batch_2,  Train_loss : 5409.1719  Test_loss : 5528.0225, Time/batch_file : 2.2670, Training time: 8372.6451\n",
      "Epoch : 721/2000 data_batch_3,  Train_loss : 5499.7959  Test_loss : 5037.5459, Time/batch_file : 2.3007, Training time: 8374.9460\n",
      "Epoch : 721/2000 data_batch_4,  Train_loss : 5303.0869  Test_loss : 4879.8965, Time/batch_file : 2.2684, Training time: 8377.2146\n",
      "Epoch : 721/2000 data_batch_5,  Train_loss : 5639.8032  Test_loss : 5174.3457, Time/batch_file : 2.2805, Training time: 8379.4953\n",
      "Epoch : 722/2000 data_batch_1,  Train_loss : 5311.1895  Test_loss : 5787.8374, Time/batch_file : 2.2729, Training time: 8381.7683\n",
      "Epoch : 722/2000 data_batch_2,  Train_loss : 5159.7339  Test_loss : 5829.2192, Time/batch_file : 2.2862, Training time: 8384.0548\n",
      "Epoch : 722/2000 data_batch_3,  Train_loss : 5499.2798  Test_loss : 6221.7188, Time/batch_file : 2.2799, Training time: 8386.3349\n",
      "Epoch : 722/2000 data_batch_4,  Train_loss : 5352.2324  Test_loss : 5884.7651, Time/batch_file : 2.2846, Training time: 8388.6197\n",
      "Epoch : 722/2000 data_batch_5,  Train_loss : 5457.3569  Test_loss : 5866.7891, Time/batch_file : 2.2829, Training time: 8390.9029\n",
      "Epoch : 723/2000 data_batch_1,  Train_loss : 5067.0732  Test_loss : 5046.7256, Time/batch_file : 2.2753, Training time: 8393.1783\n",
      "Epoch : 723/2000 data_batch_2,  Train_loss : 5023.3555  Test_loss : 5196.2236, Time/batch_file : 2.2851, Training time: 8395.4636\n",
      "Epoch : 723/2000 data_batch_3,  Train_loss : 5317.1348  Test_loss : 5057.7559, Time/batch_file : 2.2781, Training time: 8397.7419\n",
      "Epoch : 723/2000 data_batch_4,  Train_loss : 5025.3008  Test_loss : 4976.7163, Time/batch_file : 2.3007, Training time: 8400.0428\n",
      "Epoch : 723/2000 data_batch_5,  Train_loss : 4887.8989  Test_loss : 4965.0576, Time/batch_file : 2.2763, Training time: 8402.3193\n",
      "Epoch : 724/2000 data_batch_1,  Train_loss : 4933.6367  Test_loss : 5210.0488, Time/batch_file : 2.2670, Training time: 8404.5865\n",
      "Epoch : 724/2000 data_batch_2,  Train_loss : 4887.6318  Test_loss : 5754.8955, Time/batch_file : 2.2688, Training time: 8406.8555\n",
      "Epoch : 724/2000 data_batch_3,  Train_loss : 5109.3340  Test_loss : 5225.8091, Time/batch_file : 2.2747, Training time: 8409.1304\n",
      "Epoch : 724/2000 data_batch_4,  Train_loss : 5064.9336  Test_loss : 5507.8457, Time/batch_file : 2.2675, Training time: 8411.3982\n",
      "Epoch : 724/2000 data_batch_5,  Train_loss : 5014.9829  Test_loss : 5556.7749, Time/batch_file : 2.2665, Training time: 8413.6650\n",
      "Epoch : 725/2000 data_batch_1,  Train_loss : 5343.7217  Test_loss : 5769.1104, Time/batch_file : 2.2851, Training time: 8415.9503\n",
      "Epoch : 725/2000 data_batch_2,  Train_loss : 5295.7310  Test_loss : 5772.8135, Time/batch_file : 2.2826, Training time: 8418.2331\n",
      "Epoch : 725/2000 data_batch_3,  Train_loss : 5326.7788  Test_loss : 5831.4834, Time/batch_file : 2.3218, Training time: 8420.5550\n",
      "Epoch : 725/2000 data_batch_4,  Train_loss : 5374.0435  Test_loss : 5730.9043, Time/batch_file : 2.2742, Training time: 8422.8294\n",
      "Epoch : 725/2000 data_batch_5,  Train_loss : 5135.5171  Test_loss : 5655.6924, Time/batch_file : 2.2883, Training time: 8425.1179\n",
      "Epoch : 726/2000 data_batch_1,  Train_loss : 5016.4434  Test_loss : 4822.7012, Time/batch_file : 2.2619, Training time: 8427.3800\n",
      "Epoch : 726/2000 data_batch_2,  Train_loss : 5287.3682  Test_loss : 4820.9946, Time/batch_file : 2.2834, Training time: 8429.6638\n",
      "Epoch : 726/2000 data_batch_3,  Train_loss : 5383.9463  Test_loss : 4913.3335, Time/batch_file : 2.2651, Training time: 8431.9292\n",
      "Epoch : 726/2000 data_batch_4,  Train_loss : 5270.7144  Test_loss : 5072.6875, Time/batch_file : 2.2689, Training time: 8434.1983\n",
      "Epoch : 726/2000 data_batch_5,  Train_loss : 5373.6011  Test_loss : 4772.9883, Time/batch_file : 2.2689, Training time: 8436.4674\n",
      "Epoch : 727/2000 data_batch_1,  Train_loss : 5266.4995  Test_loss : 4832.9707, Time/batch_file : 2.2815, Training time: 8438.7491\n",
      "Epoch : 727/2000 data_batch_2,  Train_loss : 5244.7349  Test_loss : 5046.5122, Time/batch_file : 2.2910, Training time: 8441.0404\n",
      "Epoch : 727/2000 data_batch_3,  Train_loss : 5382.1519  Test_loss : 5270.7485, Time/batch_file : 2.2789, Training time: 8443.3194\n",
      "Epoch : 727/2000 data_batch_4,  Train_loss : 5262.7134  Test_loss : 5480.7866, Time/batch_file : 2.2823, Training time: 8445.6020\n",
      "Epoch : 727/2000 data_batch_5,  Train_loss : 5243.8330  Test_loss : 5462.7554, Time/batch_file : 2.2789, Training time: 8447.8811\n",
      "Epoch : 728/2000 data_batch_1,  Train_loss : 5364.7192  Test_loss : 5464.8501, Time/batch_file : 2.2631, Training time: 8450.1444\n",
      "Epoch : 728/2000 data_batch_2,  Train_loss : 5223.1836  Test_loss : 5680.9268, Time/batch_file : 2.2627, Training time: 8452.4073\n",
      "Epoch : 728/2000 data_batch_3,  Train_loss : 5151.7598  Test_loss : 5518.9233, Time/batch_file : 2.2718, Training time: 8454.6793\n",
      "Epoch : 728/2000 data_batch_4,  Train_loss : 5186.7725  Test_loss : 5469.8193, Time/batch_file : 2.2687, Training time: 8456.9482\n",
      "Epoch : 728/2000 data_batch_5,  Train_loss : 5003.6401  Test_loss : 5475.1514, Time/batch_file : 2.2720, Training time: 8459.2203\n",
      "Epoch : 729/2000 data_batch_1,  Train_loss : 5334.6597  Test_loss : 5129.3706, Time/batch_file : 2.2826, Training time: 8461.5031\n",
      "Epoch : 729/2000 data_batch_2,  Train_loss : 5170.1685  Test_loss : 5259.6079, Time/batch_file : 2.2880, Training time: 8463.7913\n",
      "Epoch : 729/2000 data_batch_3,  Train_loss : 5197.3984  Test_loss : 5105.4116, Time/batch_file : 2.2808, Training time: 8466.0722\n",
      "Epoch : 729/2000 data_batch_4,  Train_loss : 5455.1787  Test_loss : 5059.8848, Time/batch_file : 2.2912, Training time: 8468.3637\n",
      "Epoch : 729/2000 data_batch_5,  Train_loss : 5280.7627  Test_loss : 5251.9751, Time/batch_file : 2.2911, Training time: 8470.6550\n",
      "Epoch : 730/2000 data_batch_1,  Train_loss : 5353.3750  Test_loss : 4936.9023, Time/batch_file : 2.2748, Training time: 8472.9300\n",
      "Epoch : 730/2000 data_batch_2,  Train_loss : 5470.2031  Test_loss : 5197.7300, Time/batch_file : 2.2934, Training time: 8475.2236\n",
      "Epoch : 730/2000 data_batch_3,  Train_loss : 5474.7583  Test_loss : 4995.5332, Time/batch_file : 2.2765, Training time: 8477.5003\n",
      "Epoch : 730/2000 data_batch_4,  Train_loss : 5466.5000  Test_loss : 4842.2300, Time/batch_file : 2.2766, Training time: 8479.7772\n",
      "Epoch : 730/2000 data_batch_5,  Train_loss : 4918.1235  Test_loss : 5132.1719, Time/batch_file : 2.2616, Training time: 8482.0391\n",
      "[./nets/net-730.ckpt] SAVED\n",
      "Epoch : 731/2000 data_batch_1,  Train_loss : 4986.5645  Test_loss : 5075.4707, Time/batch_file : 2.2997, Training time: 8485.6114\n",
      "Epoch : 731/2000 data_batch_2,  Train_loss : 4984.9531  Test_loss : 4643.5127, Time/batch_file : 2.2856, Training time: 8487.8973\n",
      "Epoch : 731/2000 data_batch_3,  Train_loss : 5156.7456  Test_loss : 4803.4033, Time/batch_file : 2.2778, Training time: 8490.1752\n",
      "Epoch : 731/2000 data_batch_4,  Train_loss : 5196.0000  Test_loss : 5069.8047, Time/batch_file : 2.2843, Training time: 8492.4597\n",
      "Epoch : 731/2000 data_batch_5,  Train_loss : 4954.3672  Test_loss : 4949.9355, Time/batch_file : 2.2814, Training time: 8494.7413\n",
      "Epoch : 732/2000 data_batch_1,  Train_loss : 5537.8125  Test_loss : 5230.8369, Time/batch_file : 2.2858, Training time: 8497.0274\n",
      "Epoch : 732/2000 data_batch_2,  Train_loss : 5553.9922  Test_loss : 5375.2017, Time/batch_file : 2.2677, Training time: 8499.2953\n",
      "Epoch : 732/2000 data_batch_3,  Train_loss : 5517.1914  Test_loss : 5178.6411, Time/batch_file : 2.2725, Training time: 8501.5680\n",
      "Epoch : 732/2000 data_batch_4,  Train_loss : 5565.8867  Test_loss : 5009.7969, Time/batch_file : 2.2740, Training time: 8503.8423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 732/2000 data_batch_5,  Train_loss : 5190.2314  Test_loss : 5108.8447, Time/batch_file : 2.2888, Training time: 8506.1314\n",
      "Epoch : 733/2000 data_batch_1,  Train_loss : 5144.6318  Test_loss : 5762.8032, Time/batch_file : 2.2782, Training time: 8508.4098\n",
      "Epoch : 733/2000 data_batch_2,  Train_loss : 5195.6963  Test_loss : 5526.4326, Time/batch_file : 2.2862, Training time: 8510.6962\n",
      "Epoch : 733/2000 data_batch_3,  Train_loss : 5126.8604  Test_loss : 5736.8032, Time/batch_file : 2.2641, Training time: 8512.9605\n",
      "Epoch : 733/2000 data_batch_4,  Train_loss : 5385.8354  Test_loss : 5565.6187, Time/batch_file : 2.2923, Training time: 8515.2529\n",
      "Epoch : 733/2000 data_batch_5,  Train_loss : 5388.4482  Test_loss : 5899.3232, Time/batch_file : 2.2881, Training time: 8517.5412\n",
      "Epoch : 734/2000 data_batch_1,  Train_loss : 5182.6367  Test_loss : 6106.3237, Time/batch_file : 2.2780, Training time: 8519.8195\n",
      "Epoch : 734/2000 data_batch_2,  Train_loss : 5138.6318  Test_loss : 5706.8110, Time/batch_file : 2.2780, Training time: 8522.0976\n",
      "Epoch : 734/2000 data_batch_3,  Train_loss : 5203.6299  Test_loss : 5975.5361, Time/batch_file : 2.2898, Training time: 8524.3877\n",
      "Epoch : 734/2000 data_batch_4,  Train_loss : 5205.1108  Test_loss : 6168.9580, Time/batch_file : 2.2829, Training time: 8526.6709\n",
      "Epoch : 734/2000 data_batch_5,  Train_loss : 5286.6943  Test_loss : 5961.6396, Time/batch_file : 2.2992, Training time: 8528.9703\n",
      "Epoch : 735/2000 data_batch_1,  Train_loss : 4991.1685  Test_loss : 5675.7363, Time/batch_file : 2.2537, Training time: 8531.2241\n",
      "Epoch : 735/2000 data_batch_2,  Train_loss : 5022.3413  Test_loss : 5557.5254, Time/batch_file : 2.2755, Training time: 8533.4998\n",
      "Epoch : 735/2000 data_batch_3,  Train_loss : 4745.1367  Test_loss : 5407.3052, Time/batch_file : 2.2730, Training time: 8535.7731\n",
      "Epoch : 735/2000 data_batch_4,  Train_loss : 5007.6484  Test_loss : 5461.3784, Time/batch_file : 2.2677, Training time: 8538.0411\n",
      "Epoch : 735/2000 data_batch_5,  Train_loss : 5050.2944  Test_loss : 5553.7686, Time/batch_file : 2.2657, Training time: 8540.3069\n",
      "Epoch : 736/2000 data_batch_1,  Train_loss : 5142.7935  Test_loss : 4888.0459, Time/batch_file : 2.2822, Training time: 8542.5893\n",
      "Epoch : 736/2000 data_batch_2,  Train_loss : 5116.5513  Test_loss : 5179.7275, Time/batch_file : 2.2670, Training time: 8544.8566\n",
      "Epoch : 736/2000 data_batch_3,  Train_loss : 5006.2686  Test_loss : 5023.2871, Time/batch_file : 2.2773, Training time: 8547.1341\n",
      "Epoch : 736/2000 data_batch_4,  Train_loss : 5165.7832  Test_loss : 5505.6719, Time/batch_file : 2.2705, Training time: 8549.4048\n",
      "Epoch : 736/2000 data_batch_5,  Train_loss : 5266.4766  Test_loss : 4930.4897, Time/batch_file : 2.2908, Training time: 8551.6958\n",
      "Epoch : 737/2000 data_batch_1,  Train_loss : 5081.2578  Test_loss : 5121.3477, Time/batch_file : 2.2678, Training time: 8553.9638\n",
      "Epoch : 737/2000 data_batch_2,  Train_loss : 5043.7178  Test_loss : 5201.9551, Time/batch_file : 2.2776, Training time: 8556.2416\n",
      "Epoch : 737/2000 data_batch_3,  Train_loss : 5055.4785  Test_loss : 5522.2251, Time/batch_file : 2.2724, Training time: 8558.5143\n",
      "Epoch : 737/2000 data_batch_4,  Train_loss : 5186.0596  Test_loss : 5749.0562, Time/batch_file : 2.2860, Training time: 8560.8005\n",
      "Epoch : 737/2000 data_batch_5,  Train_loss : 4686.6953  Test_loss : 5207.0396, Time/batch_file : 2.2824, Training time: 8563.0832\n",
      "Epoch : 738/2000 data_batch_1,  Train_loss : 4904.0190  Test_loss : 5432.9150, Time/batch_file : 2.3039, Training time: 8565.3874\n",
      "Epoch : 738/2000 data_batch_2,  Train_loss : 4572.7983  Test_loss : 5340.9219, Time/batch_file : 2.2696, Training time: 8567.6572\n",
      "Epoch : 738/2000 data_batch_3,  Train_loss : 4765.5723  Test_loss : 5413.8408, Time/batch_file : 2.2887, Training time: 8569.9462\n",
      "Epoch : 738/2000 data_batch_4,  Train_loss : 4530.4282  Test_loss : 5487.0713, Time/batch_file : 2.2921, Training time: 8572.2385\n",
      "Epoch : 738/2000 data_batch_5,  Train_loss : 4573.1875  Test_loss : 5269.9795, Time/batch_file : 2.2857, Training time: 8574.5246\n",
      "Epoch : 739/2000 data_batch_1,  Train_loss : 5271.5039  Test_loss : 4827.2065, Time/batch_file : 2.2770, Training time: 8576.8017\n",
      "Epoch : 739/2000 data_batch_2,  Train_loss : 4974.0464  Test_loss : 4943.6963, Time/batch_file : 2.2991, Training time: 8579.1010\n",
      "Epoch : 739/2000 data_batch_3,  Train_loss : 5087.9805  Test_loss : 4900.3477, Time/batch_file : 2.2597, Training time: 8581.3609\n",
      "Epoch : 739/2000 data_batch_4,  Train_loss : 5337.1450  Test_loss : 5126.0928, Time/batch_file : 2.2844, Training time: 8583.6455\n",
      "Epoch : 739/2000 data_batch_5,  Train_loss : 5199.7666  Test_loss : 5216.4761, Time/batch_file : 2.2617, Training time: 8585.9075\n",
      "Epoch : 740/2000 data_batch_1,  Train_loss : 5194.0576  Test_loss : 5150.3877, Time/batch_file : 2.3073, Training time: 8588.2150\n",
      "Epoch : 740/2000 data_batch_2,  Train_loss : 5009.4585  Test_loss : 5135.5933, Time/batch_file : 2.2922, Training time: 8590.5076\n",
      "Epoch : 740/2000 data_batch_3,  Train_loss : 5351.9189  Test_loss : 5064.8291, Time/batch_file : 2.3030, Training time: 8592.8108\n",
      "Epoch : 740/2000 data_batch_4,  Train_loss : 5368.1533  Test_loss : 5158.8691, Time/batch_file : 2.2947, Training time: 8595.1056\n",
      "Epoch : 740/2000 data_batch_5,  Train_loss : 4886.2471  Test_loss : 5193.8750, Time/batch_file : 2.3010, Training time: 8597.4069\n",
      "[./nets/net-740.ckpt] SAVED\n",
      "Epoch : 741/2000 data_batch_1,  Train_loss : 4693.7773  Test_loss : 5036.5879, Time/batch_file : 2.2622, Training time: 8600.9377\n",
      "Epoch : 741/2000 data_batch_2,  Train_loss : 4802.6055  Test_loss : 5025.4302, Time/batch_file : 2.2600, Training time: 8603.1979\n",
      "Epoch : 741/2000 data_batch_3,  Train_loss : 4541.7437  Test_loss : 5539.1172, Time/batch_file : 2.2630, Training time: 8605.4611\n",
      "Epoch : 741/2000 data_batch_4,  Train_loss : 4642.8916  Test_loss : 5382.0259, Time/batch_file : 2.2511, Training time: 8607.7125\n",
      "Epoch : 741/2000 data_batch_5,  Train_loss : 4696.5327  Test_loss : 4999.0942, Time/batch_file : 2.2502, Training time: 8609.9629\n",
      "Epoch : 742/2000 data_batch_1,  Train_loss : 5300.0781  Test_loss : 5307.6914, Time/batch_file : 2.2548, Training time: 8612.2180\n",
      "Epoch : 742/2000 data_batch_2,  Train_loss : 5234.3359  Test_loss : 5073.8804, Time/batch_file : 2.2626, Training time: 8614.4807\n",
      "Epoch : 742/2000 data_batch_3,  Train_loss : 5280.3857  Test_loss : 5051.7803, Time/batch_file : 2.2692, Training time: 8616.7501\n",
      "Epoch : 742/2000 data_batch_4,  Train_loss : 5134.6416  Test_loss : 5211.1050, Time/batch_file : 2.2576, Training time: 8619.0079\n",
      "Epoch : 742/2000 data_batch_5,  Train_loss : 5310.6753  Test_loss : 5069.8594, Time/batch_file : 2.2603, Training time: 8621.2684\n",
      "Epoch : 743/2000 data_batch_1,  Train_loss : 4977.9053  Test_loss : 5700.7959, Time/batch_file : 2.2707, Training time: 8623.5392\n",
      "Epoch : 743/2000 data_batch_2,  Train_loss : 5067.9678  Test_loss : 5570.8540, Time/batch_file : 2.2812, Training time: 8625.8206\n",
      "Epoch : 743/2000 data_batch_3,  Train_loss : 5091.2871  Test_loss : 5345.2783, Time/batch_file : 2.2765, Training time: 8628.0973\n",
      "Epoch : 743/2000 data_batch_4,  Train_loss : 4958.7173  Test_loss : 5764.3218, Time/batch_file : 2.2767, Training time: 8630.3743\n",
      "Epoch : 743/2000 data_batch_5,  Train_loss : 4902.2998  Test_loss : 5811.9053, Time/batch_file : 2.2756, Training time: 8632.6501\n",
      "Epoch : 744/2000 data_batch_1,  Train_loss : 4736.8794  Test_loss : 4867.1274, Time/batch_file : 2.2727, Training time: 8634.9230\n",
      "Epoch : 744/2000 data_batch_2,  Train_loss : 4298.4976  Test_loss : 5084.3193, Time/batch_file : 2.2629, Training time: 8637.1861\n",
      "Epoch : 744/2000 data_batch_3,  Train_loss : 4752.3389  Test_loss : 4839.7305, Time/batch_file : 2.2691, Training time: 8639.4555\n",
      "Epoch : 744/2000 data_batch_4,  Train_loss : 4567.1133  Test_loss : 4802.0010, Time/batch_file : 2.2669, Training time: 8641.7226\n",
      "Epoch : 744/2000 data_batch_5,  Train_loss : 4273.3481  Test_loss : 4890.0615, Time/batch_file : 2.2725, Training time: 8643.9954\n",
      "Epoch : 745/2000 data_batch_1,  Train_loss : 5451.2822  Test_loss : 5006.1411, Time/batch_file : 2.2599, Training time: 8646.2555\n",
      "Epoch : 745/2000 data_batch_2,  Train_loss : 5641.4414  Test_loss : 5194.3179, Time/batch_file : 2.2790, Training time: 8648.5346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 745/2000 data_batch_3,  Train_loss : 5598.0347  Test_loss : 5190.9331, Time/batch_file : 2.2668, Training time: 8650.8016\n",
      "Epoch : 745/2000 data_batch_4,  Train_loss : 5228.3652  Test_loss : 5396.7725, Time/batch_file : 2.2866, Training time: 8653.0883\n",
      "Epoch : 745/2000 data_batch_5,  Train_loss : 5434.2920  Test_loss : 5191.8477, Time/batch_file : 2.2692, Training time: 8655.3577\n",
      "Epoch : 746/2000 data_batch_1,  Train_loss : 5227.8057  Test_loss : 5109.9570, Time/batch_file : 2.2857, Training time: 8657.6436\n",
      "Epoch : 746/2000 data_batch_2,  Train_loss : 5461.0229  Test_loss : 5092.9326, Time/batch_file : 2.2755, Training time: 8659.9193\n",
      "Epoch : 746/2000 data_batch_3,  Train_loss : 5442.4658  Test_loss : 5217.8809, Time/batch_file : 2.2834, Training time: 8662.2029\n",
      "Epoch : 746/2000 data_batch_4,  Train_loss : 5198.6265  Test_loss : 4888.2686, Time/batch_file : 2.2787, Training time: 8664.4817\n",
      "Epoch : 746/2000 data_batch_5,  Train_loss : 5424.7832  Test_loss : 5515.0942, Time/batch_file : 2.2835, Training time: 8666.7654\n",
      "Epoch : 747/2000 data_batch_1,  Train_loss : 5086.3066  Test_loss : 5211.1201, Time/batch_file : 2.2587, Training time: 8669.0243\n",
      "Epoch : 747/2000 data_batch_2,  Train_loss : 4683.7881  Test_loss : 5291.0337, Time/batch_file : 2.2729, Training time: 8671.2974\n",
      "Epoch : 747/2000 data_batch_3,  Train_loss : 4976.5552  Test_loss : 5206.9814, Time/batch_file : 2.2622, Training time: 8673.5597\n",
      "Epoch : 747/2000 data_batch_4,  Train_loss : 5253.0845  Test_loss : 5137.0913, Time/batch_file : 2.2680, Training time: 8675.8279\n",
      "Epoch : 747/2000 data_batch_5,  Train_loss : 5072.7861  Test_loss : 5228.9653, Time/batch_file : 2.2694, Training time: 8678.0976\n",
      "Epoch : 748/2000 data_batch_1,  Train_loss : 5386.7051  Test_loss : 5320.2246, Time/batch_file : 2.2770, Training time: 8680.3748\n",
      "Epoch : 748/2000 data_batch_2,  Train_loss : 5285.2217  Test_loss : 5792.0869, Time/batch_file : 2.2718, Training time: 8682.6468\n",
      "Epoch : 748/2000 data_batch_3,  Train_loss : 5528.6113  Test_loss : 5661.3628, Time/batch_file : 2.2782, Training time: 8684.9252\n",
      "Epoch : 748/2000 data_batch_4,  Train_loss : 5456.9307  Test_loss : 5309.4170, Time/batch_file : 2.2603, Training time: 8687.1857\n",
      "Epoch : 748/2000 data_batch_5,  Train_loss : 5423.6895  Test_loss : 5383.4668, Time/batch_file : 2.2890, Training time: 8689.4749\n",
      "Epoch : 749/2000 data_batch_1,  Train_loss : 5278.7588  Test_loss : 5415.9668, Time/batch_file : 2.2636, Training time: 8691.7386\n",
      "Epoch : 749/2000 data_batch_2,  Train_loss : 5544.3887  Test_loss : 5188.1523, Time/batch_file : 2.2882, Training time: 8694.0269\n",
      "Epoch : 749/2000 data_batch_3,  Train_loss : 5459.5244  Test_loss : 5300.1416, Time/batch_file : 2.2698, Training time: 8696.2969\n",
      "Epoch : 749/2000 data_batch_4,  Train_loss : 5383.8936  Test_loss : 5030.6699, Time/batch_file : 2.2819, Training time: 8698.5790\n",
      "Epoch : 749/2000 data_batch_5,  Train_loss : 5320.7559  Test_loss : 5184.8452, Time/batch_file : 2.2700, Training time: 8700.8492\n",
      "Epoch : 750/2000 data_batch_1,  Train_loss : 4565.8086  Test_loss : 5342.8691, Time/batch_file : 2.2801, Training time: 8703.1296\n",
      "Epoch : 750/2000 data_batch_2,  Train_loss : 4965.0908  Test_loss : 5444.3867, Time/batch_file : 2.2678, Training time: 8705.3976\n",
      "Epoch : 750/2000 data_batch_3,  Train_loss : 4744.6680  Test_loss : 5025.2788, Time/batch_file : 2.2805, Training time: 8707.6784\n",
      "Epoch : 750/2000 data_batch_4,  Train_loss : 4700.7700  Test_loss : 5601.7168, Time/batch_file : 2.2708, Training time: 8709.9494\n",
      "Epoch : 750/2000 data_batch_5,  Train_loss : 4500.0000  Test_loss : 5500.5000, Time/batch_file : 2.2887, Training time: 8712.2383\n",
      "[./nets/net-750.ckpt] SAVED\n",
      "Epoch : 751/2000 data_batch_1,  Train_loss : 4906.7085  Test_loss : 5523.7471, Time/batch_file : 2.3069, Training time: 8715.8219\n",
      "Epoch : 751/2000 data_batch_2,  Train_loss : 4675.7427  Test_loss : 5381.8105, Time/batch_file : 2.3140, Training time: 8718.1361\n",
      "Epoch : 751/2000 data_batch_3,  Train_loss : 4684.4736  Test_loss : 5860.1221, Time/batch_file : 2.3189, Training time: 8720.4552\n",
      "Epoch : 751/2000 data_batch_4,  Train_loss : 4362.0884  Test_loss : 5547.8081, Time/batch_file : 2.2836, Training time: 8722.7390\n",
      "Epoch : 751/2000 data_batch_5,  Train_loss : 4473.6719  Test_loss : 5601.0693, Time/batch_file : 2.2769, Training time: 8725.0161\n",
      "Epoch : 752/2000 data_batch_1,  Train_loss : 4952.2002  Test_loss : 5719.3491, Time/batch_file : 2.2706, Training time: 8727.2870\n",
      "Epoch : 752/2000 data_batch_2,  Train_loss : 4903.0195  Test_loss : 5463.6348, Time/batch_file : 2.2833, Training time: 8729.5706\n",
      "Epoch : 752/2000 data_batch_3,  Train_loss : 4923.9907  Test_loss : 5525.8354, Time/batch_file : 2.2864, Training time: 8731.8572\n",
      "Epoch : 752/2000 data_batch_4,  Train_loss : 4947.1685  Test_loss : 5674.7832, Time/batch_file : 2.2766, Training time: 8734.1340\n",
      "Epoch : 752/2000 data_batch_5,  Train_loss : 4691.3418  Test_loss : 5475.3774, Time/batch_file : 2.2729, Training time: 8736.4071\n",
      "Epoch : 753/2000 data_batch_1,  Train_loss : 5431.4736  Test_loss : 5232.2949, Time/batch_file : 2.2765, Training time: 8738.6839\n",
      "Epoch : 753/2000 data_batch_2,  Train_loss : 5544.5947  Test_loss : 5309.7432, Time/batch_file : 2.2760, Training time: 8740.9601\n",
      "Epoch : 753/2000 data_batch_3,  Train_loss : 5433.8433  Test_loss : 5012.2192, Time/batch_file : 2.2867, Training time: 8743.2470\n",
      "Epoch : 753/2000 data_batch_4,  Train_loss : 5446.3906  Test_loss : 5399.6689, Time/batch_file : 2.2706, Training time: 8745.5177\n",
      "Epoch : 753/2000 data_batch_5,  Train_loss : 5535.3525  Test_loss : 5449.8662, Time/batch_file : 2.2802, Training time: 8747.7981\n",
      "Epoch : 754/2000 data_batch_1,  Train_loss : 5348.1807  Test_loss : 4942.6885, Time/batch_file : 2.2935, Training time: 8750.0918\n",
      "Epoch : 754/2000 data_batch_2,  Train_loss : 5466.0225  Test_loss : 5193.5557, Time/batch_file : 2.2822, Training time: 8752.3743\n",
      "Epoch : 754/2000 data_batch_3,  Train_loss : 5357.2588  Test_loss : 5183.2051, Time/batch_file : 2.2893, Training time: 8754.6638\n",
      "Epoch : 754/2000 data_batch_4,  Train_loss : 5522.0693  Test_loss : 4988.2051, Time/batch_file : 2.2860, Training time: 8756.9500\n",
      "Epoch : 754/2000 data_batch_5,  Train_loss : 5195.7334  Test_loss : 4934.0542, Time/batch_file : 2.2856, Training time: 8759.2358\n",
      "Epoch : 755/2000 data_batch_1,  Train_loss : 5612.7114  Test_loss : 5279.4238, Time/batch_file : 2.2734, Training time: 8761.5094\n",
      "Epoch : 755/2000 data_batch_2,  Train_loss : 5488.3242  Test_loss : 5293.6826, Time/batch_file : 2.2768, Training time: 8763.7864\n",
      "Epoch : 755/2000 data_batch_3,  Train_loss : 5397.3735  Test_loss : 5583.2197, Time/batch_file : 2.2860, Training time: 8766.0726\n",
      "Epoch : 755/2000 data_batch_4,  Train_loss : 5216.8408  Test_loss : 5471.2998, Time/batch_file : 2.2896, Training time: 8768.3624\n",
      "Epoch : 755/2000 data_batch_5,  Train_loss : 5322.5020  Test_loss : 5485.4634, Time/batch_file : 2.2873, Training time: 8770.6501\n",
      "Epoch : 756/2000 data_batch_1,  Train_loss : 5031.1230  Test_loss : 5482.6562, Time/batch_file : 2.2759, Training time: 8772.9261\n",
      "Epoch : 756/2000 data_batch_2,  Train_loss : 5227.8164  Test_loss : 5525.9600, Time/batch_file : 2.2806, Training time: 8775.2068\n",
      "Epoch : 756/2000 data_batch_3,  Train_loss : 4884.1030  Test_loss : 5425.1504, Time/batch_file : 2.2931, Training time: 8777.5000\n",
      "Epoch : 756/2000 data_batch_4,  Train_loss : 5082.0811  Test_loss : 5599.3330, Time/batch_file : 2.2856, Training time: 8779.7860\n",
      "Epoch : 756/2000 data_batch_5,  Train_loss : 5346.7290  Test_loss : 5566.6533, Time/batch_file : 2.2714, Training time: 8782.0575\n",
      "Epoch : 757/2000 data_batch_1,  Train_loss : 5385.5439  Test_loss : 5525.1924, Time/batch_file : 2.2857, Training time: 8784.3435\n",
      "Epoch : 757/2000 data_batch_2,  Train_loss : 4891.4126  Test_loss : 5582.0034, Time/batch_file : 2.2788, Training time: 8786.6225\n",
      "Epoch : 757/2000 data_batch_3,  Train_loss : 4991.4639  Test_loss : 5545.9541, Time/batch_file : 2.2909, Training time: 8788.9136\n",
      "Epoch : 757/2000 data_batch_4,  Train_loss : 5072.0762  Test_loss : 5647.4619, Time/batch_file : 2.2981, Training time: 8791.2118\n",
      "Epoch : 757/2000 data_batch_5,  Train_loss : 5215.7046  Test_loss : 5654.4614, Time/batch_file : 2.2931, Training time: 8793.5051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 758/2000 data_batch_1,  Train_loss : 5281.6982  Test_loss : 5452.5674, Time/batch_file : 2.2869, Training time: 8795.7922\n",
      "Epoch : 758/2000 data_batch_2,  Train_loss : 5170.4717  Test_loss : 5530.2778, Time/batch_file : 2.2787, Training time: 8798.0712\n",
      "Epoch : 758/2000 data_batch_3,  Train_loss : 5388.8135  Test_loss : 5593.0693, Time/batch_file : 2.2806, Training time: 8800.3520\n",
      "Epoch : 758/2000 data_batch_4,  Train_loss : 5220.8843  Test_loss : 5613.2188, Time/batch_file : 2.2849, Training time: 8802.6371\n",
      "Epoch : 758/2000 data_batch_5,  Train_loss : 5263.9746  Test_loss : 5432.5342, Time/batch_file : 2.2944, Training time: 8804.9316\n",
      "Epoch : 759/2000 data_batch_1,  Train_loss : 4810.3560  Test_loss : 5552.1035, Time/batch_file : 2.2813, Training time: 8807.2130\n",
      "Epoch : 759/2000 data_batch_2,  Train_loss : 5142.4053  Test_loss : 5200.8940, Time/batch_file : 2.2692, Training time: 8809.4825\n",
      "Epoch : 759/2000 data_batch_3,  Train_loss : 5168.8901  Test_loss : 5390.3071, Time/batch_file : 2.2837, Training time: 8811.7664\n",
      "Epoch : 759/2000 data_batch_4,  Train_loss : 5436.9336  Test_loss : 5382.3540, Time/batch_file : 2.2834, Training time: 8814.0500\n",
      "Epoch : 759/2000 data_batch_5,  Train_loss : 5018.8779  Test_loss : 5397.0356, Time/batch_file : 2.2672, Training time: 8816.3174\n",
      "Epoch : 760/2000 data_batch_1,  Train_loss : 5041.0176  Test_loss : 5188.1802, Time/batch_file : 2.2788, Training time: 8818.5964\n",
      "Epoch : 760/2000 data_batch_2,  Train_loss : 4759.9346  Test_loss : 5288.1226, Time/batch_file : 2.2847, Training time: 8820.8813\n",
      "Epoch : 760/2000 data_batch_3,  Train_loss : 5283.9639  Test_loss : 5413.3623, Time/batch_file : 2.2682, Training time: 8823.1497\n",
      "Epoch : 760/2000 data_batch_4,  Train_loss : 5118.2417  Test_loss : 4900.5015, Time/batch_file : 2.2834, Training time: 8825.4333\n",
      "Epoch : 760/2000 data_batch_5,  Train_loss : 5100.2910  Test_loss : 5229.8042, Time/batch_file : 2.2733, Training time: 8827.7068\n",
      "[./nets/net-760.ckpt] SAVED\n",
      "Epoch : 761/2000 data_batch_1,  Train_loss : 4873.4683  Test_loss : 5338.9272, Time/batch_file : 2.2911, Training time: 8831.2658\n",
      "Epoch : 761/2000 data_batch_2,  Train_loss : 5050.8101  Test_loss : 5331.1406, Time/batch_file : 2.2934, Training time: 8833.5594\n",
      "Epoch : 761/2000 data_batch_3,  Train_loss : 5122.3530  Test_loss : 5182.6426, Time/batch_file : 2.2725, Training time: 8835.8322\n",
      "Epoch : 761/2000 data_batch_4,  Train_loss : 5023.4482  Test_loss : 5271.1738, Time/batch_file : 2.2936, Training time: 8838.1260\n",
      "Epoch : 761/2000 data_batch_5,  Train_loss : 5104.5850  Test_loss : 5423.2207, Time/batch_file : 2.3123, Training time: 8840.4385\n",
      "Epoch : 762/2000 data_batch_1,  Train_loss : 5520.7451  Test_loss : 5305.4048, Time/batch_file : 2.2707, Training time: 8842.7095\n",
      "Epoch : 762/2000 data_batch_2,  Train_loss : 5659.6421  Test_loss : 5218.7051, Time/batch_file : 2.3058, Training time: 8845.0154\n",
      "Epoch : 762/2000 data_batch_3,  Train_loss : 5557.8218  Test_loss : 5342.7314, Time/batch_file : 2.2728, Training time: 8847.2885\n",
      "Epoch : 762/2000 data_batch_4,  Train_loss : 5294.2266  Test_loss : 5150.5713, Time/batch_file : 2.3078, Training time: 8849.5964\n",
      "Epoch : 762/2000 data_batch_5,  Train_loss : 5321.1006  Test_loss : 5385.6772, Time/batch_file : 2.2758, Training time: 8851.8724\n",
      "Epoch : 763/2000 data_batch_1,  Train_loss : 5285.3945  Test_loss : 5249.1826, Time/batch_file : 2.3049, Training time: 8854.1776\n",
      "Epoch : 763/2000 data_batch_2,  Train_loss : 5322.4248  Test_loss : 5110.5522, Time/batch_file : 2.2770, Training time: 8856.4547\n",
      "Epoch : 763/2000 data_batch_3,  Train_loss : 5450.8135  Test_loss : 5181.6011, Time/batch_file : 2.3141, Training time: 8858.7691\n",
      "Epoch : 763/2000 data_batch_4,  Train_loss : 5092.8281  Test_loss : 5231.4795, Time/batch_file : 2.2774, Training time: 8861.0468\n",
      "Epoch : 763/2000 data_batch_5,  Train_loss : 4898.1621  Test_loss : 4975.2534, Time/batch_file : 2.3143, Training time: 8863.3613\n",
      "Epoch : 764/2000 data_batch_1,  Train_loss : 5314.5625  Test_loss : 5298.9531, Time/batch_file : 2.2746, Training time: 8865.6361\n",
      "Epoch : 764/2000 data_batch_2,  Train_loss : 5377.0039  Test_loss : 4956.3530, Time/batch_file : 2.3105, Training time: 8867.9468\n",
      "Epoch : 764/2000 data_batch_3,  Train_loss : 5416.7646  Test_loss : 5078.9277, Time/batch_file : 2.2908, Training time: 8870.2378\n",
      "Epoch : 764/2000 data_batch_4,  Train_loss : 5358.6372  Test_loss : 5395.1255, Time/batch_file : 2.3055, Training time: 8872.5434\n",
      "Epoch : 764/2000 data_batch_5,  Train_loss : 5237.8164  Test_loss : 5398.5903, Time/batch_file : 2.2861, Training time: 8874.8298\n",
      "Epoch : 765/2000 data_batch_1,  Train_loss : 5344.2979  Test_loss : 5186.4053, Time/batch_file : 2.3100, Training time: 8877.1400\n",
      "Epoch : 765/2000 data_batch_2,  Train_loss : 5268.1279  Test_loss : 5570.8730, Time/batch_file : 2.2809, Training time: 8879.4211\n",
      "Epoch : 765/2000 data_batch_3,  Train_loss : 5432.3721  Test_loss : 5133.6855, Time/batch_file : 2.3037, Training time: 8881.7248\n",
      "Epoch : 765/2000 data_batch_4,  Train_loss : 5575.9756  Test_loss : 5323.0605, Time/batch_file : 2.2815, Training time: 8884.0065\n",
      "Epoch : 765/2000 data_batch_5,  Train_loss : 5152.6660  Test_loss : 5672.8286, Time/batch_file : 2.3090, Training time: 8886.3156\n",
      "Epoch : 766/2000 data_batch_1,  Train_loss : 5325.5371  Test_loss : 5783.7217, Time/batch_file : 2.2923, Training time: 8888.6082\n",
      "Epoch : 766/2000 data_batch_2,  Train_loss : 5203.7559  Test_loss : 5446.2183, Time/batch_file : 2.3149, Training time: 8890.9233\n",
      "Epoch : 766/2000 data_batch_3,  Train_loss : 5308.0933  Test_loss : 5469.4009, Time/batch_file : 2.2841, Training time: 8893.2076\n",
      "Epoch : 766/2000 data_batch_4,  Train_loss : 5200.6631  Test_loss : 5589.2026, Time/batch_file : 2.3168, Training time: 8895.5246\n",
      "Epoch : 766/2000 data_batch_5,  Train_loss : 5251.6816  Test_loss : 5341.1328, Time/batch_file : 2.2911, Training time: 8897.8159\n",
      "Epoch : 767/2000 data_batch_1,  Train_loss : 4707.8018  Test_loss : 5391.7334, Time/batch_file : 2.3051, Training time: 8900.1212\n",
      "Epoch : 767/2000 data_batch_2,  Train_loss : 4551.9312  Test_loss : 5126.5649, Time/batch_file : 2.2724, Training time: 8902.3938\n",
      "Epoch : 767/2000 data_batch_3,  Train_loss : 4637.0195  Test_loss : 5364.7900, Time/batch_file : 2.2980, Training time: 8904.6920\n",
      "Epoch : 767/2000 data_batch_4,  Train_loss : 4426.0244  Test_loss : 5158.8262, Time/batch_file : 2.2691, Training time: 8906.9612\n",
      "Epoch : 767/2000 data_batch_5,  Train_loss : 4684.7061  Test_loss : 5388.5488, Time/batch_file : 2.3029, Training time: 8909.2644\n",
      "Epoch : 768/2000 data_batch_1,  Train_loss : 5069.6221  Test_loss : 5873.8022, Time/batch_file : 2.2695, Training time: 8911.5341\n",
      "Epoch : 768/2000 data_batch_2,  Train_loss : 4976.2402  Test_loss : 5640.8530, Time/batch_file : 2.3017, Training time: 8913.8360\n",
      "Epoch : 768/2000 data_batch_3,  Train_loss : 4877.8027  Test_loss : 5654.6719, Time/batch_file : 2.2745, Training time: 8916.1107\n",
      "Epoch : 768/2000 data_batch_4,  Train_loss : 4834.4688  Test_loss : 5926.6953, Time/batch_file : 2.3024, Training time: 8918.4133\n",
      "Epoch : 768/2000 data_batch_5,  Train_loss : 5081.3486  Test_loss : 6045.0967, Time/batch_file : 2.2684, Training time: 8920.6819\n",
      "Epoch : 769/2000 data_batch_1,  Train_loss : 4494.1689  Test_loss : 5148.6025, Time/batch_file : 2.2973, Training time: 8922.9793\n",
      "Epoch : 769/2000 data_batch_2,  Train_loss : 4593.9297  Test_loss : 5364.2808, Time/batch_file : 2.2673, Training time: 8925.2469\n",
      "Epoch : 769/2000 data_batch_3,  Train_loss : 4568.3457  Test_loss : 5184.8467, Time/batch_file : 2.2970, Training time: 8927.5441\n",
      "Epoch : 769/2000 data_batch_4,  Train_loss : 4393.2695  Test_loss : 5686.7905, Time/batch_file : 2.2655, Training time: 8929.8099\n",
      "Epoch : 769/2000 data_batch_5,  Train_loss : 4291.2178  Test_loss : 5143.3779, Time/batch_file : 2.3058, Training time: 8932.1159\n",
      "Epoch : 770/2000 data_batch_1,  Train_loss : 4907.5356  Test_loss : 5527.2651, Time/batch_file : 2.2847, Training time: 8934.4008\n",
      "Epoch : 770/2000 data_batch_2,  Train_loss : 4992.8213  Test_loss : 5531.4658, Time/batch_file : 2.3310, Training time: 8936.7320\n",
      "Epoch : 770/2000 data_batch_3,  Train_loss : 4699.8408  Test_loss : 5608.3379, Time/batch_file : 2.3005, Training time: 8939.0326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 770/2000 data_batch_4,  Train_loss : 5099.3389  Test_loss : 5454.6523, Time/batch_file : 2.3159, Training time: 8941.3487\n",
      "Epoch : 770/2000 data_batch_5,  Train_loss : 5144.0508  Test_loss : 5810.8555, Time/batch_file : 2.2950, Training time: 8943.6438\n",
      "[./nets/net-770.ckpt] SAVED\n",
      "Epoch : 771/2000 data_batch_1,  Train_loss : 5086.7520  Test_loss : 5390.0547, Time/batch_file : 2.2865, Training time: 8947.1901\n",
      "Epoch : 771/2000 data_batch_2,  Train_loss : 5001.4995  Test_loss : 5042.7998, Time/batch_file : 2.2756, Training time: 8949.4658\n",
      "Epoch : 771/2000 data_batch_3,  Train_loss : 5451.1709  Test_loss : 5450.4482, Time/batch_file : 2.2711, Training time: 8951.7372\n",
      "Epoch : 771/2000 data_batch_4,  Train_loss : 5128.0249  Test_loss : 5406.9482, Time/batch_file : 2.2790, Training time: 8954.0164\n",
      "Epoch : 771/2000 data_batch_5,  Train_loss : 5280.1230  Test_loss : 5608.0273, Time/batch_file : 2.2754, Training time: 8956.2920\n",
      "Epoch : 772/2000 data_batch_1,  Train_loss : 5223.9927  Test_loss : 4648.1382, Time/batch_file : 2.2696, Training time: 8958.5617\n",
      "Epoch : 772/2000 data_batch_2,  Train_loss : 5205.3350  Test_loss : 4739.2603, Time/batch_file : 2.2783, Training time: 8960.8402\n",
      "Epoch : 772/2000 data_batch_3,  Train_loss : 5186.7930  Test_loss : 4920.5845, Time/batch_file : 2.2640, Training time: 8963.1044\n",
      "Epoch : 772/2000 data_batch_4,  Train_loss : 5333.4160  Test_loss : 4716.7690, Time/batch_file : 2.2744, Training time: 8965.3790\n",
      "Epoch : 772/2000 data_batch_5,  Train_loss : 5504.0200  Test_loss : 4790.8848, Time/batch_file : 2.2622, Training time: 8967.6415\n",
      "Epoch : 773/2000 data_batch_1,  Train_loss : 4864.9727  Test_loss : 5619.0938, Time/batch_file : 2.2766, Training time: 8969.9182\n",
      "Epoch : 773/2000 data_batch_2,  Train_loss : 5055.6191  Test_loss : 5532.9302, Time/batch_file : 2.2657, Training time: 8972.1842\n",
      "Epoch : 773/2000 data_batch_3,  Train_loss : 5056.1914  Test_loss : 5610.0903, Time/batch_file : 2.2716, Training time: 8974.4560\n",
      "Epoch : 773/2000 data_batch_4,  Train_loss : 5034.2192  Test_loss : 5500.1392, Time/batch_file : 2.2614, Training time: 8976.7176\n",
      "Epoch : 773/2000 data_batch_5,  Train_loss : 5015.4473  Test_loss : 5497.5776, Time/batch_file : 2.2776, Training time: 8978.9954\n",
      "Epoch : 774/2000 data_batch_1,  Train_loss : 4734.9053  Test_loss : 5035.1533, Time/batch_file : 2.2928, Training time: 8981.2885\n",
      "Epoch : 774/2000 data_batch_2,  Train_loss : 4744.3916  Test_loss : 5085.5957, Time/batch_file : 2.2803, Training time: 8983.5689\n",
      "Epoch : 774/2000 data_batch_3,  Train_loss : 4728.9707  Test_loss : 5089.5405, Time/batch_file : 2.2776, Training time: 8985.8467\n",
      "Epoch : 774/2000 data_batch_4,  Train_loss : 4639.4551  Test_loss : 5163.0391, Time/batch_file : 2.2905, Training time: 8988.1374\n",
      "Epoch : 774/2000 data_batch_5,  Train_loss : 4444.1860  Test_loss : 4967.2812, Time/batch_file : 2.2621, Training time: 8990.3997\n",
      "Epoch : 775/2000 data_batch_1,  Train_loss : 4774.9976  Test_loss : 5452.2529, Time/batch_file : 2.2732, Training time: 8992.6730\n",
      "Epoch : 775/2000 data_batch_2,  Train_loss : 4710.0527  Test_loss : 5287.9429, Time/batch_file : 2.2536, Training time: 8994.9269\n",
      "Epoch : 775/2000 data_batch_3,  Train_loss : 4900.4946  Test_loss : 5201.1182, Time/batch_file : 2.2598, Training time: 8997.1869\n",
      "Epoch : 775/2000 data_batch_4,  Train_loss : 4685.0249  Test_loss : 5497.7334, Time/batch_file : 2.2632, Training time: 8999.4503\n",
      "Epoch : 775/2000 data_batch_5,  Train_loss : 4708.6055  Test_loss : 5412.0352, Time/batch_file : 2.2496, Training time: 9001.7000\n",
      "Epoch : 776/2000 data_batch_1,  Train_loss : 5494.3682  Test_loss : 5568.7637, Time/batch_file : 2.2765, Training time: 9003.9767\n",
      "Epoch : 776/2000 data_batch_2,  Train_loss : 5205.9692  Test_loss : 5373.6924, Time/batch_file : 2.2673, Training time: 9006.2443\n",
      "Epoch : 776/2000 data_batch_3,  Train_loss : 5206.7095  Test_loss : 5596.5767, Time/batch_file : 2.2693, Training time: 9008.5138\n",
      "Epoch : 776/2000 data_batch_4,  Train_loss : 4909.3130  Test_loss : 5242.6738, Time/batch_file : 2.2681, Training time: 9010.7820\n",
      "Epoch : 776/2000 data_batch_5,  Train_loss : 5037.7930  Test_loss : 5292.0801, Time/batch_file : 2.2657, Training time: 9013.0478\n",
      "Epoch : 777/2000 data_batch_1,  Train_loss : 4697.7588  Test_loss : 5103.4326, Time/batch_file : 2.2736, Training time: 9015.3216\n",
      "Epoch : 777/2000 data_batch_2,  Train_loss : 5189.2695  Test_loss : 5065.1436, Time/batch_file : 2.2522, Training time: 9017.5740\n",
      "Epoch : 777/2000 data_batch_3,  Train_loss : 4916.5342  Test_loss : 5037.9824, Time/batch_file : 2.2656, Training time: 9019.8398\n",
      "Epoch : 777/2000 data_batch_4,  Train_loss : 5227.7231  Test_loss : 4831.2388, Time/batch_file : 2.2620, Training time: 9022.1021\n",
      "Epoch : 777/2000 data_batch_5,  Train_loss : 4882.4702  Test_loss : 4702.8071, Time/batch_file : 2.2607, Training time: 9024.3629\n",
      "Epoch : 778/2000 data_batch_1,  Train_loss : 4620.6973  Test_loss : 5598.3726, Time/batch_file : 2.2646, Training time: 9026.6277\n",
      "Epoch : 778/2000 data_batch_2,  Train_loss : 4590.4233  Test_loss : 5685.4702, Time/batch_file : 2.2822, Training time: 9028.9101\n",
      "Epoch : 778/2000 data_batch_3,  Train_loss : 4584.1240  Test_loss : 5630.9326, Time/batch_file : 2.2660, Training time: 9031.1763\n",
      "Epoch : 778/2000 data_batch_4,  Train_loss : 4896.2681  Test_loss : 5767.0562, Time/batch_file : 2.2633, Training time: 9033.4398\n",
      "Epoch : 778/2000 data_batch_5,  Train_loss : 4703.3027  Test_loss : 5634.0542, Time/batch_file : 2.2658, Training time: 9035.7058\n",
      "Epoch : 779/2000 data_batch_1,  Train_loss : 5096.5410  Test_loss : 5545.4961, Time/batch_file : 2.2620, Training time: 9037.9681\n",
      "Epoch : 779/2000 data_batch_2,  Train_loss : 5031.1772  Test_loss : 5189.1284, Time/batch_file : 2.2571, Training time: 9040.2254\n",
      "Epoch : 779/2000 data_batch_3,  Train_loss : 5120.4746  Test_loss : 5122.3564, Time/batch_file : 2.2537, Training time: 9042.4793\n",
      "Epoch : 779/2000 data_batch_4,  Train_loss : 4839.4756  Test_loss : 5220.7041, Time/batch_file : 2.2619, Training time: 9044.7414\n",
      "Epoch : 779/2000 data_batch_5,  Train_loss : 4899.6055  Test_loss : 5270.2969, Time/batch_file : 2.2553, Training time: 9046.9970\n",
      "Epoch : 780/2000 data_batch_1,  Train_loss : 4953.0317  Test_loss : 5404.0283, Time/batch_file : 2.2553, Training time: 9049.2524\n",
      "Epoch : 780/2000 data_batch_2,  Train_loss : 4890.3569  Test_loss : 5586.2954, Time/batch_file : 2.2508, Training time: 9051.5034\n",
      "Epoch : 780/2000 data_batch_3,  Train_loss : 4746.9062  Test_loss : 5496.2812, Time/batch_file : 2.2508, Training time: 9053.7544\n",
      "Epoch : 780/2000 data_batch_4,  Train_loss : 4620.1152  Test_loss : 5519.1816, Time/batch_file : 2.2579, Training time: 9056.0124\n",
      "Epoch : 780/2000 data_batch_5,  Train_loss : 4742.3013  Test_loss : 5473.0503, Time/batch_file : 2.2729, Training time: 9058.2855\n",
      "[./nets/net-780.ckpt] SAVED\n",
      "Epoch : 781/2000 data_batch_1,  Train_loss : 4619.1626  Test_loss : 5493.6851, Time/batch_file : 2.2829, Training time: 9061.8429\n",
      "Epoch : 781/2000 data_batch_2,  Train_loss : 4519.7632  Test_loss : 5583.5903, Time/batch_file : 2.2792, Training time: 9064.1223\n",
      "Epoch : 781/2000 data_batch_3,  Train_loss : 4594.8989  Test_loss : 5746.3691, Time/batch_file : 2.2560, Training time: 9066.3785\n",
      "Epoch : 781/2000 data_batch_4,  Train_loss : 4778.3604  Test_loss : 5633.7881, Time/batch_file : 2.2731, Training time: 9068.6517\n",
      "Epoch : 781/2000 data_batch_5,  Train_loss : 5000.4399  Test_loss : 5763.3066, Time/batch_file : 2.2658, Training time: 9070.9177\n",
      "Epoch : 782/2000 data_batch_1,  Train_loss : 4848.5762  Test_loss : 5170.7134, Time/batch_file : 2.2771, Training time: 9073.1951\n",
      "Epoch : 782/2000 data_batch_2,  Train_loss : 4978.6929  Test_loss : 5056.1665, Time/batch_file : 2.2706, Training time: 9075.4659\n",
      "Epoch : 782/2000 data_batch_3,  Train_loss : 5129.4346  Test_loss : 5202.0312, Time/batch_file : 2.2768, Training time: 9077.7429\n",
      "Epoch : 782/2000 data_batch_4,  Train_loss : 5308.1924  Test_loss : 5195.1650, Time/batch_file : 2.2720, Training time: 9080.0151\n",
      "Epoch : 782/2000 data_batch_5,  Train_loss : 5251.5391  Test_loss : 5086.2583, Time/batch_file : 2.2829, Training time: 9082.2982\n",
      "Epoch : 783/2000 data_batch_1,  Train_loss : 4901.0903  Test_loss : 5511.4258, Time/batch_file : 2.2783, Training time: 9084.5767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 783/2000 data_batch_2,  Train_loss : 5023.4600  Test_loss : 5222.2510, Time/batch_file : 2.2738, Training time: 9086.8507\n",
      "Epoch : 783/2000 data_batch_3,  Train_loss : 5020.3062  Test_loss : 5515.3955, Time/batch_file : 2.2690, Training time: 9089.1199\n",
      "Epoch : 783/2000 data_batch_4,  Train_loss : 4783.6260  Test_loss : 5262.4043, Time/batch_file : 2.2675, Training time: 9091.3876\n",
      "Epoch : 783/2000 data_batch_5,  Train_loss : 4937.9404  Test_loss : 5291.1455, Time/batch_file : 2.2748, Training time: 9093.6627\n",
      "Epoch : 784/2000 data_batch_1,  Train_loss : 5007.0366  Test_loss : 4942.8589, Time/batch_file : 2.2675, Training time: 9095.9304\n",
      "Epoch : 784/2000 data_batch_2,  Train_loss : 4883.5708  Test_loss : 4954.4180, Time/batch_file : 2.2696, Training time: 9098.2001\n",
      "Epoch : 784/2000 data_batch_3,  Train_loss : 4882.4180  Test_loss : 5352.9355, Time/batch_file : 2.2754, Training time: 9100.4757\n",
      "Epoch : 784/2000 data_batch_4,  Train_loss : 4856.9185  Test_loss : 5005.6006, Time/batch_file : 2.2731, Training time: 9102.7490\n",
      "Epoch : 784/2000 data_batch_5,  Train_loss : 4870.8994  Test_loss : 4968.8369, Time/batch_file : 2.2727, Training time: 9105.0218\n",
      "Epoch : 785/2000 data_batch_1,  Train_loss : 4807.1948  Test_loss : 5320.0405, Time/batch_file : 2.2817, Training time: 9107.3038\n",
      "Epoch : 785/2000 data_batch_2,  Train_loss : 4720.1772  Test_loss : 5399.5781, Time/batch_file : 2.2812, Training time: 9109.5852\n",
      "Epoch : 785/2000 data_batch_3,  Train_loss : 4883.6074  Test_loss : 5361.2183, Time/batch_file : 2.2795, Training time: 9111.8648\n",
      "Epoch : 785/2000 data_batch_4,  Train_loss : 4703.2725  Test_loss : 5427.6670, Time/batch_file : 2.2695, Training time: 9114.1345\n",
      "Epoch : 785/2000 data_batch_5,  Train_loss : 4670.7588  Test_loss : 5055.5015, Time/batch_file : 2.2828, Training time: 9116.4174\n",
      "Epoch : 786/2000 data_batch_1,  Train_loss : 5282.4619  Test_loss : 5494.9526, Time/batch_file : 2.2733, Training time: 9118.6910\n",
      "Epoch : 786/2000 data_batch_2,  Train_loss : 5159.3047  Test_loss : 5334.7109, Time/batch_file : 2.2787, Training time: 9120.9700\n",
      "Epoch : 786/2000 data_batch_3,  Train_loss : 5155.0723  Test_loss : 5731.5889, Time/batch_file : 2.2727, Training time: 9123.2429\n",
      "Epoch : 786/2000 data_batch_4,  Train_loss : 5207.8926  Test_loss : 5097.0229, Time/batch_file : 2.2844, Training time: 9125.5275\n",
      "Epoch : 786/2000 data_batch_5,  Train_loss : 5302.3281  Test_loss : 5386.9365, Time/batch_file : 2.2700, Training time: 9127.7976\n",
      "Epoch : 787/2000 data_batch_1,  Train_loss : 5537.5493  Test_loss : 4921.2646, Time/batch_file : 2.2898, Training time: 9130.0876\n",
      "Epoch : 787/2000 data_batch_2,  Train_loss : 5379.7964  Test_loss : 4993.2734, Time/batch_file : 2.2655, Training time: 9132.3533\n",
      "Epoch : 787/2000 data_batch_3,  Train_loss : 5181.2744  Test_loss : 5069.6123, Time/batch_file : 2.2700, Training time: 9134.6235\n",
      "Epoch : 787/2000 data_batch_4,  Train_loss : 5183.1489  Test_loss : 4919.1924, Time/batch_file : 2.2766, Training time: 9136.9002\n",
      "Epoch : 787/2000 data_batch_5,  Train_loss : 5122.3389  Test_loss : 5034.8433, Time/batch_file : 2.2836, Training time: 9139.1840\n",
      "Epoch : 788/2000 data_batch_1,  Train_loss : 5119.9463  Test_loss : 5486.5674, Time/batch_file : 2.2763, Training time: 9141.4605\n",
      "Epoch : 788/2000 data_batch_2,  Train_loss : 5081.7231  Test_loss : 5461.3608, Time/batch_file : 2.2799, Training time: 9143.7407\n",
      "Epoch : 788/2000 data_batch_3,  Train_loss : 4957.7432  Test_loss : 5447.7129, Time/batch_file : 2.2636, Training time: 9146.0046\n",
      "Epoch : 788/2000 data_batch_4,  Train_loss : 5045.0537  Test_loss : 5591.0938, Time/batch_file : 2.2728, Training time: 9148.2776\n",
      "Epoch : 788/2000 data_batch_5,  Train_loss : 4845.0000  Test_loss : 5614.2891, Time/batch_file : 2.2838, Training time: 9150.5617\n",
      "Epoch : 789/2000 data_batch_1,  Train_loss : 4950.3643  Test_loss : 5452.3081, Time/batch_file : 2.2868, Training time: 9152.8487\n",
      "Epoch : 789/2000 data_batch_2,  Train_loss : 5057.1030  Test_loss : 5740.7959, Time/batch_file : 2.2933, Training time: 9155.1421\n",
      "Epoch : 789/2000 data_batch_3,  Train_loss : 4818.7764  Test_loss : 5341.9170, Time/batch_file : 2.2870, Training time: 9157.4293\n",
      "Epoch : 789/2000 data_batch_4,  Train_loss : 5096.6084  Test_loss : 5603.6548, Time/batch_file : 2.2941, Training time: 9159.7236\n",
      "Epoch : 789/2000 data_batch_5,  Train_loss : 5313.7832  Test_loss : 5877.2119, Time/batch_file : 2.2831, Training time: 9162.0069\n",
      "Epoch : 790/2000 data_batch_1,  Train_loss : 4727.5332  Test_loss : 5060.3242, Time/batch_file : 2.2946, Training time: 9164.3017\n",
      "Epoch : 790/2000 data_batch_2,  Train_loss : 4500.6572  Test_loss : 5224.7300, Time/batch_file : 2.2860, Training time: 9166.5879\n",
      "Epoch : 790/2000 data_batch_3,  Train_loss : 5049.4824  Test_loss : 5202.7261, Time/batch_file : 2.2890, Training time: 9168.8771\n",
      "Epoch : 790/2000 data_batch_4,  Train_loss : 4681.9038  Test_loss : 5264.5015, Time/batch_file : 2.2828, Training time: 9171.1601\n",
      "Epoch : 790/2000 data_batch_5,  Train_loss : 4893.6494  Test_loss : 5474.0088, Time/batch_file : 2.2872, Training time: 9173.4475\n",
      "[./nets/net-790.ckpt] SAVED\n",
      "Epoch : 791/2000 data_batch_1,  Train_loss : 5212.8530  Test_loss : 5301.6660, Time/batch_file : 2.3022, Training time: 9177.0148\n",
      "Epoch : 791/2000 data_batch_2,  Train_loss : 5150.3306  Test_loss : 5432.7847, Time/batch_file : 2.2601, Training time: 9179.2751\n",
      "Epoch : 791/2000 data_batch_3,  Train_loss : 5303.7725  Test_loss : 4951.4946, Time/batch_file : 2.2808, Training time: 9181.5561\n",
      "Epoch : 791/2000 data_batch_4,  Train_loss : 5272.9834  Test_loss : 5129.5361, Time/batch_file : 2.2648, Training time: 9183.8211\n",
      "Epoch : 791/2000 data_batch_5,  Train_loss : 4995.1670  Test_loss : 5292.4058, Time/batch_file : 2.2653, Training time: 9186.0865\n",
      "Epoch : 792/2000 data_batch_1,  Train_loss : 4939.0898  Test_loss : 4933.0029, Time/batch_file : 2.2808, Training time: 9188.3675\n",
      "Epoch : 792/2000 data_batch_2,  Train_loss : 4721.3027  Test_loss : 4942.0049, Time/batch_file : 2.2822, Training time: 9190.6498\n",
      "Epoch : 792/2000 data_batch_3,  Train_loss : 4733.3164  Test_loss : 5002.5010, Time/batch_file : 2.2702, Training time: 9192.9202\n",
      "Epoch : 792/2000 data_batch_4,  Train_loss : 4892.9131  Test_loss : 4959.7422, Time/batch_file : 2.2828, Training time: 9195.2033\n",
      "Epoch : 792/2000 data_batch_5,  Train_loss : 4980.0840  Test_loss : 4787.8882, Time/batch_file : 2.2773, Training time: 9197.4808\n",
      "Epoch : 793/2000 data_batch_1,  Train_loss : 4854.4805  Test_loss : 4826.7539, Time/batch_file : 2.2650, Training time: 9199.7461\n",
      "Epoch : 793/2000 data_batch_2,  Train_loss : 4877.2354  Test_loss : 4988.1030, Time/batch_file : 2.2536, Training time: 9201.9998\n",
      "Epoch : 793/2000 data_batch_3,  Train_loss : 4965.2065  Test_loss : 5011.8633, Time/batch_file : 2.2558, Training time: 9204.2558\n",
      "Epoch : 793/2000 data_batch_4,  Train_loss : 4637.0317  Test_loss : 4626.3213, Time/batch_file : 2.2668, Training time: 9206.5227\n",
      "Epoch : 793/2000 data_batch_5,  Train_loss : 4852.0791  Test_loss : 5074.1270, Time/batch_file : 2.2540, Training time: 9208.7769\n",
      "Epoch : 794/2000 data_batch_1,  Train_loss : 4916.4390  Test_loss : 5411.0938, Time/batch_file : 2.2719, Training time: 9211.0491\n",
      "Epoch : 794/2000 data_batch_2,  Train_loss : 5094.1890  Test_loss : 5323.3281, Time/batch_file : 2.2736, Training time: 9213.3229\n",
      "Epoch : 794/2000 data_batch_3,  Train_loss : 4843.6943  Test_loss : 5045.8745, Time/batch_file : 2.2687, Training time: 9215.5918\n",
      "Epoch : 794/2000 data_batch_4,  Train_loss : 4863.9521  Test_loss : 5210.7744, Time/batch_file : 2.2717, Training time: 9217.8635\n",
      "Epoch : 794/2000 data_batch_5,  Train_loss : 4689.4014  Test_loss : 5335.1489, Time/batch_file : 2.2541, Training time: 9220.1179\n",
      "Epoch : 795/2000 data_batch_1,  Train_loss : 4889.1294  Test_loss : 5515.2686, Time/batch_file : 2.2614, Training time: 9222.3795\n",
      "Epoch : 795/2000 data_batch_2,  Train_loss : 5248.3091  Test_loss : 5274.5898, Time/batch_file : 2.2640, Training time: 9224.6438\n",
      "Epoch : 795/2000 data_batch_3,  Train_loss : 5007.7314  Test_loss : 5405.0889, Time/batch_file : 2.2680, Training time: 9226.9120\n",
      "Epoch : 795/2000 data_batch_4,  Train_loss : 5004.2915  Test_loss : 5457.6929, Time/batch_file : 2.2482, Training time: 9229.1603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 795/2000 data_batch_5,  Train_loss : 5020.9478  Test_loss : 5396.0332, Time/batch_file : 2.2637, Training time: 9231.4242\n",
      "Epoch : 796/2000 data_batch_1,  Train_loss : 4415.5283  Test_loss : 5108.7393, Time/batch_file : 2.2577, Training time: 9233.6820\n",
      "Epoch : 796/2000 data_batch_2,  Train_loss : 4512.1899  Test_loss : 5180.4502, Time/batch_file : 2.2678, Training time: 9235.9501\n",
      "Epoch : 796/2000 data_batch_3,  Train_loss : 4855.1230  Test_loss : 5766.6909, Time/batch_file : 2.2638, Training time: 9238.2141\n",
      "Epoch : 796/2000 data_batch_4,  Train_loss : 4506.8623  Test_loss : 5449.5879, Time/batch_file : 2.2656, Training time: 9240.4798\n",
      "Epoch : 796/2000 data_batch_5,  Train_loss : 4729.0762  Test_loss : 5222.0625, Time/batch_file : 2.2683, Training time: 9242.7482\n",
      "Epoch : 797/2000 data_batch_1,  Train_loss : 4841.8936  Test_loss : 5317.7266, Time/batch_file : 2.2736, Training time: 9245.0221\n",
      "Epoch : 797/2000 data_batch_2,  Train_loss : 4956.6768  Test_loss : 5090.9648, Time/batch_file : 2.2632, Training time: 9247.2855\n",
      "Epoch : 797/2000 data_batch_3,  Train_loss : 4995.2783  Test_loss : 5066.9727, Time/batch_file : 2.2699, Training time: 9249.5555\n",
      "Epoch : 797/2000 data_batch_4,  Train_loss : 4909.8193  Test_loss : 5407.7910, Time/batch_file : 2.2745, Training time: 9251.8303\n",
      "Epoch : 797/2000 data_batch_5,  Train_loss : 5293.1318  Test_loss : 5153.4019, Time/batch_file : 2.2689, Training time: 9254.0994\n",
      "Epoch : 798/2000 data_batch_1,  Train_loss : 5581.6631  Test_loss : 5409.4761, Time/batch_file : 2.2488, Training time: 9256.3483\n",
      "Epoch : 798/2000 data_batch_2,  Train_loss : 5263.4912  Test_loss : 5503.3911, Time/batch_file : 2.2553, Training time: 9258.6038\n",
      "Epoch : 798/2000 data_batch_3,  Train_loss : 5650.9531  Test_loss : 5445.5615, Time/batch_file : 2.2642, Training time: 9260.8683\n",
      "Epoch : 798/2000 data_batch_4,  Train_loss : 5354.1240  Test_loss : 5488.5273, Time/batch_file : 2.2526, Training time: 9263.1210\n",
      "Epoch : 798/2000 data_batch_5,  Train_loss : 5405.0518  Test_loss : 5634.6182, Time/batch_file : 2.2444, Training time: 9265.3656\n",
      "Epoch : 799/2000 data_batch_1,  Train_loss : 5658.8501  Test_loss : 5688.2461, Time/batch_file : 2.2650, Training time: 9267.6307\n",
      "Epoch : 799/2000 data_batch_2,  Train_loss : 5431.6128  Test_loss : 5538.0508, Time/batch_file : 2.2691, Training time: 9269.9000\n",
      "Epoch : 799/2000 data_batch_3,  Train_loss : 5713.9854  Test_loss : 5647.3384, Time/batch_file : 2.2708, Training time: 9272.1710\n",
      "Epoch : 799/2000 data_batch_4,  Train_loss : 5487.2729  Test_loss : 5786.2715, Time/batch_file : 2.2768, Training time: 9274.4480\n",
      "Epoch : 799/2000 data_batch_5,  Train_loss : 5632.2666  Test_loss : 5969.7236, Time/batch_file : 2.2692, Training time: 9276.7174\n",
      "Epoch : 800/2000 data_batch_1,  Train_loss : 4889.3833  Test_loss : 5195.8750, Time/batch_file : 2.2862, Training time: 9279.0037\n",
      "Epoch : 800/2000 data_batch_2,  Train_loss : 4878.6421  Test_loss : 5246.7642, Time/batch_file : 2.2787, Training time: 9281.2826\n",
      "Epoch : 800/2000 data_batch_3,  Train_loss : 4848.6416  Test_loss : 5098.5293, Time/batch_file : 2.2729, Training time: 9283.5557\n",
      "Epoch : 800/2000 data_batch_4,  Train_loss : 4945.0654  Test_loss : 5253.0527, Time/batch_file : 2.2821, Training time: 9285.8380\n",
      "Epoch : 800/2000 data_batch_5,  Train_loss : 4916.7285  Test_loss : 5200.8442, Time/batch_file : 2.2791, Training time: 9288.1174\n",
      "[./nets/net-800.ckpt] SAVED\n",
      "Epoch : 801/2000 data_batch_1,  Train_loss : 5777.8135  Test_loss : 4408.8745, Time/batch_file : 2.2982, Training time: 9291.6835\n",
      "Epoch : 801/2000 data_batch_2,  Train_loss : 5477.3750  Test_loss : 4558.3359, Time/batch_file : 2.2790, Training time: 9293.9627\n",
      "Epoch : 801/2000 data_batch_3,  Train_loss : 5712.2817  Test_loss : 4430.1636, Time/batch_file : 2.2705, Training time: 9296.2335\n",
      "Epoch : 801/2000 data_batch_4,  Train_loss : 5711.3335  Test_loss : 4675.0840, Time/batch_file : 2.3029, Training time: 9298.5365\n",
      "Epoch : 801/2000 data_batch_5,  Train_loss : 5805.8672  Test_loss : 4179.3242, Time/batch_file : 2.2635, Training time: 9300.8002\n",
      "Epoch : 802/2000 data_batch_1,  Train_loss : 5461.3745  Test_loss : 5635.9287, Time/batch_file : 2.2821, Training time: 9303.0824\n",
      "Epoch : 802/2000 data_batch_2,  Train_loss : 5123.1016  Test_loss : 5339.9473, Time/batch_file : 2.2755, Training time: 9305.3581\n",
      "Epoch : 802/2000 data_batch_3,  Train_loss : 5447.1943  Test_loss : 5497.6934, Time/batch_file : 2.2733, Training time: 9307.6316\n",
      "Epoch : 802/2000 data_batch_4,  Train_loss : 5204.1826  Test_loss : 5792.3599, Time/batch_file : 2.2699, Training time: 9309.9019\n",
      "Epoch : 802/2000 data_batch_5,  Train_loss : 5631.6445  Test_loss : 5649.1123, Time/batch_file : 2.2696, Training time: 9312.1718\n",
      "Epoch : 803/2000 data_batch_1,  Train_loss : 5338.7910  Test_loss : 5535.0498, Time/batch_file : 2.2680, Training time: 9314.4400\n",
      "Epoch : 803/2000 data_batch_2,  Train_loss : 4985.8848  Test_loss : 5677.2852, Time/batch_file : 2.2747, Training time: 9316.7149\n",
      "Epoch : 803/2000 data_batch_3,  Train_loss : 5012.3086  Test_loss : 5779.5303, Time/batch_file : 2.2887, Training time: 9319.0038\n",
      "Epoch : 803/2000 data_batch_4,  Train_loss : 4958.8501  Test_loss : 5644.4517, Time/batch_file : 2.3127, Training time: 9321.3167\n",
      "Epoch : 803/2000 data_batch_5,  Train_loss : 4897.6816  Test_loss : 5503.3594, Time/batch_file : 2.2720, Training time: 9323.5890\n",
      "Epoch : 804/2000 data_batch_1,  Train_loss : 5450.5586  Test_loss : 5430.5376, Time/batch_file : 2.2653, Training time: 9325.8544\n",
      "Epoch : 804/2000 data_batch_2,  Train_loss : 5288.3706  Test_loss : 5125.9810, Time/batch_file : 2.2685, Training time: 9328.1231\n",
      "Epoch : 804/2000 data_batch_3,  Train_loss : 5158.7349  Test_loss : 5131.5337, Time/batch_file : 2.2562, Training time: 9330.3796\n",
      "Epoch : 804/2000 data_batch_4,  Train_loss : 5294.4873  Test_loss : 4839.1230, Time/batch_file : 2.2708, Training time: 9332.6507\n",
      "Epoch : 804/2000 data_batch_5,  Train_loss : 5182.4209  Test_loss : 4832.6660, Time/batch_file : 2.3051, Training time: 9334.9559\n",
      "Epoch : 805/2000 data_batch_1,  Train_loss : 5015.1646  Test_loss : 5386.7241, Time/batch_file : 2.2847, Training time: 9337.2408\n",
      "Epoch : 805/2000 data_batch_2,  Train_loss : 4590.0273  Test_loss : 5536.8599, Time/batch_file : 2.2814, Training time: 9339.5223\n",
      "Epoch : 805/2000 data_batch_3,  Train_loss : 4896.8047  Test_loss : 5624.1074, Time/batch_file : 2.2724, Training time: 9341.7949\n",
      "Epoch : 805/2000 data_batch_4,  Train_loss : 5012.9814  Test_loss : 5475.8008, Time/batch_file : 2.2845, Training time: 9344.0796\n",
      "Epoch : 805/2000 data_batch_5,  Train_loss : 4704.6167  Test_loss : 5491.8286, Time/batch_file : 2.2742, Training time: 9346.3541\n",
      "Epoch : 806/2000 data_batch_1,  Train_loss : 5148.1226  Test_loss : 5052.2607, Time/batch_file : 2.2657, Training time: 9348.6201\n",
      "Epoch : 806/2000 data_batch_2,  Train_loss : 5131.6152  Test_loss : 4976.9575, Time/batch_file : 2.2837, Training time: 9350.9040\n",
      "Epoch : 806/2000 data_batch_3,  Train_loss : 5439.8540  Test_loss : 5195.4106, Time/batch_file : 2.2733, Training time: 9353.1775\n",
      "Epoch : 806/2000 data_batch_4,  Train_loss : 5432.3936  Test_loss : 4768.1089, Time/batch_file : 2.2760, Training time: 9355.4537\n",
      "Epoch : 806/2000 data_batch_5,  Train_loss : 5446.0298  Test_loss : 5048.1816, Time/batch_file : 2.2879, Training time: 9357.7417\n",
      "Epoch : 807/2000 data_batch_1,  Train_loss : 4759.1426  Test_loss : 5676.6348, Time/batch_file : 2.2695, Training time: 9360.0114\n",
      "Epoch : 807/2000 data_batch_2,  Train_loss : 4454.5879  Test_loss : 6065.7129, Time/batch_file : 2.2752, Training time: 9362.2867\n",
      "Epoch : 807/2000 data_batch_3,  Train_loss : 4867.0278  Test_loss : 5564.9834, Time/batch_file : 2.2700, Training time: 9364.5570\n",
      "Epoch : 807/2000 data_batch_4,  Train_loss : 4590.0596  Test_loss : 5927.9609, Time/batch_file : 2.2757, Training time: 9366.8328\n",
      "Epoch : 807/2000 data_batch_5,  Train_loss : 4604.7617  Test_loss : 5667.4941, Time/batch_file : 2.2792, Training time: 9369.1122\n",
      "Epoch : 808/2000 data_batch_1,  Train_loss : 5205.5186  Test_loss : 5152.2046, Time/batch_file : 2.2515, Training time: 9371.3639\n",
      "Epoch : 808/2000 data_batch_2,  Train_loss : 4922.4512  Test_loss : 5482.4912, Time/batch_file : 2.2677, Training time: 9373.6318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 808/2000 data_batch_3,  Train_loss : 4633.1636  Test_loss : 5215.3799, Time/batch_file : 2.2685, Training time: 9375.9004\n",
      "Epoch : 808/2000 data_batch_4,  Train_loss : 4987.9722  Test_loss : 5654.3428, Time/batch_file : 2.2673, Training time: 9378.1679\n",
      "Epoch : 808/2000 data_batch_5,  Train_loss : 5046.1113  Test_loss : 5351.8569, Time/batch_file : 2.2679, Training time: 9380.4359\n",
      "Epoch : 809/2000 data_batch_1,  Train_loss : 4613.4214  Test_loss : 5190.5356, Time/batch_file : 2.2697, Training time: 9382.7058\n",
      "Epoch : 809/2000 data_batch_2,  Train_loss : 4606.0083  Test_loss : 5096.4502, Time/batch_file : 2.2630, Training time: 9384.9690\n",
      "Epoch : 809/2000 data_batch_3,  Train_loss : 4775.4614  Test_loss : 5057.1382, Time/batch_file : 2.2656, Training time: 9387.2348\n",
      "Epoch : 809/2000 data_batch_4,  Train_loss : 4500.5190  Test_loss : 5320.9429, Time/batch_file : 2.2524, Training time: 9389.4874\n",
      "Epoch : 809/2000 data_batch_5,  Train_loss : 4571.5747  Test_loss : 4846.3828, Time/batch_file : 2.2694, Training time: 9391.7570\n",
      "Epoch : 810/2000 data_batch_1,  Train_loss : 5102.9746  Test_loss : 5592.7407, Time/batch_file : 2.2793, Training time: 9394.0366\n",
      "Epoch : 810/2000 data_batch_2,  Train_loss : 5030.1084  Test_loss : 5703.2900, Time/batch_file : 2.2606, Training time: 9396.2974\n",
      "Epoch : 810/2000 data_batch_3,  Train_loss : 4803.7881  Test_loss : 5931.6304, Time/batch_file : 2.2742, Training time: 9398.5718\n",
      "Epoch : 810/2000 data_batch_4,  Train_loss : 5247.0972  Test_loss : 6134.8984, Time/batch_file : 2.2695, Training time: 9400.8415\n",
      "Epoch : 810/2000 data_batch_5,  Train_loss : 5173.3438  Test_loss : 5526.8916, Time/batch_file : 2.3006, Training time: 9403.1423\n",
      "[./nets/net-810.ckpt] SAVED\n",
      "Epoch : 811/2000 data_batch_1,  Train_loss : 5063.7319  Test_loss : 5331.8062, Time/batch_file : 2.2904, Training time: 9409.1304\n",
      "Epoch : 811/2000 data_batch_2,  Train_loss : 5001.9663  Test_loss : 5070.2554, Time/batch_file : 2.3074, Training time: 9411.4381\n",
      "Epoch : 811/2000 data_batch_3,  Train_loss : 5266.6914  Test_loss : 5585.6318, Time/batch_file : 2.2795, Training time: 9413.7178\n",
      "Epoch : 811/2000 data_batch_4,  Train_loss : 5139.6797  Test_loss : 5208.8037, Time/batch_file : 2.2857, Training time: 9416.0038\n",
      "Epoch : 811/2000 data_batch_5,  Train_loss : 5078.2227  Test_loss : 5349.3418, Time/batch_file : 2.2873, Training time: 9418.2914\n",
      "Epoch : 812/2000 data_batch_1,  Train_loss : 4527.3291  Test_loss : 5306.5806, Time/batch_file : 2.3029, Training time: 9420.5945\n",
      "Epoch : 812/2000 data_batch_2,  Train_loss : 5140.6514  Test_loss : 5485.4277, Time/batch_file : 2.3207, Training time: 9422.9155\n",
      "Epoch : 812/2000 data_batch_3,  Train_loss : 4626.8330  Test_loss : 5636.9487, Time/batch_file : 2.3183, Training time: 9425.2341\n",
      "Epoch : 812/2000 data_batch_4,  Train_loss : 4718.2080  Test_loss : 5601.1353, Time/batch_file : 2.3295, Training time: 9427.5638\n",
      "Epoch : 812/2000 data_batch_5,  Train_loss : 4731.3652  Test_loss : 5309.6963, Time/batch_file : 2.3176, Training time: 9429.8816\n",
      "Epoch : 813/2000 data_batch_1,  Train_loss : 5247.2295  Test_loss : 4930.1680, Time/batch_file : 2.3069, Training time: 9432.1887\n",
      "Epoch : 813/2000 data_batch_2,  Train_loss : 5068.9507  Test_loss : 5301.1953, Time/batch_file : 2.2979, Training time: 9434.4868\n",
      "Epoch : 813/2000 data_batch_3,  Train_loss : 5045.2598  Test_loss : 5042.8555, Time/batch_file : 2.2991, Training time: 9436.7861\n",
      "Epoch : 813/2000 data_batch_4,  Train_loss : 5057.1660  Test_loss : 5185.6943, Time/batch_file : 2.2897, Training time: 9439.0760\n",
      "Epoch : 813/2000 data_batch_5,  Train_loss : 5080.3267  Test_loss : 5174.4028, Time/batch_file : 2.3152, Training time: 9441.3914\n",
      "Epoch : 814/2000 data_batch_1,  Train_loss : 4928.5439  Test_loss : 5660.1064, Time/batch_file : 2.3006, Training time: 9443.6923\n",
      "Epoch : 814/2000 data_batch_2,  Train_loss : 5045.9629  Test_loss : 5822.9707, Time/batch_file : 2.3158, Training time: 9446.0083\n",
      "Epoch : 814/2000 data_batch_3,  Train_loss : 4914.3887  Test_loss : 5654.6631, Time/batch_file : 2.2955, Training time: 9448.3040\n",
      "Epoch : 814/2000 data_batch_4,  Train_loss : 4748.3535  Test_loss : 5401.3281, Time/batch_file : 2.3109, Training time: 9450.6151\n",
      "Epoch : 814/2000 data_batch_5,  Train_loss : 4633.2031  Test_loss : 5662.6924, Time/batch_file : 2.3030, Training time: 9452.9184\n",
      "Epoch : 815/2000 data_batch_1,  Train_loss : 5315.6836  Test_loss : 4952.2729, Time/batch_file : 2.3176, Training time: 9455.2362\n",
      "Epoch : 815/2000 data_batch_2,  Train_loss : 5294.3184  Test_loss : 4682.0410, Time/batch_file : 2.3034, Training time: 9457.5398\n",
      "Epoch : 815/2000 data_batch_3,  Train_loss : 5318.9995  Test_loss : 5118.6958, Time/batch_file : 2.3187, Training time: 9459.8587\n",
      "Epoch : 815/2000 data_batch_4,  Train_loss : 5416.0557  Test_loss : 4694.0737, Time/batch_file : 2.3016, Training time: 9462.1606\n",
      "Epoch : 815/2000 data_batch_5,  Train_loss : 5320.8745  Test_loss : 4697.6567, Time/batch_file : 2.3123, Training time: 9464.4731\n",
      "Epoch : 816/2000 data_batch_1,  Train_loss : 5535.9595  Test_loss : 5105.0503, Time/batch_file : 2.3107, Training time: 9466.7839\n",
      "Epoch : 816/2000 data_batch_2,  Train_loss : 5250.4238  Test_loss : 5047.5605, Time/batch_file : 2.3134, Training time: 9469.0976\n",
      "Epoch : 816/2000 data_batch_3,  Train_loss : 5394.8311  Test_loss : 5047.7339, Time/batch_file : 2.3041, Training time: 9471.4019\n",
      "Epoch : 816/2000 data_batch_4,  Train_loss : 5345.8770  Test_loss : 5253.3198, Time/batch_file : 2.3276, Training time: 9473.7296\n",
      "Epoch : 816/2000 data_batch_5,  Train_loss : 5543.8340  Test_loss : 5533.3750, Time/batch_file : 2.3174, Training time: 9476.0473\n",
      "Epoch : 817/2000 data_batch_1,  Train_loss : 5199.7266  Test_loss : 5497.9766, Time/batch_file : 2.3200, Training time: 9478.3675\n",
      "Epoch : 817/2000 data_batch_2,  Train_loss : 4981.9849  Test_loss : 5286.8320, Time/batch_file : 2.2894, Training time: 9480.6572\n",
      "Epoch : 817/2000 data_batch_3,  Train_loss : 5232.1685  Test_loss : 5598.4131, Time/batch_file : 2.3020, Training time: 9482.9594\n",
      "Epoch : 817/2000 data_batch_4,  Train_loss : 5045.3384  Test_loss : 5296.7310, Time/batch_file : 2.3033, Training time: 9485.2629\n",
      "Epoch : 817/2000 data_batch_5,  Train_loss : 5077.7656  Test_loss : 5080.3154, Time/batch_file : 2.2976, Training time: 9487.5608\n",
      "Epoch : 818/2000 data_batch_1,  Train_loss : 5341.2080  Test_loss : 5386.2734, Time/batch_file : 2.2819, Training time: 9489.8430\n",
      "Epoch : 818/2000 data_batch_2,  Train_loss : 5223.1445  Test_loss : 5336.6855, Time/batch_file : 2.3120, Training time: 9492.1552\n",
      "Epoch : 818/2000 data_batch_3,  Train_loss : 5558.0254  Test_loss : 5042.7080, Time/batch_file : 2.2865, Training time: 9494.4420\n",
      "Epoch : 818/2000 data_batch_4,  Train_loss : 5189.4346  Test_loss : 5188.0283, Time/batch_file : 2.2972, Training time: 9496.7394\n",
      "Epoch : 818/2000 data_batch_5,  Train_loss : 5065.7466  Test_loss : 5121.7065, Time/batch_file : 2.3047, Training time: 9499.0444\n",
      "Epoch : 819/2000 data_batch_1,  Train_loss : 4755.3413  Test_loss : 5310.5977, Time/batch_file : 2.3053, Training time: 9501.3498\n",
      "Epoch : 819/2000 data_batch_2,  Train_loss : 4627.0825  Test_loss : 5427.5293, Time/batch_file : 2.3106, Training time: 9503.6607\n",
      "Epoch : 819/2000 data_batch_3,  Train_loss : 4583.6440  Test_loss : 5475.7036, Time/batch_file : 2.3206, Training time: 9505.9815\n",
      "Epoch : 819/2000 data_batch_4,  Train_loss : 4908.1631  Test_loss : 5399.1299, Time/batch_file : 2.2960, Training time: 9508.2777\n",
      "Epoch : 819/2000 data_batch_5,  Train_loss : 4596.3960  Test_loss : 5466.2417, Time/batch_file : 2.3131, Training time: 9510.5911\n",
      "Epoch : 820/2000 data_batch_1,  Train_loss : 5043.1104  Test_loss : 5520.1514, Time/batch_file : 2.3087, Training time: 9512.8999\n",
      "Epoch : 820/2000 data_batch_2,  Train_loss : 4835.3638  Test_loss : 6032.4087, Time/batch_file : 2.3136, Training time: 9515.2136\n",
      "Epoch : 820/2000 data_batch_3,  Train_loss : 4849.0967  Test_loss : 5627.9482, Time/batch_file : 2.3028, Training time: 9517.5166\n",
      "Epoch : 820/2000 data_batch_4,  Train_loss : 4961.2773  Test_loss : 5618.1436, Time/batch_file : 2.3290, Training time: 9519.8459\n",
      "Epoch : 820/2000 data_batch_5,  Train_loss : 4724.4072  Test_loss : 5977.4165, Time/batch_file : 2.3061, Training time: 9522.1522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[./nets/net-820.ckpt] SAVED\n",
      "Epoch : 821/2000 data_batch_1,  Train_loss : 4701.4854  Test_loss : 4900.1475, Time/batch_file : 2.3317, Training time: 9525.7697\n",
      "Epoch : 821/2000 data_batch_2,  Train_loss : 4655.5205  Test_loss : 5422.5508, Time/batch_file : 2.2866, Training time: 9528.0565\n",
      "Epoch : 821/2000 data_batch_3,  Train_loss : 4916.3472  Test_loss : 5245.6758, Time/batch_file : 2.2996, Training time: 9530.3562\n",
      "Epoch : 821/2000 data_batch_4,  Train_loss : 4833.5552  Test_loss : 5252.8013, Time/batch_file : 2.2690, Training time: 9532.6254\n",
      "Epoch : 821/2000 data_batch_5,  Train_loss : 5033.6104  Test_loss : 5201.2930, Time/batch_file : 2.2915, Training time: 9534.9172\n",
      "Epoch : 822/2000 data_batch_1,  Train_loss : 4824.9878  Test_loss : 5251.2627, Time/batch_file : 2.2789, Training time: 9537.1963\n",
      "Epoch : 822/2000 data_batch_2,  Train_loss : 4942.5225  Test_loss : 4950.2471, Time/batch_file : 2.3025, Training time: 9539.4990\n",
      "Epoch : 822/2000 data_batch_3,  Train_loss : 5151.3203  Test_loss : 5226.9893, Time/batch_file : 2.2701, Training time: 9541.7693\n",
      "Epoch : 822/2000 data_batch_4,  Train_loss : 5140.0996  Test_loss : 5569.4048, Time/batch_file : 2.2847, Training time: 9544.0542\n",
      "Epoch : 822/2000 data_batch_5,  Train_loss : 4740.1992  Test_loss : 5396.2349, Time/batch_file : 2.2801, Training time: 9546.3344\n",
      "Epoch : 823/2000 data_batch_1,  Train_loss : 4797.3184  Test_loss : 4938.6440, Time/batch_file : 2.2789, Training time: 9548.6135\n",
      "Epoch : 823/2000 data_batch_2,  Train_loss : 4998.9902  Test_loss : 5017.6685, Time/batch_file : 2.2883, Training time: 9550.9020\n",
      "Epoch : 823/2000 data_batch_3,  Train_loss : 5107.8989  Test_loss : 4750.4990, Time/batch_file : 2.3081, Training time: 9553.2104\n",
      "Epoch : 823/2000 data_batch_4,  Train_loss : 5036.6968  Test_loss : 4817.7954, Time/batch_file : 2.2826, Training time: 9555.4932\n",
      "Epoch : 823/2000 data_batch_5,  Train_loss : 5282.6694  Test_loss : 4778.2339, Time/batch_file : 2.2892, Training time: 9557.7826\n",
      "Epoch : 824/2000 data_batch_1,  Train_loss : 4612.9121  Test_loss : 5686.7236, Time/batch_file : 2.2679, Training time: 9560.0508\n",
      "Epoch : 824/2000 data_batch_2,  Train_loss : 5094.0464  Test_loss : 5457.3345, Time/batch_file : 2.2798, Training time: 9562.3308\n",
      "Epoch : 824/2000 data_batch_3,  Train_loss : 5018.5068  Test_loss : 5703.8359, Time/batch_file : 2.2923, Training time: 9564.6234\n",
      "Epoch : 824/2000 data_batch_4,  Train_loss : 4878.3525  Test_loss : 5415.4912, Time/batch_file : 2.2560, Training time: 9566.8795\n",
      "Epoch : 824/2000 data_batch_5,  Train_loss : 4781.2988  Test_loss : 5701.4961, Time/batch_file : 2.2948, Training time: 9569.1746\n",
      "Epoch : 825/2000 data_batch_1,  Train_loss : 5015.4541  Test_loss : 5399.1313, Time/batch_file : 2.2540, Training time: 9571.4288\n",
      "Epoch : 825/2000 data_batch_2,  Train_loss : 4969.5415  Test_loss : 5212.1953, Time/batch_file : 2.2984, Training time: 9573.7273\n",
      "Epoch : 825/2000 data_batch_3,  Train_loss : 5254.4150  Test_loss : 5391.9893, Time/batch_file : 2.2604, Training time: 9575.9880\n",
      "Epoch : 825/2000 data_batch_4,  Train_loss : 5351.5200  Test_loss : 5335.9048, Time/batch_file : 2.2761, Training time: 9578.2642\n",
      "Epoch : 825/2000 data_batch_5,  Train_loss : 5124.0947  Test_loss : 5575.6094, Time/batch_file : 2.2598, Training time: 9580.5242\n",
      "Epoch : 826/2000 data_batch_1,  Train_loss : 4783.5830  Test_loss : 5557.3906, Time/batch_file : 2.2870, Training time: 9582.8114\n",
      "Epoch : 826/2000 data_batch_2,  Train_loss : 4553.3018  Test_loss : 5147.1846, Time/batch_file : 2.2700, Training time: 9585.0816\n",
      "Epoch : 826/2000 data_batch_3,  Train_loss : 4686.2139  Test_loss : 5447.7021, Time/batch_file : 2.3159, Training time: 9587.3978\n",
      "Epoch : 826/2000 data_batch_4,  Train_loss : 4711.4678  Test_loss : 5482.5146, Time/batch_file : 2.2736, Training time: 9589.6716\n",
      "Epoch : 826/2000 data_batch_5,  Train_loss : 4637.7280  Test_loss : 5441.4785, Time/batch_file : 2.3033, Training time: 9591.9751\n",
      "Epoch : 827/2000 data_batch_1,  Train_loss : 4794.9502  Test_loss : 4858.5737, Time/batch_file : 2.2739, Training time: 9594.2492\n",
      "Epoch : 827/2000 data_batch_2,  Train_loss : 5108.1738  Test_loss : 4808.5645, Time/batch_file : 2.2701, Training time: 9596.5194\n",
      "Epoch : 827/2000 data_batch_3,  Train_loss : 4954.1411  Test_loss : 4883.5225, Time/batch_file : 2.2636, Training time: 9598.7832\n",
      "Epoch : 827/2000 data_batch_4,  Train_loss : 5092.5039  Test_loss : 4818.5654, Time/batch_file : 2.2880, Training time: 9601.0714\n",
      "Epoch : 827/2000 data_batch_5,  Train_loss : 5145.5166  Test_loss : 4766.4951, Time/batch_file : 2.2583, Training time: 9603.3300\n",
      "Epoch : 828/2000 data_batch_1,  Train_loss : 5446.2197  Test_loss : 5072.5171, Time/batch_file : 2.2937, Training time: 9605.6239\n",
      "Epoch : 828/2000 data_batch_2,  Train_loss : 5111.7036  Test_loss : 4908.9663, Time/batch_file : 2.2679, Training time: 9607.8920\n",
      "Epoch : 828/2000 data_batch_3,  Train_loss : 4954.6504  Test_loss : 5467.3291, Time/batch_file : 2.2992, Training time: 9610.1913\n",
      "Epoch : 828/2000 data_batch_4,  Train_loss : 4911.8315  Test_loss : 5454.1558, Time/batch_file : 2.2705, Training time: 9612.4619\n",
      "Epoch : 828/2000 data_batch_5,  Train_loss : 5041.9326  Test_loss : 5196.1538, Time/batch_file : 2.2908, Training time: 9614.7530\n",
      "Epoch : 829/2000 data_batch_1,  Train_loss : 5216.5034  Test_loss : 5003.1738, Time/batch_file : 2.2656, Training time: 9617.0187\n",
      "Epoch : 829/2000 data_batch_2,  Train_loss : 5342.4941  Test_loss : 5063.5635, Time/batch_file : 2.2999, Training time: 9619.3189\n",
      "Epoch : 829/2000 data_batch_3,  Train_loss : 5226.0205  Test_loss : 5428.0186, Time/batch_file : 2.2958, Training time: 9621.6149\n",
      "Epoch : 829/2000 data_batch_4,  Train_loss : 5234.8892  Test_loss : 5306.1777, Time/batch_file : 2.2918, Training time: 9623.9068\n",
      "Epoch : 829/2000 data_batch_5,  Train_loss : 5401.9473  Test_loss : 5353.8047, Time/batch_file : 2.2691, Training time: 9626.1761\n",
      "Epoch : 830/2000 data_batch_1,  Train_loss : 4911.2344  Test_loss : 5014.0293, Time/batch_file : 2.2929, Training time: 9628.4692\n",
      "Epoch : 830/2000 data_batch_2,  Train_loss : 5145.6821  Test_loss : 5310.8296, Time/batch_file : 2.2684, Training time: 9630.7378\n",
      "Epoch : 830/2000 data_batch_3,  Train_loss : 4843.8306  Test_loss : 5149.4492, Time/batch_file : 2.2888, Training time: 9633.0268\n",
      "Epoch : 830/2000 data_batch_4,  Train_loss : 4771.4678  Test_loss : 5099.4194, Time/batch_file : 2.2749, Training time: 9635.3019\n",
      "Epoch : 830/2000 data_batch_5,  Train_loss : 4766.1152  Test_loss : 4849.5791, Time/batch_file : 2.2964, Training time: 9637.5985\n",
      "[./nets/net-830.ckpt] SAVED\n",
      "Epoch : 831/2000 data_batch_1,  Train_loss : 5715.3770  Test_loss : 5064.7163, Time/batch_file : 2.3018, Training time: 9641.1787\n",
      "Epoch : 831/2000 data_batch_2,  Train_loss : 5461.2324  Test_loss : 5217.4619, Time/batch_file : 2.2969, Training time: 9643.4758\n",
      "Epoch : 831/2000 data_batch_3,  Train_loss : 5584.0005  Test_loss : 5171.2583, Time/batch_file : 2.2823, Training time: 9645.7584\n",
      "Epoch : 831/2000 data_batch_4,  Train_loss : 5519.0713  Test_loss : 5298.9380, Time/batch_file : 2.2804, Training time: 9648.0390\n",
      "Epoch : 831/2000 data_batch_5,  Train_loss : 5568.6299  Test_loss : 5021.9473, Time/batch_file : 2.2913, Training time: 9650.3304\n",
      "Epoch : 832/2000 data_batch_1,  Train_loss : 4669.7192  Test_loss : 5174.2275, Time/batch_file : 2.2708, Training time: 9652.6014\n",
      "Epoch : 832/2000 data_batch_2,  Train_loss : 4762.7871  Test_loss : 5261.1992, Time/batch_file : 2.2758, Training time: 9654.8774\n",
      "Epoch : 832/2000 data_batch_3,  Train_loss : 4433.7549  Test_loss : 5449.9165, Time/batch_file : 2.2827, Training time: 9657.1603\n",
      "Epoch : 832/2000 data_batch_4,  Train_loss : 4557.6826  Test_loss : 5167.2119, Time/batch_file : 2.2879, Training time: 9659.4484\n",
      "Epoch : 832/2000 data_batch_5,  Train_loss : 4762.8960  Test_loss : 5411.5786, Time/batch_file : 2.2781, Training time: 9661.7267\n",
      "Epoch : 833/2000 data_batch_1,  Train_loss : 4529.3599  Test_loss : 5308.1133, Time/batch_file : 2.2877, Training time: 9664.0146\n",
      "Epoch : 833/2000 data_batch_2,  Train_loss : 4445.9688  Test_loss : 5482.5181, Time/batch_file : 2.2724, Training time: 9666.2871\n",
      "Epoch : 833/2000 data_batch_3,  Train_loss : 4642.5371  Test_loss : 5267.8184, Time/batch_file : 2.2894, Training time: 9668.5768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 833/2000 data_batch_4,  Train_loss : 4429.7163  Test_loss : 5156.4321, Time/batch_file : 2.2822, Training time: 9670.8591\n",
      "Epoch : 833/2000 data_batch_5,  Train_loss : 4371.6807  Test_loss : 5503.1636, Time/batch_file : 2.2785, Training time: 9673.1378\n",
      "Epoch : 834/2000 data_batch_1,  Train_loss : 5244.1582  Test_loss : 5383.8042, Time/batch_file : 2.2672, Training time: 9675.4052\n",
      "Epoch : 834/2000 data_batch_2,  Train_loss : 5354.3745  Test_loss : 5092.2910, Time/batch_file : 2.2697, Training time: 9677.6752\n",
      "Epoch : 834/2000 data_batch_3,  Train_loss : 5515.7593  Test_loss : 5110.3164, Time/batch_file : 2.2707, Training time: 9679.9460\n",
      "Epoch : 834/2000 data_batch_4,  Train_loss : 5144.7803  Test_loss : 5546.6548, Time/batch_file : 2.2711, Training time: 9682.2174\n",
      "Epoch : 834/2000 data_batch_5,  Train_loss : 5088.9424  Test_loss : 5413.7549, Time/batch_file : 2.2652, Training time: 9684.4828\n",
      "Epoch : 835/2000 data_batch_1,  Train_loss : 4753.4932  Test_loss : 5055.9668, Time/batch_file : 2.2683, Training time: 9686.7512\n",
      "Epoch : 835/2000 data_batch_2,  Train_loss : 4997.6846  Test_loss : 5398.2188, Time/batch_file : 2.2776, Training time: 9689.0291\n",
      "Epoch : 835/2000 data_batch_3,  Train_loss : 5281.5010  Test_loss : 5175.2241, Time/batch_file : 2.2619, Training time: 9691.2912\n",
      "Epoch : 835/2000 data_batch_4,  Train_loss : 4902.2090  Test_loss : 5334.7319, Time/batch_file : 2.2662, Training time: 9693.5576\n",
      "Epoch : 835/2000 data_batch_5,  Train_loss : 5090.2964  Test_loss : 4980.1978, Time/batch_file : 2.2686, Training time: 9695.8264\n",
      "Epoch : 836/2000 data_batch_1,  Train_loss : 4769.7451  Test_loss : 4748.5054, Time/batch_file : 2.2811, Training time: 9698.1078\n",
      "Epoch : 836/2000 data_batch_2,  Train_loss : 4928.1802  Test_loss : 4833.2427, Time/batch_file : 2.2865, Training time: 9700.3944\n",
      "Epoch : 836/2000 data_batch_3,  Train_loss : 4789.2783  Test_loss : 4614.4331, Time/batch_file : 2.2852, Training time: 9702.6799\n",
      "Epoch : 836/2000 data_batch_4,  Train_loss : 4778.8569  Test_loss : 5402.8252, Time/batch_file : 2.2852, Training time: 9704.9653\n",
      "Epoch : 836/2000 data_batch_5,  Train_loss : 4799.1133  Test_loss : 5118.4482, Time/batch_file : 2.2982, Training time: 9707.2637\n",
      "Epoch : 837/2000 data_batch_1,  Train_loss : 5416.9590  Test_loss : 5319.2524, Time/batch_file : 2.2936, Training time: 9709.5574\n",
      "Epoch : 837/2000 data_batch_2,  Train_loss : 5478.0464  Test_loss : 5519.4258, Time/batch_file : 2.2688, Training time: 9711.8265\n",
      "Epoch : 837/2000 data_batch_3,  Train_loss : 5530.6812  Test_loss : 5702.6230, Time/batch_file : 2.2745, Training time: 9714.1012\n",
      "Epoch : 837/2000 data_batch_4,  Train_loss : 5286.8105  Test_loss : 5496.0913, Time/batch_file : 2.2732, Training time: 9716.3745\n",
      "Epoch : 837/2000 data_batch_5,  Train_loss : 5493.6396  Test_loss : 5496.9395, Time/batch_file : 2.3001, Training time: 9718.6749\n",
      "Epoch : 838/2000 data_batch_1,  Train_loss : 4908.2627  Test_loss : 5682.1328, Time/batch_file : 2.2793, Training time: 9720.9543\n",
      "Epoch : 838/2000 data_batch_2,  Train_loss : 4893.5029  Test_loss : 5654.9014, Time/batch_file : 2.2719, Training time: 9723.2265\n",
      "Epoch : 838/2000 data_batch_3,  Train_loss : 4893.8535  Test_loss : 5590.7739, Time/batch_file : 2.2745, Training time: 9725.5011\n",
      "Epoch : 838/2000 data_batch_4,  Train_loss : 5256.6777  Test_loss : 5748.1582, Time/batch_file : 2.3028, Training time: 9727.8041\n",
      "Epoch : 838/2000 data_batch_5,  Train_loss : 4884.4043  Test_loss : 5417.4624, Time/batch_file : 2.2739, Training time: 9730.0782\n",
      "Epoch : 839/2000 data_batch_1,  Train_loss : 4959.5557  Test_loss : 5319.6406, Time/batch_file : 2.2796, Training time: 9732.3581\n",
      "Epoch : 839/2000 data_batch_2,  Train_loss : 4882.2402  Test_loss : 5309.5322, Time/batch_file : 2.2796, Training time: 9734.6378\n",
      "Epoch : 839/2000 data_batch_3,  Train_loss : 4912.6938  Test_loss : 5066.2983, Time/batch_file : 2.2798, Training time: 9736.9179\n",
      "Epoch : 839/2000 data_batch_4,  Train_loss : 4534.0938  Test_loss : 4880.8218, Time/batch_file : 2.2846, Training time: 9739.2027\n",
      "Epoch : 839/2000 data_batch_5,  Train_loss : 4752.1514  Test_loss : 5325.4644, Time/batch_file : 2.2752, Training time: 9741.4781\n",
      "Epoch : 840/2000 data_batch_1,  Train_loss : 4888.0635  Test_loss : 5235.1938, Time/batch_file : 2.2608, Training time: 9743.7391\n",
      "Epoch : 840/2000 data_batch_2,  Train_loss : 5267.3672  Test_loss : 5455.4023, Time/batch_file : 2.2673, Training time: 9746.0066\n",
      "Epoch : 840/2000 data_batch_3,  Train_loss : 5151.0352  Test_loss : 5252.6558, Time/batch_file : 2.2608, Training time: 9748.2676\n",
      "Epoch : 840/2000 data_batch_4,  Train_loss : 5084.9072  Test_loss : 5405.8306, Time/batch_file : 2.2761, Training time: 9750.5440\n",
      "Epoch : 840/2000 data_batch_5,  Train_loss : 5013.2998  Test_loss : 5117.3564, Time/batch_file : 2.2682, Training time: 9752.8123\n",
      "[./nets/net-840.ckpt] SAVED\n",
      "Epoch : 841/2000 data_batch_1,  Train_loss : 4555.8740  Test_loss : 5042.8613, Time/batch_file : 2.3014, Training time: 9756.3761\n",
      "Epoch : 841/2000 data_batch_2,  Train_loss : 4814.8965  Test_loss : 5018.6211, Time/batch_file : 2.3108, Training time: 9758.6871\n",
      "Epoch : 841/2000 data_batch_3,  Train_loss : 4609.7529  Test_loss : 5097.7271, Time/batch_file : 2.2910, Training time: 9760.9784\n",
      "Epoch : 841/2000 data_batch_4,  Train_loss : 4637.4438  Test_loss : 5114.9653, Time/batch_file : 2.2862, Training time: 9763.2648\n",
      "Epoch : 841/2000 data_batch_5,  Train_loss : 4959.8066  Test_loss : 5056.5312, Time/batch_file : 2.3032, Training time: 9765.5682\n",
      "Epoch : 842/2000 data_batch_1,  Train_loss : 5473.1548  Test_loss : 5433.3184, Time/batch_file : 2.3044, Training time: 9767.8728\n",
      "Epoch : 842/2000 data_batch_2,  Train_loss : 5278.7754  Test_loss : 5518.7676, Time/batch_file : 2.3242, Training time: 9770.1973\n",
      "Epoch : 842/2000 data_batch_3,  Train_loss : 5201.5752  Test_loss : 5474.5151, Time/batch_file : 2.2800, Training time: 9772.4774\n",
      "Epoch : 842/2000 data_batch_4,  Train_loss : 5101.5542  Test_loss : 5898.0874, Time/batch_file : 2.3143, Training time: 9774.7919\n",
      "Epoch : 842/2000 data_batch_5,  Train_loss : 5213.0488  Test_loss : 5366.1362, Time/batch_file : 2.3254, Training time: 9777.1176\n",
      "Epoch : 843/2000 data_batch_1,  Train_loss : 5203.4639  Test_loss : 5394.6719, Time/batch_file : 2.2908, Training time: 9779.4086\n",
      "Epoch : 843/2000 data_batch_2,  Train_loss : 4980.3325  Test_loss : 5525.6650, Time/batch_file : 2.2853, Training time: 9781.6941\n",
      "Epoch : 843/2000 data_batch_3,  Train_loss : 5208.5020  Test_loss : 5253.8789, Time/batch_file : 2.2811, Training time: 9783.9754\n",
      "Epoch : 843/2000 data_batch_4,  Train_loss : 4854.1494  Test_loss : 5540.1836, Time/batch_file : 2.2763, Training time: 9786.2519\n",
      "Epoch : 843/2000 data_batch_5,  Train_loss : 4879.6758  Test_loss : 5646.0947, Time/batch_file : 2.2860, Training time: 9788.5382\n",
      "Epoch : 844/2000 data_batch_1,  Train_loss : 4813.7861  Test_loss : 5009.4795, Time/batch_file : 2.2868, Training time: 9790.8251\n",
      "Epoch : 844/2000 data_batch_2,  Train_loss : 4590.2354  Test_loss : 4990.8550, Time/batch_file : 2.3041, Training time: 9793.1294\n",
      "Epoch : 844/2000 data_batch_3,  Train_loss : 4832.5405  Test_loss : 5124.9307, Time/batch_file : 2.2767, Training time: 9795.4064\n",
      "Epoch : 844/2000 data_batch_4,  Train_loss : 4878.4785  Test_loss : 4967.1704, Time/batch_file : 2.2982, Training time: 9797.7048\n",
      "Epoch : 844/2000 data_batch_5,  Train_loss : 4935.9321  Test_loss : 5075.8965, Time/batch_file : 2.2743, Training time: 9799.9793\n",
      "Epoch : 845/2000 data_batch_1,  Train_loss : 4949.5151  Test_loss : 5175.9775, Time/batch_file : 2.3063, Training time: 9802.2859\n",
      "Epoch : 845/2000 data_batch_2,  Train_loss : 4927.0947  Test_loss : 5358.8594, Time/batch_file : 2.2831, Training time: 9804.5692\n",
      "Epoch : 845/2000 data_batch_3,  Train_loss : 4947.2324  Test_loss : 5410.8276, Time/batch_file : 2.2911, Training time: 9806.8605\n",
      "Epoch : 845/2000 data_batch_4,  Train_loss : 5065.3159  Test_loss : 5223.2227, Time/batch_file : 2.3002, Training time: 9809.1610\n",
      "Epoch : 845/2000 data_batch_5,  Train_loss : 4929.9224  Test_loss : 5038.2744, Time/batch_file : 2.3007, Training time: 9811.4618\n",
      "Epoch : 846/2000 data_batch_1,  Train_loss : 5003.0923  Test_loss : 5331.2764, Time/batch_file : 2.2857, Training time: 9813.7477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 846/2000 data_batch_2,  Train_loss : 5103.1567  Test_loss : 5577.5312, Time/batch_file : 2.2945, Training time: 9816.0424\n",
      "Epoch : 846/2000 data_batch_3,  Train_loss : 5029.1958  Test_loss : 5471.1724, Time/batch_file : 2.2929, Training time: 9818.3356\n",
      "Epoch : 846/2000 data_batch_4,  Train_loss : 5311.4341  Test_loss : 5372.9980, Time/batch_file : 2.3273, Training time: 9820.6632\n",
      "Epoch : 846/2000 data_batch_5,  Train_loss : 5223.0205  Test_loss : 5342.2056, Time/batch_file : 2.2817, Training time: 9822.9451\n",
      "Epoch : 847/2000 data_batch_1,  Train_loss : 5060.4375  Test_loss : 5412.4468, Time/batch_file : 2.2809, Training time: 9825.2262\n",
      "Epoch : 847/2000 data_batch_2,  Train_loss : 5052.6270  Test_loss : 5255.4541, Time/batch_file : 2.3188, Training time: 9827.5451\n",
      "Epoch : 847/2000 data_batch_3,  Train_loss : 4815.0688  Test_loss : 5312.4653, Time/batch_file : 2.2824, Training time: 9829.8277\n",
      "Epoch : 847/2000 data_batch_4,  Train_loss : 5118.7202  Test_loss : 5123.0205, Time/batch_file : 2.3042, Training time: 9832.1321\n",
      "Epoch : 847/2000 data_batch_5,  Train_loss : 4985.9893  Test_loss : 5138.6201, Time/batch_file : 2.2902, Training time: 9834.4226\n",
      "Epoch : 848/2000 data_batch_1,  Train_loss : 5359.4219  Test_loss : 5301.5986, Time/batch_file : 2.3126, Training time: 9836.7353\n",
      "Epoch : 848/2000 data_batch_2,  Train_loss : 5651.9019  Test_loss : 4997.9131, Time/batch_file : 2.2936, Training time: 9839.0290\n",
      "Epoch : 848/2000 data_batch_3,  Train_loss : 5408.5044  Test_loss : 4999.5693, Time/batch_file : 2.3014, Training time: 9841.3306\n",
      "Epoch : 848/2000 data_batch_4,  Train_loss : 5278.3711  Test_loss : 5038.9893, Time/batch_file : 2.3099, Training time: 9843.6407\n",
      "Epoch : 848/2000 data_batch_5,  Train_loss : 5660.6235  Test_loss : 5117.7227, Time/batch_file : 2.3045, Training time: 9845.9454\n",
      "Epoch : 849/2000 data_batch_1,  Train_loss : 5070.7393  Test_loss : 5424.1670, Time/batch_file : 2.2631, Training time: 9848.2088\n",
      "Epoch : 849/2000 data_batch_2,  Train_loss : 5061.2354  Test_loss : 5254.9697, Time/batch_file : 2.2973, Training time: 9850.5062\n",
      "Epoch : 849/2000 data_batch_3,  Train_loss : 5116.7017  Test_loss : 5445.2559, Time/batch_file : 2.2581, Training time: 9852.7646\n",
      "Epoch : 849/2000 data_batch_4,  Train_loss : 5059.0342  Test_loss : 5501.3857, Time/batch_file : 2.2736, Training time: 9855.0384\n",
      "Epoch : 849/2000 data_batch_5,  Train_loss : 5353.3730  Test_loss : 5553.9634, Time/batch_file : 2.2654, Training time: 9857.3041\n",
      "Epoch : 850/2000 data_batch_1,  Train_loss : 5010.9380  Test_loss : 5173.4814, Time/batch_file : 2.2767, Training time: 9859.5810\n",
      "Epoch : 850/2000 data_batch_2,  Train_loss : 5180.6338  Test_loss : 5121.2285, Time/batch_file : 2.3334, Training time: 9861.9146\n",
      "Epoch : 850/2000 data_batch_3,  Train_loss : 5189.5029  Test_loss : 5225.2778, Time/batch_file : 2.2836, Training time: 9864.1984\n",
      "Epoch : 850/2000 data_batch_4,  Train_loss : 5125.0562  Test_loss : 4858.5791, Time/batch_file : 2.2960, Training time: 9866.4946\n",
      "Epoch : 850/2000 data_batch_5,  Train_loss : 4930.3047  Test_loss : 4946.2217, Time/batch_file : 2.2978, Training time: 9868.7926\n",
      "[./nets/net-850.ckpt] SAVED\n",
      "Epoch : 851/2000 data_batch_1,  Train_loss : 4671.8423  Test_loss : 4789.4644, Time/batch_file : 2.3181, Training time: 9872.3818\n",
      "Epoch : 851/2000 data_batch_2,  Train_loss : 4550.5488  Test_loss : 5292.3608, Time/batch_file : 2.2730, Training time: 9874.6550\n",
      "Epoch : 851/2000 data_batch_3,  Train_loss : 4852.3071  Test_loss : 4989.3428, Time/batch_file : 2.2677, Training time: 9876.9229\n",
      "Epoch : 851/2000 data_batch_4,  Train_loss : 4931.4497  Test_loss : 5188.3027, Time/batch_file : 2.3230, Training time: 9879.2461\n",
      "Epoch : 851/2000 data_batch_5,  Train_loss : 4534.9229  Test_loss : 5067.5625, Time/batch_file : 2.2726, Training time: 9881.5189\n",
      "Epoch : 852/2000 data_batch_1,  Train_loss : 4609.7139  Test_loss : 5114.8047, Time/batch_file : 2.2957, Training time: 9883.8147\n",
      "Epoch : 852/2000 data_batch_2,  Train_loss : 4886.3691  Test_loss : 5087.7632, Time/batch_file : 2.2740, Training time: 9886.0889\n",
      "Epoch : 852/2000 data_batch_3,  Train_loss : 4589.5293  Test_loss : 5354.3940, Time/batch_file : 2.2859, Training time: 9888.3750\n",
      "Epoch : 852/2000 data_batch_4,  Train_loss : 4835.6733  Test_loss : 5243.4082, Time/batch_file : 2.2868, Training time: 9890.6620\n",
      "Epoch : 852/2000 data_batch_5,  Train_loss : 4732.6484  Test_loss : 5200.6387, Time/batch_file : 2.2854, Training time: 9892.9476\n",
      "Epoch : 853/2000 data_batch_1,  Train_loss : 4915.8223  Test_loss : 5361.1733, Time/batch_file : 2.2898, Training time: 9895.2375\n",
      "Epoch : 853/2000 data_batch_2,  Train_loss : 4877.7793  Test_loss : 5129.5615, Time/batch_file : 2.2733, Training time: 9897.5111\n",
      "Epoch : 853/2000 data_batch_3,  Train_loss : 4745.1270  Test_loss : 5373.1172, Time/batch_file : 2.2977, Training time: 9899.8090\n",
      "Epoch : 853/2000 data_batch_4,  Train_loss : 4938.4331  Test_loss : 5452.2119, Time/batch_file : 2.2680, Training time: 9902.0772\n",
      "Epoch : 853/2000 data_batch_5,  Train_loss : 4798.7090  Test_loss : 5430.7490, Time/batch_file : 2.3010, Training time: 9904.3785\n",
      "Epoch : 854/2000 data_batch_1,  Train_loss : 4588.7119  Test_loss : 5777.6855, Time/batch_file : 2.2800, Training time: 9906.6587\n",
      "Epoch : 854/2000 data_batch_2,  Train_loss : 4762.2275  Test_loss : 5628.8931, Time/batch_file : 2.2754, Training time: 9908.9342\n",
      "Epoch : 854/2000 data_batch_3,  Train_loss : 4959.4199  Test_loss : 6043.8320, Time/batch_file : 2.2699, Training time: 9911.2044\n",
      "Epoch : 854/2000 data_batch_4,  Train_loss : 4881.5801  Test_loss : 5296.6792, Time/batch_file : 2.2863, Training time: 9913.4909\n",
      "Epoch : 854/2000 data_batch_5,  Train_loss : 4510.3179  Test_loss : 5772.4810, Time/batch_file : 2.2900, Training time: 9915.7811\n",
      "Epoch : 855/2000 data_batch_1,  Train_loss : 5371.7139  Test_loss : 4737.1279, Time/batch_file : 2.2986, Training time: 9918.0799\n",
      "Epoch : 855/2000 data_batch_2,  Train_loss : 5306.7603  Test_loss : 4705.1973, Time/batch_file : 2.3057, Training time: 9920.3858\n",
      "Epoch : 855/2000 data_batch_3,  Train_loss : 5286.3374  Test_loss : 5063.2954, Time/batch_file : 2.3380, Training time: 9922.7241\n",
      "Epoch : 855/2000 data_batch_4,  Train_loss : 5100.4590  Test_loss : 4761.4058, Time/batch_file : 2.2873, Training time: 9925.0115\n",
      "Epoch : 855/2000 data_batch_5,  Train_loss : 5026.9619  Test_loss : 5000.0830, Time/batch_file : 2.2887, Training time: 9927.3005\n",
      "Epoch : 856/2000 data_batch_1,  Train_loss : 5080.0771  Test_loss : 5733.4395, Time/batch_file : 2.2831, Training time: 9929.5838\n",
      "Epoch : 856/2000 data_batch_2,  Train_loss : 5290.7070  Test_loss : 5824.4414, Time/batch_file : 2.3076, Training time: 9931.8915\n",
      "Epoch : 856/2000 data_batch_3,  Train_loss : 5415.8330  Test_loss : 5798.3511, Time/batch_file : 2.2891, Training time: 9934.1808\n",
      "Epoch : 856/2000 data_batch_4,  Train_loss : 5294.9902  Test_loss : 5660.0723, Time/batch_file : 2.3139, Training time: 9936.4951\n",
      "Epoch : 856/2000 data_batch_5,  Train_loss : 5259.2114  Test_loss : 5855.0884, Time/batch_file : 2.2934, Training time: 9938.7886\n",
      "Epoch : 857/2000 data_batch_1,  Train_loss : 5204.1465  Test_loss : 5677.5566, Time/batch_file : 2.3094, Training time: 9941.0981\n",
      "Epoch : 857/2000 data_batch_2,  Train_loss : 5567.7188  Test_loss : 5468.3398, Time/batch_file : 2.2745, Training time: 9943.3727\n",
      "Epoch : 857/2000 data_batch_3,  Train_loss : 5643.1938  Test_loss : 5332.8584, Time/batch_file : 2.2794, Training time: 9945.6524\n",
      "Epoch : 857/2000 data_batch_4,  Train_loss : 5368.8979  Test_loss : 5478.9292, Time/batch_file : 2.2725, Training time: 9947.9252\n",
      "Epoch : 857/2000 data_batch_5,  Train_loss : 5216.2803  Test_loss : 5241.5127, Time/batch_file : 2.2865, Training time: 9950.2118\n",
      "Epoch : 858/2000 data_batch_1,  Train_loss : 4918.1772  Test_loss : 5760.4258, Time/batch_file : 2.2929, Training time: 9952.5050\n",
      "Epoch : 858/2000 data_batch_2,  Train_loss : 4714.0352  Test_loss : 5630.4438, Time/batch_file : 2.3178, Training time: 9954.8231\n",
      "Epoch : 858/2000 data_batch_3,  Train_loss : 4592.1558  Test_loss : 5459.8213, Time/batch_file : 2.2762, Training time: 9957.0994\n",
      "Epoch : 858/2000 data_batch_4,  Train_loss : 4923.7197  Test_loss : 5795.1543, Time/batch_file : 2.3288, Training time: 9959.4284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 858/2000 data_batch_5,  Train_loss : 4711.8154  Test_loss : 5364.8193, Time/batch_file : 2.2938, Training time: 9961.7224\n",
      "Epoch : 859/2000 data_batch_1,  Train_loss : 5238.8135  Test_loss : 5574.7500, Time/batch_file : 2.2945, Training time: 9964.0171\n",
      "Epoch : 859/2000 data_batch_2,  Train_loss : 5012.7104  Test_loss : 5330.2168, Time/batch_file : 2.2653, Training time: 9966.2826\n",
      "Epoch : 859/2000 data_batch_3,  Train_loss : 4973.1572  Test_loss : 5536.7905, Time/batch_file : 2.2965, Training time: 9968.5793\n",
      "Epoch : 859/2000 data_batch_4,  Train_loss : 5033.8428  Test_loss : 5582.4170, Time/batch_file : 2.2721, Training time: 9970.8516\n",
      "Epoch : 859/2000 data_batch_5,  Train_loss : 5222.2734  Test_loss : 5504.1309, Time/batch_file : 2.3085, Training time: 9973.1603\n",
      "Epoch : 860/2000 data_batch_1,  Train_loss : 5454.1318  Test_loss : 5458.4170, Time/batch_file : 2.2782, Training time: 9975.4388\n",
      "Epoch : 860/2000 data_batch_2,  Train_loss : 5370.0801  Test_loss : 5620.6255, Time/batch_file : 2.3066, Training time: 9977.7456\n",
      "Epoch : 860/2000 data_batch_3,  Train_loss : 5698.3745  Test_loss : 5323.0952, Time/batch_file : 2.2701, Training time: 9980.0159\n",
      "Epoch : 860/2000 data_batch_4,  Train_loss : 5757.6064  Test_loss : 5524.4004, Time/batch_file : 2.2730, Training time: 9982.2890\n",
      "Epoch : 860/2000 data_batch_5,  Train_loss : 5502.7915  Test_loss : 5560.6870, Time/batch_file : 2.2667, Training time: 9984.5559\n",
      "[./nets/net-860.ckpt] SAVED\n",
      "Epoch : 861/2000 data_batch_1,  Train_loss : 5088.5742  Test_loss : 5217.6660, Time/batch_file : 2.3016, Training time: 9988.1342\n",
      "Epoch : 861/2000 data_batch_2,  Train_loss : 5329.1626  Test_loss : 4980.9595, Time/batch_file : 2.2938, Training time: 9990.4282\n",
      "Epoch : 861/2000 data_batch_3,  Train_loss : 5138.2607  Test_loss : 5246.8242, Time/batch_file : 2.3120, Training time: 9992.7404\n",
      "Epoch : 861/2000 data_batch_4,  Train_loss : 5494.2861  Test_loss : 5008.0669, Time/batch_file : 2.3035, Training time: 9995.0442\n",
      "Epoch : 861/2000 data_batch_5,  Train_loss : 5403.2607  Test_loss : 5064.0195, Time/batch_file : 2.2797, Training time: 9997.3241\n",
      "Epoch : 862/2000 data_batch_1,  Train_loss : 4958.1318  Test_loss : 5174.9761, Time/batch_file : 2.3411, Training time: 9999.6655\n",
      "Epoch : 862/2000 data_batch_2,  Train_loss : 4960.9219  Test_loss : 5177.1279, Time/batch_file : 2.2993, Training time: 10001.9649\n",
      "Epoch : 862/2000 data_batch_3,  Train_loss : 4964.0264  Test_loss : 5318.0532, Time/batch_file : 2.3373, Training time: 10004.3024\n",
      "Epoch : 862/2000 data_batch_4,  Train_loss : 4780.7988  Test_loss : 5133.5273, Time/batch_file : 2.3017, Training time: 10006.6043\n",
      "Epoch : 862/2000 data_batch_5,  Train_loss : 5036.0308  Test_loss : 5156.1621, Time/batch_file : 2.3395, Training time: 10008.9440\n",
      "Epoch : 863/2000 data_batch_1,  Train_loss : 5045.4868  Test_loss : 5293.8213, Time/batch_file : 2.2849, Training time: 10011.2290\n",
      "Epoch : 863/2000 data_batch_2,  Train_loss : 5306.1396  Test_loss : 5181.5078, Time/batch_file : 2.3435, Training time: 10013.5727\n",
      "Epoch : 863/2000 data_batch_3,  Train_loss : 4923.8027  Test_loss : 5351.0815, Time/batch_file : 2.2968, Training time: 10015.8697\n",
      "Epoch : 863/2000 data_batch_4,  Train_loss : 5177.4648  Test_loss : 5522.2700, Time/batch_file : 2.3527, Training time: 10018.2226\n",
      "Epoch : 863/2000 data_batch_5,  Train_loss : 5100.2480  Test_loss : 5238.4751, Time/batch_file : 2.2975, Training time: 10020.5203\n",
      "Epoch : 864/2000 data_batch_1,  Train_loss : 4826.6089  Test_loss : 5470.3994, Time/batch_file : 2.3298, Training time: 10022.8503\n",
      "Epoch : 864/2000 data_batch_2,  Train_loss : 5026.6499  Test_loss : 5183.3389, Time/batch_file : 2.2937, Training time: 10025.1444\n",
      "Epoch : 864/2000 data_batch_3,  Train_loss : 4977.9639  Test_loss : 5018.4019, Time/batch_file : 2.3276, Training time: 10027.4721\n",
      "Epoch : 864/2000 data_batch_4,  Train_loss : 4892.1841  Test_loss : 5251.0010, Time/batch_file : 2.2950, Training time: 10029.7673\n",
      "Epoch : 864/2000 data_batch_5,  Train_loss : 4686.5908  Test_loss : 5105.5352, Time/batch_file : 2.3354, Training time: 10032.1029\n",
      "Epoch : 865/2000 data_batch_1,  Train_loss : 4614.2192  Test_loss : 4654.9180, Time/batch_file : 2.2841, Training time: 10034.3872\n",
      "Epoch : 865/2000 data_batch_2,  Train_loss : 4782.9966  Test_loss : 4951.9561, Time/batch_file : 2.3301, Training time: 10036.7174\n",
      "Epoch : 865/2000 data_batch_3,  Train_loss : 4752.7773  Test_loss : 5098.5742, Time/batch_file : 2.2858, Training time: 10039.0035\n",
      "Epoch : 865/2000 data_batch_4,  Train_loss : 4713.2607  Test_loss : 4732.0225, Time/batch_file : 2.3320, Training time: 10041.3356\n",
      "Epoch : 865/2000 data_batch_5,  Train_loss : 4538.0742  Test_loss : 4949.1821, Time/batch_file : 2.2895, Training time: 10043.6255\n",
      "Epoch : 866/2000 data_batch_1,  Train_loss : 5331.1128  Test_loss : 5269.6377, Time/batch_file : 2.3284, Training time: 10045.9540\n",
      "Epoch : 866/2000 data_batch_2,  Train_loss : 5724.1934  Test_loss : 5115.4473, Time/batch_file : 2.2937, Training time: 10048.2478\n",
      "Epoch : 866/2000 data_batch_3,  Train_loss : 5331.3120  Test_loss : 5095.2822, Time/batch_file : 2.3272, Training time: 10050.5753\n",
      "Epoch : 866/2000 data_batch_4,  Train_loss : 5254.3291  Test_loss : 5126.1323, Time/batch_file : 2.2771, Training time: 10052.8526\n",
      "Epoch : 866/2000 data_batch_5,  Train_loss : 5572.2324  Test_loss : 5073.3228, Time/batch_file : 2.3260, Training time: 10055.1788\n",
      "Epoch : 867/2000 data_batch_1,  Train_loss : 4537.0020  Test_loss : 5537.6719, Time/batch_file : 2.2866, Training time: 10057.4656\n",
      "Epoch : 867/2000 data_batch_2,  Train_loss : 4611.0859  Test_loss : 5974.7617, Time/batch_file : 2.3328, Training time: 10059.7987\n",
      "Epoch : 867/2000 data_batch_3,  Train_loss : 4612.8018  Test_loss : 5580.1177, Time/batch_file : 2.2845, Training time: 10062.0835\n",
      "Epoch : 867/2000 data_batch_4,  Train_loss : 4576.6826  Test_loss : 5849.7729, Time/batch_file : 2.3243, Training time: 10064.4080\n",
      "Epoch : 867/2000 data_batch_5,  Train_loss : 4493.8740  Test_loss : 5405.0640, Time/batch_file : 2.2852, Training time: 10066.6934\n",
      "Epoch : 868/2000 data_batch_1,  Train_loss : 4985.6152  Test_loss : 5243.2646, Time/batch_file : 2.3229, Training time: 10069.0165\n",
      "Epoch : 868/2000 data_batch_2,  Train_loss : 5081.9458  Test_loss : 5566.4858, Time/batch_file : 2.2810, Training time: 10071.2977\n",
      "Epoch : 868/2000 data_batch_3,  Train_loss : 4955.4072  Test_loss : 5577.7090, Time/batch_file : 2.3205, Training time: 10073.6184\n",
      "Epoch : 868/2000 data_batch_4,  Train_loss : 5037.8325  Test_loss : 5398.0503, Time/batch_file : 2.2772, Training time: 10075.8959\n",
      "Epoch : 868/2000 data_batch_5,  Train_loss : 4963.1045  Test_loss : 5142.0356, Time/batch_file : 2.3175, Training time: 10078.2135\n",
      "Epoch : 869/2000 data_batch_1,  Train_loss : 5169.0474  Test_loss : 4910.5854, Time/batch_file : 2.3034, Training time: 10080.5171\n",
      "Epoch : 869/2000 data_batch_2,  Train_loss : 5190.0137  Test_loss : 4540.7666, Time/batch_file : 2.3376, Training time: 10082.8549\n",
      "Epoch : 869/2000 data_batch_3,  Train_loss : 5165.8213  Test_loss : 5252.5068, Time/batch_file : 2.3039, Training time: 10085.1590\n",
      "Epoch : 869/2000 data_batch_4,  Train_loss : 5177.5581  Test_loss : 5001.1211, Time/batch_file : 2.3406, Training time: 10087.4997\n",
      "Epoch : 869/2000 data_batch_5,  Train_loss : 5145.3926  Test_loss : 5015.6484, Time/batch_file : 2.3008, Training time: 10089.8007\n",
      "Epoch : 870/2000 data_batch_1,  Train_loss : 4806.4712  Test_loss : 5692.9346, Time/batch_file : 2.3287, Training time: 10092.1295\n",
      "Epoch : 870/2000 data_batch_2,  Train_loss : 4688.3770  Test_loss : 5591.7188, Time/batch_file : 2.2766, Training time: 10094.4063\n",
      "Epoch : 870/2000 data_batch_3,  Train_loss : 4773.4834  Test_loss : 5037.4521, Time/batch_file : 2.3258, Training time: 10096.7324\n",
      "Epoch : 870/2000 data_batch_4,  Train_loss : 4530.6479  Test_loss : 5235.6338, Time/batch_file : 2.2893, Training time: 10099.0219\n",
      "Epoch : 870/2000 data_batch_5,  Train_loss : 5046.8682  Test_loss : 5564.3008, Time/batch_file : 2.3286, Training time: 10101.3507\n",
      "[./nets/net-870.ckpt] SAVED\n",
      "Epoch : 871/2000 data_batch_1,  Train_loss : 4472.3169  Test_loss : 5472.9556, Time/batch_file : 2.3155, Training time: 10104.9244\n",
      "Epoch : 871/2000 data_batch_2,  Train_loss : 4793.7656  Test_loss : 5282.2427, Time/batch_file : 2.3115, Training time: 10107.2360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 871/2000 data_batch_3,  Train_loss : 4532.4556  Test_loss : 5432.4941, Time/batch_file : 2.2830, Training time: 10109.5192\n",
      "Epoch : 871/2000 data_batch_4,  Train_loss : 4595.3467  Test_loss : 5219.6836, Time/batch_file : 2.3320, Training time: 10111.8514\n",
      "Epoch : 871/2000 data_batch_5,  Train_loss : 4643.0005  Test_loss : 5243.7925, Time/batch_file : 2.2923, Training time: 10114.1439\n",
      "Epoch : 872/2000 data_batch_1,  Train_loss : 4844.2334  Test_loss : 5111.2373, Time/batch_file : 2.3171, Training time: 10116.4612\n",
      "Epoch : 872/2000 data_batch_2,  Train_loss : 5074.6729  Test_loss : 5506.2734, Time/batch_file : 2.3150, Training time: 10118.7764\n",
      "Epoch : 872/2000 data_batch_3,  Train_loss : 4691.5386  Test_loss : 5223.8384, Time/batch_file : 2.3273, Training time: 10121.1039\n",
      "Epoch : 872/2000 data_batch_4,  Train_loss : 4994.8633  Test_loss : 5054.0464, Time/batch_file : 2.3074, Training time: 10123.4114\n",
      "Epoch : 872/2000 data_batch_5,  Train_loss : 5129.5869  Test_loss : 5514.5361, Time/batch_file : 2.3080, Training time: 10125.7197\n",
      "Epoch : 873/2000 data_batch_1,  Train_loss : 5275.4990  Test_loss : 5345.3076, Time/batch_file : 2.3080, Training time: 10128.0280\n",
      "Epoch : 873/2000 data_batch_2,  Train_loss : 5271.6064  Test_loss : 5308.1045, Time/batch_file : 2.2745, Training time: 10130.3028\n",
      "Epoch : 873/2000 data_batch_3,  Train_loss : 5218.1860  Test_loss : 5230.4336, Time/batch_file : 2.2985, Training time: 10132.6015\n",
      "Epoch : 873/2000 data_batch_4,  Train_loss : 5054.2920  Test_loss : 5162.7734, Time/batch_file : 2.2829, Training time: 10134.8846\n",
      "Epoch : 873/2000 data_batch_5,  Train_loss : 5057.5146  Test_loss : 5167.0449, Time/batch_file : 2.3297, Training time: 10137.2145\n",
      "Epoch : 874/2000 data_batch_1,  Train_loss : 4495.6025  Test_loss : 5688.1880, Time/batch_file : 2.2953, Training time: 10139.5100\n",
      "Epoch : 874/2000 data_batch_2,  Train_loss : 4771.1709  Test_loss : 5588.5166, Time/batch_file : 2.3343, Training time: 10141.8445\n",
      "Epoch : 874/2000 data_batch_3,  Train_loss : 4417.0762  Test_loss : 5543.4453, Time/batch_file : 2.3263, Training time: 10144.1711\n",
      "Epoch : 874/2000 data_batch_4,  Train_loss : 4763.4033  Test_loss : 5791.7954, Time/batch_file : 2.2975, Training time: 10146.4688\n",
      "Epoch : 874/2000 data_batch_5,  Train_loss : 4642.1353  Test_loss : 5488.2539, Time/batch_file : 2.3122, Training time: 10148.7811\n",
      "Epoch : 875/2000 data_batch_1,  Train_loss : 5095.3496  Test_loss : 5066.8662, Time/batch_file : 2.3022, Training time: 10151.0835\n",
      "Epoch : 875/2000 data_batch_2,  Train_loss : 5005.9160  Test_loss : 5204.2168, Time/batch_file : 2.3006, Training time: 10153.3843\n",
      "Epoch : 875/2000 data_batch_3,  Train_loss : 5429.9072  Test_loss : 4767.8872, Time/batch_file : 2.2895, Training time: 10155.6740\n",
      "Epoch : 875/2000 data_batch_4,  Train_loss : 5243.4512  Test_loss : 5171.7178, Time/batch_file : 2.3113, Training time: 10157.9855\n",
      "Epoch : 875/2000 data_batch_5,  Train_loss : 5064.1099  Test_loss : 5352.5840, Time/batch_file : 2.2934, Training time: 10160.2792\n",
      "Epoch : 876/2000 data_batch_1,  Train_loss : 5423.7119  Test_loss : 5128.4829, Time/batch_file : 2.3055, Training time: 10162.5849\n",
      "Epoch : 876/2000 data_batch_2,  Train_loss : 5323.0684  Test_loss : 5586.0229, Time/batch_file : 2.3084, Training time: 10164.8935\n",
      "Epoch : 876/2000 data_batch_3,  Train_loss : 5183.4326  Test_loss : 5175.2080, Time/batch_file : 2.2778, Training time: 10167.1715\n",
      "Epoch : 876/2000 data_batch_4,  Train_loss : 5395.0254  Test_loss : 4946.0938, Time/batch_file : 2.3072, Training time: 10169.4788\n",
      "Epoch : 876/2000 data_batch_5,  Train_loss : 5528.8628  Test_loss : 5320.3833, Time/batch_file : 2.2854, Training time: 10171.7644\n",
      "Epoch : 877/2000 data_batch_1,  Train_loss : 4816.7139  Test_loss : 5241.8472, Time/batch_file : 2.3364, Training time: 10174.1011\n",
      "Epoch : 877/2000 data_batch_2,  Train_loss : 4615.7583  Test_loss : 5718.4746, Time/batch_file : 2.2987, Training time: 10176.4000\n",
      "Epoch : 877/2000 data_batch_3,  Train_loss : 4658.1108  Test_loss : 5149.8184, Time/batch_file : 2.3119, Training time: 10178.7120\n",
      "Epoch : 877/2000 data_batch_4,  Train_loss : 4689.7163  Test_loss : 5280.6494, Time/batch_file : 2.3268, Training time: 10181.0390\n",
      "Epoch : 877/2000 data_batch_5,  Train_loss : 4624.5156  Test_loss : 5047.1040, Time/batch_file : 2.2941, Training time: 10183.3333\n",
      "Epoch : 878/2000 data_batch_1,  Train_loss : 4923.0527  Test_loss : 5320.5400, Time/batch_file : 2.2920, Training time: 10185.6256\n",
      "Epoch : 878/2000 data_batch_2,  Train_loss : 5205.8071  Test_loss : 5232.1953, Time/batch_file : 2.2932, Training time: 10187.9190\n",
      "Epoch : 878/2000 data_batch_3,  Train_loss : 5328.8164  Test_loss : 5215.3184, Time/batch_file : 2.2946, Training time: 10190.2139\n",
      "Epoch : 878/2000 data_batch_4,  Train_loss : 4947.8350  Test_loss : 5234.6226, Time/batch_file : 2.2953, Training time: 10192.5093\n",
      "Epoch : 878/2000 data_batch_5,  Train_loss : 5184.2002  Test_loss : 5342.3584, Time/batch_file : 2.3014, Training time: 10194.8109\n",
      "Epoch : 879/2000 data_batch_1,  Train_loss : 4762.4092  Test_loss : 4940.3994, Time/batch_file : 2.2994, Training time: 10197.1105\n",
      "Epoch : 879/2000 data_batch_2,  Train_loss : 4965.8770  Test_loss : 5144.9561, Time/batch_file : 2.2955, Training time: 10199.4061\n",
      "Epoch : 879/2000 data_batch_3,  Train_loss : 4871.3130  Test_loss : 5118.1895, Time/batch_file : 2.2999, Training time: 10201.7062\n",
      "Epoch : 879/2000 data_batch_4,  Train_loss : 5010.3145  Test_loss : 4725.0981, Time/batch_file : 2.2751, Training time: 10203.9814\n",
      "Epoch : 879/2000 data_batch_5,  Train_loss : 4761.4829  Test_loss : 4998.6851, Time/batch_file : 2.2929, Training time: 10206.2746\n",
      "Epoch : 880/2000 data_batch_1,  Train_loss : 4955.4194  Test_loss : 5309.5308, Time/batch_file : 2.2683, Training time: 10208.5432\n",
      "Epoch : 880/2000 data_batch_2,  Train_loss : 4833.5762  Test_loss : 5089.9409, Time/batch_file : 2.3209, Training time: 10210.8643\n",
      "Epoch : 880/2000 data_batch_3,  Train_loss : 4725.6221  Test_loss : 5196.6641, Time/batch_file : 2.2749, Training time: 10213.1394\n",
      "Epoch : 880/2000 data_batch_4,  Train_loss : 5011.3135  Test_loss : 5020.1812, Time/batch_file : 2.2995, Training time: 10215.4391\n",
      "Epoch : 880/2000 data_batch_5,  Train_loss : 4687.3750  Test_loss : 5664.3027, Time/batch_file : 2.3038, Training time: 10217.7430\n",
      "[./nets/net-880.ckpt] SAVED\n",
      "Epoch : 881/2000 data_batch_1,  Train_loss : 4926.4229  Test_loss : 4824.3091, Time/batch_file : 2.3553, Training time: 10221.3687\n",
      "Epoch : 881/2000 data_batch_2,  Train_loss : 4671.5400  Test_loss : 4737.1211, Time/batch_file : 2.3021, Training time: 10223.6709\n",
      "Epoch : 881/2000 data_batch_3,  Train_loss : 4967.4561  Test_loss : 4708.8252, Time/batch_file : 2.3314, Training time: 10226.0024\n",
      "Epoch : 881/2000 data_batch_4,  Train_loss : 4925.7705  Test_loss : 5129.1904, Time/batch_file : 2.3255, Training time: 10228.3280\n",
      "Epoch : 881/2000 data_batch_5,  Train_loss : 5069.0752  Test_loss : 4789.2842, Time/batch_file : 2.3347, Training time: 10230.6629\n",
      "Epoch : 882/2000 data_batch_1,  Train_loss : 5215.3477  Test_loss : 5425.7490, Time/batch_file : 2.2972, Training time: 10232.9603\n",
      "Epoch : 882/2000 data_batch_2,  Train_loss : 5240.4766  Test_loss : 5177.5259, Time/batch_file : 2.3354, Training time: 10235.2959\n",
      "Epoch : 882/2000 data_batch_3,  Train_loss : 5184.6343  Test_loss : 5317.2124, Time/batch_file : 2.2983, Training time: 10237.5945\n",
      "Epoch : 882/2000 data_batch_4,  Train_loss : 5286.7861  Test_loss : 5384.8125, Time/batch_file : 2.3334, Training time: 10239.9280\n",
      "Epoch : 882/2000 data_batch_5,  Train_loss : 5037.1733  Test_loss : 5169.3350, Time/batch_file : 2.3013, Training time: 10242.2295\n",
      "Epoch : 883/2000 data_batch_1,  Train_loss : 5178.8721  Test_loss : 5961.3760, Time/batch_file : 2.3133, Training time: 10244.5430\n",
      "Epoch : 883/2000 data_batch_2,  Train_loss : 5359.7139  Test_loss : 6087.9165, Time/batch_file : 2.2944, Training time: 10246.8375\n",
      "Epoch : 883/2000 data_batch_3,  Train_loss : 5308.2559  Test_loss : 6096.0732, Time/batch_file : 2.3272, Training time: 10249.1650\n",
      "Epoch : 883/2000 data_batch_4,  Train_loss : 5390.5762  Test_loss : 5744.8535, Time/batch_file : 2.3003, Training time: 10251.4655\n",
      "Epoch : 883/2000 data_batch_5,  Train_loss : 5682.6055  Test_loss : 6004.0649, Time/batch_file : 2.3161, Training time: 10253.7819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 884/2000 data_batch_1,  Train_loss : 5370.5688  Test_loss : 5343.7490, Time/batch_file : 2.3033, Training time: 10256.0855\n",
      "Epoch : 884/2000 data_batch_2,  Train_loss : 5189.3813  Test_loss : 5124.5586, Time/batch_file : 2.3438, Training time: 10258.4294\n",
      "Epoch : 884/2000 data_batch_3,  Train_loss : 5319.4219  Test_loss : 5230.7710, Time/batch_file : 2.3038, Training time: 10260.7335\n",
      "Epoch : 884/2000 data_batch_4,  Train_loss : 5300.4570  Test_loss : 5255.4268, Time/batch_file : 2.3377, Training time: 10263.0712\n",
      "Epoch : 884/2000 data_batch_5,  Train_loss : 5258.1802  Test_loss : 4951.6772, Time/batch_file : 2.3116, Training time: 10265.3830\n",
      "Epoch : 885/2000 data_batch_1,  Train_loss : 4901.4453  Test_loss : 5335.4092, Time/batch_file : 2.3350, Training time: 10267.7182\n",
      "Epoch : 885/2000 data_batch_2,  Train_loss : 4738.2139  Test_loss : 5276.8433, Time/batch_file : 2.3188, Training time: 10270.0373\n",
      "Epoch : 885/2000 data_batch_3,  Train_loss : 5066.1875  Test_loss : 5617.4941, Time/batch_file : 2.3259, Training time: 10272.3633\n",
      "Epoch : 885/2000 data_batch_4,  Train_loss : 4868.6455  Test_loss : 5711.5293, Time/batch_file : 2.3215, Training time: 10274.6850\n",
      "Epoch : 885/2000 data_batch_5,  Train_loss : 4929.4531  Test_loss : 5903.2168, Time/batch_file : 2.3218, Training time: 10277.0069\n",
      "Epoch : 886/2000 data_batch_1,  Train_loss : 4659.9023  Test_loss : 5380.9736, Time/batch_file : 2.3000, Training time: 10279.3071\n",
      "Epoch : 886/2000 data_batch_2,  Train_loss : 4913.5430  Test_loss : 5455.5366, Time/batch_file : 2.3170, Training time: 10281.6244\n",
      "Epoch : 886/2000 data_batch_3,  Train_loss : 4697.4111  Test_loss : 5108.6104, Time/batch_file : 2.2952, Training time: 10283.9197\n",
      "Epoch : 886/2000 data_batch_4,  Train_loss : 4719.9741  Test_loss : 5156.3223, Time/batch_file : 2.3168, Training time: 10286.2368\n",
      "Epoch : 886/2000 data_batch_5,  Train_loss : 4926.8970  Test_loss : 4828.9717, Time/batch_file : 2.2901, Training time: 10288.5271\n",
      "Epoch : 887/2000 data_batch_1,  Train_loss : 4897.2959  Test_loss : 5758.9365, Time/batch_file : 2.3316, Training time: 10290.8589\n",
      "Epoch : 887/2000 data_batch_2,  Train_loss : 4712.8120  Test_loss : 5447.8789, Time/batch_file : 2.3128, Training time: 10293.1720\n",
      "Epoch : 887/2000 data_batch_3,  Train_loss : 4711.8091  Test_loss : 5408.9360, Time/batch_file : 2.3162, Training time: 10295.4885\n",
      "Epoch : 887/2000 data_batch_4,  Train_loss : 4985.6377  Test_loss : 5348.3701, Time/batch_file : 2.3031, Training time: 10297.7917\n",
      "Epoch : 887/2000 data_batch_5,  Train_loss : 4697.4907  Test_loss : 5565.6519, Time/batch_file : 2.3277, Training time: 10300.1197\n",
      "Epoch : 888/2000 data_batch_1,  Train_loss : 4725.9038  Test_loss : 5329.9785, Time/batch_file : 2.3019, Training time: 10302.4218\n",
      "Epoch : 888/2000 data_batch_2,  Train_loss : 4735.7485  Test_loss : 5386.8101, Time/batch_file : 2.3239, Training time: 10304.7458\n",
      "Epoch : 888/2000 data_batch_3,  Train_loss : 4614.8345  Test_loss : 5566.6035, Time/batch_file : 2.2942, Training time: 10307.0401\n",
      "Epoch : 888/2000 data_batch_4,  Train_loss : 4666.9019  Test_loss : 5405.8765, Time/batch_file : 2.3311, Training time: 10309.3716\n",
      "Epoch : 888/2000 data_batch_5,  Train_loss : 4716.9214  Test_loss : 5529.0981, Time/batch_file : 2.2951, Training time: 10311.6671\n",
      "Epoch : 889/2000 data_batch_1,  Train_loss : 4695.7822  Test_loss : 5132.8716, Time/batch_file : 2.3339, Training time: 10314.0012\n",
      "Epoch : 889/2000 data_batch_2,  Train_loss : 5012.0938  Test_loss : 5250.6465, Time/batch_file : 2.3075, Training time: 10316.3089\n",
      "Epoch : 889/2000 data_batch_3,  Train_loss : 4634.0137  Test_loss : 5119.6753, Time/batch_file : 2.3265, Training time: 10318.6356\n",
      "Epoch : 889/2000 data_batch_4,  Train_loss : 4757.6055  Test_loss : 5161.3154, Time/batch_file : 2.3084, Training time: 10320.9441\n",
      "Epoch : 889/2000 data_batch_5,  Train_loss : 4960.6250  Test_loss : 4956.2637, Time/batch_file : 2.3291, Training time: 10323.2735\n",
      "Epoch : 890/2000 data_batch_1,  Train_loss : 5033.5244  Test_loss : 5103.5981, Time/batch_file : 2.2987, Training time: 10325.5724\n",
      "Epoch : 890/2000 data_batch_2,  Train_loss : 4767.5483  Test_loss : 5234.5239, Time/batch_file : 2.3229, Training time: 10327.8955\n",
      "Epoch : 890/2000 data_batch_3,  Train_loss : 4938.4380  Test_loss : 4997.2061, Time/batch_file : 2.2904, Training time: 10330.1861\n",
      "Epoch : 890/2000 data_batch_4,  Train_loss : 4796.4629  Test_loss : 5185.1367, Time/batch_file : 2.3271, Training time: 10332.5134\n",
      "Epoch : 890/2000 data_batch_5,  Train_loss : 4770.7275  Test_loss : 4933.2183, Time/batch_file : 2.3031, Training time: 10334.8167\n",
      "[./nets/net-890.ckpt] SAVED\n",
      "Epoch : 891/2000 data_batch_1,  Train_loss : 4470.7441  Test_loss : 5117.9761, Time/batch_file : 2.2879, Training time: 10338.3783\n",
      "Epoch : 891/2000 data_batch_2,  Train_loss : 4452.3262  Test_loss : 4841.9316, Time/batch_file : 2.2788, Training time: 10340.6573\n",
      "Epoch : 891/2000 data_batch_3,  Train_loss : 4572.7676  Test_loss : 5045.1650, Time/batch_file : 2.2746, Training time: 10342.9320\n",
      "Epoch : 891/2000 data_batch_4,  Train_loss : 4629.2148  Test_loss : 5173.8301, Time/batch_file : 2.2599, Training time: 10345.1921\n",
      "Epoch : 891/2000 data_batch_5,  Train_loss : 4482.8887  Test_loss : 5245.8867, Time/batch_file : 2.2784, Training time: 10347.4708\n",
      "Epoch : 892/2000 data_batch_1,  Train_loss : 5119.8623  Test_loss : 5314.2979, Time/batch_file : 2.2664, Training time: 10349.7375\n",
      "Epoch : 892/2000 data_batch_2,  Train_loss : 4779.5112  Test_loss : 5179.0068, Time/batch_file : 2.2755, Training time: 10352.0131\n",
      "Epoch : 892/2000 data_batch_3,  Train_loss : 5021.2627  Test_loss : 5481.5107, Time/batch_file : 2.2688, Training time: 10354.2821\n",
      "Epoch : 892/2000 data_batch_4,  Train_loss : 4890.0122  Test_loss : 5300.8164, Time/batch_file : 2.2670, Training time: 10356.5492\n",
      "Epoch : 892/2000 data_batch_5,  Train_loss : 4744.0127  Test_loss : 5306.8086, Time/batch_file : 2.2911, Training time: 10358.8405\n",
      "Epoch : 893/2000 data_batch_1,  Train_loss : 4694.3330  Test_loss : 4706.2178, Time/batch_file : 2.2560, Training time: 10361.0966\n",
      "Epoch : 893/2000 data_batch_2,  Train_loss : 4648.4053  Test_loss : 4891.3057, Time/batch_file : 2.2654, Training time: 10363.3622\n",
      "Epoch : 893/2000 data_batch_3,  Train_loss : 4698.8848  Test_loss : 4923.1895, Time/batch_file : 2.2551, Training time: 10365.6174\n",
      "Epoch : 893/2000 data_batch_4,  Train_loss : 4573.4238  Test_loss : 5241.3564, Time/batch_file : 2.2581, Training time: 10367.8756\n",
      "Epoch : 893/2000 data_batch_5,  Train_loss : 4646.5283  Test_loss : 5242.3862, Time/batch_file : 2.2710, Training time: 10370.1468\n",
      "Epoch : 894/2000 data_batch_1,  Train_loss : 4944.0239  Test_loss : 4861.1689, Time/batch_file : 2.2664, Training time: 10372.4134\n",
      "Epoch : 894/2000 data_batch_2,  Train_loss : 5234.8848  Test_loss : 5123.0942, Time/batch_file : 2.2557, Training time: 10374.6694\n",
      "Epoch : 894/2000 data_batch_3,  Train_loss : 5091.3843  Test_loss : 4952.1011, Time/batch_file : 2.2769, Training time: 10376.9465\n",
      "Epoch : 894/2000 data_batch_4,  Train_loss : 5333.4668  Test_loss : 5038.4961, Time/batch_file : 2.2668, Training time: 10379.2135\n",
      "Epoch : 894/2000 data_batch_5,  Train_loss : 5070.1626  Test_loss : 5344.6577, Time/batch_file : 2.2598, Training time: 10381.4733\n",
      "Epoch : 895/2000 data_batch_1,  Train_loss : 5566.4731  Test_loss : 5108.4819, Time/batch_file : 2.2803, Training time: 10383.7538\n",
      "Epoch : 895/2000 data_batch_2,  Train_loss : 5446.7749  Test_loss : 5695.4146, Time/batch_file : 2.2743, Training time: 10386.0283\n",
      "Epoch : 895/2000 data_batch_3,  Train_loss : 5459.9185  Test_loss : 5600.5845, Time/batch_file : 2.2808, Training time: 10388.3094\n",
      "Epoch : 895/2000 data_batch_4,  Train_loss : 5612.7637  Test_loss : 5546.3770, Time/batch_file : 2.2894, Training time: 10390.5990\n",
      "Epoch : 895/2000 data_batch_5,  Train_loss : 5718.5283  Test_loss : 5650.2969, Time/batch_file : 2.2750, Training time: 10392.8742\n",
      "Epoch : 896/2000 data_batch_1,  Train_loss : 5396.5229  Test_loss : 5120.9502, Time/batch_file : 2.2746, Training time: 10395.1490\n",
      "Epoch : 896/2000 data_batch_2,  Train_loss : 5101.4238  Test_loss : 5280.5640, Time/batch_file : 2.2633, Training time: 10397.4124\n",
      "Epoch : 896/2000 data_batch_3,  Train_loss : 4995.0464  Test_loss : 5146.6699, Time/batch_file : 2.2752, Training time: 10399.6877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 896/2000 data_batch_4,  Train_loss : 5036.2158  Test_loss : 5145.2109, Time/batch_file : 2.2680, Training time: 10401.9559\n",
      "Epoch : 896/2000 data_batch_5,  Train_loss : 5020.9795  Test_loss : 5312.7036, Time/batch_file : 2.2654, Training time: 10404.2215\n",
      "Epoch : 897/2000 data_batch_1,  Train_loss : 4689.6724  Test_loss : 4260.0029, Time/batch_file : 2.2547, Training time: 10406.4764\n",
      "Epoch : 897/2000 data_batch_2,  Train_loss : 4805.8672  Test_loss : 4392.8354, Time/batch_file : 2.2699, Training time: 10408.7465\n",
      "Epoch : 897/2000 data_batch_3,  Train_loss : 4782.9985  Test_loss : 4444.4395, Time/batch_file : 2.2583, Training time: 10411.0050\n",
      "Epoch : 897/2000 data_batch_4,  Train_loss : 5043.4297  Test_loss : 4375.1396, Time/batch_file : 2.2695, Training time: 10413.2747\n",
      "Epoch : 897/2000 data_batch_5,  Train_loss : 4758.1631  Test_loss : 4345.0283, Time/batch_file : 2.2536, Training time: 10415.5286\n",
      "Epoch : 898/2000 data_batch_1,  Train_loss : 4999.3652  Test_loss : 5312.2534, Time/batch_file : 2.2546, Training time: 10417.7834\n",
      "Epoch : 898/2000 data_batch_2,  Train_loss : 5062.5781  Test_loss : 5039.1328, Time/batch_file : 2.2682, Training time: 10420.0517\n",
      "Epoch : 898/2000 data_batch_3,  Train_loss : 4884.9897  Test_loss : 4990.0215, Time/batch_file : 2.2574, Training time: 10422.3094\n",
      "Epoch : 898/2000 data_batch_4,  Train_loss : 4784.3911  Test_loss : 5131.3457, Time/batch_file : 2.2452, Training time: 10424.5547\n",
      "Epoch : 898/2000 data_batch_5,  Train_loss : 4830.8979  Test_loss : 5345.6426, Time/batch_file : 2.2555, Training time: 10426.8105\n",
      "Epoch : 899/2000 data_batch_1,  Train_loss : 4917.8613  Test_loss : 5476.3008, Time/batch_file : 2.2846, Training time: 10429.0953\n",
      "Epoch : 899/2000 data_batch_2,  Train_loss : 4818.7822  Test_loss : 5475.5244, Time/batch_file : 2.2816, Training time: 10431.3771\n",
      "Epoch : 899/2000 data_batch_3,  Train_loss : 4798.8481  Test_loss : 5533.4541, Time/batch_file : 2.2666, Training time: 10433.6438\n",
      "Epoch : 899/2000 data_batch_4,  Train_loss : 4670.8291  Test_loss : 5546.3374, Time/batch_file : 2.2810, Training time: 10435.9250\n",
      "Epoch : 899/2000 data_batch_5,  Train_loss : 4784.0298  Test_loss : 5576.2988, Time/batch_file : 2.2693, Training time: 10438.1946\n",
      "Epoch : 900/2000 data_batch_1,  Train_loss : 5173.9795  Test_loss : 5117.0000, Time/batch_file : 2.2829, Training time: 10440.4777\n",
      "Epoch : 900/2000 data_batch_2,  Train_loss : 5223.1133  Test_loss : 5140.5513, Time/batch_file : 2.2735, Training time: 10442.7515\n",
      "Epoch : 900/2000 data_batch_3,  Train_loss : 5334.4395  Test_loss : 4985.0283, Time/batch_file : 2.2794, Training time: 10445.0310\n",
      "Epoch : 900/2000 data_batch_4,  Train_loss : 5141.7100  Test_loss : 4917.1543, Time/batch_file : 2.2686, Training time: 10447.2997\n",
      "Epoch : 900/2000 data_batch_5,  Train_loss : 5007.9463  Test_loss : 4899.9912, Time/batch_file : 2.2855, Training time: 10449.5855\n",
      "[./nets/net-900.ckpt] SAVED\n",
      "Epoch : 901/2000 data_batch_1,  Train_loss : 4597.4570  Test_loss : 4877.1421, Time/batch_file : 2.2833, Training time: 10453.1449\n",
      "Epoch : 901/2000 data_batch_2,  Train_loss : 4873.5171  Test_loss : 4901.7871, Time/batch_file : 2.3043, Training time: 10455.4495\n",
      "Epoch : 901/2000 data_batch_3,  Train_loss : 4525.4019  Test_loss : 4834.1025, Time/batch_file : 2.2812, Training time: 10457.7308\n",
      "Epoch : 901/2000 data_batch_4,  Train_loss : 4321.6689  Test_loss : 4970.4980, Time/batch_file : 2.2738, Training time: 10460.0049\n",
      "Epoch : 901/2000 data_batch_5,  Train_loss : 4830.5986  Test_loss : 4917.7515, Time/batch_file : 2.2764, Training time: 10462.2814\n",
      "Epoch : 902/2000 data_batch_1,  Train_loss : 5043.2832  Test_loss : 5471.5967, Time/batch_file : 2.2731, Training time: 10464.5548\n",
      "Epoch : 902/2000 data_batch_2,  Train_loss : 5233.1055  Test_loss : 5591.6797, Time/batch_file : 2.2939, Training time: 10466.8489\n",
      "Epoch : 902/2000 data_batch_3,  Train_loss : 4965.7637  Test_loss : 5896.1797, Time/batch_file : 2.2669, Training time: 10469.1160\n",
      "Epoch : 902/2000 data_batch_4,  Train_loss : 5207.4897  Test_loss : 5808.1704, Time/batch_file : 2.2826, Training time: 10471.3988\n",
      "Epoch : 902/2000 data_batch_5,  Train_loss : 5114.9717  Test_loss : 6168.6357, Time/batch_file : 2.2643, Training time: 10473.6632\n",
      "Epoch : 903/2000 data_batch_1,  Train_loss : 4767.4253  Test_loss : 5090.4424, Time/batch_file : 2.3067, Training time: 10475.9703\n",
      "Epoch : 903/2000 data_batch_2,  Train_loss : 4829.4019  Test_loss : 5087.1240, Time/batch_file : 2.2955, Training time: 10478.2660\n",
      "Epoch : 903/2000 data_batch_3,  Train_loss : 4754.5127  Test_loss : 5030.2300, Time/batch_file : 2.2993, Training time: 10480.5656\n",
      "Epoch : 903/2000 data_batch_4,  Train_loss : 4764.4526  Test_loss : 5065.5293, Time/batch_file : 2.3012, Training time: 10482.8668\n",
      "Epoch : 903/2000 data_batch_5,  Train_loss : 5012.4780  Test_loss : 5007.9648, Time/batch_file : 2.3089, Training time: 10485.1760\n",
      "Epoch : 904/2000 data_batch_1,  Train_loss : 4589.7471  Test_loss : 5206.5415, Time/batch_file : 2.2773, Training time: 10487.4536\n",
      "Epoch : 904/2000 data_batch_2,  Train_loss : 4814.5049  Test_loss : 5317.7427, Time/batch_file : 2.2992, Training time: 10489.7530\n",
      "Epoch : 904/2000 data_batch_3,  Train_loss : 4805.7842  Test_loss : 5096.8398, Time/batch_file : 2.2674, Training time: 10492.0205\n",
      "Epoch : 904/2000 data_batch_4,  Train_loss : 4750.0474  Test_loss : 5335.7954, Time/batch_file : 2.2935, Training time: 10494.3143\n",
      "Epoch : 904/2000 data_batch_5,  Train_loss : 4859.7090  Test_loss : 5164.0205, Time/batch_file : 2.2769, Training time: 10496.5914\n",
      "Epoch : 905/2000 data_batch_1,  Train_loss : 5449.6299  Test_loss : 4967.4502, Time/batch_file : 2.2675, Training time: 10498.8592\n",
      "Epoch : 905/2000 data_batch_2,  Train_loss : 5041.6787  Test_loss : 5230.1909, Time/batch_file : 2.2767, Training time: 10501.1361\n",
      "Epoch : 905/2000 data_batch_3,  Train_loss : 5132.1909  Test_loss : 5183.4268, Time/batch_file : 2.2681, Training time: 10503.4044\n",
      "Epoch : 905/2000 data_batch_4,  Train_loss : 5201.6333  Test_loss : 5233.0615, Time/batch_file : 2.2548, Training time: 10505.6594\n",
      "Epoch : 905/2000 data_batch_5,  Train_loss : 4723.5420  Test_loss : 4975.6973, Time/batch_file : 2.2708, Training time: 10507.9305\n",
      "Epoch : 906/2000 data_batch_1,  Train_loss : 4900.9585  Test_loss : 4898.9219, Time/batch_file : 2.2840, Training time: 10510.2147\n",
      "Epoch : 906/2000 data_batch_2,  Train_loss : 4949.6934  Test_loss : 4987.6357, Time/batch_file : 2.2778, Training time: 10512.4927\n",
      "Epoch : 906/2000 data_batch_3,  Train_loss : 4978.4321  Test_loss : 5191.7012, Time/batch_file : 2.2877, Training time: 10514.7807\n",
      "Epoch : 906/2000 data_batch_4,  Train_loss : 5265.0547  Test_loss : 4733.3262, Time/batch_file : 2.2835, Training time: 10517.0643\n",
      "Epoch : 906/2000 data_batch_5,  Train_loss : 5163.1226  Test_loss : 4785.0825, Time/batch_file : 2.2863, Training time: 10519.3509\n",
      "Epoch : 907/2000 data_batch_1,  Train_loss : 5277.4912  Test_loss : 5295.6670, Time/batch_file : 2.3197, Training time: 10521.6707\n",
      "Epoch : 907/2000 data_batch_2,  Train_loss : 4956.0146  Test_loss : 5137.6914, Time/batch_file : 2.2802, Training time: 10523.9510\n",
      "Epoch : 907/2000 data_batch_3,  Train_loss : 5213.4468  Test_loss : 5073.3281, Time/batch_file : 2.2873, Training time: 10526.2385\n",
      "Epoch : 907/2000 data_batch_4,  Train_loss : 5212.8555  Test_loss : 5216.0986, Time/batch_file : 2.2720, Training time: 10528.5107\n",
      "Epoch : 907/2000 data_batch_5,  Train_loss : 5076.1768  Test_loss : 4879.0479, Time/batch_file : 2.2874, Training time: 10530.7983\n",
      "Epoch : 908/2000 data_batch_1,  Train_loss : 5209.3770  Test_loss : 5003.7925, Time/batch_file : 2.2665, Training time: 10533.0651\n",
      "Epoch : 908/2000 data_batch_2,  Train_loss : 5223.8486  Test_loss : 5037.2280, Time/batch_file : 2.2745, Training time: 10535.3398\n",
      "Epoch : 908/2000 data_batch_3,  Train_loss : 5152.6787  Test_loss : 5072.5649, Time/batch_file : 2.2680, Training time: 10537.6079\n",
      "Epoch : 908/2000 data_batch_4,  Train_loss : 5203.3096  Test_loss : 4977.5757, Time/batch_file : 2.2735, Training time: 10539.8816\n",
      "Epoch : 908/2000 data_batch_5,  Train_loss : 5148.1865  Test_loss : 5181.7666, Time/batch_file : 2.2643, Training time: 10542.1461\n",
      "Epoch : 909/2000 data_batch_1,  Train_loss : 5371.4863  Test_loss : 4925.0259, Time/batch_file : 2.2832, Training time: 10544.4295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 909/2000 data_batch_2,  Train_loss : 5138.4678  Test_loss : 4803.6997, Time/batch_file : 2.2708, Training time: 10546.7005\n",
      "Epoch : 909/2000 data_batch_3,  Train_loss : 5200.9209  Test_loss : 4783.1001, Time/batch_file : 2.2732, Training time: 10548.9739\n",
      "Epoch : 909/2000 data_batch_4,  Train_loss : 5299.5815  Test_loss : 4785.2700, Time/batch_file : 2.2749, Training time: 10551.2490\n",
      "Epoch : 909/2000 data_batch_5,  Train_loss : 5177.3506  Test_loss : 5146.8057, Time/batch_file : 2.2709, Training time: 10553.5202\n",
      "Epoch : 910/2000 data_batch_1,  Train_loss : 4799.5947  Test_loss : 5284.4229, Time/batch_file : 2.2762, Training time: 10555.7966\n",
      "Epoch : 910/2000 data_batch_2,  Train_loss : 4939.4072  Test_loss : 5280.9131, Time/batch_file : 2.2857, Training time: 10558.0826\n",
      "Epoch : 910/2000 data_batch_3,  Train_loss : 5170.4897  Test_loss : 5292.9902, Time/batch_file : 2.2771, Training time: 10560.3598\n",
      "Epoch : 910/2000 data_batch_4,  Train_loss : 4600.1792  Test_loss : 5091.7368, Time/batch_file : 2.2859, Training time: 10562.6459\n",
      "Epoch : 910/2000 data_batch_5,  Train_loss : 4821.8828  Test_loss : 5483.2910, Time/batch_file : 2.2713, Training time: 10564.9174\n",
      "[./nets/net-910.ckpt] SAVED\n",
      "Epoch : 911/2000 data_batch_1,  Train_loss : 5438.0635  Test_loss : 4291.3545, Time/batch_file : 2.2893, Training time: 10568.4657\n",
      "Epoch : 911/2000 data_batch_2,  Train_loss : 5442.0786  Test_loss : 4394.7827, Time/batch_file : 2.2748, Training time: 10570.7407\n",
      "Epoch : 911/2000 data_batch_3,  Train_loss : 5156.2314  Test_loss : 4497.9790, Time/batch_file : 2.2634, Training time: 10573.0043\n",
      "Epoch : 911/2000 data_batch_4,  Train_loss : 5619.7603  Test_loss : 4481.7700, Time/batch_file : 2.2877, Training time: 10575.2922\n",
      "Epoch : 911/2000 data_batch_5,  Train_loss : 5364.5020  Test_loss : 4417.3057, Time/batch_file : 2.2585, Training time: 10577.5509\n",
      "Epoch : 912/2000 data_batch_1,  Train_loss : 4801.7969  Test_loss : 5610.3784, Time/batch_file : 2.2843, Training time: 10579.8354\n",
      "Epoch : 912/2000 data_batch_2,  Train_loss : 5245.2803  Test_loss : 5237.0049, Time/batch_file : 2.2584, Training time: 10582.0939\n",
      "Epoch : 912/2000 data_batch_3,  Train_loss : 5028.8394  Test_loss : 5232.7075, Time/batch_file : 2.2915, Training time: 10584.3856\n",
      "Epoch : 912/2000 data_batch_4,  Train_loss : 5225.2617  Test_loss : 5184.1890, Time/batch_file : 2.2675, Training time: 10586.6534\n",
      "Epoch : 912/2000 data_batch_5,  Train_loss : 4883.6865  Test_loss : 5460.0127, Time/batch_file : 2.2771, Training time: 10588.9307\n",
      "Epoch : 913/2000 data_batch_1,  Train_loss : 4617.9902  Test_loss : 4709.6846, Time/batch_file : 2.2646, Training time: 10591.1955\n",
      "Epoch : 913/2000 data_batch_2,  Train_loss : 4631.6484  Test_loss : 4974.7363, Time/batch_file : 2.2770, Training time: 10593.4726\n",
      "Epoch : 913/2000 data_batch_3,  Train_loss : 4634.7744  Test_loss : 5009.6816, Time/batch_file : 2.2699, Training time: 10595.7427\n",
      "Epoch : 913/2000 data_batch_4,  Train_loss : 4391.8438  Test_loss : 4953.8545, Time/batch_file : 2.2744, Training time: 10598.0173\n",
      "Epoch : 913/2000 data_batch_5,  Train_loss : 4559.9360  Test_loss : 5382.1235, Time/batch_file : 2.2464, Training time: 10600.2640\n",
      "Epoch : 914/2000 data_batch_1,  Train_loss : 5194.1733  Test_loss : 5280.1133, Time/batch_file : 2.2843, Training time: 10602.5486\n",
      "Epoch : 914/2000 data_batch_2,  Train_loss : 5101.8115  Test_loss : 5447.2207, Time/batch_file : 2.2709, Training time: 10604.8197\n",
      "Epoch : 914/2000 data_batch_3,  Train_loss : 5188.9219  Test_loss : 4902.7427, Time/batch_file : 2.2851, Training time: 10607.1050\n",
      "Epoch : 914/2000 data_batch_4,  Train_loss : 4980.5225  Test_loss : 5566.1416, Time/batch_file : 2.2657, Training time: 10609.3709\n",
      "Epoch : 914/2000 data_batch_5,  Train_loss : 4828.3037  Test_loss : 4871.9082, Time/batch_file : 2.2677, Training time: 10611.6388\n",
      "Epoch : 915/2000 data_batch_1,  Train_loss : 5225.0581  Test_loss : 5036.8013, Time/batch_file : 2.2750, Training time: 10613.9140\n",
      "Epoch : 915/2000 data_batch_2,  Train_loss : 5212.2441  Test_loss : 5253.0381, Time/batch_file : 2.2832, Training time: 10616.1975\n",
      "Epoch : 915/2000 data_batch_3,  Train_loss : 5376.4048  Test_loss : 5213.8340, Time/batch_file : 2.2717, Training time: 10618.4694\n",
      "Epoch : 915/2000 data_batch_4,  Train_loss : 5238.8447  Test_loss : 4839.4395, Time/batch_file : 2.2664, Training time: 10620.7360\n",
      "Epoch : 915/2000 data_batch_5,  Train_loss : 5243.1133  Test_loss : 5145.1636, Time/batch_file : 2.2643, Training time: 10623.0005\n",
      "Epoch : 916/2000 data_batch_1,  Train_loss : 5451.1553  Test_loss : 5430.3955, Time/batch_file : 2.2779, Training time: 10625.2786\n",
      "Epoch : 916/2000 data_batch_2,  Train_loss : 5393.0498  Test_loss : 5152.7095, Time/batch_file : 2.2749, Training time: 10627.5537\n",
      "Epoch : 916/2000 data_batch_3,  Train_loss : 5410.0186  Test_loss : 5192.0615, Time/batch_file : 2.2767, Training time: 10629.8306\n",
      "Epoch : 916/2000 data_batch_4,  Train_loss : 5221.8237  Test_loss : 5268.0552, Time/batch_file : 2.2543, Training time: 10632.0850\n",
      "Epoch : 916/2000 data_batch_5,  Train_loss : 5473.9268  Test_loss : 5072.1030, Time/batch_file : 2.2685, Training time: 10634.3537\n",
      "Epoch : 917/2000 data_batch_1,  Train_loss : 4296.9355  Test_loss : 5350.8018, Time/batch_file : 2.2607, Training time: 10636.6146\n",
      "Epoch : 917/2000 data_batch_2,  Train_loss : 4402.7666  Test_loss : 5526.4209, Time/batch_file : 2.2769, Training time: 10638.8917\n",
      "Epoch : 917/2000 data_batch_3,  Train_loss : 4636.7344  Test_loss : 5325.2622, Time/batch_file : 2.2766, Training time: 10641.1684\n",
      "Epoch : 917/2000 data_batch_4,  Train_loss : 4299.2397  Test_loss : 5003.6826, Time/batch_file : 2.2763, Training time: 10643.4452\n",
      "Epoch : 917/2000 data_batch_5,  Train_loss : 4823.2705  Test_loss : 5472.0942, Time/batch_file : 2.2745, Training time: 10645.7198\n",
      "Epoch : 918/2000 data_batch_1,  Train_loss : 4993.1411  Test_loss : 5205.1885, Time/batch_file : 2.2840, Training time: 10648.0040\n",
      "Epoch : 918/2000 data_batch_2,  Train_loss : 5072.0664  Test_loss : 5332.8701, Time/batch_file : 2.2898, Training time: 10650.2939\n",
      "Epoch : 918/2000 data_batch_3,  Train_loss : 4926.4111  Test_loss : 5321.3711, Time/batch_file : 2.2933, Training time: 10652.5874\n",
      "Epoch : 918/2000 data_batch_4,  Train_loss : 4903.2617  Test_loss : 5054.5356, Time/batch_file : 2.2729, Training time: 10654.8604\n",
      "Epoch : 918/2000 data_batch_5,  Train_loss : 4847.2539  Test_loss : 5284.0063, Time/batch_file : 2.2808, Training time: 10657.1414\n",
      "Epoch : 919/2000 data_batch_1,  Train_loss : 4822.4805  Test_loss : 5231.5454, Time/batch_file : 2.2683, Training time: 10659.4100\n",
      "Epoch : 919/2000 data_batch_2,  Train_loss : 5000.1992  Test_loss : 5351.5576, Time/batch_file : 2.2685, Training time: 10661.6788\n",
      "Epoch : 919/2000 data_batch_3,  Train_loss : 5037.3618  Test_loss : 5413.8418, Time/batch_file : 2.2657, Training time: 10663.9447\n",
      "Epoch : 919/2000 data_batch_4,  Train_loss : 5148.2144  Test_loss : 5530.6025, Time/batch_file : 2.2690, Training time: 10666.2140\n",
      "Epoch : 919/2000 data_batch_5,  Train_loss : 4947.6455  Test_loss : 5296.0869, Time/batch_file : 2.2666, Training time: 10668.4807\n",
      "Epoch : 920/2000 data_batch_1,  Train_loss : 5170.2134  Test_loss : 5305.3838, Time/batch_file : 2.2732, Training time: 10670.7540\n",
      "Epoch : 920/2000 data_batch_2,  Train_loss : 5279.2578  Test_loss : 5096.8159, Time/batch_file : 2.2754, Training time: 10673.0296\n",
      "Epoch : 920/2000 data_batch_3,  Train_loss : 5389.9937  Test_loss : 5229.9609, Time/batch_file : 2.2830, Training time: 10675.3128\n",
      "Epoch : 920/2000 data_batch_4,  Train_loss : 5710.7085  Test_loss : 5348.3818, Time/batch_file : 2.2777, Training time: 10677.5907\n",
      "Epoch : 920/2000 data_batch_5,  Train_loss : 5197.1733  Test_loss : 5106.3374, Time/batch_file : 2.2705, Training time: 10679.8615\n",
      "[./nets/net-920.ckpt] SAVED\n",
      "Epoch : 921/2000 data_batch_1,  Train_loss : 4832.1460  Test_loss : 5631.1021, Time/batch_file : 2.2983, Training time: 10683.4305\n",
      "Epoch : 921/2000 data_batch_2,  Train_loss : 4877.9009  Test_loss : 5576.7954, Time/batch_file : 2.2742, Training time: 10685.7048\n",
      "Epoch : 921/2000 data_batch_3,  Train_loss : 5035.3408  Test_loss : 5743.5376, Time/batch_file : 2.2923, Training time: 10687.9973\n",
      "Epoch : 921/2000 data_batch_4,  Train_loss : 4768.4307  Test_loss : 5693.9448, Time/batch_file : 2.2730, Training time: 10690.2706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 921/2000 data_batch_5,  Train_loss : 5031.0801  Test_loss : 5652.2158, Time/batch_file : 2.2806, Training time: 10692.5513\n",
      "Epoch : 922/2000 data_batch_1,  Train_loss : 4773.4531  Test_loss : 5423.1367, Time/batch_file : 2.2834, Training time: 10694.8350\n",
      "Epoch : 922/2000 data_batch_2,  Train_loss : 5075.4243  Test_loss : 5245.4033, Time/batch_file : 2.3130, Training time: 10697.1481\n",
      "Epoch : 922/2000 data_batch_3,  Train_loss : 5016.0137  Test_loss : 5390.5078, Time/batch_file : 2.2889, Training time: 10699.4371\n",
      "Epoch : 922/2000 data_batch_4,  Train_loss : 4857.8496  Test_loss : 5696.9731, Time/batch_file : 2.2810, Training time: 10701.7183\n",
      "Epoch : 922/2000 data_batch_5,  Train_loss : 4954.0435  Test_loss : 5562.1992, Time/batch_file : 2.2848, Training time: 10704.0033\n",
      "Epoch : 923/2000 data_batch_1,  Train_loss : 4904.9082  Test_loss : 5370.0933, Time/batch_file : 2.2690, Training time: 10706.2725\n",
      "Epoch : 923/2000 data_batch_2,  Train_loss : 4736.2515  Test_loss : 5556.4258, Time/batch_file : 2.2986, Training time: 10708.5713\n",
      "Epoch : 923/2000 data_batch_3,  Train_loss : 4844.8921  Test_loss : 5749.3359, Time/batch_file : 2.2805, Training time: 10710.8520\n",
      "Epoch : 923/2000 data_batch_4,  Train_loss : 5144.7773  Test_loss : 5412.1777, Time/batch_file : 2.3071, Training time: 10713.1593\n",
      "Epoch : 923/2000 data_batch_5,  Train_loss : 4959.4985  Test_loss : 5461.6289, Time/batch_file : 2.3100, Training time: 10715.4694\n",
      "Epoch : 924/2000 data_batch_1,  Train_loss : 4841.0889  Test_loss : 4924.4702, Time/batch_file : 2.2958, Training time: 10717.7653\n",
      "Epoch : 924/2000 data_batch_2,  Train_loss : 4702.8706  Test_loss : 4644.6553, Time/batch_file : 2.2995, Training time: 10720.0650\n",
      "Epoch : 924/2000 data_batch_3,  Train_loss : 4922.1074  Test_loss : 4731.7178, Time/batch_file : 2.2889, Training time: 10722.3540\n",
      "Epoch : 924/2000 data_batch_4,  Train_loss : 4842.0840  Test_loss : 4918.0645, Time/batch_file : 2.2828, Training time: 10724.6370\n",
      "Epoch : 924/2000 data_batch_5,  Train_loss : 4577.5234  Test_loss : 4951.8022, Time/batch_file : 2.2794, Training time: 10726.9165\n",
      "Epoch : 925/2000 data_batch_1,  Train_loss : 4929.0210  Test_loss : 5554.5703, Time/batch_file : 2.2652, Training time: 10729.1820\n",
      "Epoch : 925/2000 data_batch_2,  Train_loss : 4868.5957  Test_loss : 5791.0728, Time/batch_file : 2.2959, Training time: 10731.4779\n",
      "Epoch : 925/2000 data_batch_3,  Train_loss : 4982.9072  Test_loss : 5548.7808, Time/batch_file : 2.2912, Training time: 10733.7694\n",
      "Epoch : 925/2000 data_batch_4,  Train_loss : 5124.6855  Test_loss : 5569.4229, Time/batch_file : 2.2850, Training time: 10736.0547\n",
      "Epoch : 925/2000 data_batch_5,  Train_loss : 4794.4082  Test_loss : 5485.9092, Time/batch_file : 2.2897, Training time: 10738.3446\n",
      "Epoch : 926/2000 data_batch_1,  Train_loss : 4916.2876  Test_loss : 5035.9473, Time/batch_file : 2.2732, Training time: 10740.6180\n",
      "Epoch : 926/2000 data_batch_2,  Train_loss : 4681.7529  Test_loss : 5032.3838, Time/batch_file : 2.2728, Training time: 10742.8909\n",
      "Epoch : 926/2000 data_batch_3,  Train_loss : 4904.8818  Test_loss : 5077.6841, Time/batch_file : 2.2677, Training time: 10745.1590\n",
      "Epoch : 926/2000 data_batch_4,  Train_loss : 4646.6523  Test_loss : 5124.9321, Time/batch_file : 2.2905, Training time: 10747.4497\n",
      "Epoch : 926/2000 data_batch_5,  Train_loss : 4649.8618  Test_loss : 5135.6816, Time/batch_file : 2.2792, Training time: 10749.7292\n",
      "Epoch : 927/2000 data_batch_1,  Train_loss : 4463.3423  Test_loss : 5522.7896, Time/batch_file : 2.2916, Training time: 10752.0209\n",
      "Epoch : 927/2000 data_batch_2,  Train_loss : 4448.0244  Test_loss : 5167.6157, Time/batch_file : 2.2711, Training time: 10754.2923\n",
      "Epoch : 927/2000 data_batch_3,  Train_loss : 4694.5674  Test_loss : 5244.5625, Time/batch_file : 2.2932, Training time: 10756.5857\n",
      "Epoch : 927/2000 data_batch_4,  Train_loss : 4564.3008  Test_loss : 5793.4644, Time/batch_file : 2.2729, Training time: 10758.8588\n",
      "Epoch : 927/2000 data_batch_5,  Train_loss : 4664.1572  Test_loss : 5112.8159, Time/batch_file : 2.2916, Training time: 10761.1506\n",
      "Epoch : 928/2000 data_batch_1,  Train_loss : 5266.4585  Test_loss : 5012.6494, Time/batch_file : 2.2803, Training time: 10763.4311\n",
      "Epoch : 928/2000 data_batch_2,  Train_loss : 5425.3252  Test_loss : 4704.7373, Time/batch_file : 2.3016, Training time: 10765.7329\n",
      "Epoch : 928/2000 data_batch_3,  Train_loss : 5053.0747  Test_loss : 5021.1772, Time/batch_file : 2.2780, Training time: 10768.0111\n",
      "Epoch : 928/2000 data_batch_4,  Train_loss : 4889.0586  Test_loss : 5162.9443, Time/batch_file : 2.2989, Training time: 10770.3103\n",
      "Epoch : 928/2000 data_batch_5,  Train_loss : 5124.7139  Test_loss : 5173.3330, Time/batch_file : 2.2690, Training time: 10772.5795\n",
      "Epoch : 929/2000 data_batch_1,  Train_loss : 4729.0776  Test_loss : 4958.3896, Time/batch_file : 2.2916, Training time: 10774.8712\n",
      "Epoch : 929/2000 data_batch_2,  Train_loss : 4849.6367  Test_loss : 4752.2959, Time/batch_file : 2.2677, Training time: 10777.1390\n",
      "Epoch : 929/2000 data_batch_3,  Train_loss : 4867.6782  Test_loss : 5025.4351, Time/batch_file : 2.2960, Training time: 10779.4352\n",
      "Epoch : 929/2000 data_batch_4,  Train_loss : 5063.8672  Test_loss : 5046.2456, Time/batch_file : 2.2744, Training time: 10781.7099\n",
      "Epoch : 929/2000 data_batch_5,  Train_loss : 4737.0889  Test_loss : 4980.9351, Time/batch_file : 2.2960, Training time: 10784.0061\n",
      "Epoch : 930/2000 data_batch_1,  Train_loss : 5282.3027  Test_loss : 5810.3926, Time/batch_file : 2.2672, Training time: 10786.2735\n",
      "Epoch : 930/2000 data_batch_2,  Train_loss : 5258.3584  Test_loss : 5712.7402, Time/batch_file : 2.2848, Training time: 10788.5585\n",
      "Epoch : 930/2000 data_batch_3,  Train_loss : 5047.9253  Test_loss : 5736.7490, Time/batch_file : 2.2673, Training time: 10790.8260\n",
      "Epoch : 930/2000 data_batch_4,  Train_loss : 5069.9902  Test_loss : 5954.2363, Time/batch_file : 2.2972, Training time: 10793.1234\n",
      "Epoch : 930/2000 data_batch_5,  Train_loss : 5069.2236  Test_loss : 5749.9102, Time/batch_file : 2.2648, Training time: 10795.3885\n",
      "[./nets/net-930.ckpt] SAVED\n",
      "Epoch : 931/2000 data_batch_1,  Train_loss : 4909.4258  Test_loss : 5181.6934, Time/batch_file : 2.3066, Training time: 10798.9665\n",
      "Epoch : 931/2000 data_batch_2,  Train_loss : 4915.8008  Test_loss : 5134.7979, Time/batch_file : 2.2737, Training time: 10801.2404\n",
      "Epoch : 931/2000 data_batch_3,  Train_loss : 5123.4780  Test_loss : 5167.3560, Time/batch_file : 2.3091, Training time: 10803.5496\n",
      "Epoch : 931/2000 data_batch_4,  Train_loss : 4802.1543  Test_loss : 5221.2666, Time/batch_file : 2.2664, Training time: 10805.8162\n",
      "Epoch : 931/2000 data_batch_5,  Train_loss : 4893.9141  Test_loss : 4950.1992, Time/batch_file : 2.2997, Training time: 10808.1161\n",
      "Epoch : 932/2000 data_batch_1,  Train_loss : 4690.2627  Test_loss : 5216.8584, Time/batch_file : 2.2767, Training time: 10810.3930\n",
      "Epoch : 932/2000 data_batch_2,  Train_loss : 4617.0771  Test_loss : 5094.0508, Time/batch_file : 2.2818, Training time: 10812.6750\n",
      "Epoch : 932/2000 data_batch_3,  Train_loss : 4916.7227  Test_loss : 5008.3911, Time/batch_file : 2.2763, Training time: 10814.9515\n",
      "Epoch : 932/2000 data_batch_4,  Train_loss : 4542.1904  Test_loss : 5176.8853, Time/batch_file : 2.2753, Training time: 10817.2270\n",
      "Epoch : 932/2000 data_batch_5,  Train_loss : 4582.9712  Test_loss : 5016.3062, Time/batch_file : 2.2827, Training time: 10819.5099\n",
      "Epoch : 933/2000 data_batch_1,  Train_loss : 4900.1104  Test_loss : 4790.8936, Time/batch_file : 2.3115, Training time: 10821.8216\n",
      "Epoch : 933/2000 data_batch_2,  Train_loss : 5231.5010  Test_loss : 5327.7671, Time/batch_file : 2.2806, Training time: 10824.1023\n",
      "Epoch : 933/2000 data_batch_3,  Train_loss : 5199.4995  Test_loss : 5379.5449, Time/batch_file : 2.2636, Training time: 10826.3660\n",
      "Epoch : 933/2000 data_batch_4,  Train_loss : 5060.1230  Test_loss : 5065.8765, Time/batch_file : 2.2836, Training time: 10828.6499\n",
      "Epoch : 933/2000 data_batch_5,  Train_loss : 4988.2080  Test_loss : 5176.7666, Time/batch_file : 2.3075, Training time: 10830.9576\n",
      "Epoch : 934/2000 data_batch_1,  Train_loss : 4894.9497  Test_loss : 5396.7070, Time/batch_file : 2.2700, Training time: 10833.2278\n",
      "Epoch : 934/2000 data_batch_2,  Train_loss : 5025.0225  Test_loss : 5438.4072, Time/batch_file : 2.2824, Training time: 10835.5104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 934/2000 data_batch_3,  Train_loss : 5014.4487  Test_loss : 5571.1021, Time/batch_file : 2.2648, Training time: 10837.7755\n",
      "Epoch : 934/2000 data_batch_4,  Train_loss : 5224.8809  Test_loss : 5396.2031, Time/batch_file : 2.2792, Training time: 10840.0549\n",
      "Epoch : 934/2000 data_batch_5,  Train_loss : 5119.9287  Test_loss : 5472.7412, Time/batch_file : 2.2791, Training time: 10842.3341\n",
      "Epoch : 935/2000 data_batch_1,  Train_loss : 5344.9536  Test_loss : 5009.0127, Time/batch_file : 2.2775, Training time: 10844.6118\n",
      "Epoch : 935/2000 data_batch_2,  Train_loss : 5358.3042  Test_loss : 4965.7456, Time/batch_file : 2.2758, Training time: 10846.8880\n",
      "Epoch : 935/2000 data_batch_3,  Train_loss : 5377.6382  Test_loss : 5064.4062, Time/batch_file : 2.2725, Training time: 10849.1607\n",
      "Epoch : 935/2000 data_batch_4,  Train_loss : 5443.8184  Test_loss : 5108.4688, Time/batch_file : 2.2674, Training time: 10851.4283\n",
      "Epoch : 935/2000 data_batch_5,  Train_loss : 5380.1973  Test_loss : 4979.8696, Time/batch_file : 2.2721, Training time: 10853.7006\n",
      "Epoch : 936/2000 data_batch_1,  Train_loss : 5265.8486  Test_loss : 5341.5469, Time/batch_file : 2.2821, Training time: 10855.9830\n",
      "Epoch : 936/2000 data_batch_2,  Train_loss : 4899.9604  Test_loss : 5140.0205, Time/batch_file : 2.3271, Training time: 10858.3105\n",
      "Epoch : 936/2000 data_batch_3,  Train_loss : 5452.2983  Test_loss : 5530.5083, Time/batch_file : 2.2667, Training time: 10860.5774\n",
      "Epoch : 936/2000 data_batch_4,  Train_loss : 4996.7822  Test_loss : 5425.6934, Time/batch_file : 2.2737, Training time: 10862.8513\n",
      "Epoch : 936/2000 data_batch_5,  Train_loss : 4958.5962  Test_loss : 5501.2891, Time/batch_file : 2.2684, Training time: 10865.1200\n",
      "Epoch : 937/2000 data_batch_1,  Train_loss : 4918.7148  Test_loss : 4782.2871, Time/batch_file : 2.2844, Training time: 10867.4046\n",
      "Epoch : 937/2000 data_batch_2,  Train_loss : 4857.8467  Test_loss : 4977.2334, Time/batch_file : 2.2680, Training time: 10869.6727\n",
      "Epoch : 937/2000 data_batch_3,  Train_loss : 4920.5137  Test_loss : 5217.4048, Time/batch_file : 2.2794, Training time: 10871.9523\n",
      "Epoch : 937/2000 data_batch_4,  Train_loss : 4896.7227  Test_loss : 4822.9443, Time/batch_file : 2.2798, Training time: 10874.2323\n",
      "Epoch : 937/2000 data_batch_5,  Train_loss : 5027.6035  Test_loss : 4747.8423, Time/batch_file : 2.2774, Training time: 10876.5099\n",
      "Epoch : 938/2000 data_batch_1,  Train_loss : 4486.4268  Test_loss : 5579.9751, Time/batch_file : 2.2686, Training time: 10878.7786\n",
      "Epoch : 938/2000 data_batch_2,  Train_loss : 4505.6602  Test_loss : 5548.0586, Time/batch_file : 2.2912, Training time: 10881.0700\n",
      "Epoch : 938/2000 data_batch_3,  Train_loss : 4478.0518  Test_loss : 5776.7549, Time/batch_file : 2.2877, Training time: 10883.3579\n",
      "Epoch : 938/2000 data_batch_4,  Train_loss : 4518.3027  Test_loss : 5440.5674, Time/batch_file : 2.2950, Training time: 10885.6531\n",
      "Epoch : 938/2000 data_batch_5,  Train_loss : 4476.9263  Test_loss : 5529.8320, Time/batch_file : 2.2614, Training time: 10887.9146\n",
      "Epoch : 939/2000 data_batch_1,  Train_loss : 4494.8267  Test_loss : 4962.3672, Time/batch_file : 2.2837, Training time: 10890.1986\n",
      "Epoch : 939/2000 data_batch_2,  Train_loss : 5007.9814  Test_loss : 5386.2412, Time/batch_file : 2.2753, Training time: 10892.4741\n",
      "Epoch : 939/2000 data_batch_3,  Train_loss : 4655.6484  Test_loss : 4928.7915, Time/batch_file : 2.2868, Training time: 10894.7612\n",
      "Epoch : 939/2000 data_batch_4,  Train_loss : 4826.6523  Test_loss : 5254.7334, Time/batch_file : 2.2852, Training time: 10897.0466\n",
      "Epoch : 939/2000 data_batch_5,  Train_loss : 4710.4590  Test_loss : 4781.4487, Time/batch_file : 2.2815, Training time: 10899.3283\n",
      "Epoch : 940/2000 data_batch_1,  Train_loss : 5180.6226  Test_loss : 5995.6973, Time/batch_file : 2.2749, Training time: 10901.6034\n",
      "Epoch : 940/2000 data_batch_2,  Train_loss : 5200.3228  Test_loss : 5839.4331, Time/batch_file : 2.2865, Training time: 10903.8901\n",
      "Epoch : 940/2000 data_batch_3,  Train_loss : 5017.0498  Test_loss : 5593.6382, Time/batch_file : 2.2664, Training time: 10906.1567\n",
      "Epoch : 940/2000 data_batch_4,  Train_loss : 5181.6924  Test_loss : 5614.6108, Time/batch_file : 2.2779, Training time: 10908.4348\n",
      "Epoch : 940/2000 data_batch_5,  Train_loss : 5357.0273  Test_loss : 5631.0098, Time/batch_file : 2.2719, Training time: 10910.7068\n",
      "[./nets/net-940.ckpt] SAVED\n",
      "Epoch : 941/2000 data_batch_1,  Train_loss : 4304.5361  Test_loss : 5281.6753, Time/batch_file : 2.2949, Training time: 10914.2693\n",
      "Epoch : 941/2000 data_batch_2,  Train_loss : 4527.4111  Test_loss : 5074.0454, Time/batch_file : 2.2744, Training time: 10916.5440\n",
      "Epoch : 941/2000 data_batch_3,  Train_loss : 4623.5996  Test_loss : 5233.3125, Time/batch_file : 2.2677, Training time: 10918.8119\n",
      "Epoch : 941/2000 data_batch_4,  Train_loss : 4416.2632  Test_loss : 5348.3877, Time/batch_file : 2.2715, Training time: 10921.0836\n",
      "Epoch : 941/2000 data_batch_5,  Train_loss : 4252.8374  Test_loss : 5401.4971, Time/batch_file : 2.2657, Training time: 10923.3495\n",
      "Epoch : 942/2000 data_batch_1,  Train_loss : 4629.1650  Test_loss : 5694.9648, Time/batch_file : 2.2707, Training time: 10925.6205\n",
      "Epoch : 942/2000 data_batch_2,  Train_loss : 4488.9277  Test_loss : 5433.3320, Time/batch_file : 2.2577, Training time: 10927.8784\n",
      "Epoch : 942/2000 data_batch_3,  Train_loss : 4605.6680  Test_loss : 5512.0830, Time/batch_file : 2.2698, Training time: 10930.1485\n",
      "Epoch : 942/2000 data_batch_4,  Train_loss : 4603.9766  Test_loss : 5612.8521, Time/batch_file : 2.2635, Training time: 10932.4121\n",
      "Epoch : 942/2000 data_batch_5,  Train_loss : 4830.0762  Test_loss : 5541.7656, Time/batch_file : 2.2840, Training time: 10934.6964\n",
      "Epoch : 943/2000 data_batch_1,  Train_loss : 4573.3184  Test_loss : 4878.7271, Time/batch_file : 2.2760, Training time: 10936.9726\n",
      "Epoch : 943/2000 data_batch_2,  Train_loss : 4427.4990  Test_loss : 4668.6719, Time/batch_file : 2.2777, Training time: 10939.2504\n",
      "Epoch : 943/2000 data_batch_3,  Train_loss : 4739.8931  Test_loss : 4810.2686, Time/batch_file : 2.2785, Training time: 10941.5291\n",
      "Epoch : 943/2000 data_batch_4,  Train_loss : 4547.9136  Test_loss : 4965.2368, Time/batch_file : 2.2821, Training time: 10943.8114\n",
      "Epoch : 943/2000 data_batch_5,  Train_loss : 4675.6519  Test_loss : 4818.2842, Time/batch_file : 2.2843, Training time: 10946.0959\n",
      "Epoch : 944/2000 data_batch_1,  Train_loss : 5083.9722  Test_loss : 5556.8911, Time/batch_file : 2.2833, Training time: 10948.3794\n",
      "Epoch : 944/2000 data_batch_2,  Train_loss : 5211.2808  Test_loss : 5251.6353, Time/batch_file : 2.2813, Training time: 10950.6608\n",
      "Epoch : 944/2000 data_batch_3,  Train_loss : 5059.7529  Test_loss : 5253.5586, Time/batch_file : 2.2772, Training time: 10952.9383\n",
      "Epoch : 944/2000 data_batch_4,  Train_loss : 4909.7622  Test_loss : 5573.0068, Time/batch_file : 2.2985, Training time: 10955.2370\n",
      "Epoch : 944/2000 data_batch_5,  Train_loss : 4853.7051  Test_loss : 5214.6553, Time/batch_file : 2.2795, Training time: 10957.5168\n",
      "Epoch : 945/2000 data_batch_1,  Train_loss : 4894.8555  Test_loss : 4959.7939, Time/batch_file : 2.2688, Training time: 10959.7858\n",
      "Epoch : 945/2000 data_batch_2,  Train_loss : 5160.4609  Test_loss : 4667.2368, Time/batch_file : 2.2587, Training time: 10962.0446\n",
      "Epoch : 945/2000 data_batch_3,  Train_loss : 5012.8477  Test_loss : 4710.8813, Time/batch_file : 2.2993, Training time: 10964.3442\n",
      "Epoch : 945/2000 data_batch_4,  Train_loss : 5125.3013  Test_loss : 5047.0620, Time/batch_file : 2.2586, Training time: 10966.6030\n",
      "Epoch : 945/2000 data_batch_5,  Train_loss : 5003.5903  Test_loss : 5017.0820, Time/batch_file : 2.2799, Training time: 10968.8831\n",
      "Epoch : 946/2000 data_batch_1,  Train_loss : 5352.7046  Test_loss : 4981.1475, Time/batch_file : 2.2681, Training time: 10971.1513\n",
      "Epoch : 946/2000 data_batch_2,  Train_loss : 5190.4355  Test_loss : 5095.0249, Time/batch_file : 2.2753, Training time: 10973.4270\n",
      "Epoch : 946/2000 data_batch_3,  Train_loss : 5349.2573  Test_loss : 4691.7437, Time/batch_file : 2.2718, Training time: 10975.6989\n",
      "Epoch : 946/2000 data_batch_4,  Train_loss : 5327.5513  Test_loss : 5067.4658, Time/batch_file : 2.3000, Training time: 10977.9991\n",
      "Epoch : 946/2000 data_batch_5,  Train_loss : 5246.1479  Test_loss : 4764.7725, Time/batch_file : 2.2827, Training time: 10980.2821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 947/2000 data_batch_1,  Train_loss : 4643.4634  Test_loss : 5463.7793, Time/batch_file : 2.2752, Training time: 10982.5575\n",
      "Epoch : 947/2000 data_batch_2,  Train_loss : 4545.9756  Test_loss : 5513.9199, Time/batch_file : 2.2805, Training time: 10984.8381\n",
      "Epoch : 947/2000 data_batch_3,  Train_loss : 4614.4976  Test_loss : 5402.3301, Time/batch_file : 2.2687, Training time: 10987.1071\n",
      "Epoch : 947/2000 data_batch_4,  Train_loss : 4695.9062  Test_loss : 5262.6338, Time/batch_file : 2.2811, Training time: 10989.3885\n",
      "Epoch : 947/2000 data_batch_5,  Train_loss : 4808.1113  Test_loss : 5719.1055, Time/batch_file : 2.2721, Training time: 10991.6608\n",
      "Epoch : 948/2000 data_batch_1,  Train_loss : 5096.3267  Test_loss : 5137.1650, Time/batch_file : 2.2901, Training time: 10993.9511\n",
      "Epoch : 948/2000 data_batch_2,  Train_loss : 5052.4531  Test_loss : 5079.1992, Time/batch_file : 2.2757, Training time: 10996.2270\n",
      "Epoch : 948/2000 data_batch_3,  Train_loss : 5211.8262  Test_loss : 5077.9233, Time/batch_file : 2.2801, Training time: 10998.5072\n",
      "Epoch : 948/2000 data_batch_4,  Train_loss : 5007.1562  Test_loss : 5073.6689, Time/batch_file : 2.2842, Training time: 11000.7916\n",
      "Epoch : 948/2000 data_batch_5,  Train_loss : 4789.2109  Test_loss : 5191.7036, Time/batch_file : 2.2704, Training time: 11003.0620\n",
      "Epoch : 949/2000 data_batch_1,  Train_loss : 5098.7451  Test_loss : 5131.4409, Time/batch_file : 2.2814, Training time: 11005.3437\n",
      "Epoch : 949/2000 data_batch_2,  Train_loss : 5152.9736  Test_loss : 5270.5366, Time/batch_file : 2.2639, Training time: 11007.6079\n",
      "Epoch : 949/2000 data_batch_3,  Train_loss : 5008.6426  Test_loss : 5207.6367, Time/batch_file : 2.3026, Training time: 11009.9107\n",
      "Epoch : 949/2000 data_batch_4,  Train_loss : 5141.7275  Test_loss : 5337.2871, Time/batch_file : 2.2689, Training time: 11012.1797\n",
      "Epoch : 949/2000 data_batch_5,  Train_loss : 5059.2373  Test_loss : 5365.0620, Time/batch_file : 2.2728, Training time: 11014.4528\n",
      "Epoch : 950/2000 data_batch_1,  Train_loss : 4822.4160  Test_loss : 5283.1768, Time/batch_file : 2.2650, Training time: 11016.7180\n",
      "Epoch : 950/2000 data_batch_2,  Train_loss : 4956.0591  Test_loss : 5200.1606, Time/batch_file : 2.3049, Training time: 11019.0231\n",
      "Epoch : 950/2000 data_batch_3,  Train_loss : 4901.2227  Test_loss : 5422.5991, Time/batch_file : 2.2720, Training time: 11021.2954\n",
      "Epoch : 950/2000 data_batch_4,  Train_loss : 4802.4653  Test_loss : 5328.2612, Time/batch_file : 2.2927, Training time: 11023.5883\n",
      "Epoch : 950/2000 data_batch_5,  Train_loss : 4863.6729  Test_loss : 5519.7153, Time/batch_file : 2.2724, Training time: 11025.8610\n",
      "[./nets/net-950.ckpt] SAVED\n",
      "Epoch : 951/2000 data_batch_1,  Train_loss : 4410.7148  Test_loss : 5189.7344, Time/batch_file : 2.3097, Training time: 11029.4377\n",
      "Epoch : 951/2000 data_batch_2,  Train_loss : 4517.7944  Test_loss : 5117.6152, Time/batch_file : 2.2944, Training time: 11031.7322\n",
      "Epoch : 951/2000 data_batch_3,  Train_loss : 4595.8296  Test_loss : 4998.9980, Time/batch_file : 2.2610, Training time: 11033.9935\n",
      "Epoch : 951/2000 data_batch_4,  Train_loss : 4450.9688  Test_loss : 5062.8779, Time/batch_file : 2.2972, Training time: 11036.2910\n",
      "Epoch : 951/2000 data_batch_5,  Train_loss : 4359.4155  Test_loss : 5535.5396, Time/batch_file : 2.3060, Training time: 11038.5972\n",
      "Epoch : 952/2000 data_batch_1,  Train_loss : 4877.1479  Test_loss : 4715.6753, Time/batch_file : 2.3053, Training time: 11040.9027\n",
      "Epoch : 952/2000 data_batch_2,  Train_loss : 4984.6250  Test_loss : 5077.0020, Time/batch_file : 2.3019, Training time: 11043.2048\n",
      "Epoch : 952/2000 data_batch_3,  Train_loss : 4759.5225  Test_loss : 5247.7319, Time/batch_file : 2.2861, Training time: 11045.4912\n",
      "Epoch : 952/2000 data_batch_4,  Train_loss : 4910.5928  Test_loss : 4892.1094, Time/batch_file : 2.3188, Training time: 11047.8103\n",
      "Epoch : 952/2000 data_batch_5,  Train_loss : 5057.7461  Test_loss : 4869.6357, Time/batch_file : 2.2972, Training time: 11050.1077\n",
      "Epoch : 953/2000 data_batch_1,  Train_loss : 4867.0112  Test_loss : 5535.6230, Time/batch_file : 2.2919, Training time: 11052.3998\n",
      "Epoch : 953/2000 data_batch_2,  Train_loss : 4819.3257  Test_loss : 5724.4277, Time/batch_file : 2.2881, Training time: 11054.6880\n",
      "Epoch : 953/2000 data_batch_3,  Train_loss : 4873.5737  Test_loss : 5554.9741, Time/batch_file : 2.2990, Training time: 11056.9873\n",
      "Epoch : 953/2000 data_batch_4,  Train_loss : 4760.9443  Test_loss : 5491.2856, Time/batch_file : 2.2913, Training time: 11059.2789\n",
      "Epoch : 953/2000 data_batch_5,  Train_loss : 5019.0454  Test_loss : 5710.7871, Time/batch_file : 2.2967, Training time: 11061.5758\n",
      "Epoch : 954/2000 data_batch_1,  Train_loss : 5147.4902  Test_loss : 4991.6460, Time/batch_file : 2.2960, Training time: 11063.8719\n",
      "Epoch : 954/2000 data_batch_2,  Train_loss : 5323.4326  Test_loss : 5357.0273, Time/batch_file : 2.2996, Training time: 11066.1717\n",
      "Epoch : 954/2000 data_batch_3,  Train_loss : 5355.6196  Test_loss : 4756.8438, Time/batch_file : 2.2879, Training time: 11068.4599\n",
      "Epoch : 954/2000 data_batch_4,  Train_loss : 5127.0410  Test_loss : 5120.5723, Time/batch_file : 2.3208, Training time: 11070.7809\n",
      "Epoch : 954/2000 data_batch_5,  Train_loss : 5314.1587  Test_loss : 5137.4902, Time/batch_file : 2.2988, Training time: 11073.0800\n",
      "Epoch : 955/2000 data_batch_1,  Train_loss : 5077.3560  Test_loss : 5611.6865, Time/batch_file : 2.2936, Training time: 11075.3738\n",
      "Epoch : 955/2000 data_batch_2,  Train_loss : 5385.7114  Test_loss : 5579.5342, Time/batch_file : 2.2810, Training time: 11077.6550\n",
      "Epoch : 955/2000 data_batch_3,  Train_loss : 5220.8047  Test_loss : 5755.9482, Time/batch_file : 2.2985, Training time: 11079.9537\n",
      "Epoch : 955/2000 data_batch_4,  Train_loss : 5219.5273  Test_loss : 5799.6543, Time/batch_file : 2.2802, Training time: 11082.2341\n",
      "Epoch : 955/2000 data_batch_5,  Train_loss : 5063.4175  Test_loss : 5578.9023, Time/batch_file : 2.3002, Training time: 11084.5345\n",
      "Epoch : 956/2000 data_batch_1,  Train_loss : 4965.7520  Test_loss : 5402.4160, Time/batch_file : 2.2819, Training time: 11086.8166\n",
      "Epoch : 956/2000 data_batch_2,  Train_loss : 5002.0420  Test_loss : 5427.0874, Time/batch_file : 2.2957, Training time: 11089.1125\n",
      "Epoch : 956/2000 data_batch_3,  Train_loss : 4570.6279  Test_loss : 5508.3799, Time/batch_file : 2.2869, Training time: 11091.3996\n",
      "Epoch : 956/2000 data_batch_4,  Train_loss : 5134.9297  Test_loss : 5463.2817, Time/batch_file : 2.2929, Training time: 11093.6927\n",
      "Epoch : 956/2000 data_batch_5,  Train_loss : 4887.4307  Test_loss : 5108.6641, Time/batch_file : 2.2808, Training time: 11095.9737\n",
      "Epoch : 957/2000 data_batch_1,  Train_loss : 5111.9238  Test_loss : 5234.8813, Time/batch_file : 2.3058, Training time: 11098.2797\n",
      "Epoch : 957/2000 data_batch_2,  Train_loss : 4950.8413  Test_loss : 5051.8931, Time/batch_file : 2.2856, Training time: 11100.5653\n",
      "Epoch : 957/2000 data_batch_3,  Train_loss : 4801.2627  Test_loss : 4731.9663, Time/batch_file : 2.3002, Training time: 11102.8658\n",
      "Epoch : 957/2000 data_batch_4,  Train_loss : 5271.9790  Test_loss : 4839.8242, Time/batch_file : 2.2803, Training time: 11105.1463\n",
      "Epoch : 957/2000 data_batch_5,  Train_loss : 4789.2905  Test_loss : 4966.9189, Time/batch_file : 2.2914, Training time: 11107.4379\n",
      "Epoch : 958/2000 data_batch_1,  Train_loss : 5024.1489  Test_loss : 5946.1011, Time/batch_file : 2.2936, Training time: 11109.7316\n",
      "Epoch : 958/2000 data_batch_2,  Train_loss : 4665.1787  Test_loss : 5978.0674, Time/batch_file : 2.3105, Training time: 11112.0423\n",
      "Epoch : 958/2000 data_batch_3,  Train_loss : 4600.0615  Test_loss : 5481.0186, Time/batch_file : 2.2954, Training time: 11114.3379\n",
      "Epoch : 958/2000 data_batch_4,  Train_loss : 4856.0361  Test_loss : 5516.6074, Time/batch_file : 2.3083, Training time: 11116.6463\n",
      "Epoch : 958/2000 data_batch_5,  Train_loss : 4760.8970  Test_loss : 5453.0239, Time/batch_file : 2.2952, Training time: 11118.9418\n",
      "Epoch : 959/2000 data_batch_1,  Train_loss : 4335.5781  Test_loss : 4196.5996, Time/batch_file : 2.3312, Training time: 11121.2732\n",
      "Epoch : 959/2000 data_batch_2,  Train_loss : 4545.3389  Test_loss : 4229.6816, Time/batch_file : 2.2834, Training time: 11123.5568\n",
      "Epoch : 959/2000 data_batch_3,  Train_loss : 4575.2891  Test_loss : 4162.9082, Time/batch_file : 2.2953, Training time: 11125.8523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 959/2000 data_batch_4,  Train_loss : 4673.0293  Test_loss : 4181.1582, Time/batch_file : 2.2766, Training time: 11128.1290\n",
      "Epoch : 959/2000 data_batch_5,  Train_loss : 4758.7324  Test_loss : 3996.3208, Time/batch_file : 2.3009, Training time: 11130.4301\n",
      "Epoch : 960/2000 data_batch_1,  Train_loss : 5336.0205  Test_loss : 5193.4795, Time/batch_file : 2.2846, Training time: 11132.7149\n",
      "Epoch : 960/2000 data_batch_2,  Train_loss : 5412.2471  Test_loss : 5263.1885, Time/batch_file : 2.2936, Training time: 11135.0088\n",
      "Epoch : 960/2000 data_batch_3,  Train_loss : 5366.2480  Test_loss : 5534.1689, Time/batch_file : 2.2645, Training time: 11137.2735\n",
      "Epoch : 960/2000 data_batch_4,  Train_loss : 5381.6431  Test_loss : 5097.6475, Time/batch_file : 2.2960, Training time: 11139.5697\n",
      "Epoch : 960/2000 data_batch_5,  Train_loss : 5215.1387  Test_loss : 5537.8359, Time/batch_file : 2.2773, Training time: 11141.8473\n",
      "[./nets/net-960.ckpt] SAVED\n",
      "Epoch : 961/2000 data_batch_1,  Train_loss : 4350.8457  Test_loss : 5383.6709, Time/batch_file : 2.3175, Training time: 11145.4327\n",
      "Epoch : 961/2000 data_batch_2,  Train_loss : 4534.0342  Test_loss : 5650.3721, Time/batch_file : 2.2832, Training time: 11147.7161\n",
      "Epoch : 961/2000 data_batch_3,  Train_loss : 4567.8008  Test_loss : 4897.5806, Time/batch_file : 2.2620, Training time: 11149.9782\n",
      "Epoch : 961/2000 data_batch_4,  Train_loss : 4502.6309  Test_loss : 5069.0586, Time/batch_file : 2.2795, Training time: 11152.2580\n",
      "Epoch : 961/2000 data_batch_5,  Train_loss : 4236.8433  Test_loss : 5189.1411, Time/batch_file : 2.2682, Training time: 11154.5264\n",
      "Epoch : 962/2000 data_batch_1,  Train_loss : 4509.2104  Test_loss : 5388.1987, Time/batch_file : 2.2881, Training time: 11156.8147\n",
      "Epoch : 962/2000 data_batch_2,  Train_loss : 4856.3345  Test_loss : 5515.9521, Time/batch_file : 2.3012, Training time: 11159.1160\n",
      "Epoch : 962/2000 data_batch_3,  Train_loss : 4709.1646  Test_loss : 5568.5664, Time/batch_file : 2.2855, Training time: 11161.4017\n",
      "Epoch : 962/2000 data_batch_4,  Train_loss : 4498.6064  Test_loss : 5436.7456, Time/batch_file : 2.2945, Training time: 11163.6964\n",
      "Epoch : 962/2000 data_batch_5,  Train_loss : 4642.4541  Test_loss : 5302.6274, Time/batch_file : 2.2803, Training time: 11165.9768\n",
      "Epoch : 963/2000 data_batch_1,  Train_loss : 4841.0757  Test_loss : 5210.5425, Time/batch_file : 2.2642, Training time: 11168.2413\n",
      "Epoch : 963/2000 data_batch_2,  Train_loss : 4988.8687  Test_loss : 5444.2705, Time/batch_file : 2.2789, Training time: 11170.5204\n",
      "Epoch : 963/2000 data_batch_3,  Train_loss : 5227.3740  Test_loss : 5417.5850, Time/batch_file : 2.2695, Training time: 11172.7900\n",
      "Epoch : 963/2000 data_batch_4,  Train_loss : 4841.0562  Test_loss : 5230.5967, Time/batch_file : 2.2761, Training time: 11175.0663\n",
      "Epoch : 963/2000 data_batch_5,  Train_loss : 4901.8066  Test_loss : 5177.9121, Time/batch_file : 2.2551, Training time: 11177.3217\n",
      "Epoch : 964/2000 data_batch_1,  Train_loss : 5521.2524  Test_loss : 5218.6782, Time/batch_file : 2.2867, Training time: 11179.6087\n",
      "Epoch : 964/2000 data_batch_2,  Train_loss : 5374.6797  Test_loss : 5379.0518, Time/batch_file : 2.2760, Training time: 11181.8849\n",
      "Epoch : 964/2000 data_batch_3,  Train_loss : 5420.6123  Test_loss : 5069.8916, Time/batch_file : 2.3009, Training time: 11184.1861\n",
      "Epoch : 964/2000 data_batch_4,  Train_loss : 5672.8994  Test_loss : 5623.9277, Time/batch_file : 2.2862, Training time: 11186.4724\n",
      "Epoch : 964/2000 data_batch_5,  Train_loss : 5633.4971  Test_loss : 5075.5708, Time/batch_file : 2.2809, Training time: 11188.7534\n",
      "Epoch : 965/2000 data_batch_1,  Train_loss : 4950.0244  Test_loss : 5270.4561, Time/batch_file : 2.2966, Training time: 11191.0504\n",
      "Epoch : 965/2000 data_batch_2,  Train_loss : 5187.8311  Test_loss : 5480.6553, Time/batch_file : 2.3087, Training time: 11193.3593\n",
      "Epoch : 965/2000 data_batch_3,  Train_loss : 5241.8896  Test_loss : 5191.7549, Time/batch_file : 2.3303, Training time: 11195.6898\n",
      "Epoch : 965/2000 data_batch_4,  Train_loss : 5306.4160  Test_loss : 5090.4805, Time/batch_file : 2.2867, Training time: 11197.9767\n",
      "Epoch : 965/2000 data_batch_5,  Train_loss : 4929.9902  Test_loss : 5114.5654, Time/batch_file : 2.3006, Training time: 11200.2775\n",
      "Epoch : 966/2000 data_batch_1,  Train_loss : 5145.8882  Test_loss : 5336.4175, Time/batch_file : 2.2691, Training time: 11202.5468\n",
      "Epoch : 966/2000 data_batch_2,  Train_loss : 5348.2388  Test_loss : 5281.1396, Time/batch_file : 2.3117, Training time: 11204.8586\n",
      "Epoch : 966/2000 data_batch_3,  Train_loss : 5179.3242  Test_loss : 4953.5435, Time/batch_file : 2.2859, Training time: 11207.1446\n",
      "Epoch : 966/2000 data_batch_4,  Train_loss : 5120.9155  Test_loss : 4775.8892, Time/batch_file : 2.2972, Training time: 11209.4421\n",
      "Epoch : 966/2000 data_batch_5,  Train_loss : 4757.4424  Test_loss : 4881.9736, Time/batch_file : 2.2791, Training time: 11211.7215\n",
      "Epoch : 967/2000 data_batch_1,  Train_loss : 5235.0293  Test_loss : 5211.1602, Time/batch_file : 2.2996, Training time: 11214.0213\n",
      "Epoch : 967/2000 data_batch_2,  Train_loss : 5220.0869  Test_loss : 5398.4072, Time/batch_file : 2.2980, Training time: 11216.3194\n",
      "Epoch : 967/2000 data_batch_3,  Train_loss : 5003.7979  Test_loss : 5475.7246, Time/batch_file : 2.3383, Training time: 11218.6579\n",
      "Epoch : 967/2000 data_batch_4,  Train_loss : 5275.4375  Test_loss : 5409.5830, Time/batch_file : 2.2950, Training time: 11220.9532\n",
      "Epoch : 967/2000 data_batch_5,  Train_loss : 5029.7397  Test_loss : 5502.3594, Time/batch_file : 2.2836, Training time: 11223.2371\n",
      "Epoch : 968/2000 data_batch_1,  Train_loss : 5041.9399  Test_loss : 5571.4917, Time/batch_file : 2.2782, Training time: 11225.5154\n",
      "Epoch : 968/2000 data_batch_2,  Train_loss : 5236.1147  Test_loss : 5560.1016, Time/batch_file : 2.2804, Training time: 11227.7960\n",
      "Epoch : 968/2000 data_batch_3,  Train_loss : 4779.4912  Test_loss : 5779.2632, Time/batch_file : 2.2758, Training time: 11230.0720\n",
      "Epoch : 968/2000 data_batch_4,  Train_loss : 5131.8125  Test_loss : 5898.9424, Time/batch_file : 2.2966, Training time: 11232.3688\n",
      "Epoch : 968/2000 data_batch_5,  Train_loss : 4756.6377  Test_loss : 5429.4424, Time/batch_file : 2.2772, Training time: 11234.6462\n",
      "Epoch : 969/2000 data_batch_1,  Train_loss : 5314.9961  Test_loss : 5346.3555, Time/batch_file : 2.2905, Training time: 11236.9369\n",
      "Epoch : 969/2000 data_batch_2,  Train_loss : 5302.8750  Test_loss : 5159.9062, Time/batch_file : 2.2705, Training time: 11239.2077\n",
      "Epoch : 969/2000 data_batch_3,  Train_loss : 5292.3125  Test_loss : 5016.4570, Time/batch_file : 2.2951, Training time: 11241.5029\n",
      "Epoch : 969/2000 data_batch_4,  Train_loss : 5191.6211  Test_loss : 5369.6553, Time/batch_file : 2.2637, Training time: 11243.7668\n",
      "Epoch : 969/2000 data_batch_5,  Train_loss : 5067.4897  Test_loss : 5081.2891, Time/batch_file : 2.2678, Training time: 11246.0349\n",
      "Epoch : 970/2000 data_batch_1,  Train_loss : 5097.6855  Test_loss : 5860.5806, Time/batch_file : 2.2794, Training time: 11248.3144\n",
      "Epoch : 970/2000 data_batch_2,  Train_loss : 5403.5732  Test_loss : 6232.5674, Time/batch_file : 2.2937, Training time: 11250.6084\n",
      "Epoch : 970/2000 data_batch_3,  Train_loss : 5305.4331  Test_loss : 5794.6885, Time/batch_file : 2.2846, Training time: 11252.8932\n",
      "Epoch : 970/2000 data_batch_4,  Train_loss : 5241.8979  Test_loss : 5718.8921, Time/batch_file : 2.2748, Training time: 11255.1682\n",
      "Epoch : 970/2000 data_batch_5,  Train_loss : 5269.2290  Test_loss : 5832.6504, Time/batch_file : 2.2904, Training time: 11257.4587\n",
      "[./nets/net-970.ckpt] SAVED\n",
      "Epoch : 971/2000 data_batch_1,  Train_loss : 4896.1689  Test_loss : 5106.7773, Time/batch_file : 2.2948, Training time: 11261.0339\n",
      "Epoch : 971/2000 data_batch_2,  Train_loss : 4742.1436  Test_loss : 5003.7793, Time/batch_file : 2.2808, Training time: 11263.3148\n",
      "Epoch : 971/2000 data_batch_3,  Train_loss : 4842.9937  Test_loss : 4837.4507, Time/batch_file : 2.2773, Training time: 11265.5924\n",
      "Epoch : 971/2000 data_batch_4,  Train_loss : 4758.8477  Test_loss : 5265.5986, Time/batch_file : 2.2751, Training time: 11267.8676\n",
      "Epoch : 971/2000 data_batch_5,  Train_loss : 4747.0342  Test_loss : 5191.4751, Time/batch_file : 2.2863, Training time: 11270.1542\n",
      "Epoch : 972/2000 data_batch_1,  Train_loss : 4646.8174  Test_loss : 5358.2759, Time/batch_file : 2.2685, Training time: 11272.4228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 972/2000 data_batch_2,  Train_loss : 4907.2915  Test_loss : 5127.4180, Time/batch_file : 2.2941, Training time: 11274.7171\n",
      "Epoch : 972/2000 data_batch_3,  Train_loss : 5012.8081  Test_loss : 5277.6006, Time/batch_file : 2.2639, Training time: 11276.9812\n",
      "Epoch : 972/2000 data_batch_4,  Train_loss : 4550.0669  Test_loss : 5330.5957, Time/batch_file : 2.2724, Training time: 11279.2539\n",
      "Epoch : 972/2000 data_batch_5,  Train_loss : 4762.6904  Test_loss : 5318.1436, Time/batch_file : 2.2704, Training time: 11281.5245\n",
      "Epoch : 973/2000 data_batch_1,  Train_loss : 5110.0293  Test_loss : 5069.5996, Time/batch_file : 2.2917, Training time: 11283.8163\n",
      "Epoch : 973/2000 data_batch_2,  Train_loss : 4925.9814  Test_loss : 5579.2227, Time/batch_file : 2.2923, Training time: 11286.1087\n",
      "Epoch : 973/2000 data_batch_3,  Train_loss : 5033.1523  Test_loss : 4908.0488, Time/batch_file : 2.2930, Training time: 11288.4019\n",
      "Epoch : 973/2000 data_batch_4,  Train_loss : 4836.0771  Test_loss : 5096.2720, Time/batch_file : 2.2753, Training time: 11290.6774\n",
      "Epoch : 973/2000 data_batch_5,  Train_loss : 4965.2388  Test_loss : 5059.5967, Time/batch_file : 2.2972, Training time: 11292.9747\n",
      "Epoch : 974/2000 data_batch_1,  Train_loss : 4933.0376  Test_loss : 5060.7559, Time/batch_file : 2.2662, Training time: 11295.2412\n",
      "Epoch : 974/2000 data_batch_2,  Train_loss : 4999.1709  Test_loss : 4977.7939, Time/batch_file : 2.2732, Training time: 11297.5145\n",
      "Epoch : 974/2000 data_batch_3,  Train_loss : 4826.0195  Test_loss : 4952.2295, Time/batch_file : 2.2687, Training time: 11299.7834\n",
      "Epoch : 974/2000 data_batch_4,  Train_loss : 4905.4116  Test_loss : 4878.4336, Time/batch_file : 2.2817, Training time: 11302.0653\n",
      "Epoch : 974/2000 data_batch_5,  Train_loss : 4927.2920  Test_loss : 4811.4702, Time/batch_file : 2.2657, Training time: 11304.3312\n",
      "Epoch : 975/2000 data_batch_1,  Train_loss : 5027.2739  Test_loss : 5015.7881, Time/batch_file : 2.2875, Training time: 11306.6189\n",
      "Epoch : 975/2000 data_batch_2,  Train_loss : 4997.2090  Test_loss : 5140.6709, Time/batch_file : 2.2766, Training time: 11308.8957\n",
      "Epoch : 975/2000 data_batch_3,  Train_loss : 5105.5942  Test_loss : 5100.4502, Time/batch_file : 2.2882, Training time: 11311.1842\n",
      "Epoch : 975/2000 data_batch_4,  Train_loss : 5256.3652  Test_loss : 5034.5229, Time/batch_file : 2.2927, Training time: 11313.4771\n",
      "Epoch : 975/2000 data_batch_5,  Train_loss : 5065.8799  Test_loss : 5113.6377, Time/batch_file : 2.2863, Training time: 11315.7637\n",
      "Epoch : 976/2000 data_batch_1,  Train_loss : 5052.9473  Test_loss : 4988.4502, Time/batch_file : 2.2755, Training time: 11318.0395\n",
      "Epoch : 976/2000 data_batch_2,  Train_loss : 4887.5859  Test_loss : 4777.3735, Time/batch_file : 2.3094, Training time: 11320.3490\n",
      "Epoch : 976/2000 data_batch_3,  Train_loss : 4836.3359  Test_loss : 4949.7090, Time/batch_file : 2.2885, Training time: 11322.6377\n",
      "Epoch : 976/2000 data_batch_4,  Train_loss : 4712.7148  Test_loss : 5198.4580, Time/batch_file : 2.3015, Training time: 11324.9395\n",
      "Epoch : 976/2000 data_batch_5,  Train_loss : 4870.3174  Test_loss : 4919.5420, Time/batch_file : 2.2816, Training time: 11327.2213\n",
      "Epoch : 977/2000 data_batch_1,  Train_loss : 4710.1304  Test_loss : 5046.7378, Time/batch_file : 2.2928, Training time: 11329.5143\n",
      "Epoch : 977/2000 data_batch_2,  Train_loss : 4930.3740  Test_loss : 5031.1606, Time/batch_file : 2.2760, Training time: 11331.7904\n",
      "Epoch : 977/2000 data_batch_3,  Train_loss : 4937.1641  Test_loss : 5122.6494, Time/batch_file : 2.2825, Training time: 11334.0731\n",
      "Epoch : 977/2000 data_batch_4,  Train_loss : 4905.1064  Test_loss : 5125.6006, Time/batch_file : 2.2811, Training time: 11336.3543\n",
      "Epoch : 977/2000 data_batch_5,  Train_loss : 4882.2852  Test_loss : 5275.1836, Time/batch_file : 2.3140, Training time: 11338.6686\n",
      "Epoch : 978/2000 data_batch_1,  Train_loss : 5148.6870  Test_loss : 5006.0605, Time/batch_file : 2.2881, Training time: 11340.9570\n",
      "Epoch : 978/2000 data_batch_2,  Train_loss : 5208.3018  Test_loss : 5047.4946, Time/batch_file : 2.2887, Training time: 11343.2459\n",
      "Epoch : 978/2000 data_batch_3,  Train_loss : 5393.9795  Test_loss : 5114.6685, Time/batch_file : 2.2789, Training time: 11345.5250\n",
      "Epoch : 978/2000 data_batch_4,  Train_loss : 4966.8159  Test_loss : 5136.6699, Time/batch_file : 2.2881, Training time: 11347.8132\n",
      "Epoch : 978/2000 data_batch_5,  Train_loss : 5069.2642  Test_loss : 5225.3848, Time/batch_file : 2.2770, Training time: 11350.0905\n",
      "Epoch : 979/2000 data_batch_1,  Train_loss : 4757.7349  Test_loss : 5020.9927, Time/batch_file : 2.2984, Training time: 11352.3891\n",
      "Epoch : 979/2000 data_batch_2,  Train_loss : 5177.3164  Test_loss : 4923.0581, Time/batch_file : 2.2737, Training time: 11354.6629\n",
      "Epoch : 979/2000 data_batch_3,  Train_loss : 4763.7227  Test_loss : 4912.2944, Time/batch_file : 2.3043, Training time: 11356.9674\n",
      "Epoch : 979/2000 data_batch_4,  Train_loss : 5211.5928  Test_loss : 4994.6284, Time/batch_file : 2.2696, Training time: 11359.2372\n",
      "Epoch : 979/2000 data_batch_5,  Train_loss : 4950.8208  Test_loss : 4830.3872, Time/batch_file : 2.2902, Training time: 11361.5276\n",
      "Epoch : 980/2000 data_batch_1,  Train_loss : 5165.0352  Test_loss : 5277.5703, Time/batch_file : 2.2706, Training time: 11363.7984\n",
      "Epoch : 980/2000 data_batch_2,  Train_loss : 5289.2134  Test_loss : 5312.5547, Time/batch_file : 2.2783, Training time: 11366.0768\n",
      "Epoch : 980/2000 data_batch_3,  Train_loss : 5338.7935  Test_loss : 5167.7891, Time/batch_file : 2.2847, Training time: 11368.3616\n",
      "Epoch : 980/2000 data_batch_4,  Train_loss : 5163.6035  Test_loss : 5247.5908, Time/batch_file : 2.2807, Training time: 11370.6425\n",
      "Epoch : 980/2000 data_batch_5,  Train_loss : 5338.6284  Test_loss : 5093.3330, Time/batch_file : 2.2602, Training time: 11372.9030\n",
      "[./nets/net-980.ckpt] SAVED\n",
      "Epoch : 981/2000 data_batch_1,  Train_loss : 5360.9624  Test_loss : 4999.5200, Time/batch_file : 2.3327, Training time: 11379.7394\n",
      "Epoch : 981/2000 data_batch_2,  Train_loss : 5298.2578  Test_loss : 5051.9072, Time/batch_file : 2.3039, Training time: 11382.0434\n",
      "Epoch : 981/2000 data_batch_3,  Train_loss : 5224.8682  Test_loss : 4820.9600, Time/batch_file : 2.2849, Training time: 11384.3285\n",
      "Epoch : 981/2000 data_batch_4,  Train_loss : 5374.6255  Test_loss : 4957.9756, Time/batch_file : 2.2987, Training time: 11386.6273\n",
      "Epoch : 981/2000 data_batch_5,  Train_loss : 5265.2695  Test_loss : 4815.4727, Time/batch_file : 2.2732, Training time: 11388.9008\n",
      "Epoch : 982/2000 data_batch_1,  Train_loss : 4393.3071  Test_loss : 5300.7061, Time/batch_file : 2.2720, Training time: 11391.1731\n",
      "Epoch : 982/2000 data_batch_2,  Train_loss : 4403.2798  Test_loss : 4932.6426, Time/batch_file : 2.2487, Training time: 11393.4220\n",
      "Epoch : 982/2000 data_batch_3,  Train_loss : 4506.6592  Test_loss : 5118.6753, Time/batch_file : 2.2629, Training time: 11395.6851\n",
      "Epoch : 982/2000 data_batch_4,  Train_loss : 4457.0615  Test_loss : 5264.6479, Time/batch_file : 2.2504, Training time: 11397.9358\n",
      "Epoch : 982/2000 data_batch_5,  Train_loss : 4438.2661  Test_loss : 5354.4805, Time/batch_file : 2.2759, Training time: 11400.2119\n",
      "Epoch : 983/2000 data_batch_1,  Train_loss : 5153.0850  Test_loss : 4923.2402, Time/batch_file : 2.2643, Training time: 11402.4765\n",
      "Epoch : 983/2000 data_batch_2,  Train_loss : 5242.8120  Test_loss : 5024.7461, Time/batch_file : 2.2916, Training time: 11404.7682\n",
      "Epoch : 983/2000 data_batch_3,  Train_loss : 5058.9258  Test_loss : 5028.3926, Time/batch_file : 2.2655, Training time: 11407.0339\n",
      "Epoch : 983/2000 data_batch_4,  Train_loss : 4621.9858  Test_loss : 5146.0586, Time/batch_file : 2.2879, Training time: 11409.3221\n",
      "Epoch : 983/2000 data_batch_5,  Train_loss : 5137.5942  Test_loss : 5322.6362, Time/batch_file : 2.2725, Training time: 11411.5948\n",
      "Epoch : 984/2000 data_batch_1,  Train_loss : 5402.9458  Test_loss : 4891.7661, Time/batch_file : 2.2897, Training time: 11413.8847\n",
      "Epoch : 984/2000 data_batch_2,  Train_loss : 5000.3105  Test_loss : 4897.2734, Time/batch_file : 2.2650, Training time: 11416.1500\n",
      "Epoch : 984/2000 data_batch_3,  Train_loss : 5127.5249  Test_loss : 4648.3218, Time/batch_file : 2.2859, Training time: 11418.4361\n",
      "Epoch : 984/2000 data_batch_4,  Train_loss : 4951.6509  Test_loss : 5131.3062, Time/batch_file : 2.3091, Training time: 11420.7453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 984/2000 data_batch_5,  Train_loss : 4891.3569  Test_loss : 5085.3193, Time/batch_file : 2.2817, Training time: 11423.0272\n",
      "Epoch : 985/2000 data_batch_1,  Train_loss : 4738.0747  Test_loss : 5372.4521, Time/batch_file : 2.2758, Training time: 11425.3031\n",
      "Epoch : 985/2000 data_batch_2,  Train_loss : 4907.0146  Test_loss : 5102.3345, Time/batch_file : 2.2832, Training time: 11427.5866\n",
      "Epoch : 985/2000 data_batch_3,  Train_loss : 4870.0532  Test_loss : 5335.7202, Time/batch_file : 2.2716, Training time: 11429.8584\n",
      "Epoch : 985/2000 data_batch_4,  Train_loss : 4894.2920  Test_loss : 4972.8940, Time/batch_file : 2.2940, Training time: 11432.1526\n",
      "Epoch : 985/2000 data_batch_5,  Train_loss : 5171.5801  Test_loss : 5447.6724, Time/batch_file : 2.2770, Training time: 11434.4298\n",
      "Epoch : 986/2000 data_batch_1,  Train_loss : 5185.0913  Test_loss : 5330.5337, Time/batch_file : 2.2972, Training time: 11436.7272\n",
      "Epoch : 986/2000 data_batch_2,  Train_loss : 4865.6147  Test_loss : 5540.9131, Time/batch_file : 2.2764, Training time: 11439.0039\n",
      "Epoch : 986/2000 data_batch_3,  Train_loss : 4811.9219  Test_loss : 5295.5469, Time/batch_file : 2.2929, Training time: 11441.2970\n",
      "Epoch : 986/2000 data_batch_4,  Train_loss : 5241.6841  Test_loss : 5384.1284, Time/batch_file : 2.2781, Training time: 11443.5752\n",
      "Epoch : 986/2000 data_batch_5,  Train_loss : 5001.1123  Test_loss : 5390.2876, Time/batch_file : 2.2955, Training time: 11445.8709\n",
      "Epoch : 987/2000 data_batch_1,  Train_loss : 4495.4966  Test_loss : 5756.8911, Time/batch_file : 2.2685, Training time: 11448.1396\n",
      "Epoch : 987/2000 data_batch_2,  Train_loss : 4386.7241  Test_loss : 5233.0498, Time/batch_file : 2.2720, Training time: 11450.4119\n",
      "Epoch : 987/2000 data_batch_3,  Train_loss : 4512.8633  Test_loss : 5351.6230, Time/batch_file : 2.2655, Training time: 11452.6776\n",
      "Epoch : 987/2000 data_batch_4,  Train_loss : 4656.0264  Test_loss : 5234.7515, Time/batch_file : 2.2854, Training time: 11454.9633\n",
      "Epoch : 987/2000 data_batch_5,  Train_loss : 4505.0449  Test_loss : 5628.4849, Time/batch_file : 2.2841, Training time: 11457.2476\n",
      "Epoch : 988/2000 data_batch_1,  Train_loss : 5314.0811  Test_loss : 5428.3901, Time/batch_file : 2.2832, Training time: 11459.5311\n",
      "Epoch : 988/2000 data_batch_2,  Train_loss : 5249.2441  Test_loss : 5144.7974, Time/batch_file : 2.2645, Training time: 11461.7958\n",
      "Epoch : 988/2000 data_batch_3,  Train_loss : 5227.9282  Test_loss : 5182.3262, Time/batch_file : 2.2803, Training time: 11464.0763\n",
      "Epoch : 988/2000 data_batch_4,  Train_loss : 5162.4766  Test_loss : 5559.1953, Time/batch_file : 2.2599, Training time: 11466.3364\n",
      "Epoch : 988/2000 data_batch_5,  Train_loss : 5011.2080  Test_loss : 5381.2148, Time/batch_file : 2.2853, Training time: 11468.6220\n",
      "Epoch : 989/2000 data_batch_1,  Train_loss : 5174.3994  Test_loss : 5450.7236, Time/batch_file : 2.2645, Training time: 11470.8867\n",
      "Epoch : 989/2000 data_batch_2,  Train_loss : 5064.0161  Test_loss : 5180.6582, Time/batch_file : 2.2917, Training time: 11473.1787\n",
      "Epoch : 989/2000 data_batch_3,  Train_loss : 5257.7202  Test_loss : 5453.5830, Time/batch_file : 2.2757, Training time: 11475.4547\n",
      "Epoch : 989/2000 data_batch_4,  Train_loss : 5039.5815  Test_loss : 5214.5664, Time/batch_file : 2.2818, Training time: 11477.7367\n",
      "Epoch : 989/2000 data_batch_5,  Train_loss : 5287.6167  Test_loss : 5465.3857, Time/batch_file : 2.2672, Training time: 11480.0041\n",
      "Epoch : 990/2000 data_batch_1,  Train_loss : 4917.6011  Test_loss : 5625.7168, Time/batch_file : 2.2753, Training time: 11482.2797\n",
      "Epoch : 990/2000 data_batch_2,  Train_loss : 5004.8442  Test_loss : 5828.8853, Time/batch_file : 2.2602, Training time: 11484.5402\n",
      "Epoch : 990/2000 data_batch_3,  Train_loss : 4972.0679  Test_loss : 5715.4683, Time/batch_file : 2.2707, Training time: 11486.8110\n",
      "Epoch : 990/2000 data_batch_4,  Train_loss : 4941.0469  Test_loss : 5714.6313, Time/batch_file : 2.2631, Training time: 11489.0743\n",
      "Epoch : 990/2000 data_batch_5,  Train_loss : 5197.8784  Test_loss : 5720.9507, Time/batch_file : 2.2715, Training time: 11491.3462\n",
      "[./nets/net-990.ckpt] SAVED\n",
      "Epoch : 991/2000 data_batch_1,  Train_loss : 5190.7417  Test_loss : 5036.5342, Time/batch_file : 2.3171, Training time: 11494.9486\n",
      "Epoch : 991/2000 data_batch_2,  Train_loss : 4879.3438  Test_loss : 5685.8677, Time/batch_file : 2.3085, Training time: 11497.2573\n",
      "Epoch : 991/2000 data_batch_3,  Train_loss : 4953.0322  Test_loss : 5393.4155, Time/batch_file : 2.2770, Training time: 11499.5345\n",
      "Epoch : 991/2000 data_batch_4,  Train_loss : 4931.1338  Test_loss : 5146.8213, Time/batch_file : 2.3204, Training time: 11501.8552\n",
      "Epoch : 991/2000 data_batch_5,  Train_loss : 4730.2422  Test_loss : 5216.5234, Time/batch_file : 2.3212, Training time: 11504.1765\n",
      "Epoch : 992/2000 data_batch_1,  Train_loss : 5021.5200  Test_loss : 4711.1626, Time/batch_file : 2.2748, Training time: 11506.4517\n",
      "Epoch : 992/2000 data_batch_2,  Train_loss : 5112.7461  Test_loss : 4478.2578, Time/batch_file : 2.2978, Training time: 11508.7496\n",
      "Epoch : 992/2000 data_batch_3,  Train_loss : 5331.8232  Test_loss : 5003.2383, Time/batch_file : 2.2607, Training time: 11511.0106\n",
      "Epoch : 992/2000 data_batch_4,  Train_loss : 4995.6089  Test_loss : 4825.3384, Time/batch_file : 2.2665, Training time: 11513.2774\n",
      "Epoch : 992/2000 data_batch_5,  Train_loss : 4845.1973  Test_loss : 4537.5708, Time/batch_file : 2.2825, Training time: 11515.5600\n",
      "Epoch : 993/2000 data_batch_1,  Train_loss : 4821.8857  Test_loss : 4780.6626, Time/batch_file : 2.3152, Training time: 11517.8753\n",
      "Epoch : 993/2000 data_batch_2,  Train_loss : 5035.3877  Test_loss : 4938.4468, Time/batch_file : 2.2644, Training time: 11520.1399\n",
      "Epoch : 993/2000 data_batch_3,  Train_loss : 4831.1772  Test_loss : 4467.9707, Time/batch_file : 2.2933, Training time: 11522.4334\n",
      "Epoch : 993/2000 data_batch_4,  Train_loss : 4873.6973  Test_loss : 4719.7539, Time/batch_file : 2.2756, Training time: 11524.7092\n",
      "Epoch : 993/2000 data_batch_5,  Train_loss : 4846.3823  Test_loss : 4859.1333, Time/batch_file : 2.2829, Training time: 11526.9923\n",
      "Epoch : 994/2000 data_batch_1,  Train_loss : 5074.5801  Test_loss : 4978.5742, Time/batch_file : 2.2939, Training time: 11529.2864\n",
      "Epoch : 994/2000 data_batch_2,  Train_loss : 4934.6167  Test_loss : 4928.9546, Time/batch_file : 2.2678, Training time: 11531.5545\n",
      "Epoch : 994/2000 data_batch_3,  Train_loss : 5155.5532  Test_loss : 5514.3076, Time/batch_file : 2.2961, Training time: 11533.8510\n",
      "Epoch : 994/2000 data_batch_4,  Train_loss : 4759.3760  Test_loss : 5421.4219, Time/batch_file : 2.2822, Training time: 11536.1334\n",
      "Epoch : 994/2000 data_batch_5,  Train_loss : 4975.7471  Test_loss : 4884.0854, Time/batch_file : 2.2991, Training time: 11538.4326\n",
      "Epoch : 995/2000 data_batch_1,  Train_loss : 5373.3535  Test_loss : 5392.1880, Time/batch_file : 2.2991, Training time: 11540.7319\n",
      "Epoch : 995/2000 data_batch_2,  Train_loss : 5322.5381  Test_loss : 5583.7344, Time/batch_file : 2.2950, Training time: 11543.0272\n",
      "Epoch : 995/2000 data_batch_3,  Train_loss : 5563.4443  Test_loss : 5565.4985, Time/batch_file : 2.3113, Training time: 11545.3388\n",
      "Epoch : 995/2000 data_batch_4,  Train_loss : 5092.1797  Test_loss : 5540.1372, Time/batch_file : 2.3091, Training time: 11547.6481\n",
      "Epoch : 995/2000 data_batch_5,  Train_loss : 5463.0771  Test_loss : 5528.6548, Time/batch_file : 2.2732, Training time: 11549.9215\n",
      "Epoch : 996/2000 data_batch_1,  Train_loss : 5052.3130  Test_loss : 5396.6709, Time/batch_file : 2.2883, Training time: 11552.2099\n",
      "Epoch : 996/2000 data_batch_2,  Train_loss : 5029.5391  Test_loss : 5723.2344, Time/batch_file : 2.2930, Training time: 11554.5031\n",
      "Epoch : 996/2000 data_batch_3,  Train_loss : 4912.6592  Test_loss : 5449.1797, Time/batch_file : 2.3086, Training time: 11556.8119\n",
      "Epoch : 996/2000 data_batch_4,  Train_loss : 5292.8809  Test_loss : 5690.9639, Time/batch_file : 2.2789, Training time: 11559.0910\n",
      "Epoch : 996/2000 data_batch_5,  Train_loss : 5005.8096  Test_loss : 5492.0430, Time/batch_file : 2.3138, Training time: 11561.4051\n",
      "Epoch : 997/2000 data_batch_1,  Train_loss : 5100.2827  Test_loss : 5785.2744, Time/batch_file : 2.2952, Training time: 11563.7004\n",
      "Epoch : 997/2000 data_batch_2,  Train_loss : 5138.2905  Test_loss : 5678.4609, Time/batch_file : 2.2952, Training time: 11565.9958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 997/2000 data_batch_3,  Train_loss : 5390.6802  Test_loss : 5608.9302, Time/batch_file : 2.3097, Training time: 11568.3057\n",
      "Epoch : 997/2000 data_batch_4,  Train_loss : 5110.4180  Test_loss : 5648.8008, Time/batch_file : 2.2903, Training time: 11570.5961\n",
      "Epoch : 997/2000 data_batch_5,  Train_loss : 5238.0942  Test_loss : 5990.5518, Time/batch_file : 2.2757, Training time: 11572.8720\n",
      "Epoch : 998/2000 data_batch_1,  Train_loss : 4892.3008  Test_loss : 5365.0356, Time/batch_file : 2.2686, Training time: 11575.1408\n",
      "Epoch : 998/2000 data_batch_2,  Train_loss : 4817.4326  Test_loss : 5225.6040, Time/batch_file : 2.3045, Training time: 11577.4456\n",
      "Epoch : 998/2000 data_batch_3,  Train_loss : 4871.5918  Test_loss : 4949.8467, Time/batch_file : 2.2821, Training time: 11579.7278\n",
      "Epoch : 998/2000 data_batch_4,  Train_loss : 4896.7568  Test_loss : 5311.4263, Time/batch_file : 2.2852, Training time: 11582.0132\n",
      "Epoch : 998/2000 data_batch_5,  Train_loss : 4680.7188  Test_loss : 5137.6060, Time/batch_file : 2.2798, Training time: 11584.2933\n",
      "Epoch : 999/2000 data_batch_1,  Train_loss : 5199.8364  Test_loss : 5912.3970, Time/batch_file : 2.2873, Training time: 11586.5809\n",
      "Epoch : 999/2000 data_batch_2,  Train_loss : 4988.2354  Test_loss : 5745.8906, Time/batch_file : 2.3023, Training time: 11588.8833\n",
      "Epoch : 999/2000 data_batch_3,  Train_loss : 5059.1904  Test_loss : 5690.8433, Time/batch_file : 2.2778, Training time: 11591.1613\n",
      "Epoch : 999/2000 data_batch_4,  Train_loss : 5310.9326  Test_loss : 5715.4004, Time/batch_file : 2.3028, Training time: 11593.4643\n",
      "Epoch : 999/2000 data_batch_5,  Train_loss : 5397.9375  Test_loss : 6068.3643, Time/batch_file : 2.2826, Training time: 11595.7470\n",
      "Epoch : 1000/2000 data_batch_1,  Train_loss : 4974.2935  Test_loss : 5236.3379, Time/batch_file : 2.2918, Training time: 11598.0390\n",
      "Epoch : 1000/2000 data_batch_2,  Train_loss : 5255.1982  Test_loss : 5639.3486, Time/batch_file : 2.2649, Training time: 11600.3040\n",
      "Epoch : 1000/2000 data_batch_3,  Train_loss : 5064.4995  Test_loss : 5313.6909, Time/batch_file : 2.2844, Training time: 11602.5886\n",
      "Epoch : 1000/2000 data_batch_4,  Train_loss : 4922.4917  Test_loss : 5383.0869, Time/batch_file : 2.2688, Training time: 11604.8576\n",
      "Epoch : 1000/2000 data_batch_5,  Train_loss : 5137.3062  Test_loss : 5216.9897, Time/batch_file : 2.2968, Training time: 11607.1545\n",
      "[./nets/net-1000.ckpt] SAVED\n",
      "Epoch : 1001/2000 data_batch_1,  Train_loss : 4662.7241  Test_loss : 5031.2266, Time/batch_file : 2.2833, Training time: 11610.7130\n",
      "Epoch : 1001/2000 data_batch_2,  Train_loss : 4771.8716  Test_loss : 4923.5293, Time/batch_file : 2.2723, Training time: 11612.9854\n",
      "Epoch : 1001/2000 data_batch_3,  Train_loss : 4739.4873  Test_loss : 5168.7393, Time/batch_file : 2.2739, Training time: 11615.2595\n",
      "Epoch : 1001/2000 data_batch_4,  Train_loss : 4788.1631  Test_loss : 4913.1025, Time/batch_file : 2.2805, Training time: 11617.5403\n",
      "Epoch : 1001/2000 data_batch_5,  Train_loss : 4713.1489  Test_loss : 4967.0312, Time/batch_file : 2.2805, Training time: 11619.8210\n",
      "Epoch : 1002/2000 data_batch_1,  Train_loss : 5389.8594  Test_loss : 5739.6108, Time/batch_file : 2.2866, Training time: 11622.1077\n",
      "Epoch : 1002/2000 data_batch_2,  Train_loss : 5210.2300  Test_loss : 5052.8926, Time/batch_file : 2.2793, Training time: 11624.3870\n",
      "Epoch : 1002/2000 data_batch_3,  Train_loss : 5241.4355  Test_loss : 5814.0020, Time/batch_file : 2.2825, Training time: 11626.6697\n",
      "Epoch : 1002/2000 data_batch_4,  Train_loss : 5366.5938  Test_loss : 5719.7949, Time/batch_file : 2.2914, Training time: 11628.9614\n",
      "Epoch : 1002/2000 data_batch_5,  Train_loss : 5060.4307  Test_loss : 5659.2339, Time/batch_file : 2.2869, Training time: 11631.2486\n",
      "Epoch : 1003/2000 data_batch_1,  Train_loss : 4875.2100  Test_loss : 5100.2861, Time/batch_file : 2.3005, Training time: 11633.5493\n",
      "Epoch : 1003/2000 data_batch_2,  Train_loss : 4727.3955  Test_loss : 5159.9355, Time/batch_file : 2.2852, Training time: 11635.8346\n",
      "Epoch : 1003/2000 data_batch_3,  Train_loss : 4805.8848  Test_loss : 5392.7788, Time/batch_file : 2.2855, Training time: 11638.1204\n",
      "Epoch : 1003/2000 data_batch_4,  Train_loss : 4780.1045  Test_loss : 5224.9448, Time/batch_file : 2.2723, Training time: 11640.3929\n",
      "Epoch : 1003/2000 data_batch_5,  Train_loss : 4723.9395  Test_loss : 5136.8154, Time/batch_file : 2.3009, Training time: 11642.6939\n",
      "Epoch : 1004/2000 data_batch_1,  Train_loss : 4993.3823  Test_loss : 5033.2705, Time/batch_file : 2.2730, Training time: 11644.9671\n",
      "Epoch : 1004/2000 data_batch_2,  Train_loss : 5082.4463  Test_loss : 5227.0391, Time/batch_file : 2.2676, Training time: 11647.2349\n",
      "Epoch : 1004/2000 data_batch_3,  Train_loss : 5098.6709  Test_loss : 5242.1133, Time/batch_file : 2.2722, Training time: 11649.5073\n",
      "Epoch : 1004/2000 data_batch_4,  Train_loss : 4919.8330  Test_loss : 5250.6113, Time/batch_file : 2.2583, Training time: 11651.7658\n",
      "Epoch : 1004/2000 data_batch_5,  Train_loss : 4894.0308  Test_loss : 5507.3506, Time/batch_file : 2.2742, Training time: 11654.0402\n",
      "Epoch : 1005/2000 data_batch_1,  Train_loss : 4338.3252  Test_loss : 5451.4663, Time/batch_file : 2.2847, Training time: 11656.3251\n",
      "Epoch : 1005/2000 data_batch_2,  Train_loss : 4522.3657  Test_loss : 5244.0107, Time/batch_file : 2.2837, Training time: 11658.6091\n",
      "Epoch : 1005/2000 data_batch_3,  Train_loss : 4424.0786  Test_loss : 5266.3657, Time/batch_file : 2.3020, Training time: 11660.9114\n",
      "Epoch : 1005/2000 data_batch_4,  Train_loss : 4413.2637  Test_loss : 5807.9624, Time/batch_file : 2.2842, Training time: 11663.1958\n",
      "Epoch : 1005/2000 data_batch_5,  Train_loss : 4288.6963  Test_loss : 5682.9883, Time/batch_file : 2.2751, Training time: 11665.4710\n",
      "Epoch : 1006/2000 data_batch_1,  Train_loss : 5214.7427  Test_loss : 4973.2422, Time/batch_file : 2.2858, Training time: 11667.7570\n",
      "Epoch : 1006/2000 data_batch_2,  Train_loss : 5161.5400  Test_loss : 5178.1929, Time/batch_file : 2.2884, Training time: 11670.0457\n",
      "Epoch : 1006/2000 data_batch_3,  Train_loss : 5314.0176  Test_loss : 5054.3931, Time/batch_file : 2.2752, Training time: 11672.3212\n",
      "Epoch : 1006/2000 data_batch_4,  Train_loss : 5310.0957  Test_loss : 5099.6904, Time/batch_file : 2.2831, Training time: 11674.6045\n",
      "Epoch : 1006/2000 data_batch_5,  Train_loss : 5362.4009  Test_loss : 5052.9189, Time/batch_file : 2.2861, Training time: 11676.8908\n",
      "Epoch : 1007/2000 data_batch_1,  Train_loss : 5123.5664  Test_loss : 6071.0327, Time/batch_file : 2.2816, Training time: 11679.1727\n",
      "Epoch : 1007/2000 data_batch_2,  Train_loss : 4773.2793  Test_loss : 5741.0869, Time/batch_file : 2.2897, Training time: 11681.4626\n",
      "Epoch : 1007/2000 data_batch_3,  Train_loss : 4926.0938  Test_loss : 5718.4131, Time/batch_file : 2.2918, Training time: 11683.7546\n",
      "Epoch : 1007/2000 data_batch_4,  Train_loss : 4771.8159  Test_loss : 5426.8623, Time/batch_file : 2.2856, Training time: 11686.0404\n",
      "Epoch : 1007/2000 data_batch_5,  Train_loss : 4789.4829  Test_loss : 5781.2280, Time/batch_file : 2.3053, Training time: 11688.3459\n",
      "Epoch : 1008/2000 data_batch_1,  Train_loss : 5061.3159  Test_loss : 4874.7930, Time/batch_file : 2.2846, Training time: 11690.6307\n",
      "Epoch : 1008/2000 data_batch_2,  Train_loss : 5357.3926  Test_loss : 5103.8560, Time/batch_file : 2.2869, Training time: 11692.9178\n",
      "Epoch : 1008/2000 data_batch_3,  Train_loss : 5289.8096  Test_loss : 5133.2861, Time/batch_file : 2.2646, Training time: 11695.1826\n",
      "Epoch : 1008/2000 data_batch_4,  Train_loss : 5084.5806  Test_loss : 5116.3555, Time/batch_file : 2.2964, Training time: 11697.4792\n",
      "Epoch : 1008/2000 data_batch_5,  Train_loss : 5223.6440  Test_loss : 5291.4399, Time/batch_file : 2.2783, Training time: 11699.7578\n",
      "Epoch : 1009/2000 data_batch_1,  Train_loss : 5161.4438  Test_loss : 5220.2769, Time/batch_file : 2.2714, Training time: 11702.0294\n",
      "Epoch : 1009/2000 data_batch_2,  Train_loss : 4852.5664  Test_loss : 5202.4404, Time/batch_file : 2.2727, Training time: 11704.3024\n",
      "Epoch : 1009/2000 data_batch_3,  Train_loss : 5105.9775  Test_loss : 5118.8022, Time/batch_file : 2.2714, Training time: 11706.5741\n",
      "Epoch : 1009/2000 data_batch_4,  Train_loss : 5049.1055  Test_loss : 4821.6821, Time/batch_file : 2.2868, Training time: 11708.8611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1009/2000 data_batch_5,  Train_loss : 4846.7808  Test_loss : 5027.5640, Time/batch_file : 2.2895, Training time: 11711.1508\n",
      "Epoch : 1010/2000 data_batch_1,  Train_loss : 5831.0312  Test_loss : 5176.9502, Time/batch_file : 2.2912, Training time: 11713.4421\n",
      "Epoch : 1010/2000 data_batch_2,  Train_loss : 5663.8828  Test_loss : 5154.6855, Time/batch_file : 2.3082, Training time: 11715.7505\n",
      "Epoch : 1010/2000 data_batch_3,  Train_loss : 5680.2764  Test_loss : 5096.5664, Time/batch_file : 2.3012, Training time: 11718.0519\n",
      "Epoch : 1010/2000 data_batch_4,  Train_loss : 5469.5508  Test_loss : 5043.9946, Time/batch_file : 2.3445, Training time: 11720.3966\n",
      "Epoch : 1010/2000 data_batch_5,  Train_loss : 5702.9795  Test_loss : 5125.9775, Time/batch_file : 2.2922, Training time: 11722.6890\n",
      "[./nets/net-1010.ckpt] SAVED\n",
      "Epoch : 1011/2000 data_batch_1,  Train_loss : 4634.4854  Test_loss : 4830.9502, Time/batch_file : 2.3030, Training time: 11726.2938\n",
      "Epoch : 1011/2000 data_batch_2,  Train_loss : 4981.4839  Test_loss : 4851.4253, Time/batch_file : 2.2737, Training time: 11728.5676\n",
      "Epoch : 1011/2000 data_batch_3,  Train_loss : 4862.0605  Test_loss : 5021.9741, Time/batch_file : 2.3065, Training time: 11730.8744\n",
      "Epoch : 1011/2000 data_batch_4,  Train_loss : 4748.8423  Test_loss : 4676.4600, Time/batch_file : 2.2694, Training time: 11733.1440\n",
      "Epoch : 1011/2000 data_batch_5,  Train_loss : 4742.6792  Test_loss : 5085.9004, Time/batch_file : 2.2899, Training time: 11735.4341\n",
      "Epoch : 1012/2000 data_batch_1,  Train_loss : 4238.4990  Test_loss : 5035.1025, Time/batch_file : 2.2742, Training time: 11737.7085\n",
      "Epoch : 1012/2000 data_batch_2,  Train_loss : 4254.1162  Test_loss : 4618.5928, Time/batch_file : 2.2698, Training time: 11739.9785\n",
      "Epoch : 1012/2000 data_batch_3,  Train_loss : 4428.3887  Test_loss : 4691.7705, Time/batch_file : 2.2654, Training time: 11742.2440\n",
      "Epoch : 1012/2000 data_batch_4,  Train_loss : 4568.4800  Test_loss : 5068.3750, Time/batch_file : 2.2717, Training time: 11744.5159\n",
      "Epoch : 1012/2000 data_batch_5,  Train_loss : 4412.9932  Test_loss : 4648.1367, Time/batch_file : 2.2608, Training time: 11746.7770\n",
      "Epoch : 1013/2000 data_batch_1,  Train_loss : 5306.2065  Test_loss : 5781.2344, Time/batch_file : 2.3089, Training time: 11749.0861\n",
      "Epoch : 1013/2000 data_batch_2,  Train_loss : 5068.3755  Test_loss : 5796.8877, Time/batch_file : 2.2600, Training time: 11751.3463\n",
      "Epoch : 1013/2000 data_batch_3,  Train_loss : 5082.9121  Test_loss : 5938.1621, Time/batch_file : 2.2985, Training time: 11753.6450\n",
      "Epoch : 1013/2000 data_batch_4,  Train_loss : 5141.3726  Test_loss : 6027.7896, Time/batch_file : 2.2715, Training time: 11755.9167\n",
      "Epoch : 1013/2000 data_batch_5,  Train_loss : 5208.3037  Test_loss : 5713.0825, Time/batch_file : 2.2705, Training time: 11758.1874\n",
      "Epoch : 1014/2000 data_batch_1,  Train_loss : 4787.7910  Test_loss : 5113.4404, Time/batch_file : 2.2707, Training time: 11760.4583\n",
      "Epoch : 1014/2000 data_batch_2,  Train_loss : 4773.5269  Test_loss : 5747.6445, Time/batch_file : 2.2725, Training time: 11762.7310\n",
      "Epoch : 1014/2000 data_batch_3,  Train_loss : 4387.3105  Test_loss : 5402.6499, Time/batch_file : 2.2754, Training time: 11765.0066\n",
      "Epoch : 1014/2000 data_batch_4,  Train_loss : 4670.2983  Test_loss : 5614.6836, Time/batch_file : 2.3085, Training time: 11767.3153\n",
      "Epoch : 1014/2000 data_batch_5,  Train_loss : 4408.1143  Test_loss : 5485.7075, Time/batch_file : 2.2803, Training time: 11769.5959\n",
      "Epoch : 1015/2000 data_batch_1,  Train_loss : 4608.1177  Test_loss : 5191.3999, Time/batch_file : 2.2910, Training time: 11771.8871\n",
      "Epoch : 1015/2000 data_batch_2,  Train_loss : 4763.2510  Test_loss : 5769.6836, Time/batch_file : 2.2959, Training time: 11774.1833\n",
      "Epoch : 1015/2000 data_batch_3,  Train_loss : 4748.1118  Test_loss : 5533.1494, Time/batch_file : 2.2750, Training time: 11776.4587\n",
      "Epoch : 1015/2000 data_batch_4,  Train_loss : 4690.7593  Test_loss : 5352.4224, Time/batch_file : 2.2746, Training time: 11778.7335\n",
      "Epoch : 1015/2000 data_batch_5,  Train_loss : 4929.1997  Test_loss : 5728.8291, Time/batch_file : 2.2890, Training time: 11781.0227\n",
      "Epoch : 1016/2000 data_batch_1,  Train_loss : 5205.0391  Test_loss : 5811.3467, Time/batch_file : 2.2759, Training time: 11783.2988\n",
      "Epoch : 1016/2000 data_batch_2,  Train_loss : 5129.5898  Test_loss : 5480.2876, Time/batch_file : 2.3013, Training time: 11785.6003\n",
      "Epoch : 1016/2000 data_batch_3,  Train_loss : 5035.0161  Test_loss : 5494.8164, Time/batch_file : 2.2656, Training time: 11787.8663\n",
      "Epoch : 1016/2000 data_batch_4,  Train_loss : 5365.5073  Test_loss : 5875.5654, Time/batch_file : 2.2950, Training time: 11790.1615\n",
      "Epoch : 1016/2000 data_batch_5,  Train_loss : 5238.4858  Test_loss : 5734.3735, Time/batch_file : 2.2733, Training time: 11792.4352\n",
      "Epoch : 1017/2000 data_batch_1,  Train_loss : 4761.3979  Test_loss : 4770.9619, Time/batch_file : 2.2788, Training time: 11794.7144\n",
      "Epoch : 1017/2000 data_batch_2,  Train_loss : 4805.1372  Test_loss : 5316.2334, Time/batch_file : 2.2760, Training time: 11796.9906\n",
      "Epoch : 1017/2000 data_batch_3,  Train_loss : 5046.9238  Test_loss : 5079.9961, Time/batch_file : 2.2782, Training time: 11799.2691\n",
      "Epoch : 1017/2000 data_batch_4,  Train_loss : 4676.7217  Test_loss : 5026.9795, Time/batch_file : 2.2896, Training time: 11801.5588\n",
      "Epoch : 1017/2000 data_batch_5,  Train_loss : 5053.5786  Test_loss : 4912.8740, Time/batch_file : 2.3067, Training time: 11803.8659\n",
      "Epoch : 1018/2000 data_batch_1,  Train_loss : 4912.6860  Test_loss : 5354.8379, Time/batch_file : 2.2689, Training time: 11806.1350\n",
      "Epoch : 1018/2000 data_batch_2,  Train_loss : 4867.6470  Test_loss : 5214.1318, Time/batch_file : 2.2792, Training time: 11808.4143\n",
      "Epoch : 1018/2000 data_batch_3,  Train_loss : 4669.0146  Test_loss : 5199.6846, Time/batch_file : 2.2738, Training time: 11810.6883\n",
      "Epoch : 1018/2000 data_batch_4,  Train_loss : 4829.8506  Test_loss : 4980.7295, Time/batch_file : 2.2930, Training time: 11812.9814\n",
      "Epoch : 1018/2000 data_batch_5,  Train_loss : 5024.6831  Test_loss : 5326.1113, Time/batch_file : 2.2847, Training time: 11815.2664\n",
      "Epoch : 1019/2000 data_batch_1,  Train_loss : 4750.5352  Test_loss : 5222.6235, Time/batch_file : 2.2961, Training time: 11817.5627\n",
      "Epoch : 1019/2000 data_batch_2,  Train_loss : 4731.6362  Test_loss : 5238.3848, Time/batch_file : 2.2909, Training time: 11819.8538\n",
      "Epoch : 1019/2000 data_batch_3,  Train_loss : 4769.3086  Test_loss : 4986.5220, Time/batch_file : 2.3081, Training time: 11822.1620\n",
      "Epoch : 1019/2000 data_batch_4,  Train_loss : 4819.5269  Test_loss : 5123.6724, Time/batch_file : 2.2761, Training time: 11824.4383\n",
      "Epoch : 1019/2000 data_batch_5,  Train_loss : 4706.2295  Test_loss : 4948.4688, Time/batch_file : 2.2751, Training time: 11826.7137\n",
      "Epoch : 1020/2000 data_batch_1,  Train_loss : 4657.8145  Test_loss : 4774.3652, Time/batch_file : 2.2821, Training time: 11828.9960\n",
      "Epoch : 1020/2000 data_batch_2,  Train_loss : 4614.1362  Test_loss : 4870.5737, Time/batch_file : 2.2800, Training time: 11831.2761\n",
      "Epoch : 1020/2000 data_batch_3,  Train_loss : 4572.9746  Test_loss : 5137.0645, Time/batch_file : 2.2649, Training time: 11833.5412\n",
      "Epoch : 1020/2000 data_batch_4,  Train_loss : 5021.6255  Test_loss : 5118.5508, Time/batch_file : 2.2832, Training time: 11835.8246\n",
      "Epoch : 1020/2000 data_batch_5,  Train_loss : 4663.6636  Test_loss : 5047.2314, Time/batch_file : 2.2654, Training time: 11838.0903\n",
      "[./nets/net-1020.ckpt] SAVED\n",
      "Epoch : 1021/2000 data_batch_1,  Train_loss : 5452.7881  Test_loss : 4751.3828, Time/batch_file : 2.3065, Training time: 11841.6829\n",
      "Epoch : 1021/2000 data_batch_2,  Train_loss : 5315.9131  Test_loss : 4778.1587, Time/batch_file : 2.3403, Training time: 11844.0234\n",
      "Epoch : 1021/2000 data_batch_3,  Train_loss : 5435.6924  Test_loss : 4965.9170, Time/batch_file : 2.2931, Training time: 11846.3167\n",
      "Epoch : 1021/2000 data_batch_4,  Train_loss : 4978.4116  Test_loss : 4592.6538, Time/batch_file : 2.2725, Training time: 11848.5893\n",
      "Epoch : 1021/2000 data_batch_5,  Train_loss : 5325.1689  Test_loss : 5002.3174, Time/batch_file : 2.3024, Training time: 11850.8918\n",
      "Epoch : 1022/2000 data_batch_1,  Train_loss : 4716.3960  Test_loss : 5248.7490, Time/batch_file : 2.5144, Training time: 11853.4065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1022/2000 data_batch_2,  Train_loss : 4514.5464  Test_loss : 5015.5508, Time/batch_file : 2.2873, Training time: 11855.6941\n",
      "Epoch : 1022/2000 data_batch_3,  Train_loss : 4443.6919  Test_loss : 4657.8755, Time/batch_file : 2.2738, Training time: 11857.9681\n",
      "Epoch : 1022/2000 data_batch_4,  Train_loss : 4688.2539  Test_loss : 5055.9194, Time/batch_file : 2.2713, Training time: 11860.2396\n",
      "Epoch : 1022/2000 data_batch_5,  Train_loss : 4627.9272  Test_loss : 4977.9150, Time/batch_file : 2.2724, Training time: 11862.5123\n",
      "Epoch : 1023/2000 data_batch_1,  Train_loss : 4745.2529  Test_loss : 5001.8711, Time/batch_file : 2.2724, Training time: 11864.7850\n",
      "Epoch : 1023/2000 data_batch_2,  Train_loss : 4905.0186  Test_loss : 5019.5835, Time/batch_file : 2.2682, Training time: 11867.0533\n",
      "Epoch : 1023/2000 data_batch_3,  Train_loss : 4710.2939  Test_loss : 4979.1279, Time/batch_file : 2.2855, Training time: 11869.3391\n",
      "Epoch : 1023/2000 data_batch_4,  Train_loss : 4585.5493  Test_loss : 5051.3516, Time/batch_file : 2.2616, Training time: 11871.6009\n",
      "Epoch : 1023/2000 data_batch_5,  Train_loss : 4736.5312  Test_loss : 5120.3721, Time/batch_file : 2.2668, Training time: 11873.8680\n",
      "Epoch : 1024/2000 data_batch_1,  Train_loss : 4914.6240  Test_loss : 5535.7227, Time/batch_file : 2.2590, Training time: 11876.1272\n",
      "Epoch : 1024/2000 data_batch_2,  Train_loss : 4527.7290  Test_loss : 5101.1621, Time/batch_file : 2.2714, Training time: 11878.3988\n",
      "Epoch : 1024/2000 data_batch_3,  Train_loss : 4618.6582  Test_loss : 5084.3447, Time/batch_file : 2.2618, Training time: 11880.6608\n",
      "Epoch : 1024/2000 data_batch_4,  Train_loss : 4673.4888  Test_loss : 5385.8755, Time/batch_file : 2.2594, Training time: 11882.9204\n",
      "Epoch : 1024/2000 data_batch_5,  Train_loss : 4842.2871  Test_loss : 5173.5435, Time/batch_file : 2.2656, Training time: 11885.1862\n",
      "Epoch : 1025/2000 data_batch_1,  Train_loss : 4925.6572  Test_loss : 5475.4814, Time/batch_file : 2.2675, Training time: 11887.4540\n",
      "Epoch : 1025/2000 data_batch_2,  Train_loss : 5155.0264  Test_loss : 5166.4331, Time/batch_file : 2.2787, Training time: 11889.7328\n",
      "Epoch : 1025/2000 data_batch_3,  Train_loss : 5106.1772  Test_loss : 5248.1191, Time/batch_file : 2.2632, Training time: 11891.9962\n",
      "Epoch : 1025/2000 data_batch_4,  Train_loss : 5163.0088  Test_loss : 5452.4058, Time/batch_file : 2.2996, Training time: 11894.2963\n",
      "Epoch : 1025/2000 data_batch_5,  Train_loss : 5217.6328  Test_loss : 5561.7861, Time/batch_file : 2.2758, Training time: 11896.5724\n",
      "Epoch : 1026/2000 data_batch_1,  Train_loss : 4762.4248  Test_loss : 5133.4272, Time/batch_file : 2.2956, Training time: 11898.8681\n",
      "Epoch : 1026/2000 data_batch_2,  Train_loss : 5005.6514  Test_loss : 5212.6094, Time/batch_file : 2.2729, Training time: 11901.1413\n",
      "Epoch : 1026/2000 data_batch_3,  Train_loss : 4766.5474  Test_loss : 4952.9619, Time/batch_file : 2.2985, Training time: 11903.4400\n",
      "Epoch : 1026/2000 data_batch_4,  Train_loss : 4785.1650  Test_loss : 5521.4985, Time/batch_file : 2.2708, Training time: 11905.7110\n",
      "Epoch : 1026/2000 data_batch_5,  Train_loss : 4773.9062  Test_loss : 5200.3174, Time/batch_file : 2.3150, Training time: 11908.0261\n",
      "Epoch : 1027/2000 data_batch_1,  Train_loss : 5249.8560  Test_loss : 5465.8047, Time/batch_file : 2.2798, Training time: 11910.3061\n",
      "Epoch : 1027/2000 data_batch_2,  Train_loss : 4979.8047  Test_loss : 5135.0410, Time/batch_file : 2.2794, Training time: 11912.5857\n",
      "Epoch : 1027/2000 data_batch_3,  Train_loss : 5006.3564  Test_loss : 4777.2979, Time/batch_file : 2.2640, Training time: 11914.8499\n",
      "Epoch : 1027/2000 data_batch_4,  Train_loss : 4766.7227  Test_loss : 5241.7441, Time/batch_file : 2.3060, Training time: 11917.1561\n",
      "Epoch : 1027/2000 data_batch_5,  Train_loss : 4738.0542  Test_loss : 5014.2852, Time/batch_file : 2.2697, Training time: 11919.4259\n",
      "Epoch : 1028/2000 data_batch_1,  Train_loss : 4496.2031  Test_loss : 4851.4873, Time/batch_file : 2.2978, Training time: 11921.7240\n",
      "Epoch : 1028/2000 data_batch_2,  Train_loss : 4617.8359  Test_loss : 4343.9209, Time/batch_file : 2.2835, Training time: 11924.0077\n",
      "Epoch : 1028/2000 data_batch_3,  Train_loss : 4327.0796  Test_loss : 4787.3140, Time/batch_file : 2.2929, Training time: 11926.3008\n",
      "Epoch : 1028/2000 data_batch_4,  Train_loss : 4340.0840  Test_loss : 4978.4639, Time/batch_file : 2.2882, Training time: 11928.5892\n",
      "Epoch : 1028/2000 data_batch_5,  Train_loss : 4987.1724  Test_loss : 4873.2085, Time/batch_file : 2.3085, Training time: 11930.8978\n",
      "Epoch : 1029/2000 data_batch_1,  Train_loss : 4115.7134  Test_loss : 5284.1431, Time/batch_file : 2.2716, Training time: 11933.1696\n",
      "Epoch : 1029/2000 data_batch_2,  Train_loss : 4213.7183  Test_loss : 5203.0269, Time/batch_file : 2.2985, Training time: 11935.4684\n",
      "Epoch : 1029/2000 data_batch_3,  Train_loss : 4340.8267  Test_loss : 5471.8535, Time/batch_file : 2.2929, Training time: 11937.7615\n",
      "Epoch : 1029/2000 data_batch_4,  Train_loss : 4351.4707  Test_loss : 5309.9424, Time/batch_file : 2.3002, Training time: 11940.0619\n",
      "Epoch : 1029/2000 data_batch_5,  Train_loss : 4506.9834  Test_loss : 4946.4863, Time/batch_file : 2.2716, Training time: 11942.3337\n",
      "Epoch : 1030/2000 data_batch_1,  Train_loss : 4740.4395  Test_loss : 5472.9023, Time/batch_file : 2.2940, Training time: 11944.6279\n",
      "Epoch : 1030/2000 data_batch_2,  Train_loss : 4802.1904  Test_loss : 5041.2686, Time/batch_file : 2.2695, Training time: 11946.8976\n",
      "Epoch : 1030/2000 data_batch_3,  Train_loss : 4772.1104  Test_loss : 5246.9990, Time/batch_file : 2.2934, Training time: 11949.1912\n",
      "Epoch : 1030/2000 data_batch_4,  Train_loss : 4608.7007  Test_loss : 5203.0874, Time/batch_file : 2.2741, Training time: 11951.4655\n",
      "Epoch : 1030/2000 data_batch_5,  Train_loss : 4796.0537  Test_loss : 5189.1343, Time/batch_file : 2.2918, Training time: 11953.7576\n",
      "[./nets/net-1030.ckpt] SAVED\n",
      "Epoch : 1031/2000 data_batch_1,  Train_loss : 4841.1504  Test_loss : 5171.3379, Time/batch_file : 2.5898, Training time: 11957.7186\n",
      "Epoch : 1031/2000 data_batch_2,  Train_loss : 5080.1235  Test_loss : 5213.0342, Time/batch_file : 2.6214, Training time: 11960.3401\n",
      "Epoch : 1031/2000 data_batch_3,  Train_loss : 5259.2861  Test_loss : 5178.1846, Time/batch_file : 2.6551, Training time: 11962.9954\n",
      "Epoch : 1031/2000 data_batch_4,  Train_loss : 5122.3770  Test_loss : 5145.8745, Time/batch_file : 2.2873, Training time: 11965.2831\n",
      "Epoch : 1031/2000 data_batch_5,  Train_loss : 5002.9106  Test_loss : 5250.1543, Time/batch_file : 2.2867, Training time: 11967.5700\n",
      "Epoch : 1032/2000 data_batch_1,  Train_loss : 4902.6719  Test_loss : 5276.0410, Time/batch_file : 2.2880, Training time: 11969.8581\n",
      "Epoch : 1032/2000 data_batch_2,  Train_loss : 4813.8032  Test_loss : 4945.9629, Time/batch_file : 2.2866, Training time: 11972.1450\n",
      "Epoch : 1032/2000 data_batch_3,  Train_loss : 4699.9780  Test_loss : 5394.9717, Time/batch_file : 2.2662, Training time: 11974.4114\n",
      "Epoch : 1032/2000 data_batch_4,  Train_loss : 4911.9727  Test_loss : 5284.6719, Time/batch_file : 2.2710, Training time: 11976.6825\n",
      "Epoch : 1032/2000 data_batch_5,  Train_loss : 4985.5854  Test_loss : 5136.5728, Time/batch_file : 2.2836, Training time: 11978.9664\n",
      "Epoch : 1033/2000 data_batch_1,  Train_loss : 5283.5059  Test_loss : 5281.6973, Time/batch_file : 2.2840, Training time: 11981.2506\n",
      "Epoch : 1033/2000 data_batch_2,  Train_loss : 4942.4263  Test_loss : 5090.1758, Time/batch_file : 2.2850, Training time: 11983.5359\n",
      "Epoch : 1033/2000 data_batch_3,  Train_loss : 5231.4531  Test_loss : 5314.7881, Time/batch_file : 2.2733, Training time: 11985.8093\n",
      "Epoch : 1033/2000 data_batch_4,  Train_loss : 4896.2544  Test_loss : 5435.3613, Time/batch_file : 2.2635, Training time: 11988.0730\n",
      "Epoch : 1033/2000 data_batch_5,  Train_loss : 4984.4580  Test_loss : 5486.3008, Time/batch_file : 2.2610, Training time: 11990.3342\n",
      "Epoch : 1034/2000 data_batch_1,  Train_loss : 4820.1465  Test_loss : 4964.7476, Time/batch_file : 2.2654, Training time: 11992.5998\n",
      "Epoch : 1034/2000 data_batch_2,  Train_loss : 4496.3110  Test_loss : 5100.9160, Time/batch_file : 2.2749, Training time: 11994.8749\n",
      "Epoch : 1034/2000 data_batch_3,  Train_loss : 5101.8604  Test_loss : 4773.4038, Time/batch_file : 2.2976, Training time: 11997.1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1034/2000 data_batch_4,  Train_loss : 4896.7310  Test_loss : 5315.7983, Time/batch_file : 2.2667, Training time: 11999.4397\n",
      "Epoch : 1034/2000 data_batch_5,  Train_loss : 4528.0146  Test_loss : 4969.6143, Time/batch_file : 2.2863, Training time: 12001.7262\n",
      "Epoch : 1035/2000 data_batch_1,  Train_loss : 5116.9771  Test_loss : 4654.5869, Time/batch_file : 2.2738, Training time: 12004.0002\n",
      "Epoch : 1035/2000 data_batch_2,  Train_loss : 4977.6724  Test_loss : 4882.5806, Time/batch_file : 2.2778, Training time: 12006.2781\n",
      "Epoch : 1035/2000 data_batch_3,  Train_loss : 5318.6523  Test_loss : 5046.5107, Time/batch_file : 2.2707, Training time: 12008.5490\n",
      "Epoch : 1035/2000 data_batch_4,  Train_loss : 5102.6699  Test_loss : 4904.8584, Time/batch_file : 2.2698, Training time: 12010.8191\n",
      "Epoch : 1035/2000 data_batch_5,  Train_loss : 5050.9766  Test_loss : 5056.0859, Time/batch_file : 2.2801, Training time: 12013.0993\n",
      "Epoch : 1036/2000 data_batch_1,  Train_loss : 4346.1934  Test_loss : 4790.7393, Time/batch_file : 2.2723, Training time: 12015.3718\n",
      "Epoch : 1036/2000 data_batch_2,  Train_loss : 4631.1523  Test_loss : 4925.0762, Time/batch_file : 2.2729, Training time: 12017.6448\n",
      "Epoch : 1036/2000 data_batch_3,  Train_loss : 4242.4717  Test_loss : 5179.7510, Time/batch_file : 2.2981, Training time: 12019.9432\n",
      "Epoch : 1036/2000 data_batch_4,  Train_loss : 4546.0649  Test_loss : 4719.1709, Time/batch_file : 2.2729, Training time: 12022.2164\n",
      "Epoch : 1036/2000 data_batch_5,  Train_loss : 4463.3770  Test_loss : 4819.6797, Time/batch_file : 2.3083, Training time: 12024.5250\n",
      "Epoch : 1037/2000 data_batch_1,  Train_loss : 5207.3496  Test_loss : 5326.5850, Time/batch_file : 2.2612, Training time: 12026.7864\n",
      "Epoch : 1037/2000 data_batch_2,  Train_loss : 5252.9629  Test_loss : 5338.6274, Time/batch_file : 2.2655, Training time: 12029.0521\n",
      "Epoch : 1037/2000 data_batch_3,  Train_loss : 5044.4043  Test_loss : 5092.5215, Time/batch_file : 2.5880, Training time: 12031.6402\n",
      "Epoch : 1037/2000 data_batch_4,  Train_loss : 5245.0596  Test_loss : 5350.1050, Time/batch_file : 2.3229, Training time: 12033.9634\n",
      "Epoch : 1037/2000 data_batch_5,  Train_loss : 4822.2930  Test_loss : 5660.2090, Time/batch_file : 2.2605, Training time: 12036.2242\n",
      "Epoch : 1038/2000 data_batch_1,  Train_loss : 5152.4863  Test_loss : 5309.5791, Time/batch_file : 2.2803, Training time: 12038.5046\n",
      "Epoch : 1038/2000 data_batch_2,  Train_loss : 4682.6621  Test_loss : 5035.6821, Time/batch_file : 2.2724, Training time: 12040.7772\n",
      "Epoch : 1038/2000 data_batch_3,  Train_loss : 4965.6299  Test_loss : 4927.1299, Time/batch_file : 2.2907, Training time: 12043.0681\n",
      "Epoch : 1038/2000 data_batch_4,  Train_loss : 5059.5928  Test_loss : 5448.1294, Time/batch_file : 2.2745, Training time: 12045.3428\n",
      "Epoch : 1038/2000 data_batch_5,  Train_loss : 4812.0332  Test_loss : 5117.8477, Time/batch_file : 2.2792, Training time: 12047.6222\n",
      "Epoch : 1039/2000 data_batch_1,  Train_loss : 4650.8945  Test_loss : 5252.7124, Time/batch_file : 2.2673, Training time: 12049.8897\n",
      "Epoch : 1039/2000 data_batch_2,  Train_loss : 4570.6479  Test_loss : 5340.2422, Time/batch_file : 2.2816, Training time: 12052.1715\n",
      "Epoch : 1039/2000 data_batch_3,  Train_loss : 4913.2109  Test_loss : 5223.2549, Time/batch_file : 2.2756, Training time: 12054.4473\n",
      "Epoch : 1039/2000 data_batch_4,  Train_loss : 4477.8486  Test_loss : 4940.2041, Time/batch_file : 2.2785, Training time: 12056.7260\n",
      "Epoch : 1039/2000 data_batch_5,  Train_loss : 5057.8262  Test_loss : 5153.1416, Time/batch_file : 2.3142, Training time: 12059.0405\n",
      "Epoch : 1040/2000 data_batch_1,  Train_loss : 4669.8696  Test_loss : 5056.8408, Time/batch_file : 2.2574, Training time: 12061.2982\n",
      "Epoch : 1040/2000 data_batch_2,  Train_loss : 5028.7676  Test_loss : 4824.1816, Time/batch_file : 2.2744, Training time: 12063.5728\n",
      "Epoch : 1040/2000 data_batch_3,  Train_loss : 4864.5273  Test_loss : 4812.9307, Time/batch_file : 2.2856, Training time: 12065.9063\n",
      "Epoch : 1040/2000 data_batch_4,  Train_loss : 4565.9736  Test_loss : 5145.8760, Time/batch_file : 2.2659, Training time: 12068.1725\n",
      "Epoch : 1040/2000 data_batch_5,  Train_loss : 4566.9736  Test_loss : 5246.0854, Time/batch_file : 2.2642, Training time: 12070.4368\n",
      "[./nets/net-1040.ckpt] SAVED\n",
      "Epoch : 1041/2000 data_batch_1,  Train_loss : 5111.5029  Test_loss : 5281.0664, Time/batch_file : 2.7757, Training time: 12075.1619\n",
      "Epoch : 1041/2000 data_batch_2,  Train_loss : 4983.4658  Test_loss : 5194.1909, Time/batch_file : 2.3458, Training time: 12077.5078\n",
      "Epoch : 1041/2000 data_batch_3,  Train_loss : 5041.4297  Test_loss : 4885.1426, Time/batch_file : 2.2894, Training time: 12079.7974\n",
      "Epoch : 1041/2000 data_batch_4,  Train_loss : 4955.6011  Test_loss : 4916.1445, Time/batch_file : 2.2690, Training time: 12082.0666\n",
      "Epoch : 1041/2000 data_batch_5,  Train_loss : 4827.0376  Test_loss : 4787.2178, Time/batch_file : 2.2859, Training time: 12084.3526\n",
      "Epoch : 1042/2000 data_batch_1,  Train_loss : 4982.1440  Test_loss : 5573.9561, Time/batch_file : 2.4766, Training time: 12086.8294\n",
      "Epoch : 1042/2000 data_batch_2,  Train_loss : 4980.6479  Test_loss : 5396.5322, Time/batch_file : 2.2788, Training time: 12089.1085\n",
      "Epoch : 1042/2000 data_batch_3,  Train_loss : 4980.2441  Test_loss : 5173.0513, Time/batch_file : 2.2668, Training time: 12091.3755\n",
      "Epoch : 1042/2000 data_batch_4,  Train_loss : 4922.9912  Test_loss : 5514.8154, Time/batch_file : 2.2607, Training time: 12093.6364\n",
      "Epoch : 1042/2000 data_batch_5,  Train_loss : 4906.2085  Test_loss : 5544.0835, Time/batch_file : 2.2742, Training time: 12095.9108\n",
      "Epoch : 1043/2000 data_batch_1,  Train_loss : 5239.4980  Test_loss : 5073.8359, Time/batch_file : 2.2598, Training time: 12098.1708\n",
      "Epoch : 1043/2000 data_batch_2,  Train_loss : 5524.5137  Test_loss : 5278.6411, Time/batch_file : 2.2704, Training time: 12100.4415\n",
      "Epoch : 1043/2000 data_batch_3,  Train_loss : 5472.2715  Test_loss : 5263.3525, Time/batch_file : 2.2588, Training time: 12102.7006\n",
      "Epoch : 1043/2000 data_batch_4,  Train_loss : 5373.0884  Test_loss : 5209.7559, Time/batch_file : 2.2581, Training time: 12104.9589\n",
      "Epoch : 1043/2000 data_batch_5,  Train_loss : 5455.2773  Test_loss : 4998.2622, Time/batch_file : 2.2689, Training time: 12107.2280\n",
      "Epoch : 1044/2000 data_batch_1,  Train_loss : 4955.5317  Test_loss : 5280.3423, Time/batch_file : 2.2689, Training time: 12109.4971\n",
      "Epoch : 1044/2000 data_batch_2,  Train_loss : 5181.4150  Test_loss : 5557.3286, Time/batch_file : 2.2710, Training time: 12111.7683\n",
      "Epoch : 1044/2000 data_batch_3,  Train_loss : 5029.5181  Test_loss : 5111.3125, Time/batch_file : 2.2766, Training time: 12114.0452\n",
      "Epoch : 1044/2000 data_batch_4,  Train_loss : 5019.3965  Test_loss : 5185.0918, Time/batch_file : 2.2747, Training time: 12116.3201\n",
      "Epoch : 1044/2000 data_batch_5,  Train_loss : 4838.9233  Test_loss : 5094.7891, Time/batch_file : 2.2825, Training time: 12118.6028\n",
      "Epoch : 1045/2000 data_batch_1,  Train_loss : 4428.3525  Test_loss : 5300.5796, Time/batch_file : 2.2722, Training time: 12120.8752\n",
      "Epoch : 1045/2000 data_batch_2,  Train_loss : 4765.6230  Test_loss : 5325.6982, Time/batch_file : 2.2769, Training time: 12123.1523\n",
      "Epoch : 1045/2000 data_batch_3,  Train_loss : 4553.3154  Test_loss : 5482.0781, Time/batch_file : 2.2744, Training time: 12125.4269\n",
      "Epoch : 1045/2000 data_batch_4,  Train_loss : 4469.8921  Test_loss : 5220.0825, Time/batch_file : 2.2734, Training time: 12127.7006\n",
      "Epoch : 1045/2000 data_batch_5,  Train_loss : 4619.3047  Test_loss : 5502.8262, Time/batch_file : 2.2771, Training time: 12129.9779\n",
      "Epoch : 1046/2000 data_batch_1,  Train_loss : 4940.1440  Test_loss : 4974.2832, Time/batch_file : 2.2718, Training time: 12132.2499\n",
      "Epoch : 1046/2000 data_batch_2,  Train_loss : 4923.3662  Test_loss : 4700.5669, Time/batch_file : 2.2823, Training time: 12134.5324\n",
      "Epoch : 1046/2000 data_batch_3,  Train_loss : 4935.3306  Test_loss : 4898.7852, Time/batch_file : 2.2642, Training time: 12136.7968\n",
      "Epoch : 1046/2000 data_batch_4,  Train_loss : 4814.6914  Test_loss : 4706.5576, Time/batch_file : 2.2604, Training time: 12139.0574\n",
      "Epoch : 1046/2000 data_batch_5,  Train_loss : 5034.5161  Test_loss : 4910.5000, Time/batch_file : 2.2676, Training time: 12141.3252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1047/2000 data_batch_1,  Train_loss : 4956.3896  Test_loss : 4876.0142, Time/batch_file : 2.2728, Training time: 12143.5982\n",
      "Epoch : 1047/2000 data_batch_2,  Train_loss : 5222.2236  Test_loss : 4851.2441, Time/batch_file : 2.2793, Training time: 12145.8777\n",
      "Epoch : 1047/2000 data_batch_3,  Train_loss : 5171.0830  Test_loss : 4755.2227, Time/batch_file : 2.2762, Training time: 12148.1541\n",
      "Epoch : 1047/2000 data_batch_4,  Train_loss : 5190.3613  Test_loss : 4755.3521, Time/batch_file : 2.2720, Training time: 12150.4263\n",
      "Epoch : 1047/2000 data_batch_5,  Train_loss : 5041.7876  Test_loss : 4630.1113, Time/batch_file : 2.2730, Training time: 12152.6996\n",
      "Epoch : 1048/2000 data_batch_1,  Train_loss : 4950.9980  Test_loss : 5125.6216, Time/batch_file : 2.2612, Training time: 12154.9610\n",
      "Epoch : 1048/2000 data_batch_2,  Train_loss : 4810.2285  Test_loss : 5167.1172, Time/batch_file : 2.2656, Training time: 12157.2268\n",
      "Epoch : 1048/2000 data_batch_3,  Train_loss : 4535.2725  Test_loss : 5046.5889, Time/batch_file : 2.2655, Training time: 12159.4924\n",
      "Epoch : 1048/2000 data_batch_4,  Train_loss : 4415.6597  Test_loss : 5143.9512, Time/batch_file : 2.2553, Training time: 12161.7479\n",
      "Epoch : 1048/2000 data_batch_5,  Train_loss : 4619.7295  Test_loss : 5148.5142, Time/batch_file : 2.2623, Training time: 12164.0105\n",
      "Epoch : 1049/2000 data_batch_1,  Train_loss : 4855.9819  Test_loss : 4970.3457, Time/batch_file : 2.2712, Training time: 12166.2819\n",
      "Epoch : 1049/2000 data_batch_2,  Train_loss : 4604.6543  Test_loss : 5123.3125, Time/batch_file : 2.2685, Training time: 12168.5507\n",
      "Epoch : 1049/2000 data_batch_3,  Train_loss : 4843.1851  Test_loss : 4781.6719, Time/batch_file : 2.2631, Training time: 12170.8140\n",
      "Epoch : 1049/2000 data_batch_4,  Train_loss : 4901.8359  Test_loss : 5017.3320, Time/batch_file : 2.2713, Training time: 12173.0854\n",
      "Epoch : 1049/2000 data_batch_5,  Train_loss : 5008.9756  Test_loss : 5014.6035, Time/batch_file : 2.2756, Training time: 12175.3613\n",
      "Epoch : 1050/2000 data_batch_1,  Train_loss : 4767.3833  Test_loss : 5276.7480, Time/batch_file : 2.2952, Training time: 12177.6567\n",
      "Epoch : 1050/2000 data_batch_2,  Train_loss : 4677.8701  Test_loss : 5531.8213, Time/batch_file : 2.2883, Training time: 12179.9453\n",
      "Epoch : 1050/2000 data_batch_3,  Train_loss : 4744.5713  Test_loss : 5616.9961, Time/batch_file : 2.2836, Training time: 12182.2290\n",
      "Epoch : 1050/2000 data_batch_4,  Train_loss : 5051.6333  Test_loss : 5170.3960, Time/batch_file : 2.2912, Training time: 12184.5204\n",
      "Epoch : 1050/2000 data_batch_5,  Train_loss : 4643.3979  Test_loss : 5201.3359, Time/batch_file : 2.2960, Training time: 12186.8166\n",
      "[./nets/net-1050.ckpt] SAVED\n",
      "Epoch : 1051/2000 data_batch_1,  Train_loss : 4723.5625  Test_loss : 5120.6768, Time/batch_file : 2.3120, Training time: 12190.4201\n",
      "Epoch : 1051/2000 data_batch_2,  Train_loss : 4547.7764  Test_loss : 4843.1553, Time/batch_file : 2.3123, Training time: 12192.7327\n",
      "Epoch : 1051/2000 data_batch_3,  Train_loss : 4693.9683  Test_loss : 4734.9160, Time/batch_file : 2.3137, Training time: 12195.0466\n",
      "Epoch : 1051/2000 data_batch_4,  Train_loss : 4468.1919  Test_loss : 5035.2734, Time/batch_file : 2.3021, Training time: 12197.3489\n",
      "Epoch : 1051/2000 data_batch_5,  Train_loss : 4625.8091  Test_loss : 5005.9629, Time/batch_file : 2.2967, Training time: 12199.6459\n",
      "Epoch : 1052/2000 data_batch_1,  Train_loss : 5158.1992  Test_loss : 5116.8066, Time/batch_file : 2.2784, Training time: 12201.9246\n",
      "Epoch : 1052/2000 data_batch_2,  Train_loss : 5186.4727  Test_loss : 5294.1963, Time/batch_file : 2.2884, Training time: 12204.2132\n",
      "Epoch : 1052/2000 data_batch_3,  Train_loss : 5112.4111  Test_loss : 4942.7910, Time/batch_file : 2.2880, Training time: 12206.5013\n",
      "Epoch : 1052/2000 data_batch_4,  Train_loss : 5040.6182  Test_loss : 4921.2607, Time/batch_file : 2.2700, Training time: 12208.7715\n",
      "Epoch : 1052/2000 data_batch_5,  Train_loss : 5087.8242  Test_loss : 5188.9971, Time/batch_file : 2.2976, Training time: 12211.0694\n",
      "Epoch : 1053/2000 data_batch_1,  Train_loss : 4669.0713  Test_loss : 5180.0176, Time/batch_file : 2.3005, Training time: 12213.3701\n",
      "Epoch : 1053/2000 data_batch_2,  Train_loss : 4694.2710  Test_loss : 5510.9834, Time/batch_file : 2.3020, Training time: 12215.6723\n",
      "Epoch : 1053/2000 data_batch_3,  Train_loss : 4720.7637  Test_loss : 5166.1743, Time/batch_file : 2.3200, Training time: 12217.9926\n",
      "Epoch : 1053/2000 data_batch_4,  Train_loss : 4876.1255  Test_loss : 5387.9487, Time/batch_file : 2.2846, Training time: 12220.2774\n",
      "Epoch : 1053/2000 data_batch_5,  Train_loss : 4700.6768  Test_loss : 5293.0654, Time/batch_file : 2.3044, Training time: 12222.5820\n",
      "Epoch : 1054/2000 data_batch_1,  Train_loss : 5330.0166  Test_loss : 5178.4526, Time/batch_file : 2.2904, Training time: 12224.8725\n",
      "Epoch : 1054/2000 data_batch_2,  Train_loss : 5302.1660  Test_loss : 4845.8618, Time/batch_file : 2.2898, Training time: 12227.1626\n",
      "Epoch : 1054/2000 data_batch_3,  Train_loss : 5276.1357  Test_loss : 5259.7178, Time/batch_file : 2.2916, Training time: 12229.4544\n",
      "Epoch : 1054/2000 data_batch_4,  Train_loss : 5322.6294  Test_loss : 5161.8843, Time/batch_file : 2.2917, Training time: 12231.7463\n",
      "Epoch : 1054/2000 data_batch_5,  Train_loss : 5469.5879  Test_loss : 4875.4761, Time/batch_file : 2.2986, Training time: 12234.0451\n",
      "Epoch : 1055/2000 data_batch_1,  Train_loss : 4920.6455  Test_loss : 5069.8931, Time/batch_file : 2.2791, Training time: 12236.3244\n",
      "Epoch : 1055/2000 data_batch_2,  Train_loss : 5030.2432  Test_loss : 4968.5605, Time/batch_file : 2.2895, Training time: 12238.6142\n",
      "Epoch : 1055/2000 data_batch_3,  Train_loss : 5020.0244  Test_loss : 5092.5610, Time/batch_file : 2.2969, Training time: 12240.9113\n",
      "Epoch : 1055/2000 data_batch_4,  Train_loss : 4874.8828  Test_loss : 4826.2915, Time/batch_file : 2.2655, Training time: 12243.1770\n",
      "Epoch : 1055/2000 data_batch_5,  Train_loss : 4992.5400  Test_loss : 5322.9893, Time/batch_file : 2.2746, Training time: 12245.4518\n",
      "Epoch : 1056/2000 data_batch_1,  Train_loss : 4967.4980  Test_loss : 4684.6885, Time/batch_file : 2.2927, Training time: 12247.7447\n",
      "Epoch : 1056/2000 data_batch_2,  Train_loss : 4877.2588  Test_loss : 4987.3926, Time/batch_file : 2.3176, Training time: 12250.0625\n",
      "Epoch : 1056/2000 data_batch_3,  Train_loss : 4976.7646  Test_loss : 5121.8833, Time/batch_file : 2.2837, Training time: 12252.3464\n",
      "Epoch : 1056/2000 data_batch_4,  Train_loss : 4666.6768  Test_loss : 4831.8716, Time/batch_file : 2.3110, Training time: 12254.6576\n",
      "Epoch : 1056/2000 data_batch_5,  Train_loss : 5175.8037  Test_loss : 4990.1768, Time/batch_file : 2.2994, Training time: 12256.9572\n",
      "Epoch : 1057/2000 data_batch_1,  Train_loss : 5087.1270  Test_loss : 5707.9653, Time/batch_file : 2.2634, Training time: 12259.2209\n",
      "Epoch : 1057/2000 data_batch_2,  Train_loss : 5008.8179  Test_loss : 5430.6572, Time/batch_file : 2.3047, Training time: 12261.5257\n",
      "Epoch : 1057/2000 data_batch_3,  Train_loss : 4986.8892  Test_loss : 5487.1694, Time/batch_file : 2.2808, Training time: 12263.8066\n",
      "Epoch : 1057/2000 data_batch_4,  Train_loss : 4787.2622  Test_loss : 5955.3252, Time/batch_file : 2.2844, Training time: 12266.0912\n",
      "Epoch : 1057/2000 data_batch_5,  Train_loss : 5077.7070  Test_loss : 6164.4639, Time/batch_file : 2.2791, Training time: 12268.3705\n",
      "Epoch : 1058/2000 data_batch_1,  Train_loss : 4939.7241  Test_loss : 4455.0234, Time/batch_file : 2.2693, Training time: 12270.6400\n",
      "Epoch : 1058/2000 data_batch_2,  Train_loss : 4922.4873  Test_loss : 4574.7358, Time/batch_file : 2.2941, Training time: 12272.9343\n",
      "Epoch : 1058/2000 data_batch_3,  Train_loss : 4923.8330  Test_loss : 4602.7959, Time/batch_file : 2.2752, Training time: 12275.2097\n",
      "Epoch : 1058/2000 data_batch_4,  Train_loss : 5158.9941  Test_loss : 4253.5420, Time/batch_file : 2.2638, Training time: 12277.4738\n",
      "Epoch : 1058/2000 data_batch_5,  Train_loss : 4890.0020  Test_loss : 4340.1655, Time/batch_file : 2.2621, Training time: 12279.7361\n",
      "Epoch : 1059/2000 data_batch_1,  Train_loss : 4903.7021  Test_loss : 5392.9697, Time/batch_file : 2.2956, Training time: 12282.0319\n",
      "Epoch : 1059/2000 data_batch_2,  Train_loss : 4982.8428  Test_loss : 5346.2129, Time/batch_file : 2.2672, Training time: 12284.2994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1059/2000 data_batch_3,  Train_loss : 4840.0903  Test_loss : 5119.6396, Time/batch_file : 2.2877, Training time: 12286.5873\n",
      "Epoch : 1059/2000 data_batch_4,  Train_loss : 5246.4102  Test_loss : 5028.1040, Time/batch_file : 2.2876, Training time: 12288.8751\n",
      "Epoch : 1059/2000 data_batch_5,  Train_loss : 4904.4072  Test_loss : 4865.0957, Time/batch_file : 2.2725, Training time: 12291.1479\n",
      "Epoch : 1060/2000 data_batch_1,  Train_loss : 4809.9092  Test_loss : 5593.6768, Time/batch_file : 2.2948, Training time: 12293.4429\n",
      "Epoch : 1060/2000 data_batch_2,  Train_loss : 4844.3564  Test_loss : 5529.2705, Time/batch_file : 2.2679, Training time: 12295.7109\n",
      "Epoch : 1060/2000 data_batch_3,  Train_loss : 4899.3389  Test_loss : 5374.2734, Time/batch_file : 2.3246, Training time: 12298.0357\n",
      "Epoch : 1060/2000 data_batch_4,  Train_loss : 4693.0928  Test_loss : 5415.5005, Time/batch_file : 2.2844, Training time: 12300.3203\n",
      "Epoch : 1060/2000 data_batch_5,  Train_loss : 4595.0215  Test_loss : 5575.5684, Time/batch_file : 2.2684, Training time: 12302.5890\n",
      "[./nets/net-1060.ckpt] SAVED\n",
      "Epoch : 1061/2000 data_batch_1,  Train_loss : 4752.3901  Test_loss : 5396.6118, Time/batch_file : 2.3058, Training time: 12306.1719\n",
      "Epoch : 1061/2000 data_batch_2,  Train_loss : 4681.2588  Test_loss : 5477.4673, Time/batch_file : 2.3031, Training time: 12308.4752\n",
      "Epoch : 1061/2000 data_batch_3,  Train_loss : 4967.1035  Test_loss : 5300.1558, Time/batch_file : 2.3083, Training time: 12310.7838\n",
      "Epoch : 1061/2000 data_batch_4,  Train_loss : 4685.8306  Test_loss : 5422.2539, Time/batch_file : 2.2994, Training time: 12313.0835\n",
      "Epoch : 1061/2000 data_batch_5,  Train_loss : 4940.1792  Test_loss : 5509.2944, Time/batch_file : 2.2929, Training time: 12315.3767\n",
      "Epoch : 1062/2000 data_batch_1,  Train_loss : 4443.0225  Test_loss : 4844.6641, Time/batch_file : 2.2891, Training time: 12317.6660\n",
      "Epoch : 1062/2000 data_batch_2,  Train_loss : 4788.6064  Test_loss : 4848.6724, Time/batch_file : 2.3036, Training time: 12319.9697\n",
      "Epoch : 1062/2000 data_batch_3,  Train_loss : 4850.8530  Test_loss : 4763.0996, Time/batch_file : 2.3295, Training time: 12322.2994\n",
      "Epoch : 1062/2000 data_batch_4,  Train_loss : 4827.1699  Test_loss : 4676.7832, Time/batch_file : 2.3143, Training time: 12324.6139\n",
      "Epoch : 1062/2000 data_batch_5,  Train_loss : 4727.1104  Test_loss : 4756.7080, Time/batch_file : 2.2977, Training time: 12326.9118\n",
      "Epoch : 1063/2000 data_batch_1,  Train_loss : 4946.0713  Test_loss : 5186.0488, Time/batch_file : 2.3254, Training time: 12329.2374\n",
      "Epoch : 1063/2000 data_batch_2,  Train_loss : 4904.7046  Test_loss : 5136.8999, Time/batch_file : 2.2843, Training time: 12331.5220\n",
      "Epoch : 1063/2000 data_batch_3,  Train_loss : 5089.8564  Test_loss : 5262.7598, Time/batch_file : 2.3054, Training time: 12333.8276\n",
      "Epoch : 1063/2000 data_batch_4,  Train_loss : 5010.6787  Test_loss : 5093.8232, Time/batch_file : 2.3027, Training time: 12336.1305\n",
      "Epoch : 1063/2000 data_batch_5,  Train_loss : 4829.1016  Test_loss : 5224.7402, Time/batch_file : 2.3028, Training time: 12338.4334\n",
      "Epoch : 1064/2000 data_batch_1,  Train_loss : 4669.4282  Test_loss : 5042.3818, Time/batch_file : 2.2781, Training time: 12340.7117\n",
      "Epoch : 1064/2000 data_batch_2,  Train_loss : 5015.3232  Test_loss : 5449.6582, Time/batch_file : 2.3059, Training time: 12343.0178\n",
      "Epoch : 1064/2000 data_batch_3,  Train_loss : 5000.4463  Test_loss : 5150.3267, Time/batch_file : 2.2729, Training time: 12345.2909\n",
      "Epoch : 1064/2000 data_batch_4,  Train_loss : 4781.6445  Test_loss : 5259.3223, Time/batch_file : 2.3026, Training time: 12347.5937\n",
      "Epoch : 1064/2000 data_batch_5,  Train_loss : 4983.9326  Test_loss : 4924.3516, Time/batch_file : 2.2830, Training time: 12349.8769\n",
      "Epoch : 1065/2000 data_batch_1,  Train_loss : 5018.1499  Test_loss : 5136.9346, Time/batch_file : 2.3128, Training time: 12352.1899\n",
      "Epoch : 1065/2000 data_batch_2,  Train_loss : 5110.2627  Test_loss : 5169.2344, Time/batch_file : 2.2982, Training time: 12354.4884\n",
      "Epoch : 1065/2000 data_batch_3,  Train_loss : 5215.0444  Test_loss : 5331.0894, Time/batch_file : 2.3037, Training time: 12356.7923\n",
      "Epoch : 1065/2000 data_batch_4,  Train_loss : 4976.5747  Test_loss : 5071.9912, Time/batch_file : 2.2904, Training time: 12359.0829\n",
      "Epoch : 1065/2000 data_batch_5,  Train_loss : 4850.7705  Test_loss : 5078.9648, Time/batch_file : 2.2964, Training time: 12361.3795\n",
      "Epoch : 1066/2000 data_batch_1,  Train_loss : 5117.9297  Test_loss : 5711.0005, Time/batch_file : 2.3037, Training time: 12363.6834\n",
      "Epoch : 1066/2000 data_batch_2,  Train_loss : 4451.1899  Test_loss : 5707.6875, Time/batch_file : 2.3216, Training time: 12366.0052\n",
      "Epoch : 1066/2000 data_batch_3,  Train_loss : 4926.8511  Test_loss : 5526.2520, Time/batch_file : 2.3003, Training time: 12368.3058\n",
      "Epoch : 1066/2000 data_batch_4,  Train_loss : 4731.8218  Test_loss : 5861.3701, Time/batch_file : 2.3110, Training time: 12370.6170\n",
      "Epoch : 1066/2000 data_batch_5,  Train_loss : 4690.3154  Test_loss : 5500.6436, Time/batch_file : 2.3038, Training time: 12372.9210\n",
      "Epoch : 1067/2000 data_batch_1,  Train_loss : 4927.2949  Test_loss : 5548.4214, Time/batch_file : 2.3073, Training time: 12375.2284\n",
      "Epoch : 1067/2000 data_batch_2,  Train_loss : 5179.4893  Test_loss : 5928.1147, Time/batch_file : 2.2840, Training time: 12377.5127\n",
      "Epoch : 1067/2000 data_batch_3,  Train_loss : 4831.8423  Test_loss : 5563.0405, Time/batch_file : 2.2893, Training time: 12379.8022\n",
      "Epoch : 1067/2000 data_batch_4,  Train_loss : 5144.8467  Test_loss : 5407.3115, Time/batch_file : 2.2839, Training time: 12382.0863\n",
      "Epoch : 1067/2000 data_batch_5,  Train_loss : 4686.0483  Test_loss : 5669.0396, Time/batch_file : 2.3015, Training time: 12384.3880\n",
      "Epoch : 1068/2000 data_batch_1,  Train_loss : 4899.2783  Test_loss : 4805.0889, Time/batch_file : 2.2666, Training time: 12386.6548\n",
      "Epoch : 1068/2000 data_batch_2,  Train_loss : 4821.7144  Test_loss : 4888.8389, Time/batch_file : 2.2951, Training time: 12388.9502\n",
      "Epoch : 1068/2000 data_batch_3,  Train_loss : 4918.1025  Test_loss : 4911.5488, Time/batch_file : 2.2742, Training time: 12391.2246\n",
      "Epoch : 1068/2000 data_batch_4,  Train_loss : 4630.1465  Test_loss : 4916.5688, Time/batch_file : 2.3066, Training time: 12393.5314\n",
      "Epoch : 1068/2000 data_batch_5,  Train_loss : 4715.7559  Test_loss : 4733.6968, Time/batch_file : 2.2729, Training time: 12395.8045\n",
      "Epoch : 1069/2000 data_batch_1,  Train_loss : 4343.0103  Test_loss : 5140.1582, Time/batch_file : 2.3037, Training time: 12398.1085\n",
      "Epoch : 1069/2000 data_batch_2,  Train_loss : 4415.7686  Test_loss : 5164.5918, Time/batch_file : 2.2881, Training time: 12400.3968\n",
      "Epoch : 1069/2000 data_batch_3,  Train_loss : 4592.6465  Test_loss : 5690.1899, Time/batch_file : 2.3032, Training time: 12402.7002\n",
      "Epoch : 1069/2000 data_batch_4,  Train_loss : 4418.6841  Test_loss : 5098.9043, Time/batch_file : 2.2876, Training time: 12404.9881\n",
      "Epoch : 1069/2000 data_batch_5,  Train_loss : 4468.5762  Test_loss : 5243.6362, Time/batch_file : 2.2978, Training time: 12407.2861\n",
      "Epoch : 1070/2000 data_batch_1,  Train_loss : 4416.7959  Test_loss : 5307.9868, Time/batch_file : 2.2873, Training time: 12409.5736\n",
      "Epoch : 1070/2000 data_batch_2,  Train_loss : 4286.7788  Test_loss : 5413.0371, Time/batch_file : 2.2966, Training time: 12411.8704\n",
      "Epoch : 1070/2000 data_batch_3,  Train_loss : 4197.9434  Test_loss : 5244.1973, Time/batch_file : 2.2916, Training time: 12414.1623\n",
      "Epoch : 1070/2000 data_batch_4,  Train_loss : 4144.5273  Test_loss : 5326.7598, Time/batch_file : 2.2975, Training time: 12416.4599\n",
      "Epoch : 1070/2000 data_batch_5,  Train_loss : 4299.6475  Test_loss : 5237.0527, Time/batch_file : 2.3022, Training time: 12418.7622\n",
      "[./nets/net-1070.ckpt] SAVED\n",
      "Epoch : 1071/2000 data_batch_1,  Train_loss : 4896.9829  Test_loss : 5568.4854, Time/batch_file : 2.2816, Training time: 12422.3425\n",
      "Epoch : 1071/2000 data_batch_2,  Train_loss : 4733.6426  Test_loss : 5322.9980, Time/batch_file : 2.2828, Training time: 12424.6256\n",
      "Epoch : 1071/2000 data_batch_3,  Train_loss : 5025.8374  Test_loss : 5675.8433, Time/batch_file : 2.2737, Training time: 12426.8995\n",
      "Epoch : 1071/2000 data_batch_4,  Train_loss : 4743.2969  Test_loss : 5663.6084, Time/batch_file : 2.2775, Training time: 12429.1773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1071/2000 data_batch_5,  Train_loss : 4990.1152  Test_loss : 5334.7090, Time/batch_file : 2.3079, Training time: 12431.4854\n",
      "Epoch : 1072/2000 data_batch_1,  Train_loss : 5119.6318  Test_loss : 5389.3398, Time/batch_file : 2.2580, Training time: 12433.7435\n",
      "Epoch : 1072/2000 data_batch_2,  Train_loss : 5074.5679  Test_loss : 5381.4717, Time/batch_file : 2.2657, Training time: 12436.0095\n",
      "Epoch : 1072/2000 data_batch_3,  Train_loss : 5288.2754  Test_loss : 5158.0620, Time/batch_file : 2.2689, Training time: 12438.2786\n",
      "Epoch : 1072/2000 data_batch_4,  Train_loss : 5074.9990  Test_loss : 5240.0210, Time/batch_file : 2.2605, Training time: 12440.5393\n",
      "Epoch : 1072/2000 data_batch_5,  Train_loss : 5163.7383  Test_loss : 5028.1206, Time/batch_file : 2.2563, Training time: 12442.7956\n",
      "Epoch : 1073/2000 data_batch_1,  Train_loss : 5399.2700  Test_loss : 4449.6416, Time/batch_file : 2.2974, Training time: 12445.0933\n",
      "Epoch : 1073/2000 data_batch_2,  Train_loss : 5492.3257  Test_loss : 4232.4771, Time/batch_file : 2.2666, Training time: 12447.3600\n",
      "Epoch : 1073/2000 data_batch_3,  Train_loss : 5480.3970  Test_loss : 4583.0010, Time/batch_file : 2.2749, Training time: 12449.6351\n",
      "Epoch : 1073/2000 data_batch_4,  Train_loss : 5264.5107  Test_loss : 4489.5762, Time/batch_file : 2.2832, Training time: 12451.9183\n",
      "Epoch : 1073/2000 data_batch_5,  Train_loss : 5663.1206  Test_loss : 4178.2715, Time/batch_file : 2.2694, Training time: 12454.1880\n",
      "Epoch : 1074/2000 data_batch_1,  Train_loss : 4693.4980  Test_loss : 5163.3271, Time/batch_file : 2.2868, Training time: 12456.4750\n",
      "Epoch : 1074/2000 data_batch_2,  Train_loss : 4579.7148  Test_loss : 5553.7363, Time/batch_file : 2.2869, Training time: 12458.7621\n",
      "Epoch : 1074/2000 data_batch_3,  Train_loss : 4313.4004  Test_loss : 5759.4727, Time/batch_file : 2.2724, Training time: 12461.0347\n",
      "Epoch : 1074/2000 data_batch_4,  Train_loss : 4284.1255  Test_loss : 5399.0552, Time/batch_file : 2.2848, Training time: 12463.3198\n",
      "Epoch : 1074/2000 data_batch_5,  Train_loss : 4474.4014  Test_loss : 5641.7451, Time/batch_file : 2.3019, Training time: 12465.6219\n",
      "Epoch : 1075/2000 data_batch_1,  Train_loss : 5394.0830  Test_loss : 5219.1050, Time/batch_file : 2.2704, Training time: 12467.8926\n",
      "Epoch : 1075/2000 data_batch_2,  Train_loss : 5022.2710  Test_loss : 5228.7979, Time/batch_file : 2.2766, Training time: 12470.1695\n",
      "Epoch : 1075/2000 data_batch_3,  Train_loss : 5301.0576  Test_loss : 5049.1074, Time/batch_file : 2.2953, Training time: 12472.4649\n",
      "Epoch : 1075/2000 data_batch_4,  Train_loss : 5240.0161  Test_loss : 5746.7070, Time/batch_file : 2.2714, Training time: 12474.7366\n",
      "Epoch : 1075/2000 data_batch_5,  Train_loss : 5263.8799  Test_loss : 5175.0063, Time/batch_file : 2.2667, Training time: 12477.0035\n",
      "Epoch : 1076/2000 data_batch_1,  Train_loss : 4805.5371  Test_loss : 5292.1606, Time/batch_file : 2.2828, Training time: 12479.2865\n",
      "Epoch : 1076/2000 data_batch_2,  Train_loss : 5290.6816  Test_loss : 5433.1914, Time/batch_file : 2.2641, Training time: 12481.5508\n",
      "Epoch : 1076/2000 data_batch_3,  Train_loss : 5212.4668  Test_loss : 5579.5024, Time/batch_file : 2.2710, Training time: 12483.8221\n",
      "Epoch : 1076/2000 data_batch_4,  Train_loss : 5067.8945  Test_loss : 5226.0664, Time/batch_file : 2.3118, Training time: 12486.1341\n",
      "Epoch : 1076/2000 data_batch_5,  Train_loss : 5372.3740  Test_loss : 5050.8867, Time/batch_file : 2.2580, Training time: 12488.3924\n",
      "Epoch : 1077/2000 data_batch_1,  Train_loss : 5270.3286  Test_loss : 4808.0635, Time/batch_file : 2.2919, Training time: 12490.6844\n",
      "Epoch : 1077/2000 data_batch_2,  Train_loss : 5116.6147  Test_loss : 4719.6182, Time/batch_file : 2.2824, Training time: 12492.9670\n",
      "Epoch : 1077/2000 data_batch_3,  Train_loss : 5098.8750  Test_loss : 4789.5347, Time/batch_file : 2.2757, Training time: 12495.2430\n",
      "Epoch : 1077/2000 data_batch_4,  Train_loss : 5148.7261  Test_loss : 5096.5464, Time/batch_file : 2.2972, Training time: 12497.5404\n",
      "Epoch : 1077/2000 data_batch_5,  Train_loss : 5190.6831  Test_loss : 4794.5493, Time/batch_file : 2.2971, Training time: 12499.8377\n",
      "Epoch : 1078/2000 data_batch_1,  Train_loss : 4984.9722  Test_loss : 5175.7144, Time/batch_file : 2.2625, Training time: 12502.1003\n",
      "Epoch : 1078/2000 data_batch_2,  Train_loss : 4717.2681  Test_loss : 5159.2070, Time/batch_file : 2.2728, Training time: 12504.3734\n",
      "Epoch : 1078/2000 data_batch_3,  Train_loss : 4955.7754  Test_loss : 4815.4736, Time/batch_file : 2.2851, Training time: 12506.6586\n",
      "Epoch : 1078/2000 data_batch_4,  Train_loss : 5123.9717  Test_loss : 4950.5430, Time/batch_file : 2.2593, Training time: 12508.9181\n",
      "Epoch : 1078/2000 data_batch_5,  Train_loss : 4532.7339  Test_loss : 5083.5757, Time/batch_file : 2.2735, Training time: 12511.1918\n",
      "Epoch : 1079/2000 data_batch_1,  Train_loss : 5001.2773  Test_loss : 4639.0029, Time/batch_file : 2.3022, Training time: 12513.4943\n",
      "Epoch : 1079/2000 data_batch_2,  Train_loss : 5372.1128  Test_loss : 4676.0645, Time/batch_file : 2.2674, Training time: 12515.7619\n",
      "Epoch : 1079/2000 data_batch_3,  Train_loss : 5154.0664  Test_loss : 4844.6494, Time/batch_file : 2.2705, Training time: 12518.0326\n",
      "Epoch : 1079/2000 data_batch_4,  Train_loss : 5273.3823  Test_loss : 4587.3799, Time/batch_file : 2.2773, Training time: 12520.3100\n",
      "Epoch : 1079/2000 data_batch_5,  Train_loss : 5043.9639  Test_loss : 4701.1011, Time/batch_file : 2.2721, Training time: 12522.5822\n",
      "Epoch : 1080/2000 data_batch_1,  Train_loss : 5089.5054  Test_loss : 4989.8911, Time/batch_file : 2.2728, Training time: 12524.8552\n",
      "Epoch : 1080/2000 data_batch_2,  Train_loss : 5105.5186  Test_loss : 4904.1411, Time/batch_file : 2.2832, Training time: 12527.1386\n",
      "Epoch : 1080/2000 data_batch_3,  Train_loss : 5335.2168  Test_loss : 4827.5537, Time/batch_file : 2.2606, Training time: 12529.3994\n",
      "Epoch : 1080/2000 data_batch_4,  Train_loss : 5345.0889  Test_loss : 4787.5269, Time/batch_file : 2.2636, Training time: 12531.6631\n",
      "Epoch : 1080/2000 data_batch_5,  Train_loss : 5161.1040  Test_loss : 5038.5435, Time/batch_file : 2.2853, Training time: 12533.9486\n",
      "[./nets/net-1080.ckpt] SAVED\n",
      "Epoch : 1081/2000 data_batch_1,  Train_loss : 4720.7866  Test_loss : 5001.1021, Time/batch_file : 2.3924, Training time: 12537.6510\n",
      "Epoch : 1081/2000 data_batch_2,  Train_loss : 4431.6064  Test_loss : 5020.8564, Time/batch_file : 2.4491, Training time: 12540.1003\n",
      "Epoch : 1081/2000 data_batch_3,  Train_loss : 4301.6182  Test_loss : 5004.6875, Time/batch_file : 2.2989, Training time: 12542.3994\n",
      "Epoch : 1081/2000 data_batch_4,  Train_loss : 4267.9038  Test_loss : 4854.5889, Time/batch_file : 2.2779, Training time: 12544.6775\n",
      "Epoch : 1081/2000 data_batch_5,  Train_loss : 4733.8203  Test_loss : 4820.6084, Time/batch_file : 2.3223, Training time: 12547.0000\n",
      "Epoch : 1082/2000 data_batch_1,  Train_loss : 4247.6919  Test_loss : 5237.2632, Time/batch_file : 2.3083, Training time: 12549.3085\n",
      "Epoch : 1082/2000 data_batch_2,  Train_loss : 4513.8311  Test_loss : 5391.0771, Time/batch_file : 2.3074, Training time: 12551.6162\n",
      "Epoch : 1082/2000 data_batch_3,  Train_loss : 4593.6675  Test_loss : 5524.8813, Time/batch_file : 2.2746, Training time: 12553.8909\n",
      "Epoch : 1082/2000 data_batch_4,  Train_loss : 4368.4634  Test_loss : 5338.4731, Time/batch_file : 2.3143, Training time: 12556.2054\n",
      "Epoch : 1082/2000 data_batch_5,  Train_loss : 4245.4131  Test_loss : 5070.3647, Time/batch_file : 2.2868, Training time: 12558.4924\n",
      "Epoch : 1083/2000 data_batch_1,  Train_loss : 5306.8906  Test_loss : 5112.2656, Time/batch_file : 2.2949, Training time: 12560.7874\n",
      "Epoch : 1083/2000 data_batch_2,  Train_loss : 5062.4219  Test_loss : 4798.4995, Time/batch_file : 2.2947, Training time: 12563.0824\n",
      "Epoch : 1083/2000 data_batch_3,  Train_loss : 5199.1147  Test_loss : 5268.0391, Time/batch_file : 2.3018, Training time: 12565.3843\n",
      "Epoch : 1083/2000 data_batch_4,  Train_loss : 5074.0200  Test_loss : 5042.1152, Time/batch_file : 2.2694, Training time: 12567.6540\n",
      "Epoch : 1083/2000 data_batch_5,  Train_loss : 5070.4243  Test_loss : 4917.8594, Time/batch_file : 2.3097, Training time: 12569.9639\n",
      "Epoch : 1084/2000 data_batch_1,  Train_loss : 4776.3472  Test_loss : 5658.7915, Time/batch_file : 2.2729, Training time: 12572.2369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1084/2000 data_batch_2,  Train_loss : 4937.9209  Test_loss : 5464.3389, Time/batch_file : 2.2715, Training time: 12574.5087\n",
      "Epoch : 1084/2000 data_batch_3,  Train_loss : 4438.8164  Test_loss : 5363.7295, Time/batch_file : 2.2786, Training time: 12576.7875\n",
      "Epoch : 1084/2000 data_batch_4,  Train_loss : 4724.8027  Test_loss : 5481.9478, Time/batch_file : 2.2964, Training time: 12579.0841\n",
      "Epoch : 1084/2000 data_batch_5,  Train_loss : 4531.2930  Test_loss : 5500.2383, Time/batch_file : 2.2578, Training time: 12581.3421\n",
      "Epoch : 1085/2000 data_batch_1,  Train_loss : 4731.7090  Test_loss : 5415.7666, Time/batch_file : 2.3096, Training time: 12583.6520\n",
      "Epoch : 1085/2000 data_batch_2,  Train_loss : 4409.1909  Test_loss : 5358.1260, Time/batch_file : 2.2977, Training time: 12585.9499\n",
      "Epoch : 1085/2000 data_batch_3,  Train_loss : 4735.6484  Test_loss : 5220.6821, Time/batch_file : 2.2814, Training time: 12588.2314\n",
      "Epoch : 1085/2000 data_batch_4,  Train_loss : 4517.9390  Test_loss : 5144.5703, Time/batch_file : 2.3009, Training time: 12590.5326\n",
      "Epoch : 1085/2000 data_batch_5,  Train_loss : 4280.8774  Test_loss : 5224.5474, Time/batch_file : 2.3131, Training time: 12592.8459\n",
      "Epoch : 1086/2000 data_batch_1,  Train_loss : 4560.1221  Test_loss : 4757.9233, Time/batch_file : 2.2554, Training time: 12595.1017\n",
      "Epoch : 1086/2000 data_batch_2,  Train_loss : 4773.2666  Test_loss : 4815.6182, Time/batch_file : 2.3015, Training time: 12597.4033\n",
      "Epoch : 1086/2000 data_batch_3,  Train_loss : 4742.2007  Test_loss : 5173.6108, Time/batch_file : 2.2746, Training time: 12599.6781\n",
      "Epoch : 1086/2000 data_batch_4,  Train_loss : 4829.7310  Test_loss : 5152.5693, Time/batch_file : 2.2670, Training time: 12601.9454\n",
      "Epoch : 1086/2000 data_batch_5,  Train_loss : 4919.4302  Test_loss : 4824.3750, Time/batch_file : 2.2845, Training time: 12604.2301\n",
      "Epoch : 1087/2000 data_batch_1,  Train_loss : 4702.4854  Test_loss : 4930.4380, Time/batch_file : 2.2926, Training time: 12606.5229\n",
      "Epoch : 1087/2000 data_batch_2,  Train_loss : 4893.9404  Test_loss : 4998.6455, Time/batch_file : 2.2657, Training time: 12608.7888\n",
      "Epoch : 1087/2000 data_batch_3,  Train_loss : 5079.3633  Test_loss : 4986.0264, Time/batch_file : 2.3013, Training time: 12611.0903\n",
      "Epoch : 1087/2000 data_batch_4,  Train_loss : 4931.7324  Test_loss : 4752.0723, Time/batch_file : 2.2794, Training time: 12613.3699\n",
      "Epoch : 1087/2000 data_batch_5,  Train_loss : 4910.6333  Test_loss : 4986.4277, Time/batch_file : 2.2604, Training time: 12615.6304\n",
      "Epoch : 1088/2000 data_batch_1,  Train_loss : 5121.3940  Test_loss : 5546.4556, Time/batch_file : 2.2965, Training time: 12617.9271\n",
      "Epoch : 1088/2000 data_batch_2,  Train_loss : 4928.8970  Test_loss : 5427.6919, Time/batch_file : 2.3213, Training time: 12620.2485\n",
      "Epoch : 1088/2000 data_batch_3,  Train_loss : 5025.5688  Test_loss : 5746.5879, Time/batch_file : 2.2885, Training time: 12622.5372\n",
      "Epoch : 1088/2000 data_batch_4,  Train_loss : 5057.9927  Test_loss : 5532.0283, Time/batch_file : 2.3080, Training time: 12624.8454\n",
      "Epoch : 1088/2000 data_batch_5,  Train_loss : 4960.8521  Test_loss : 5589.0127, Time/batch_file : 2.2827, Training time: 12627.1283\n",
      "Epoch : 1089/2000 data_batch_1,  Train_loss : 5025.6782  Test_loss : 4880.9980, Time/batch_file : 2.2706, Training time: 12629.3990\n",
      "Epoch : 1089/2000 data_batch_2,  Train_loss : 5209.2891  Test_loss : 5024.4121, Time/batch_file : 2.2856, Training time: 12631.6848\n",
      "Epoch : 1089/2000 data_batch_3,  Train_loss : 5195.0269  Test_loss : 4883.4941, Time/batch_file : 2.2987, Training time: 12633.9837\n",
      "Epoch : 1089/2000 data_batch_4,  Train_loss : 4937.2129  Test_loss : 5190.0811, Time/batch_file : 2.2669, Training time: 12636.2508\n",
      "Epoch : 1089/2000 data_batch_5,  Train_loss : 4945.2573  Test_loss : 5277.6289, Time/batch_file : 2.3095, Training time: 12638.5605\n",
      "Epoch : 1090/2000 data_batch_1,  Train_loss : 4639.9814  Test_loss : 5115.5659, Time/batch_file : 2.2919, Training time: 12640.8526\n",
      "Epoch : 1090/2000 data_batch_2,  Train_loss : 4592.6714  Test_loss : 5018.7637, Time/batch_file : 2.2631, Training time: 12643.1160\n",
      "Epoch : 1090/2000 data_batch_3,  Train_loss : 4923.8447  Test_loss : 5073.4805, Time/batch_file : 2.2861, Training time: 12645.4022\n",
      "Epoch : 1090/2000 data_batch_4,  Train_loss : 4645.7217  Test_loss : 4897.6240, Time/batch_file : 2.3021, Training time: 12647.7046\n",
      "Epoch : 1090/2000 data_batch_5,  Train_loss : 4868.3330  Test_loss : 5043.2920, Time/batch_file : 2.2732, Training time: 12649.9779\n",
      "[./nets/net-1090.ckpt] SAVED\n",
      "Epoch : 1091/2000 data_batch_1,  Train_loss : 4763.4463  Test_loss : 5197.7295, Time/batch_file : 2.3368, Training time: 12653.6012\n",
      "Epoch : 1091/2000 data_batch_2,  Train_loss : 4499.8672  Test_loss : 5060.1836, Time/batch_file : 2.2641, Training time: 12655.8656\n",
      "Epoch : 1091/2000 data_batch_3,  Train_loss : 4637.7793  Test_loss : 4812.3809, Time/batch_file : 2.3006, Training time: 12658.1665\n",
      "Epoch : 1091/2000 data_batch_4,  Train_loss : 4739.5352  Test_loss : 4876.4985, Time/batch_file : 2.2864, Training time: 12660.4531\n",
      "Epoch : 1091/2000 data_batch_5,  Train_loss : 4567.0703  Test_loss : 4578.6543, Time/batch_file : 2.2689, Training time: 12662.7222\n",
      "Epoch : 1092/2000 data_batch_1,  Train_loss : 4750.6514  Test_loss : 5579.8828, Time/batch_file : 2.3247, Training time: 12665.0471\n",
      "Epoch : 1092/2000 data_batch_2,  Train_loss : 4888.0400  Test_loss : 5576.9482, Time/batch_file : 2.2876, Training time: 12667.3349\n",
      "Epoch : 1092/2000 data_batch_3,  Train_loss : 4771.7412  Test_loss : 5493.4326, Time/batch_file : 2.3036, Training time: 12669.6387\n",
      "Epoch : 1092/2000 data_batch_4,  Train_loss : 4882.9966  Test_loss : 5685.5527, Time/batch_file : 2.2886, Training time: 12671.9276\n",
      "Epoch : 1092/2000 data_batch_5,  Train_loss : 4928.5967  Test_loss : 5766.9717, Time/batch_file : 2.3107, Training time: 12674.2385\n",
      "Epoch : 1093/2000 data_batch_1,  Train_loss : 4901.9585  Test_loss : 5175.3677, Time/batch_file : 2.2656, Training time: 12676.5042\n",
      "Epoch : 1093/2000 data_batch_2,  Train_loss : 4657.0547  Test_loss : 5386.9595, Time/batch_file : 2.2834, Training time: 12678.7879\n",
      "Epoch : 1093/2000 data_batch_3,  Train_loss : 4866.1880  Test_loss : 5174.8237, Time/batch_file : 2.2677, Training time: 12681.0557\n",
      "Epoch : 1093/2000 data_batch_4,  Train_loss : 4762.1934  Test_loss : 5409.1514, Time/batch_file : 2.3024, Training time: 12683.3583\n",
      "Epoch : 1093/2000 data_batch_5,  Train_loss : 4553.4912  Test_loss : 5066.5811, Time/batch_file : 2.2736, Training time: 12685.6321\n",
      "Epoch : 1094/2000 data_batch_1,  Train_loss : 4937.7275  Test_loss : 4542.5835, Time/batch_file : 2.3043, Training time: 12687.9366\n",
      "Epoch : 1094/2000 data_batch_2,  Train_loss : 4683.1636  Test_loss : 4514.2432, Time/batch_file : 2.2963, Training time: 12690.2330\n",
      "Epoch : 1094/2000 data_batch_3,  Train_loss : 4888.2612  Test_loss : 4637.7266, Time/batch_file : 2.2921, Training time: 12692.5252\n",
      "Epoch : 1094/2000 data_batch_4,  Train_loss : 4595.0186  Test_loss : 4684.6162, Time/batch_file : 2.2765, Training time: 12694.8019\n",
      "Epoch : 1094/2000 data_batch_5,  Train_loss : 5131.6694  Test_loss : 4905.8647, Time/batch_file : 2.3121, Training time: 12697.1143\n",
      "Epoch : 1095/2000 data_batch_1,  Train_loss : 4768.5347  Test_loss : 5090.3652, Time/batch_file : 2.2867, Training time: 12699.4012\n",
      "Epoch : 1095/2000 data_batch_2,  Train_loss : 4848.0894  Test_loss : 5332.2207, Time/batch_file : 2.3183, Training time: 12701.7198\n",
      "Epoch : 1095/2000 data_batch_3,  Train_loss : 4697.8916  Test_loss : 5259.3384, Time/batch_file : 2.2872, Training time: 12704.0073\n",
      "Epoch : 1095/2000 data_batch_4,  Train_loss : 4802.2842  Test_loss : 5044.7202, Time/batch_file : 2.3067, Training time: 12706.3142\n",
      "Epoch : 1095/2000 data_batch_5,  Train_loss : 4860.8418  Test_loss : 4921.4893, Time/batch_file : 2.2857, Training time: 12708.6001\n",
      "Epoch : 1096/2000 data_batch_1,  Train_loss : 4817.1167  Test_loss : 5290.6660, Time/batch_file : 2.2938, Training time: 12710.8941\n",
      "Epoch : 1096/2000 data_batch_2,  Train_loss : 4847.5420  Test_loss : 5516.3770, Time/batch_file : 2.2712, Training time: 12713.1655\n",
      "Epoch : 1096/2000 data_batch_3,  Train_loss : 4735.3135  Test_loss : 5182.1665, Time/batch_file : 2.3171, Training time: 12715.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1096/2000 data_batch_4,  Train_loss : 4899.7817  Test_loss : 5633.7905, Time/batch_file : 2.2695, Training time: 12717.7524\n",
      "Epoch : 1096/2000 data_batch_5,  Train_loss : 4965.6445  Test_loss : 5412.8833, Time/batch_file : 2.3031, Training time: 12720.0556\n",
      "Epoch : 1097/2000 data_batch_1,  Train_loss : 5304.6450  Test_loss : 4752.2549, Time/batch_file : 2.2747, Training time: 12722.3305\n",
      "Epoch : 1097/2000 data_batch_2,  Train_loss : 5122.6191  Test_loss : 4582.5151, Time/batch_file : 2.3024, Training time: 12724.6330\n",
      "Epoch : 1097/2000 data_batch_3,  Train_loss : 5445.1338  Test_loss : 4863.2959, Time/batch_file : 2.2957, Training time: 12726.9289\n",
      "Epoch : 1097/2000 data_batch_4,  Train_loss : 5191.7158  Test_loss : 4627.0093, Time/batch_file : 2.2860, Training time: 12729.2151\n",
      "Epoch : 1097/2000 data_batch_5,  Train_loss : 5255.0605  Test_loss : 4669.8813, Time/batch_file : 2.2629, Training time: 12731.4783\n",
      "Epoch : 1098/2000 data_batch_1,  Train_loss : 4579.4165  Test_loss : 5371.5635, Time/batch_file : 2.3065, Training time: 12733.7849\n",
      "Epoch : 1098/2000 data_batch_2,  Train_loss : 4620.2319  Test_loss : 5335.7075, Time/batch_file : 2.2658, Training time: 12736.0510\n",
      "Epoch : 1098/2000 data_batch_3,  Train_loss : 4469.1514  Test_loss : 5308.2363, Time/batch_file : 2.2968, Training time: 12738.3479\n",
      "Epoch : 1098/2000 data_batch_4,  Train_loss : 4319.1240  Test_loss : 5303.5728, Time/batch_file : 2.2890, Training time: 12740.6371\n",
      "Epoch : 1098/2000 data_batch_5,  Train_loss : 4698.6021  Test_loss : 5241.1802, Time/batch_file : 2.3040, Training time: 12742.9412\n",
      "Epoch : 1099/2000 data_batch_1,  Train_loss : 5019.2759  Test_loss : 4823.3833, Time/batch_file : 2.2873, Training time: 12745.2288\n",
      "Epoch : 1099/2000 data_batch_2,  Train_loss : 5113.5215  Test_loss : 4638.6992, Time/batch_file : 2.3746, Training time: 12747.6036\n",
      "Epoch : 1099/2000 data_batch_3,  Train_loss : 5146.4370  Test_loss : 4887.9141, Time/batch_file : 2.3040, Training time: 12749.9077\n",
      "Epoch : 1099/2000 data_batch_4,  Train_loss : 5255.8394  Test_loss : 4727.8926, Time/batch_file : 2.3726, Training time: 12752.2806\n",
      "Epoch : 1099/2000 data_batch_5,  Train_loss : 5181.3594  Test_loss : 4702.6011, Time/batch_file : 2.2919, Training time: 12754.5726\n",
      "Epoch : 1100/2000 data_batch_1,  Train_loss : 4907.9521  Test_loss : 4983.5767, Time/batch_file : 2.3439, Training time: 12756.9168\n",
      "Epoch : 1100/2000 data_batch_2,  Train_loss : 4511.1504  Test_loss : 5295.0352, Time/batch_file : 2.3451, Training time: 12759.2620\n",
      "Epoch : 1100/2000 data_batch_3,  Train_loss : 4775.8984  Test_loss : 5272.3901, Time/batch_file : 2.9351, Training time: 12762.1973\n",
      "Epoch : 1100/2000 data_batch_4,  Train_loss : 4660.9595  Test_loss : 5079.2349, Time/batch_file : 2.8888, Training time: 12765.0863\n",
      "Epoch : 1100/2000 data_batch_5,  Train_loss : 4908.9951  Test_loss : 4931.0068, Time/batch_file : 2.3310, Training time: 12767.4175\n",
      "[./nets/net-1100.ckpt] SAVED\n",
      "Epoch : 1101/2000 data_batch_1,  Train_loss : 5122.4351  Test_loss : 4836.9854, Time/batch_file : 2.5109, Training time: 12772.5855\n",
      "Epoch : 1101/2000 data_batch_2,  Train_loss : 4800.8979  Test_loss : 5037.8716, Time/batch_file : 2.7676, Training time: 12775.3533\n",
      "Epoch : 1101/2000 data_batch_3,  Train_loss : 5171.2998  Test_loss : 4759.1675, Time/batch_file : 2.5917, Training time: 12777.9452\n",
      "Epoch : 1101/2000 data_batch_4,  Train_loss : 5245.1963  Test_loss : 4853.7148, Time/batch_file : 2.4124, Training time: 12780.3579\n",
      "Epoch : 1101/2000 data_batch_5,  Train_loss : 4889.6846  Test_loss : 4779.8638, Time/batch_file : 2.7294, Training time: 12783.0875\n",
      "Epoch : 1102/2000 data_batch_1,  Train_loss : 5016.3486  Test_loss : 4774.2090, Time/batch_file : 2.9718, Training time: 12786.0596\n",
      "Epoch : 1102/2000 data_batch_2,  Train_loss : 5092.8096  Test_loss : 4978.3760, Time/batch_file : 2.3455, Training time: 12788.4053\n",
      "Epoch : 1102/2000 data_batch_3,  Train_loss : 4928.4023  Test_loss : 4833.4761, Time/batch_file : 2.4589, Training time: 12790.8645\n",
      "Epoch : 1102/2000 data_batch_4,  Train_loss : 4962.8335  Test_loss : 4592.8901, Time/batch_file : 2.2939, Training time: 12793.1586\n",
      "Epoch : 1102/2000 data_batch_5,  Train_loss : 4936.3442  Test_loss : 4952.4175, Time/batch_file : 2.3140, Training time: 12795.4729\n",
      "Epoch : 1103/2000 data_batch_1,  Train_loss : 5023.8257  Test_loss : 4890.8633, Time/batch_file : 2.2860, Training time: 12797.7591\n",
      "Epoch : 1103/2000 data_batch_2,  Train_loss : 4968.2339  Test_loss : 4992.5811, Time/batch_file : 2.2982, Training time: 12800.0575\n",
      "Epoch : 1103/2000 data_batch_3,  Train_loss : 4781.6440  Test_loss : 4962.1455, Time/batch_file : 2.2836, Training time: 12802.3412\n",
      "Epoch : 1103/2000 data_batch_4,  Train_loss : 4914.7847  Test_loss : 5049.1655, Time/batch_file : 2.3002, Training time: 12804.6416\n",
      "Epoch : 1103/2000 data_batch_5,  Train_loss : 4695.5942  Test_loss : 4972.6572, Time/batch_file : 2.2874, Training time: 12806.9292\n",
      "Epoch : 1104/2000 data_batch_1,  Train_loss : 4062.9009  Test_loss : 5120.7061, Time/batch_file : 2.3115, Training time: 12809.2409\n",
      "Epoch : 1104/2000 data_batch_2,  Train_loss : 4151.0259  Test_loss : 5149.0449, Time/batch_file : 2.2943, Training time: 12811.5354\n",
      "Epoch : 1104/2000 data_batch_3,  Train_loss : 4256.1426  Test_loss : 5000.1162, Time/batch_file : 2.3018, Training time: 12813.8374\n",
      "Epoch : 1104/2000 data_batch_4,  Train_loss : 4237.1650  Test_loss : 4918.7837, Time/batch_file : 2.2981, Training time: 12816.1357\n",
      "Epoch : 1104/2000 data_batch_5,  Train_loss : 4163.6372  Test_loss : 5114.8887, Time/batch_file : 2.2936, Training time: 12818.4296\n",
      "Epoch : 1105/2000 data_batch_1,  Train_loss : 5030.7979  Test_loss : 4803.7041, Time/batch_file : 2.2736, Training time: 12820.7033\n",
      "Epoch : 1105/2000 data_batch_2,  Train_loss : 4989.7012  Test_loss : 4917.4590, Time/batch_file : 2.2876, Training time: 12822.9911\n",
      "Epoch : 1105/2000 data_batch_3,  Train_loss : 5106.2227  Test_loss : 4748.7896, Time/batch_file : 2.2762, Training time: 12825.2676\n",
      "Epoch : 1105/2000 data_batch_4,  Train_loss : 5137.8828  Test_loss : 4916.0645, Time/batch_file : 2.2882, Training time: 12827.5560\n",
      "Epoch : 1105/2000 data_batch_5,  Train_loss : 4982.7646  Test_loss : 4761.6553, Time/batch_file : 2.2739, Training time: 12829.8302\n",
      "Epoch : 1106/2000 data_batch_1,  Train_loss : 4427.4351  Test_loss : 4678.0679, Time/batch_file : 2.2969, Training time: 12832.1273\n",
      "Epoch : 1106/2000 data_batch_2,  Train_loss : 4634.0205  Test_loss : 4657.9209, Time/batch_file : 2.2884, Training time: 12834.4158\n",
      "Epoch : 1106/2000 data_batch_3,  Train_loss : 4815.3809  Test_loss : 4932.9160, Time/batch_file : 2.3017, Training time: 12836.7179\n",
      "Epoch : 1106/2000 data_batch_4,  Train_loss : 4739.0674  Test_loss : 4887.5898, Time/batch_file : 2.2949, Training time: 12839.0130\n",
      "Epoch : 1106/2000 data_batch_5,  Train_loss : 4716.7148  Test_loss : 5094.6167, Time/batch_file : 2.3044, Training time: 12841.3176\n",
      "Epoch : 1107/2000 data_batch_1,  Train_loss : 4944.4736  Test_loss : 4658.7266, Time/batch_file : 2.2793, Training time: 12843.5972\n",
      "Epoch : 1107/2000 data_batch_2,  Train_loss : 4879.3057  Test_loss : 4775.0493, Time/batch_file : 2.2962, Training time: 12845.8936\n",
      "Epoch : 1107/2000 data_batch_3,  Train_loss : 4661.9512  Test_loss : 4869.6074, Time/batch_file : 2.2787, Training time: 12848.1726\n",
      "Epoch : 1107/2000 data_batch_4,  Train_loss : 4949.2969  Test_loss : 4623.2310, Time/batch_file : 2.2964, Training time: 12850.4691\n",
      "Epoch : 1107/2000 data_batch_5,  Train_loss : 4585.9136  Test_loss : 4916.9624, Time/batch_file : 2.2831, Training time: 12852.7525\n",
      "Epoch : 1108/2000 data_batch_1,  Train_loss : 4649.5415  Test_loss : 5063.7686, Time/batch_file : 2.2855, Training time: 12855.0381\n",
      "Epoch : 1108/2000 data_batch_2,  Train_loss : 4846.7832  Test_loss : 5368.8345, Time/batch_file : 2.2843, Training time: 12857.3226\n",
      "Epoch : 1108/2000 data_batch_3,  Train_loss : 4577.4424  Test_loss : 5045.0879, Time/batch_file : 2.2826, Training time: 12859.6053\n",
      "Epoch : 1108/2000 data_batch_4,  Train_loss : 4736.5967  Test_loss : 4970.0576, Time/batch_file : 2.2761, Training time: 12861.8816\n",
      "Epoch : 1108/2000 data_batch_5,  Train_loss : 4683.5293  Test_loss : 5283.4004, Time/batch_file : 2.2859, Training time: 12864.1677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1109/2000 data_batch_1,  Train_loss : 4902.1963  Test_loss : 4876.4487, Time/batch_file : 2.2846, Training time: 12866.4525\n",
      "Epoch : 1109/2000 data_batch_2,  Train_loss : 4619.7319  Test_loss : 4915.2441, Time/batch_file : 2.2996, Training time: 12868.7523\n",
      "Epoch : 1109/2000 data_batch_3,  Train_loss : 4615.1133  Test_loss : 5148.7515, Time/batch_file : 2.2889, Training time: 12871.0414\n",
      "Epoch : 1109/2000 data_batch_4,  Train_loss : 4529.3984  Test_loss : 4685.5488, Time/batch_file : 2.2994, Training time: 12873.3410\n",
      "Epoch : 1109/2000 data_batch_5,  Train_loss : 4613.5244  Test_loss : 4834.1772, Time/batch_file : 2.2866, Training time: 12875.6278\n",
      "Epoch : 1110/2000 data_batch_1,  Train_loss : 4589.9468  Test_loss : 5119.9048, Time/batch_file : 2.2862, Training time: 12877.9143\n",
      "Epoch : 1110/2000 data_batch_2,  Train_loss : 4825.5229  Test_loss : 5147.5591, Time/batch_file : 2.2720, Training time: 12880.1865\n",
      "Epoch : 1110/2000 data_batch_3,  Train_loss : 4795.8271  Test_loss : 5551.3750, Time/batch_file : 2.2893, Training time: 12882.4760\n",
      "Epoch : 1110/2000 data_batch_4,  Train_loss : 4695.5654  Test_loss : 5093.5649, Time/batch_file : 2.2787, Training time: 12884.7548\n",
      "Epoch : 1110/2000 data_batch_5,  Train_loss : 4842.1851  Test_loss : 4955.6533, Time/batch_file : 2.2943, Training time: 12887.0492\n",
      "[./nets/net-1110.ckpt] SAVED\n",
      "Epoch : 1111/2000 data_batch_1,  Train_loss : 5392.5474  Test_loss : 5417.3618, Time/batch_file : 2.3070, Training time: 12890.6582\n",
      "Epoch : 1111/2000 data_batch_2,  Train_loss : 5176.5269  Test_loss : 4855.3545, Time/batch_file : 2.2731, Training time: 12892.9315\n",
      "Epoch : 1111/2000 data_batch_3,  Train_loss : 5475.7227  Test_loss : 5151.1973, Time/batch_file : 2.2643, Training time: 12895.1958\n",
      "Epoch : 1111/2000 data_batch_4,  Train_loss : 4882.9355  Test_loss : 5323.8232, Time/batch_file : 2.3019, Training time: 12897.4979\n",
      "Epoch : 1111/2000 data_batch_5,  Train_loss : 4930.5024  Test_loss : 5191.6538, Time/batch_file : 2.2789, Training time: 12899.7769\n",
      "Epoch : 1112/2000 data_batch_1,  Train_loss : 4742.8594  Test_loss : 4859.4492, Time/batch_file : 2.2960, Training time: 12902.0733\n",
      "Epoch : 1112/2000 data_batch_2,  Train_loss : 4734.4966  Test_loss : 5001.9673, Time/batch_file : 2.2899, Training time: 12904.3634\n",
      "Epoch : 1112/2000 data_batch_3,  Train_loss : 4614.9683  Test_loss : 5010.0977, Time/batch_file : 2.2807, Training time: 12906.6442\n",
      "Epoch : 1112/2000 data_batch_4,  Train_loss : 4489.9219  Test_loss : 5195.4893, Time/batch_file : 2.2727, Training time: 12908.9171\n",
      "Epoch : 1112/2000 data_batch_5,  Train_loss : 4837.0396  Test_loss : 4963.6680, Time/batch_file : 2.2918, Training time: 12911.2092\n",
      "Epoch : 1113/2000 data_batch_1,  Train_loss : 5272.7939  Test_loss : 5250.1919, Time/batch_file : 2.2920, Training time: 12913.5013\n",
      "Epoch : 1113/2000 data_batch_2,  Train_loss : 5286.0630  Test_loss : 5002.7041, Time/batch_file : 2.2948, Training time: 12915.7963\n",
      "Epoch : 1113/2000 data_batch_3,  Train_loss : 5336.5195  Test_loss : 5024.4185, Time/batch_file : 2.2856, Training time: 12918.0821\n",
      "Epoch : 1113/2000 data_batch_4,  Train_loss : 5226.4746  Test_loss : 4992.7832, Time/batch_file : 2.2985, Training time: 12920.3808\n",
      "Epoch : 1113/2000 data_batch_5,  Train_loss : 5070.3306  Test_loss : 4834.1924, Time/batch_file : 2.3223, Training time: 12922.7033\n",
      "Epoch : 1114/2000 data_batch_1,  Train_loss : 5364.1558  Test_loss : 5473.1733, Time/batch_file : 2.2710, Training time: 12924.9745\n",
      "Epoch : 1114/2000 data_batch_2,  Train_loss : 5306.6182  Test_loss : 5317.2939, Time/batch_file : 2.2627, Training time: 12927.2375\n",
      "Epoch : 1114/2000 data_batch_3,  Train_loss : 5200.4443  Test_loss : 5226.6948, Time/batch_file : 2.2728, Training time: 12929.5106\n",
      "Epoch : 1114/2000 data_batch_4,  Train_loss : 5190.0996  Test_loss : 5288.9180, Time/batch_file : 2.2770, Training time: 12931.7878\n",
      "Epoch : 1114/2000 data_batch_5,  Train_loss : 5349.7109  Test_loss : 5289.2041, Time/batch_file : 2.2749, Training time: 12934.0628\n",
      "Epoch : 1115/2000 data_batch_1,  Train_loss : 4354.4067  Test_loss : 4534.4766, Time/batch_file : 2.2707, Training time: 12936.3337\n",
      "Epoch : 1115/2000 data_batch_2,  Train_loss : 4263.8506  Test_loss : 4423.8994, Time/batch_file : 2.2859, Training time: 12938.6198\n",
      "Epoch : 1115/2000 data_batch_3,  Train_loss : 4426.1528  Test_loss : 4443.3027, Time/batch_file : 2.2851, Training time: 12940.9051\n",
      "Epoch : 1115/2000 data_batch_4,  Train_loss : 4451.7671  Test_loss : 4689.8711, Time/batch_file : 2.2867, Training time: 12943.1921\n",
      "Epoch : 1115/2000 data_batch_5,  Train_loss : 4449.8184  Test_loss : 4754.6006, Time/batch_file : 2.2823, Training time: 12945.4746\n",
      "Epoch : 1116/2000 data_batch_1,  Train_loss : 4770.8467  Test_loss : 5192.0518, Time/batch_file : 2.2739, Training time: 12947.7488\n",
      "Epoch : 1116/2000 data_batch_2,  Train_loss : 4904.8330  Test_loss : 5236.0957, Time/batch_file : 2.2808, Training time: 12950.0298\n",
      "Epoch : 1116/2000 data_batch_3,  Train_loss : 4831.5059  Test_loss : 5138.5039, Time/batch_file : 2.2772, Training time: 12952.3072\n",
      "Epoch : 1116/2000 data_batch_4,  Train_loss : 4922.3872  Test_loss : 5169.2427, Time/batch_file : 2.2727, Training time: 12954.5801\n",
      "Epoch : 1116/2000 data_batch_5,  Train_loss : 4631.8516  Test_loss : 5205.5459, Time/batch_file : 2.2716, Training time: 12956.8519\n",
      "Epoch : 1117/2000 data_batch_1,  Train_loss : 4723.8247  Test_loss : 5034.0000, Time/batch_file : 2.2904, Training time: 12959.1425\n",
      "Epoch : 1117/2000 data_batch_2,  Train_loss : 4663.9414  Test_loss : 4921.3633, Time/batch_file : 2.2946, Training time: 12961.4373\n",
      "Epoch : 1117/2000 data_batch_3,  Train_loss : 4759.6323  Test_loss : 5320.2749, Time/batch_file : 2.2895, Training time: 12963.7270\n",
      "Epoch : 1117/2000 data_batch_4,  Train_loss : 5021.2363  Test_loss : 5275.6011, Time/batch_file : 2.2770, Training time: 12966.0043\n",
      "Epoch : 1117/2000 data_batch_5,  Train_loss : 4864.5244  Test_loss : 5047.7329, Time/batch_file : 2.2915, Training time: 12968.2960\n",
      "Epoch : 1118/2000 data_batch_1,  Train_loss : 4742.4131  Test_loss : 5251.2900, Time/batch_file : 2.2812, Training time: 12970.5773\n",
      "Epoch : 1118/2000 data_batch_2,  Train_loss : 5118.2930  Test_loss : 4987.4717, Time/batch_file : 2.2690, Training time: 12972.8466\n",
      "Epoch : 1118/2000 data_batch_3,  Train_loss : 5119.9507  Test_loss : 4953.3662, Time/batch_file : 2.2841, Training time: 12975.1309\n",
      "Epoch : 1118/2000 data_batch_4,  Train_loss : 5037.3896  Test_loss : 4827.7983, Time/batch_file : 2.2719, Training time: 12977.4029\n",
      "Epoch : 1118/2000 data_batch_5,  Train_loss : 5189.3926  Test_loss : 4855.1719, Time/batch_file : 2.2741, Training time: 12979.6772\n",
      "Epoch : 1119/2000 data_batch_1,  Train_loss : 4571.1846  Test_loss : 5008.4229, Time/batch_file : 2.2854, Training time: 12981.9628\n",
      "Epoch : 1119/2000 data_batch_2,  Train_loss : 4874.4082  Test_loss : 4612.3555, Time/batch_file : 2.3001, Training time: 12984.2631\n",
      "Epoch : 1119/2000 data_batch_3,  Train_loss : 4652.9639  Test_loss : 4652.6826, Time/batch_file : 2.2871, Training time: 12986.5504\n",
      "Epoch : 1119/2000 data_batch_4,  Train_loss : 4664.5293  Test_loss : 4668.1792, Time/batch_file : 2.3030, Training time: 12988.8537\n",
      "Epoch : 1119/2000 data_batch_5,  Train_loss : 4977.5581  Test_loss : 4581.0435, Time/batch_file : 2.2826, Training time: 12991.1365\n",
      "Epoch : 1120/2000 data_batch_1,  Train_loss : 4420.7993  Test_loss : 4767.5415, Time/batch_file : 2.2900, Training time: 12993.4266\n",
      "Epoch : 1120/2000 data_batch_2,  Train_loss : 4463.8994  Test_loss : 4793.3506, Time/batch_file : 2.2843, Training time: 12995.7111\n",
      "Epoch : 1120/2000 data_batch_3,  Train_loss : 4335.8936  Test_loss : 4728.6455, Time/batch_file : 2.2870, Training time: 12997.9982\n",
      "Epoch : 1120/2000 data_batch_4,  Train_loss : 4255.1821  Test_loss : 4688.7637, Time/batch_file : 2.2732, Training time: 13000.2717\n",
      "Epoch : 1120/2000 data_batch_5,  Train_loss : 4325.2344  Test_loss : 4535.6182, Time/batch_file : 2.2802, Training time: 13002.5520\n",
      "[./nets/net-1120.ckpt] SAVED\n",
      "Epoch : 1121/2000 data_batch_1,  Train_loss : 4296.3394  Test_loss : 4949.6035, Time/batch_file : 2.2800, Training time: 13006.1132\n",
      "Epoch : 1121/2000 data_batch_2,  Train_loss : 4249.4404  Test_loss : 5023.3462, Time/batch_file : 2.2940, Training time: 13008.4075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1121/2000 data_batch_3,  Train_loss : 4381.7861  Test_loss : 5062.0283, Time/batch_file : 2.2835, Training time: 13010.6912\n",
      "Epoch : 1121/2000 data_batch_4,  Train_loss : 4572.8789  Test_loss : 5233.7485, Time/batch_file : 2.2748, Training time: 13012.9663\n",
      "Epoch : 1121/2000 data_batch_5,  Train_loss : 4542.3125  Test_loss : 4989.9858, Time/batch_file : 2.3073, Training time: 13015.2737\n",
      "Epoch : 1122/2000 data_batch_1,  Train_loss : 5378.1797  Test_loss : 5283.7793, Time/batch_file : 2.2778, Training time: 13017.5518\n",
      "Epoch : 1122/2000 data_batch_2,  Train_loss : 4785.2422  Test_loss : 5629.8301, Time/batch_file : 2.3120, Training time: 13019.8641\n",
      "Epoch : 1122/2000 data_batch_3,  Train_loss : 4922.5278  Test_loss : 5006.6514, Time/batch_file : 2.2557, Training time: 13022.1200\n",
      "Epoch : 1122/2000 data_batch_4,  Train_loss : 4873.5312  Test_loss : 5379.7559, Time/batch_file : 2.2978, Training time: 13024.4180\n",
      "Epoch : 1122/2000 data_batch_5,  Train_loss : 5061.4893  Test_loss : 4971.8877, Time/batch_file : 2.2683, Training time: 13026.6965\n",
      "Epoch : 1123/2000 data_batch_1,  Train_loss : 4802.9766  Test_loss : 5182.2935, Time/batch_file : 2.2804, Training time: 13028.9771\n",
      "Epoch : 1123/2000 data_batch_2,  Train_loss : 4644.0498  Test_loss : 4995.5767, Time/batch_file : 2.2739, Training time: 13031.2512\n",
      "Epoch : 1123/2000 data_batch_3,  Train_loss : 4603.1177  Test_loss : 5077.7646, Time/batch_file : 2.2634, Training time: 13033.5149\n",
      "Epoch : 1123/2000 data_batch_4,  Train_loss : 4745.6899  Test_loss : 4782.0186, Time/batch_file : 2.2720, Training time: 13035.7871\n",
      "Epoch : 1123/2000 data_batch_5,  Train_loss : 5006.8730  Test_loss : 5061.6543, Time/batch_file : 2.2763, Training time: 13038.0637\n",
      "Epoch : 1124/2000 data_batch_1,  Train_loss : 4727.6758  Test_loss : 5367.1152, Time/batch_file : 2.2793, Training time: 13040.3432\n",
      "Epoch : 1124/2000 data_batch_2,  Train_loss : 5064.1538  Test_loss : 5514.7466, Time/batch_file : 2.2767, Training time: 13042.6201\n",
      "Epoch : 1124/2000 data_batch_3,  Train_loss : 4910.0098  Test_loss : 5519.6904, Time/batch_file : 2.2816, Training time: 13044.9018\n",
      "Epoch : 1124/2000 data_batch_4,  Train_loss : 5187.8047  Test_loss : 5344.6240, Time/batch_file : 2.2863, Training time: 13047.1883\n",
      "Epoch : 1124/2000 data_batch_5,  Train_loss : 4861.0552  Test_loss : 5280.1191, Time/batch_file : 2.2867, Training time: 13049.4752\n",
      "Epoch : 1125/2000 data_batch_1,  Train_loss : 4772.1416  Test_loss : 4411.9360, Time/batch_file : 2.2730, Training time: 13051.7485\n",
      "Epoch : 1125/2000 data_batch_2,  Train_loss : 4846.6865  Test_loss : 4531.4253, Time/batch_file : 2.2797, Training time: 13054.0283\n",
      "Epoch : 1125/2000 data_batch_3,  Train_loss : 5130.4023  Test_loss : 4436.3506, Time/batch_file : 2.2725, Training time: 13056.3009\n",
      "Epoch : 1125/2000 data_batch_4,  Train_loss : 4685.9219  Test_loss : 4433.5986, Time/batch_file : 2.2891, Training time: 13058.5902\n",
      "Epoch : 1125/2000 data_batch_5,  Train_loss : 4781.3159  Test_loss : 4786.8208, Time/batch_file : 2.2701, Training time: 13060.8606\n",
      "Epoch : 1126/2000 data_batch_1,  Train_loss : 4763.8232  Test_loss : 4964.7388, Time/batch_file : 2.2978, Training time: 13063.1586\n",
      "Epoch : 1126/2000 data_batch_2,  Train_loss : 4619.9131  Test_loss : 5211.1221, Time/batch_file : 2.2949, Training time: 13065.4538\n",
      "Epoch : 1126/2000 data_batch_3,  Train_loss : 4747.1943  Test_loss : 5339.1152, Time/batch_file : 2.2897, Training time: 13067.7437\n",
      "Epoch : 1126/2000 data_batch_4,  Train_loss : 4799.9512  Test_loss : 5229.3203, Time/batch_file : 2.2939, Training time: 13070.0377\n",
      "Epoch : 1126/2000 data_batch_5,  Train_loss : 4877.2061  Test_loss : 5327.5283, Time/batch_file : 2.2861, Training time: 13072.3240\n",
      "Epoch : 1127/2000 data_batch_1,  Train_loss : 4867.7344  Test_loss : 4415.7061, Time/batch_file : 2.2813, Training time: 13074.6055\n",
      "Epoch : 1127/2000 data_batch_2,  Train_loss : 5012.8247  Test_loss : 4753.3623, Time/batch_file : 2.2915, Training time: 13076.8972\n",
      "Epoch : 1127/2000 data_batch_3,  Train_loss : 4934.3594  Test_loss : 4855.6924, Time/batch_file : 2.2761, Training time: 13079.1736\n",
      "Epoch : 1127/2000 data_batch_4,  Train_loss : 5061.9600  Test_loss : 4774.3013, Time/batch_file : 2.2829, Training time: 13081.4567\n",
      "Epoch : 1127/2000 data_batch_5,  Train_loss : 4673.9160  Test_loss : 4609.7271, Time/batch_file : 2.2775, Training time: 13083.7344\n",
      "Epoch : 1128/2000 data_batch_1,  Train_loss : 4891.0010  Test_loss : 4862.1689, Time/batch_file : 2.2958, Training time: 13086.0304\n",
      "Epoch : 1128/2000 data_batch_2,  Train_loss : 4968.4639  Test_loss : 4802.8174, Time/batch_file : 2.2807, Training time: 13088.3114\n",
      "Epoch : 1128/2000 data_batch_3,  Train_loss : 5039.6904  Test_loss : 4882.7378, Time/batch_file : 2.2906, Training time: 13090.6022\n",
      "Epoch : 1128/2000 data_batch_4,  Train_loss : 4844.1172  Test_loss : 4932.9106, Time/batch_file : 2.2802, Training time: 13092.8825\n",
      "Epoch : 1128/2000 data_batch_5,  Train_loss : 4971.3652  Test_loss : 4984.2397, Time/batch_file : 2.3001, Training time: 13095.1828\n",
      "Epoch : 1129/2000 data_batch_1,  Train_loss : 5232.1680  Test_loss : 5448.5488, Time/batch_file : 2.2941, Training time: 13097.4771\n",
      "Epoch : 1129/2000 data_batch_2,  Train_loss : 5143.5938  Test_loss : 5398.2744, Time/batch_file : 2.2932, Training time: 13099.7705\n",
      "Epoch : 1129/2000 data_batch_3,  Train_loss : 5042.5190  Test_loss : 5619.4688, Time/batch_file : 2.2931, Training time: 13102.0637\n",
      "Epoch : 1129/2000 data_batch_4,  Train_loss : 5061.8076  Test_loss : 5339.0859, Time/batch_file : 2.2977, Training time: 13104.3616\n",
      "Epoch : 1129/2000 data_batch_5,  Train_loss : 5143.9111  Test_loss : 5564.2871, Time/batch_file : 2.2885, Training time: 13106.6504\n",
      "Epoch : 1130/2000 data_batch_1,  Train_loss : 4677.0176  Test_loss : 5082.5835, Time/batch_file : 2.2757, Training time: 13108.9262\n",
      "Epoch : 1130/2000 data_batch_2,  Train_loss : 4806.1621  Test_loss : 5262.9307, Time/batch_file : 2.2852, Training time: 13111.2115\n",
      "Epoch : 1130/2000 data_batch_3,  Train_loss : 4780.7964  Test_loss : 4775.4170, Time/batch_file : 2.2914, Training time: 13113.5032\n",
      "Epoch : 1130/2000 data_batch_4,  Train_loss : 4695.7676  Test_loss : 4846.6377, Time/batch_file : 2.2839, Training time: 13115.7872\n",
      "Epoch : 1130/2000 data_batch_5,  Train_loss : 4473.4941  Test_loss : 4827.0386, Time/batch_file : 2.2832, Training time: 13118.0707\n",
      "[./nets/net-1130.ckpt] SAVED\n",
      "Epoch : 1131/2000 data_batch_1,  Train_loss : 4674.7520  Test_loss : 4767.0083, Time/batch_file : 2.4401, Training time: 13121.8162\n",
      "Epoch : 1131/2000 data_batch_2,  Train_loss : 4709.7495  Test_loss : 4677.2900, Time/batch_file : 2.2733, Training time: 13124.0897\n",
      "Epoch : 1131/2000 data_batch_3,  Train_loss : 4694.0288  Test_loss : 4778.8003, Time/batch_file : 2.2632, Training time: 13126.3531\n",
      "Epoch : 1131/2000 data_batch_4,  Train_loss : 4779.1753  Test_loss : 4998.4141, Time/batch_file : 2.2685, Training time: 13128.6218\n",
      "Epoch : 1131/2000 data_batch_5,  Train_loss : 4802.8545  Test_loss : 4757.5581, Time/batch_file : 2.2594, Training time: 13130.8813\n",
      "Epoch : 1132/2000 data_batch_1,  Train_loss : 4528.2969  Test_loss : 4592.0693, Time/batch_file : 2.2810, Training time: 13133.1625\n",
      "Epoch : 1132/2000 data_batch_2,  Train_loss : 4597.5659  Test_loss : 4739.2910, Time/batch_file : 2.2748, Training time: 13135.4375\n",
      "Epoch : 1132/2000 data_batch_3,  Train_loss : 4511.6855  Test_loss : 4729.8979, Time/batch_file : 2.3062, Training time: 13137.7439\n",
      "Epoch : 1132/2000 data_batch_4,  Train_loss : 4611.9907  Test_loss : 4571.8809, Time/batch_file : 2.2804, Training time: 13140.0245\n",
      "Epoch : 1132/2000 data_batch_5,  Train_loss : 4393.0415  Test_loss : 5134.2734, Time/batch_file : 2.3100, Training time: 13142.3347\n",
      "Epoch : 1133/2000 data_batch_1,  Train_loss : 4894.2217  Test_loss : 5703.3037, Time/batch_file : 2.2756, Training time: 13144.6105\n",
      "Epoch : 1133/2000 data_batch_2,  Train_loss : 4881.9771  Test_loss : 5695.5684, Time/batch_file : 2.3006, Training time: 13146.9113\n",
      "Epoch : 1133/2000 data_batch_3,  Train_loss : 4745.5806  Test_loss : 5613.1299, Time/batch_file : 2.2729, Training time: 13149.1845\n",
      "Epoch : 1133/2000 data_batch_4,  Train_loss : 4750.5020  Test_loss : 5728.4355, Time/batch_file : 2.2926, Training time: 13151.4773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1133/2000 data_batch_5,  Train_loss : 4871.5459  Test_loss : 5613.6167, Time/batch_file : 2.2712, Training time: 13153.7487\n",
      "Epoch : 1134/2000 data_batch_1,  Train_loss : 4409.0747  Test_loss : 5000.9287, Time/batch_file : 2.3042, Training time: 13156.0533\n",
      "Epoch : 1134/2000 data_batch_2,  Train_loss : 4276.0444  Test_loss : 4776.0186, Time/batch_file : 2.2799, Training time: 13158.3334\n",
      "Epoch : 1134/2000 data_batch_3,  Train_loss : 4276.6460  Test_loss : 5434.7681, Time/batch_file : 2.2938, Training time: 13160.6274\n",
      "Epoch : 1134/2000 data_batch_4,  Train_loss : 4544.6084  Test_loss : 5043.3887, Time/batch_file : 2.2683, Training time: 13162.8959\n",
      "Epoch : 1134/2000 data_batch_5,  Train_loss : 4433.0293  Test_loss : 5079.4751, Time/batch_file : 2.3008, Training time: 13165.1969\n",
      "Epoch : 1135/2000 data_batch_1,  Train_loss : 4590.4277  Test_loss : 4852.6387, Time/batch_file : 2.2781, Training time: 13167.4753\n",
      "Epoch : 1135/2000 data_batch_2,  Train_loss : 4540.5122  Test_loss : 5002.1211, Time/batch_file : 2.2819, Training time: 13169.7574\n",
      "Epoch : 1135/2000 data_batch_3,  Train_loss : 4524.8184  Test_loss : 4891.9844, Time/batch_file : 2.2590, Training time: 13172.0166\n",
      "Epoch : 1135/2000 data_batch_4,  Train_loss : 4259.2612  Test_loss : 4913.0498, Time/batch_file : 2.2752, Training time: 13174.2919\n",
      "Epoch : 1135/2000 data_batch_5,  Train_loss : 4581.1304  Test_loss : 5180.3232, Time/batch_file : 2.2697, Training time: 13176.5618\n",
      "Epoch : 1136/2000 data_batch_1,  Train_loss : 4898.2427  Test_loss : 4851.2373, Time/batch_file : 2.2671, Training time: 13178.8292\n",
      "Epoch : 1136/2000 data_batch_2,  Train_loss : 5310.4419  Test_loss : 4732.2803, Time/batch_file : 2.2623, Training time: 13181.0916\n",
      "Epoch : 1136/2000 data_batch_3,  Train_loss : 5228.4082  Test_loss : 4756.2295, Time/batch_file : 2.2979, Training time: 13183.3897\n",
      "Epoch : 1136/2000 data_batch_4,  Train_loss : 5039.7803  Test_loss : 4668.2676, Time/batch_file : 2.2632, Training time: 13185.6531\n",
      "Epoch : 1136/2000 data_batch_5,  Train_loss : 4966.1084  Test_loss : 4634.3770, Time/batch_file : 2.2874, Training time: 13187.9408\n",
      "Epoch : 1137/2000 data_batch_1,  Train_loss : 5121.7480  Test_loss : 5049.8228, Time/batch_file : 2.2735, Training time: 13190.2145\n",
      "Epoch : 1137/2000 data_batch_2,  Train_loss : 4889.7666  Test_loss : 5234.8271, Time/batch_file : 2.3077, Training time: 13192.5224\n",
      "Epoch : 1137/2000 data_batch_3,  Train_loss : 4930.6294  Test_loss : 5174.4434, Time/batch_file : 2.2855, Training time: 13194.8081\n",
      "Epoch : 1137/2000 data_batch_4,  Train_loss : 4994.1001  Test_loss : 5012.4507, Time/batch_file : 2.2970, Training time: 13197.1054\n",
      "Epoch : 1137/2000 data_batch_5,  Train_loss : 4783.6113  Test_loss : 5347.2935, Time/batch_file : 2.2881, Training time: 13199.3937\n",
      "Epoch : 1138/2000 data_batch_1,  Train_loss : 5066.9614  Test_loss : 4835.7080, Time/batch_file : 2.2978, Training time: 13201.6917\n",
      "Epoch : 1138/2000 data_batch_2,  Train_loss : 5188.3584  Test_loss : 4773.5171, Time/batch_file : 2.2945, Training time: 13203.9864\n",
      "Epoch : 1138/2000 data_batch_3,  Train_loss : 5434.5146  Test_loss : 4930.7407, Time/batch_file : 2.2894, Training time: 13206.2760\n",
      "Epoch : 1138/2000 data_batch_4,  Train_loss : 5375.7935  Test_loss : 4831.4805, Time/batch_file : 2.2740, Training time: 13208.5502\n",
      "Epoch : 1138/2000 data_batch_5,  Train_loss : 5144.3081  Test_loss : 5086.4468, Time/batch_file : 2.2876, Training time: 13210.8380\n",
      "Epoch : 1139/2000 data_batch_1,  Train_loss : 4681.4653  Test_loss : 4530.8657, Time/batch_file : 2.2594, Training time: 13213.0976\n",
      "Epoch : 1139/2000 data_batch_2,  Train_loss : 4732.2422  Test_loss : 4801.2568, Time/batch_file : 2.2630, Training time: 13215.3608\n",
      "Epoch : 1139/2000 data_batch_3,  Train_loss : 4603.3105  Test_loss : 5079.8447, Time/batch_file : 2.2473, Training time: 13217.6084\n",
      "Epoch : 1139/2000 data_batch_4,  Train_loss : 4527.9126  Test_loss : 4686.7471, Time/batch_file : 2.3134, Training time: 13219.9220\n",
      "Epoch : 1139/2000 data_batch_5,  Train_loss : 4949.9365  Test_loss : 4652.3325, Time/batch_file : 2.2560, Training time: 13222.1782\n",
      "Epoch : 1140/2000 data_batch_1,  Train_loss : 4888.0576  Test_loss : 5172.5557, Time/batch_file : 2.2832, Training time: 13224.4616\n",
      "Epoch : 1140/2000 data_batch_2,  Train_loss : 4964.3032  Test_loss : 4801.4175, Time/batch_file : 2.2589, Training time: 13226.7207\n",
      "Epoch : 1140/2000 data_batch_3,  Train_loss : 4896.7490  Test_loss : 4787.3564, Time/batch_file : 2.3060, Training time: 13229.0269\n",
      "Epoch : 1140/2000 data_batch_4,  Train_loss : 4994.9648  Test_loss : 4978.7236, Time/batch_file : 2.2637, Training time: 13231.2908\n",
      "Epoch : 1140/2000 data_batch_5,  Train_loss : 5213.9883  Test_loss : 4944.0923, Time/batch_file : 2.2805, Training time: 13233.5714\n",
      "[./nets/net-1140.ckpt] SAVED\n",
      "Epoch : 1141/2000 data_batch_1,  Train_loss : 4747.6382  Test_loss : 5294.8247, Time/batch_file : 2.3229, Training time: 13237.1684\n",
      "Epoch : 1141/2000 data_batch_2,  Train_loss : 4716.4443  Test_loss : 5007.3115, Time/batch_file : 2.3196, Training time: 13239.4881\n",
      "Epoch : 1141/2000 data_batch_3,  Train_loss : 4845.9771  Test_loss : 5379.8740, Time/batch_file : 2.2928, Training time: 13241.7810\n",
      "Epoch : 1141/2000 data_batch_4,  Train_loss : 4380.1558  Test_loss : 4977.3037, Time/batch_file : 2.3132, Training time: 13244.0944\n",
      "Epoch : 1141/2000 data_batch_5,  Train_loss : 4532.2910  Test_loss : 5223.1260, Time/batch_file : 2.2835, Training time: 13246.3782\n",
      "Epoch : 1142/2000 data_batch_1,  Train_loss : 4880.3164  Test_loss : 5276.8770, Time/batch_file : 2.2791, Training time: 13248.6575\n",
      "Epoch : 1142/2000 data_batch_2,  Train_loss : 4766.4814  Test_loss : 5206.6689, Time/batch_file : 2.2756, Training time: 13250.9333\n",
      "Epoch : 1142/2000 data_batch_3,  Train_loss : 4500.1978  Test_loss : 5287.6396, Time/batch_file : 2.2747, Training time: 13253.2083\n",
      "Epoch : 1142/2000 data_batch_4,  Train_loss : 4781.8823  Test_loss : 5282.3086, Time/batch_file : 2.2650, Training time: 13255.4735\n",
      "Epoch : 1142/2000 data_batch_5,  Train_loss : 4775.2236  Test_loss : 5039.2495, Time/batch_file : 2.3077, Training time: 13257.7813\n",
      "Epoch : 1143/2000 data_batch_1,  Train_loss : 5188.9697  Test_loss : 5327.6650, Time/batch_file : 2.2775, Training time: 13260.0591\n",
      "Epoch : 1143/2000 data_batch_2,  Train_loss : 5490.5010  Test_loss : 5578.2080, Time/batch_file : 2.2713, Training time: 13262.3305\n",
      "Epoch : 1143/2000 data_batch_3,  Train_loss : 5513.7900  Test_loss : 5367.6182, Time/batch_file : 2.2809, Training time: 13264.6115\n",
      "Epoch : 1143/2000 data_batch_4,  Train_loss : 5227.5527  Test_loss : 5484.7393, Time/batch_file : 2.2744, Training time: 13266.8862\n",
      "Epoch : 1143/2000 data_batch_5,  Train_loss : 5232.7881  Test_loss : 5725.5122, Time/batch_file : 2.2682, Training time: 13269.1545\n",
      "Epoch : 1144/2000 data_batch_1,  Train_loss : 4711.3101  Test_loss : 5809.2451, Time/batch_file : 2.2594, Training time: 13271.4141\n",
      "Epoch : 1144/2000 data_batch_2,  Train_loss : 4850.9829  Test_loss : 5760.5527, Time/batch_file : 2.2717, Training time: 13273.6860\n",
      "Epoch : 1144/2000 data_batch_3,  Train_loss : 4438.8950  Test_loss : 6036.0264, Time/batch_file : 2.2693, Training time: 13275.9555\n",
      "Epoch : 1144/2000 data_batch_4,  Train_loss : 4450.9043  Test_loss : 5666.9175, Time/batch_file : 2.2627, Training time: 13278.2183\n",
      "Epoch : 1144/2000 data_batch_5,  Train_loss : 4574.7476  Test_loss : 5804.4678, Time/batch_file : 2.2729, Training time: 13280.4914\n",
      "Epoch : 1145/2000 data_batch_1,  Train_loss : 4906.6670  Test_loss : 4798.7217, Time/batch_file : 2.2762, Training time: 13282.7679\n",
      "Epoch : 1145/2000 data_batch_2,  Train_loss : 4606.5215  Test_loss : 4705.9014, Time/batch_file : 2.2850, Training time: 13285.0531\n",
      "Epoch : 1145/2000 data_batch_3,  Train_loss : 5188.0679  Test_loss : 4372.7720, Time/batch_file : 2.2780, Training time: 13287.3312\n",
      "Epoch : 1145/2000 data_batch_4,  Train_loss : 5066.4844  Test_loss : 4727.4775, Time/batch_file : 2.2915, Training time: 13289.6229\n",
      "Epoch : 1145/2000 data_batch_5,  Train_loss : 4883.4160  Test_loss : 4981.6167, Time/batch_file : 2.2838, Training time: 13291.9070\n",
      "Epoch : 1146/2000 data_batch_1,  Train_loss : 5073.8701  Test_loss : 5353.3936, Time/batch_file : 2.2713, Training time: 13294.1786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1146/2000 data_batch_2,  Train_loss : 5155.9819  Test_loss : 5200.4849, Time/batch_file : 2.2580, Training time: 13296.4368\n",
      "Epoch : 1146/2000 data_batch_3,  Train_loss : 5080.9839  Test_loss : 5224.2373, Time/batch_file : 2.2731, Training time: 13298.7102\n",
      "Epoch : 1146/2000 data_batch_4,  Train_loss : 5034.6641  Test_loss : 5336.8267, Time/batch_file : 2.2594, Training time: 13300.9698\n",
      "Epoch : 1146/2000 data_batch_5,  Train_loss : 5073.2715  Test_loss : 5100.8584, Time/batch_file : 2.2730, Training time: 13303.2429\n",
      "Epoch : 1147/2000 data_batch_1,  Train_loss : 4520.6318  Test_loss : 4566.8345, Time/batch_file : 2.2704, Training time: 13305.5136\n",
      "Epoch : 1147/2000 data_batch_2,  Train_loss : 4569.5830  Test_loss : 4747.0830, Time/batch_file : 2.2660, Training time: 13307.7799\n",
      "Epoch : 1147/2000 data_batch_3,  Train_loss : 4502.4302  Test_loss : 4940.4360, Time/batch_file : 2.2598, Training time: 13310.0399\n",
      "Epoch : 1147/2000 data_batch_4,  Train_loss : 4395.3916  Test_loss : 4767.6514, Time/batch_file : 2.2696, Training time: 13312.3096\n",
      "Epoch : 1147/2000 data_batch_5,  Train_loss : 4495.1641  Test_loss : 4892.9736, Time/batch_file : 2.2618, Training time: 13314.5716\n",
      "Epoch : 1148/2000 data_batch_1,  Train_loss : 4910.0557  Test_loss : 5044.7236, Time/batch_file : 2.2759, Training time: 13316.8478\n",
      "Epoch : 1148/2000 data_batch_2,  Train_loss : 5211.5117  Test_loss : 5038.2505, Time/batch_file : 2.2692, Training time: 13319.1172\n",
      "Epoch : 1148/2000 data_batch_3,  Train_loss : 5377.5200  Test_loss : 4815.9482, Time/batch_file : 2.2680, Training time: 13321.3854\n",
      "Epoch : 1148/2000 data_batch_4,  Train_loss : 5245.2876  Test_loss : 4861.8320, Time/batch_file : 2.2618, Training time: 13323.6474\n",
      "Epoch : 1148/2000 data_batch_5,  Train_loss : 5147.5020  Test_loss : 5000.6187, Time/batch_file : 2.2676, Training time: 13325.9151\n",
      "Epoch : 1149/2000 data_batch_1,  Train_loss : 4864.1030  Test_loss : 4881.9492, Time/batch_file : 2.2685, Training time: 13328.1838\n",
      "Epoch : 1149/2000 data_batch_2,  Train_loss : 4552.0171  Test_loss : 5279.0752, Time/batch_file : 2.2830, Training time: 13330.4670\n",
      "Epoch : 1149/2000 data_batch_3,  Train_loss : 4944.9302  Test_loss : 4882.4233, Time/batch_file : 2.2732, Training time: 13332.7405\n",
      "Epoch : 1149/2000 data_batch_4,  Train_loss : 4783.6372  Test_loss : 5422.7705, Time/batch_file : 2.2829, Training time: 13335.0236\n",
      "Epoch : 1149/2000 data_batch_5,  Train_loss : 4814.4385  Test_loss : 5025.8623, Time/batch_file : 2.2691, Training time: 13337.2930\n",
      "Epoch : 1150/2000 data_batch_1,  Train_loss : 4305.0913  Test_loss : 5424.6572, Time/batch_file : 2.2748, Training time: 13339.5681\n",
      "Epoch : 1150/2000 data_batch_2,  Train_loss : 4431.1802  Test_loss : 5241.0864, Time/batch_file : 2.2673, Training time: 13341.8355\n",
      "Epoch : 1150/2000 data_batch_3,  Train_loss : 4274.0601  Test_loss : 5211.0029, Time/batch_file : 2.2774, Training time: 13344.1131\n",
      "Epoch : 1150/2000 data_batch_4,  Train_loss : 4120.0942  Test_loss : 5294.1333, Time/batch_file : 2.2623, Training time: 13346.3756\n",
      "Epoch : 1150/2000 data_batch_5,  Train_loss : 4221.3447  Test_loss : 5281.2803, Time/batch_file : 2.2721, Training time: 13348.6479\n",
      "[./nets/net-1150.ckpt] SAVED\n",
      "Epoch : 1151/2000 data_batch_1,  Train_loss : 4523.7192  Test_loss : 4988.4775, Time/batch_file : 2.2957, Training time: 13352.2375\n",
      "Epoch : 1151/2000 data_batch_2,  Train_loss : 4523.6294  Test_loss : 4743.5752, Time/batch_file : 2.2890, Training time: 13354.5267\n",
      "Epoch : 1151/2000 data_batch_3,  Train_loss : 4466.0024  Test_loss : 4745.1768, Time/batch_file : 2.2594, Training time: 13356.7863\n",
      "Epoch : 1151/2000 data_batch_4,  Train_loss : 4740.3745  Test_loss : 4772.0298, Time/batch_file : 2.2836, Training time: 13359.0702\n",
      "Epoch : 1151/2000 data_batch_5,  Train_loss : 4329.9312  Test_loss : 4725.4932, Time/batch_file : 2.2830, Training time: 13361.3535\n",
      "Epoch : 1152/2000 data_batch_1,  Train_loss : 4658.2334  Test_loss : 5055.8271, Time/batch_file : 2.2863, Training time: 13363.6400\n",
      "Epoch : 1152/2000 data_batch_2,  Train_loss : 4932.6216  Test_loss : 5071.0142, Time/batch_file : 2.2882, Training time: 13365.9284\n",
      "Epoch : 1152/2000 data_batch_3,  Train_loss : 4468.8413  Test_loss : 5080.0620, Time/batch_file : 2.2786, Training time: 13368.2072\n",
      "Epoch : 1152/2000 data_batch_4,  Train_loss : 4744.5967  Test_loss : 4785.5752, Time/batch_file : 2.2770, Training time: 13370.4844\n",
      "Epoch : 1152/2000 data_batch_5,  Train_loss : 4721.9302  Test_loss : 5036.5864, Time/batch_file : 2.3149, Training time: 13372.7996\n",
      "Epoch : 1153/2000 data_batch_1,  Train_loss : 4861.2803  Test_loss : 5131.2773, Time/batch_file : 2.2668, Training time: 13375.0666\n",
      "Epoch : 1153/2000 data_batch_2,  Train_loss : 5193.5049  Test_loss : 5153.8574, Time/batch_file : 2.3193, Training time: 13377.3862\n",
      "Epoch : 1153/2000 data_batch_3,  Train_loss : 5022.5518  Test_loss : 4794.8813, Time/batch_file : 2.3169, Training time: 13379.7034\n",
      "Epoch : 1153/2000 data_batch_4,  Train_loss : 4952.6787  Test_loss : 5175.5591, Time/batch_file : 2.2922, Training time: 13381.9957\n",
      "Epoch : 1153/2000 data_batch_5,  Train_loss : 4903.2334  Test_loss : 5361.4951, Time/batch_file : 2.2915, Training time: 13384.2874\n",
      "Epoch : 1154/2000 data_batch_1,  Train_loss : 4946.9385  Test_loss : 5126.6226, Time/batch_file : 2.3080, Training time: 13386.5956\n",
      "Epoch : 1154/2000 data_batch_2,  Train_loss : 5230.1294  Test_loss : 5129.6323, Time/batch_file : 2.2742, Training time: 13388.8699\n",
      "Epoch : 1154/2000 data_batch_3,  Train_loss : 5158.6875  Test_loss : 5037.6421, Time/batch_file : 2.3003, Training time: 13391.1705\n",
      "Epoch : 1154/2000 data_batch_4,  Train_loss : 5023.7617  Test_loss : 5038.9980, Time/batch_file : 2.2753, Training time: 13393.4460\n",
      "Epoch : 1154/2000 data_batch_5,  Train_loss : 5217.0220  Test_loss : 4756.7236, Time/batch_file : 2.2806, Training time: 13395.7269\n",
      "Epoch : 1155/2000 data_batch_1,  Train_loss : 5032.1445  Test_loss : 4914.0210, Time/batch_file : 2.3061, Training time: 13398.0332\n",
      "Epoch : 1155/2000 data_batch_2,  Train_loss : 4896.7666  Test_loss : 5136.9873, Time/batch_file : 2.2741, Training time: 13400.3075\n",
      "Epoch : 1155/2000 data_batch_3,  Train_loss : 5219.7031  Test_loss : 4931.1245, Time/batch_file : 2.2910, Training time: 13402.5985\n",
      "Epoch : 1155/2000 data_batch_4,  Train_loss : 5020.7129  Test_loss : 5134.4980, Time/batch_file : 2.2827, Training time: 13404.8814\n",
      "Epoch : 1155/2000 data_batch_5,  Train_loss : 4898.0352  Test_loss : 5030.3145, Time/batch_file : 2.3063, Training time: 13407.1879\n",
      "Epoch : 1156/2000 data_batch_1,  Train_loss : 5030.0571  Test_loss : 5396.8911, Time/batch_file : 2.2726, Training time: 13409.4607\n",
      "Epoch : 1156/2000 data_batch_2,  Train_loss : 5071.7021  Test_loss : 5612.3916, Time/batch_file : 2.3055, Training time: 13411.7663\n",
      "Epoch : 1156/2000 data_batch_3,  Train_loss : 5050.2910  Test_loss : 5423.2334, Time/batch_file : 2.2970, Training time: 13414.0635\n",
      "Epoch : 1156/2000 data_batch_4,  Train_loss : 4958.3428  Test_loss : 5432.5664, Time/batch_file : 2.2967, Training time: 13416.3605\n",
      "Epoch : 1156/2000 data_batch_5,  Train_loss : 5052.8555  Test_loss : 5565.7866, Time/batch_file : 2.2974, Training time: 13418.6580\n",
      "Epoch : 1157/2000 data_batch_1,  Train_loss : 4646.3965  Test_loss : 5070.8594, Time/batch_file : 2.2777, Training time: 13420.9359\n",
      "Epoch : 1157/2000 data_batch_2,  Train_loss : 4499.3667  Test_loss : 5266.6338, Time/batch_file : 2.2675, Training time: 13423.2036\n",
      "Epoch : 1157/2000 data_batch_3,  Train_loss : 4435.0723  Test_loss : 5312.8140, Time/batch_file : 2.2816, Training time: 13425.4854\n",
      "Epoch : 1157/2000 data_batch_4,  Train_loss : 4461.6172  Test_loss : 5215.2148, Time/batch_file : 2.2865, Training time: 13427.7721\n",
      "Epoch : 1157/2000 data_batch_5,  Train_loss : 4534.1543  Test_loss : 5444.2778, Time/batch_file : 2.2923, Training time: 13430.0645\n",
      "Epoch : 1158/2000 data_batch_1,  Train_loss : 4857.1807  Test_loss : 5880.1865, Time/batch_file : 2.3015, Training time: 13432.3663\n",
      "Epoch : 1158/2000 data_batch_2,  Train_loss : 4843.3608  Test_loss : 5947.3491, Time/batch_file : 2.3149, Training time: 13434.6815\n",
      "Epoch : 1158/2000 data_batch_3,  Train_loss : 4727.1440  Test_loss : 5828.5391, Time/batch_file : 2.3035, Training time: 13436.9852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1158/2000 data_batch_4,  Train_loss : 4842.7148  Test_loss : 5479.8955, Time/batch_file : 2.3105, Training time: 13439.2959\n",
      "Epoch : 1158/2000 data_batch_5,  Train_loss : 4566.7280  Test_loss : 5690.4932, Time/batch_file : 2.2946, Training time: 13441.5907\n",
      "Epoch : 1159/2000 data_batch_1,  Train_loss : 5067.3818  Test_loss : 4501.2358, Time/batch_file : 2.2886, Training time: 13443.8795\n",
      "Epoch : 1159/2000 data_batch_2,  Train_loss : 4969.7803  Test_loss : 4602.3101, Time/batch_file : 2.2928, Training time: 13446.1724\n",
      "Epoch : 1159/2000 data_batch_3,  Train_loss : 5095.5557  Test_loss : 4596.5889, Time/batch_file : 2.3079, Training time: 13448.4805\n",
      "Epoch : 1159/2000 data_batch_4,  Train_loss : 4758.6504  Test_loss : 4657.1328, Time/batch_file : 2.3082, Training time: 13450.7892\n",
      "Epoch : 1159/2000 data_batch_5,  Train_loss : 4986.4146  Test_loss : 4765.5098, Time/batch_file : 2.2972, Training time: 13453.0867\n",
      "Epoch : 1160/2000 data_batch_1,  Train_loss : 4780.5869  Test_loss : 5152.8916, Time/batch_file : 2.2802, Training time: 13455.3671\n",
      "Epoch : 1160/2000 data_batch_2,  Train_loss : 4881.0049  Test_loss : 5507.3667, Time/batch_file : 2.2997, Training time: 13457.6670\n",
      "Epoch : 1160/2000 data_batch_3,  Train_loss : 4698.5967  Test_loss : 5272.1855, Time/batch_file : 2.2769, Training time: 13459.9441\n",
      "Epoch : 1160/2000 data_batch_4,  Train_loss : 4632.7617  Test_loss : 5547.6250, Time/batch_file : 2.3012, Training time: 13462.2454\n",
      "Epoch : 1160/2000 data_batch_5,  Train_loss : 4809.0596  Test_loss : 5211.1387, Time/batch_file : 2.2804, Training time: 13464.5261\n",
      "[./nets/net-1160.ckpt] SAVED\n",
      "Epoch : 1161/2000 data_batch_1,  Train_loss : 4784.4956  Test_loss : 4542.4824, Time/batch_file : 2.2991, Training time: 13468.0966\n",
      "Epoch : 1161/2000 data_batch_2,  Train_loss : 4850.2319  Test_loss : 4840.1909, Time/batch_file : 2.3037, Training time: 13470.4005\n",
      "Epoch : 1161/2000 data_batch_3,  Train_loss : 4885.8857  Test_loss : 4601.5703, Time/batch_file : 2.2618, Training time: 13472.6625\n",
      "Epoch : 1161/2000 data_batch_4,  Train_loss : 4752.3052  Test_loss : 4870.0059, Time/batch_file : 2.2975, Training time: 13474.9603\n",
      "Epoch : 1161/2000 data_batch_5,  Train_loss : 4632.7808  Test_loss : 4692.5396, Time/batch_file : 2.3087, Training time: 13477.2691\n",
      "Epoch : 1162/2000 data_batch_1,  Train_loss : 5000.2222  Test_loss : 5311.0088, Time/batch_file : 2.2547, Training time: 13479.5240\n",
      "Epoch : 1162/2000 data_batch_2,  Train_loss : 5123.9839  Test_loss : 5411.7900, Time/batch_file : 2.2778, Training time: 13481.8019\n",
      "Epoch : 1162/2000 data_batch_3,  Train_loss : 5492.9531  Test_loss : 5327.1865, Time/batch_file : 2.2844, Training time: 13484.0865\n",
      "Epoch : 1162/2000 data_batch_4,  Train_loss : 5226.6572  Test_loss : 5385.0312, Time/batch_file : 2.2767, Training time: 13486.3634\n",
      "Epoch : 1162/2000 data_batch_5,  Train_loss : 5238.7725  Test_loss : 5372.2056, Time/batch_file : 2.2870, Training time: 13488.6506\n",
      "Epoch : 1163/2000 data_batch_1,  Train_loss : 4351.6035  Test_loss : 4859.6592, Time/batch_file : 2.2674, Training time: 13490.9182\n",
      "Epoch : 1163/2000 data_batch_2,  Train_loss : 4511.9648  Test_loss : 5117.3672, Time/batch_file : 2.2638, Training time: 13493.1823\n",
      "Epoch : 1163/2000 data_batch_3,  Train_loss : 4697.7490  Test_loss : 5256.6777, Time/batch_file : 2.2889, Training time: 13495.4714\n",
      "Epoch : 1163/2000 data_batch_4,  Train_loss : 4772.8789  Test_loss : 5015.0825, Time/batch_file : 2.3114, Training time: 13497.7830\n",
      "Epoch : 1163/2000 data_batch_5,  Train_loss : 4349.6587  Test_loss : 5394.8521, Time/batch_file : 2.2672, Training time: 13500.0504\n",
      "Epoch : 1164/2000 data_batch_1,  Train_loss : 4238.1367  Test_loss : 5278.7534, Time/batch_file : 2.2745, Training time: 13502.3251\n",
      "Epoch : 1164/2000 data_batch_2,  Train_loss : 4311.6299  Test_loss : 5162.3413, Time/batch_file : 2.2718, Training time: 13504.5972\n",
      "Epoch : 1164/2000 data_batch_3,  Train_loss : 4321.0488  Test_loss : 5264.3003, Time/batch_file : 2.2683, Training time: 13506.8656\n",
      "Epoch : 1164/2000 data_batch_4,  Train_loss : 4250.1616  Test_loss : 5481.4111, Time/batch_file : 2.3036, Training time: 13509.1694\n",
      "Epoch : 1164/2000 data_batch_5,  Train_loss : 4133.4834  Test_loss : 5129.2886, Time/batch_file : 2.2834, Training time: 13511.4529\n",
      "Epoch : 1165/2000 data_batch_1,  Train_loss : 5317.1758  Test_loss : 4789.2803, Time/batch_file : 2.2617, Training time: 13513.7148\n",
      "Epoch : 1165/2000 data_batch_2,  Train_loss : 5236.3911  Test_loss : 4807.1802, Time/batch_file : 2.2593, Training time: 13515.9743\n",
      "Epoch : 1165/2000 data_batch_3,  Train_loss : 5017.3491  Test_loss : 4842.1489, Time/batch_file : 2.2750, Training time: 13518.2496\n",
      "Epoch : 1165/2000 data_batch_4,  Train_loss : 5025.8018  Test_loss : 4966.2856, Time/batch_file : 2.2899, Training time: 13520.5399\n",
      "Epoch : 1165/2000 data_batch_5,  Train_loss : 5060.9224  Test_loss : 5128.7549, Time/batch_file : 2.2702, Training time: 13522.8103\n",
      "Epoch : 1166/2000 data_batch_1,  Train_loss : 4675.7856  Test_loss : 4847.7563, Time/batch_file : 2.2719, Training time: 13525.0824\n",
      "Epoch : 1166/2000 data_batch_2,  Train_loss : 4918.3584  Test_loss : 4694.9199, Time/batch_file : 2.2708, Training time: 13527.3534\n",
      "Epoch : 1166/2000 data_batch_3,  Train_loss : 4978.8008  Test_loss : 4836.9512, Time/batch_file : 2.2753, Training time: 13529.6289\n",
      "Epoch : 1166/2000 data_batch_4,  Train_loss : 4820.5620  Test_loss : 4646.0859, Time/batch_file : 2.2689, Training time: 13531.8980\n",
      "Epoch : 1166/2000 data_batch_5,  Train_loss : 4841.1719  Test_loss : 4718.4922, Time/batch_file : 2.2734, Training time: 13534.1717\n",
      "Epoch : 1167/2000 data_batch_1,  Train_loss : 5016.7539  Test_loss : 4999.1777, Time/batch_file : 2.2847, Training time: 13536.4565\n",
      "Epoch : 1167/2000 data_batch_2,  Train_loss : 4998.8311  Test_loss : 4685.3657, Time/batch_file : 2.3133, Training time: 13538.7701\n",
      "Epoch : 1167/2000 data_batch_3,  Train_loss : 4954.7666  Test_loss : 4812.8467, Time/batch_file : 2.2696, Training time: 13541.0399\n",
      "Epoch : 1167/2000 data_batch_4,  Train_loss : 4836.0933  Test_loss : 4750.0781, Time/batch_file : 2.2850, Training time: 13543.3252\n",
      "Epoch : 1167/2000 data_batch_5,  Train_loss : 5013.2476  Test_loss : 4793.3257, Time/batch_file : 2.2934, Training time: 13545.6189\n",
      "Epoch : 1168/2000 data_batch_1,  Train_loss : 4456.3374  Test_loss : 5060.7637, Time/batch_file : 2.2660, Training time: 13547.8851\n",
      "Epoch : 1168/2000 data_batch_2,  Train_loss : 4434.9062  Test_loss : 5186.8086, Time/batch_file : 2.2740, Training time: 13550.1594\n",
      "Epoch : 1168/2000 data_batch_3,  Train_loss : 4374.8579  Test_loss : 5001.8833, Time/batch_file : 2.2750, Training time: 13552.4346\n",
      "Epoch : 1168/2000 data_batch_4,  Train_loss : 4373.5723  Test_loss : 5068.4824, Time/batch_file : 2.2555, Training time: 13554.6903\n",
      "Epoch : 1168/2000 data_batch_5,  Train_loss : 4313.5454  Test_loss : 5034.9971, Time/batch_file : 2.2655, Training time: 13556.9560\n",
      "Epoch : 1169/2000 data_batch_1,  Train_loss : 4555.3877  Test_loss : 4901.2905, Time/batch_file : 2.2772, Training time: 13559.2334\n",
      "Epoch : 1169/2000 data_batch_2,  Train_loss : 4542.5361  Test_loss : 4739.1909, Time/batch_file : 2.2758, Training time: 13561.5095\n",
      "Epoch : 1169/2000 data_batch_3,  Train_loss : 4605.8608  Test_loss : 4824.0825, Time/batch_file : 2.2760, Training time: 13563.7857\n",
      "Epoch : 1169/2000 data_batch_4,  Train_loss : 4472.3594  Test_loss : 4723.7056, Time/batch_file : 2.2713, Training time: 13566.0572\n",
      "Epoch : 1169/2000 data_batch_5,  Train_loss : 4417.0825  Test_loss : 5145.8311, Time/batch_file : 2.2748, Training time: 13568.3322\n",
      "Epoch : 1170/2000 data_batch_1,  Train_loss : 4670.3369  Test_loss : 4672.4678, Time/batch_file : 2.2843, Training time: 13570.6166\n",
      "Epoch : 1170/2000 data_batch_2,  Train_loss : 4849.3281  Test_loss : 4575.5557, Time/batch_file : 2.2756, Training time: 13572.8925\n",
      "Epoch : 1170/2000 data_batch_3,  Train_loss : 4663.8291  Test_loss : 4585.8291, Time/batch_file : 2.2877, Training time: 13575.1804\n",
      "Epoch : 1170/2000 data_batch_4,  Train_loss : 4677.9312  Test_loss : 4875.3398, Time/batch_file : 2.2838, Training time: 13577.4645\n",
      "Epoch : 1170/2000 data_batch_5,  Train_loss : 4593.9282  Test_loss : 4764.2007, Time/batch_file : 2.2734, Training time: 13579.7381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[./nets/net-1170.ckpt] SAVED\n",
      "Epoch : 1171/2000 data_batch_1,  Train_loss : 4723.9385  Test_loss : 5066.6060, Time/batch_file : 2.2952, Training time: 13587.2147\n",
      "Epoch : 1171/2000 data_batch_2,  Train_loss : 5130.0137  Test_loss : 5376.2432, Time/batch_file : 2.2833, Training time: 13589.4983\n",
      "Epoch : 1171/2000 data_batch_3,  Train_loss : 5219.2983  Test_loss : 5305.2568, Time/batch_file : 2.3152, Training time: 13591.8137\n",
      "Epoch : 1171/2000 data_batch_4,  Train_loss : 5163.7910  Test_loss : 5287.9297, Time/batch_file : 2.2855, Training time: 13594.0995\n",
      "Epoch : 1171/2000 data_batch_5,  Train_loss : 4873.0332  Test_loss : 5238.7168, Time/batch_file : 2.2848, Training time: 13596.3846\n",
      "Epoch : 1172/2000 data_batch_1,  Train_loss : 4176.6602  Test_loss : 5162.8882, Time/batch_file : 2.2755, Training time: 13598.6604\n",
      "Epoch : 1172/2000 data_batch_2,  Train_loss : 4442.7393  Test_loss : 4831.2744, Time/batch_file : 2.2691, Training time: 13600.9297\n",
      "Epoch : 1172/2000 data_batch_3,  Train_loss : 4377.1196  Test_loss : 5012.3408, Time/batch_file : 2.3194, Training time: 13603.2493\n",
      "Epoch : 1172/2000 data_batch_4,  Train_loss : 4454.1045  Test_loss : 5020.4541, Time/batch_file : 2.2772, Training time: 13605.5267\n",
      "Epoch : 1172/2000 data_batch_5,  Train_loss : 4279.7246  Test_loss : 5125.3838, Time/batch_file : 2.2840, Training time: 13607.8110\n",
      "Epoch : 1173/2000 data_batch_1,  Train_loss : 4763.8501  Test_loss : 5067.9409, Time/batch_file : 2.2612, Training time: 13610.0724\n",
      "Epoch : 1173/2000 data_batch_2,  Train_loss : 4480.1616  Test_loss : 5208.1357, Time/batch_file : 2.2794, Training time: 13612.3520\n",
      "Epoch : 1173/2000 data_batch_3,  Train_loss : 4609.3174  Test_loss : 4824.3701, Time/batch_file : 2.2864, Training time: 13614.6386\n",
      "Epoch : 1173/2000 data_batch_4,  Train_loss : 4530.4248  Test_loss : 4820.3091, Time/batch_file : 2.3212, Training time: 13616.9601\n",
      "Epoch : 1173/2000 data_batch_5,  Train_loss : 4647.7544  Test_loss : 4960.4878, Time/batch_file : 2.2787, Training time: 13619.2390\n",
      "Epoch : 1174/2000 data_batch_1,  Train_loss : 4617.8149  Test_loss : 4885.1865, Time/batch_file : 2.2948, Training time: 13621.5340\n",
      "Epoch : 1174/2000 data_batch_2,  Train_loss : 4616.1592  Test_loss : 4929.9126, Time/batch_file : 2.2820, Training time: 13623.8162\n",
      "Epoch : 1174/2000 data_batch_3,  Train_loss : 4430.1294  Test_loss : 5204.7607, Time/batch_file : 2.3220, Training time: 13626.1383\n",
      "Epoch : 1174/2000 data_batch_4,  Train_loss : 4396.6797  Test_loss : 5076.7891, Time/batch_file : 2.2700, Training time: 13628.4086\n",
      "Epoch : 1174/2000 data_batch_5,  Train_loss : 4268.0342  Test_loss : 5240.8657, Time/batch_file : 2.3030, Training time: 13630.7117\n",
      "Epoch : 1175/2000 data_batch_1,  Train_loss : 4641.0986  Test_loss : 4992.2788, Time/batch_file : 2.2827, Training time: 13632.9947\n",
      "Epoch : 1175/2000 data_batch_2,  Train_loss : 4520.4985  Test_loss : 4669.8857, Time/batch_file : 2.3193, Training time: 13635.3142\n",
      "Epoch : 1175/2000 data_batch_3,  Train_loss : 4619.9673  Test_loss : 4752.7656, Time/batch_file : 2.2662, Training time: 13637.5805\n",
      "Epoch : 1175/2000 data_batch_4,  Train_loss : 4339.5132  Test_loss : 4704.7402, Time/batch_file : 2.3038, Training time: 13639.8845\n",
      "Epoch : 1175/2000 data_batch_5,  Train_loss : 4525.2461  Test_loss : 5058.9731, Time/batch_file : 2.2753, Training time: 13642.1600\n",
      "Epoch : 1176/2000 data_batch_1,  Train_loss : 4451.2085  Test_loss : 4815.5288, Time/batch_file : 2.3337, Training time: 13644.4939\n",
      "Epoch : 1176/2000 data_batch_2,  Train_loss : 4985.6465  Test_loss : 4699.3604, Time/batch_file : 2.2707, Training time: 13646.7649\n",
      "Epoch : 1176/2000 data_batch_3,  Train_loss : 4911.2246  Test_loss : 4962.9077, Time/batch_file : 2.3071, Training time: 13649.0722\n",
      "Epoch : 1176/2000 data_batch_4,  Train_loss : 4683.0581  Test_loss : 4987.8833, Time/batch_file : 2.2759, Training time: 13651.3482\n",
      "Epoch : 1176/2000 data_batch_5,  Train_loss : 4661.1069  Test_loss : 4822.3154, Time/batch_file : 2.3242, Training time: 13653.6726\n",
      "Epoch : 1177/2000 data_batch_1,  Train_loss : 5279.7935  Test_loss : 4936.0303, Time/batch_file : 2.2606, Training time: 13655.9334\n",
      "Epoch : 1177/2000 data_batch_2,  Train_loss : 5123.8647  Test_loss : 4755.7969, Time/batch_file : 2.2922, Training time: 13658.2259\n",
      "Epoch : 1177/2000 data_batch_3,  Train_loss : 5333.8120  Test_loss : 5033.5859, Time/batch_file : 2.2710, Training time: 13660.4971\n",
      "Epoch : 1177/2000 data_batch_4,  Train_loss : 5299.8291  Test_loss : 4981.0742, Time/batch_file : 2.3132, Training time: 13662.8105\n",
      "Epoch : 1177/2000 data_batch_5,  Train_loss : 5256.5938  Test_loss : 5503.6924, Time/batch_file : 2.2700, Training time: 13665.0807\n",
      "Epoch : 1178/2000 data_batch_1,  Train_loss : 4512.2275  Test_loss : 5273.4478, Time/batch_file : 2.3043, Training time: 13667.3853\n",
      "Epoch : 1178/2000 data_batch_2,  Train_loss : 4748.4204  Test_loss : 5237.8345, Time/batch_file : 2.2784, Training time: 13669.6638\n",
      "Epoch : 1178/2000 data_batch_3,  Train_loss : 4998.6909  Test_loss : 5328.2349, Time/batch_file : 2.3171, Training time: 13671.9812\n",
      "Epoch : 1178/2000 data_batch_4,  Train_loss : 4598.3940  Test_loss : 5295.8408, Time/batch_file : 2.2789, Training time: 13674.2603\n",
      "Epoch : 1178/2000 data_batch_5,  Train_loss : 5070.6968  Test_loss : 5145.5469, Time/batch_file : 2.3242, Training time: 13676.5848\n",
      "Epoch : 1179/2000 data_batch_1,  Train_loss : 4944.7778  Test_loss : 5002.7363, Time/batch_file : 2.2760, Training time: 13678.8610\n",
      "Epoch : 1179/2000 data_batch_2,  Train_loss : 4726.4038  Test_loss : 5064.6445, Time/batch_file : 2.3358, Training time: 13681.1970\n",
      "Epoch : 1179/2000 data_batch_3,  Train_loss : 4830.0347  Test_loss : 5280.2368, Time/batch_file : 2.3291, Training time: 13683.5263\n",
      "Epoch : 1179/2000 data_batch_4,  Train_loss : 4780.1099  Test_loss : 5052.6084, Time/batch_file : 2.3178, Training time: 13685.8444\n",
      "Epoch : 1179/2000 data_batch_5,  Train_loss : 4876.4019  Test_loss : 4790.7188, Time/batch_file : 2.2836, Training time: 13688.1281\n",
      "Epoch : 1180/2000 data_batch_1,  Train_loss : 4760.5991  Test_loss : 5121.3657, Time/batch_file : 2.3184, Training time: 13690.4467\n",
      "Epoch : 1180/2000 data_batch_2,  Train_loss : 4614.6533  Test_loss : 5456.7749, Time/batch_file : 2.2762, Training time: 13692.7232\n",
      "Epoch : 1180/2000 data_batch_3,  Train_loss : 4817.8130  Test_loss : 5134.4302, Time/batch_file : 2.3088, Training time: 13695.0322\n",
      "Epoch : 1180/2000 data_batch_4,  Train_loss : 4901.0825  Test_loss : 5019.6714, Time/batch_file : 2.2790, Training time: 13697.3114\n",
      "Epoch : 1180/2000 data_batch_5,  Train_loss : 4712.3262  Test_loss : 5076.9434, Time/batch_file : 2.3216, Training time: 13699.6332\n",
      "[./nets/net-1180.ckpt] SAVED\n",
      "Epoch : 1181/2000 data_batch_1,  Train_loss : 4633.4414  Test_loss : 5148.3354, Time/batch_file : 2.3890, Training time: 13703.2835\n",
      "Epoch : 1181/2000 data_batch_2,  Train_loss : 4491.3193  Test_loss : 5191.2598, Time/batch_file : 2.2778, Training time: 13705.5615\n",
      "Epoch : 1181/2000 data_batch_3,  Train_loss : 4668.8628  Test_loss : 5275.6592, Time/batch_file : 2.3014, Training time: 13707.8630\n",
      "Epoch : 1181/2000 data_batch_4,  Train_loss : 4346.6328  Test_loss : 5141.2231, Time/batch_file : 2.2855, Training time: 13710.1488\n",
      "Epoch : 1181/2000 data_batch_5,  Train_loss : 4656.7275  Test_loss : 5203.3721, Time/batch_file : 2.3150, Training time: 13712.4639\n",
      "Epoch : 1182/2000 data_batch_1,  Train_loss : 5240.9985  Test_loss : 4917.9551, Time/batch_file : 2.3044, Training time: 13714.7685\n",
      "Epoch : 1182/2000 data_batch_2,  Train_loss : 4709.0254  Test_loss : 4455.4883, Time/batch_file : 2.2766, Training time: 13717.0453\n",
      "Epoch : 1182/2000 data_batch_3,  Train_loss : 5469.6191  Test_loss : 4797.2461, Time/batch_file : 2.2773, Training time: 13719.3228\n",
      "Epoch : 1182/2000 data_batch_4,  Train_loss : 4879.8979  Test_loss : 4682.2378, Time/batch_file : 2.2994, Training time: 13721.6224\n",
      "Epoch : 1182/2000 data_batch_5,  Train_loss : 5203.4707  Test_loss : 4940.8647, Time/batch_file : 2.2839, Training time: 13723.9066\n",
      "Epoch : 1183/2000 data_batch_1,  Train_loss : 4726.7783  Test_loss : 5160.9771, Time/batch_file : 2.2895, Training time: 13726.1963\n",
      "Epoch : 1183/2000 data_batch_2,  Train_loss : 4893.8687  Test_loss : 4975.7407, Time/batch_file : 2.2724, Training time: 13728.4689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1183/2000 data_batch_3,  Train_loss : 4587.5225  Test_loss : 5148.5518, Time/batch_file : 2.2607, Training time: 13730.7298\n",
      "Epoch : 1183/2000 data_batch_4,  Train_loss : 4811.4287  Test_loss : 4930.3252, Time/batch_file : 2.2842, Training time: 13733.0142\n",
      "Epoch : 1183/2000 data_batch_5,  Train_loss : 4823.2734  Test_loss : 5262.5127, Time/batch_file : 2.2769, Training time: 13735.2913\n",
      "Epoch : 1184/2000 data_batch_1,  Train_loss : 5102.6899  Test_loss : 5401.6387, Time/batch_file : 2.3124, Training time: 13737.6039\n",
      "Epoch : 1184/2000 data_batch_2,  Train_loss : 5047.5918  Test_loss : 5248.2544, Time/batch_file : 2.2830, Training time: 13739.8871\n",
      "Epoch : 1184/2000 data_batch_3,  Train_loss : 4993.1211  Test_loss : 5295.9590, Time/batch_file : 2.2848, Training time: 13742.1721\n",
      "Epoch : 1184/2000 data_batch_4,  Train_loss : 5148.2012  Test_loss : 5413.4316, Time/batch_file : 2.2810, Training time: 13744.4534\n",
      "Epoch : 1184/2000 data_batch_5,  Train_loss : 5147.7471  Test_loss : 5464.4727, Time/batch_file : 2.2824, Training time: 13746.7360\n",
      "Epoch : 1185/2000 data_batch_1,  Train_loss : 4945.0342  Test_loss : 5161.3467, Time/batch_file : 2.3021, Training time: 13749.0383\n",
      "Epoch : 1185/2000 data_batch_2,  Train_loss : 5195.4932  Test_loss : 5076.4951, Time/batch_file : 2.3168, Training time: 13751.3552\n",
      "Epoch : 1185/2000 data_batch_3,  Train_loss : 5487.2305  Test_loss : 4977.6221, Time/batch_file : 2.3028, Training time: 13753.6582\n",
      "Epoch : 1185/2000 data_batch_4,  Train_loss : 5121.7373  Test_loss : 5321.7378, Time/batch_file : 2.3044, Training time: 13755.9628\n",
      "Epoch : 1185/2000 data_batch_5,  Train_loss : 5109.6504  Test_loss : 5312.3848, Time/batch_file : 2.2831, Training time: 13758.2462\n",
      "Epoch : 1186/2000 data_batch_1,  Train_loss : 4670.6543  Test_loss : 5400.6055, Time/batch_file : 2.2829, Training time: 13760.5293\n",
      "Epoch : 1186/2000 data_batch_2,  Train_loss : 5121.0654  Test_loss : 5036.4565, Time/batch_file : 2.2772, Training time: 13762.8067\n",
      "Epoch : 1186/2000 data_batch_3,  Train_loss : 4608.1650  Test_loss : 5413.2129, Time/batch_file : 2.2954, Training time: 13765.1022\n",
      "Epoch : 1186/2000 data_batch_4,  Train_loss : 4761.8086  Test_loss : 5250.6152, Time/batch_file : 2.2897, Training time: 13767.3921\n",
      "Epoch : 1186/2000 data_batch_5,  Train_loss : 4640.7749  Test_loss : 5178.7656, Time/batch_file : 2.2925, Training time: 13769.6848\n",
      "Epoch : 1187/2000 data_batch_1,  Train_loss : 4613.9067  Test_loss : 4486.2085, Time/batch_file : 2.2901, Training time: 13771.9752\n",
      "Epoch : 1187/2000 data_batch_2,  Train_loss : 4655.8042  Test_loss : 4630.7041, Time/batch_file : 2.2863, Training time: 13774.2618\n",
      "Epoch : 1187/2000 data_batch_3,  Train_loss : 5056.0635  Test_loss : 4879.8721, Time/batch_file : 2.3242, Training time: 13776.5862\n",
      "Epoch : 1187/2000 data_batch_4,  Train_loss : 4950.8125  Test_loss : 4757.4365, Time/batch_file : 2.3110, Training time: 13778.8975\n",
      "Epoch : 1187/2000 data_batch_5,  Train_loss : 4807.0703  Test_loss : 5038.1748, Time/batch_file : 2.3241, Training time: 13781.2217\n",
      "Epoch : 1188/2000 data_batch_1,  Train_loss : 4695.1694  Test_loss : 4157.5879, Time/batch_file : 2.3032, Training time: 13783.5251\n",
      "Epoch : 1188/2000 data_batch_2,  Train_loss : 4517.7397  Test_loss : 4032.9092, Time/batch_file : 2.2866, Training time: 13785.8119\n",
      "Epoch : 1188/2000 data_batch_3,  Train_loss : 4845.9805  Test_loss : 4373.7358, Time/batch_file : 2.2975, Training time: 13788.1096\n",
      "Epoch : 1188/2000 data_batch_4,  Train_loss : 4562.9268  Test_loss : 4361.4473, Time/batch_file : 2.3139, Training time: 13790.4236\n",
      "Epoch : 1188/2000 data_batch_5,  Train_loss : 4583.2773  Test_loss : 4277.4712, Time/batch_file : 2.2957, Training time: 13792.7195\n",
      "Epoch : 1189/2000 data_batch_1,  Train_loss : 4544.7710  Test_loss : 4813.5195, Time/batch_file : 2.2917, Training time: 13795.0115\n",
      "Epoch : 1189/2000 data_batch_2,  Train_loss : 4722.5161  Test_loss : 5117.0762, Time/batch_file : 2.2849, Training time: 13797.2966\n",
      "Epoch : 1189/2000 data_batch_3,  Train_loss : 4608.6025  Test_loss : 4972.9873, Time/batch_file : 2.2658, Training time: 13799.5626\n",
      "Epoch : 1189/2000 data_batch_4,  Train_loss : 4639.1631  Test_loss : 5094.7954, Time/batch_file : 2.2711, Training time: 13801.8339\n",
      "Epoch : 1189/2000 data_batch_5,  Train_loss : 4532.2080  Test_loss : 5081.2534, Time/batch_file : 2.2742, Training time: 13804.1082\n",
      "Epoch : 1190/2000 data_batch_1,  Train_loss : 4834.1406  Test_loss : 5045.1108, Time/batch_file : 2.2939, Training time: 13806.4023\n",
      "Epoch : 1190/2000 data_batch_2,  Train_loss : 4535.2749  Test_loss : 5398.2598, Time/batch_file : 2.2955, Training time: 13808.6979\n",
      "Epoch : 1190/2000 data_batch_3,  Train_loss : 4713.9575  Test_loss : 5128.2192, Time/batch_file : 2.2894, Training time: 13810.9875\n",
      "Epoch : 1190/2000 data_batch_4,  Train_loss : 4945.2202  Test_loss : 5180.1064, Time/batch_file : 2.2829, Training time: 13813.2706\n",
      "Epoch : 1190/2000 data_batch_5,  Train_loss : 5056.0571  Test_loss : 4817.7197, Time/batch_file : 2.2776, Training time: 13815.5484\n",
      "[./nets/net-1190.ckpt] SAVED\n",
      "Epoch : 1191/2000 data_batch_1,  Train_loss : 4690.8672  Test_loss : 5388.1978, Time/batch_file : 2.3123, Training time: 13819.1809\n",
      "Epoch : 1191/2000 data_batch_2,  Train_loss : 4725.2407  Test_loss : 5035.1611, Time/batch_file : 2.3321, Training time: 13821.5132\n",
      "Epoch : 1191/2000 data_batch_3,  Train_loss : 4906.0317  Test_loss : 5247.9814, Time/batch_file : 2.3099, Training time: 13823.8233\n",
      "Epoch : 1191/2000 data_batch_4,  Train_loss : 4763.5962  Test_loss : 4771.6069, Time/batch_file : 2.3040, Training time: 13826.1275\n",
      "Epoch : 1191/2000 data_batch_5,  Train_loss : 4701.6143  Test_loss : 5349.6572, Time/batch_file : 2.3360, Training time: 13828.4638\n",
      "Epoch : 1192/2000 data_batch_1,  Train_loss : 5179.7334  Test_loss : 5382.6479, Time/batch_file : 2.2949, Training time: 13830.7588\n",
      "Epoch : 1192/2000 data_batch_2,  Train_loss : 4833.1392  Test_loss : 5364.5986, Time/batch_file : 2.3123, Training time: 13833.0714\n",
      "Epoch : 1192/2000 data_batch_3,  Train_loss : 4934.1709  Test_loss : 5602.2676, Time/batch_file : 2.2948, Training time: 13835.3663\n",
      "Epoch : 1192/2000 data_batch_4,  Train_loss : 4995.9829  Test_loss : 5483.1694, Time/batch_file : 2.3420, Training time: 13837.7086\n",
      "Epoch : 1192/2000 data_batch_5,  Train_loss : 4912.5576  Test_loss : 5262.1680, Time/batch_file : 2.2974, Training time: 13840.0063\n",
      "Epoch : 1193/2000 data_batch_1,  Train_loss : 4555.2764  Test_loss : 4525.1719, Time/batch_file : 2.3114, Training time: 13842.3180\n",
      "Epoch : 1193/2000 data_batch_2,  Train_loss : 4396.1011  Test_loss : 4932.7280, Time/batch_file : 2.3045, Training time: 13844.6226\n",
      "Epoch : 1193/2000 data_batch_3,  Train_loss : 4450.5811  Test_loss : 4542.8057, Time/batch_file : 2.3344, Training time: 13846.9572\n",
      "Epoch : 1193/2000 data_batch_4,  Train_loss : 4522.9590  Test_loss : 4351.6377, Time/batch_file : 2.2973, Training time: 13849.2548\n",
      "Epoch : 1193/2000 data_batch_5,  Train_loss : 4411.9766  Test_loss : 4878.7163, Time/batch_file : 2.3078, Training time: 13851.5627\n",
      "Epoch : 1194/2000 data_batch_1,  Train_loss : 5041.8931  Test_loss : 4966.4194, Time/batch_file : 2.2918, Training time: 13853.8546\n",
      "Epoch : 1194/2000 data_batch_2,  Train_loss : 5249.7666  Test_loss : 4891.4590, Time/batch_file : 2.3347, Training time: 13856.1895\n",
      "Epoch : 1194/2000 data_batch_3,  Train_loss : 5094.0547  Test_loss : 5255.2910, Time/batch_file : 2.3021, Training time: 13858.4918\n",
      "Epoch : 1194/2000 data_batch_4,  Train_loss : 5274.3398  Test_loss : 4735.8843, Time/batch_file : 2.3145, Training time: 13860.8064\n",
      "Epoch : 1194/2000 data_batch_5,  Train_loss : 5275.3726  Test_loss : 4959.5781, Time/batch_file : 2.2924, Training time: 13863.0990\n",
      "Epoch : 1195/2000 data_batch_1,  Train_loss : 5083.7314  Test_loss : 4847.7485, Time/batch_file : 2.3274, Training time: 13865.4266\n",
      "Epoch : 1195/2000 data_batch_2,  Train_loss : 4804.7324  Test_loss : 5027.3511, Time/batch_file : 2.2728, Training time: 13867.6997\n",
      "Epoch : 1195/2000 data_batch_3,  Train_loss : 4637.7236  Test_loss : 5164.3809, Time/batch_file : 2.2987, Training time: 13869.9985\n",
      "Epoch : 1195/2000 data_batch_4,  Train_loss : 4750.1240  Test_loss : 4846.5366, Time/batch_file : 2.2906, Training time: 13872.2894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1195/2000 data_batch_5,  Train_loss : 4721.7656  Test_loss : 4888.9346, Time/batch_file : 2.3175, Training time: 13874.6070\n",
      "Epoch : 1196/2000 data_batch_1,  Train_loss : 5060.0684  Test_loss : 5417.4634, Time/batch_file : 2.2882, Training time: 13876.8955\n",
      "Epoch : 1196/2000 data_batch_2,  Train_loss : 5109.4160  Test_loss : 5328.7646, Time/batch_file : 2.3122, Training time: 13879.2078\n",
      "Epoch : 1196/2000 data_batch_3,  Train_loss : 5093.3457  Test_loss : 5411.0205, Time/batch_file : 2.3000, Training time: 13881.5081\n",
      "Epoch : 1196/2000 data_batch_4,  Train_loss : 4827.4204  Test_loss : 5512.2090, Time/batch_file : 2.3354, Training time: 13883.8438\n",
      "Epoch : 1196/2000 data_batch_5,  Train_loss : 4769.9360  Test_loss : 5528.4355, Time/batch_file : 2.2922, Training time: 13886.1362\n",
      "Epoch : 1197/2000 data_batch_1,  Train_loss : 5125.3203  Test_loss : 4932.0093, Time/batch_file : 2.3269, Training time: 13888.4632\n",
      "Epoch : 1197/2000 data_batch_2,  Train_loss : 5010.2861  Test_loss : 5313.1685, Time/batch_file : 2.3154, Training time: 13890.7790\n",
      "Epoch : 1197/2000 data_batch_3,  Train_loss : 5070.7432  Test_loss : 4728.2100, Time/batch_file : 2.3482, Training time: 13893.1273\n",
      "Epoch : 1197/2000 data_batch_4,  Train_loss : 5157.5981  Test_loss : 5280.1084, Time/batch_file : 2.3070, Training time: 13895.4345\n",
      "Epoch : 1197/2000 data_batch_5,  Train_loss : 5167.3047  Test_loss : 4801.0859, Time/batch_file : 2.3220, Training time: 13897.7567\n",
      "Epoch : 1198/2000 data_batch_1,  Train_loss : 4178.0449  Test_loss : 5445.5615, Time/batch_file : 2.2979, Training time: 13900.0549\n",
      "Epoch : 1198/2000 data_batch_2,  Train_loss : 4325.6738  Test_loss : 5346.8442, Time/batch_file : 2.3244, Training time: 13902.3795\n",
      "Epoch : 1198/2000 data_batch_3,  Train_loss : 4436.2222  Test_loss : 5370.6509, Time/batch_file : 2.2948, Training time: 13904.6744\n",
      "Epoch : 1198/2000 data_batch_4,  Train_loss : 4343.0557  Test_loss : 5415.7456, Time/batch_file : 2.3194, Training time: 13906.9939\n",
      "Epoch : 1198/2000 data_batch_5,  Train_loss : 4126.2339  Test_loss : 5361.9736, Time/batch_file : 2.3004, Training time: 13909.2944\n",
      "Epoch : 1199/2000 data_batch_1,  Train_loss : 4779.8906  Test_loss : 5441.8262, Time/batch_file : 2.3509, Training time: 13911.6455\n",
      "Epoch : 1199/2000 data_batch_2,  Train_loss : 4499.5918  Test_loss : 5210.1772, Time/batch_file : 2.2932, Training time: 13913.9388\n",
      "Epoch : 1199/2000 data_batch_3,  Train_loss : 4799.2505  Test_loss : 5305.7544, Time/batch_file : 2.3166, Training time: 13916.2556\n",
      "Epoch : 1199/2000 data_batch_4,  Train_loss : 4700.4087  Test_loss : 5118.4653, Time/batch_file : 2.3002, Training time: 13918.5561\n",
      "Epoch : 1199/2000 data_batch_5,  Train_loss : 4771.8496  Test_loss : 5109.4214, Time/batch_file : 2.3410, Training time: 13920.8972\n",
      "Epoch : 1200/2000 data_batch_1,  Train_loss : 4856.3584  Test_loss : 4944.1284, Time/batch_file : 2.3071, Training time: 13923.2044\n",
      "Epoch : 1200/2000 data_batch_2,  Train_loss : 5014.5576  Test_loss : 5087.4487, Time/batch_file : 2.3223, Training time: 13925.5270\n",
      "Epoch : 1200/2000 data_batch_3,  Train_loss : 4891.8291  Test_loss : 4856.6982, Time/batch_file : 2.2981, Training time: 13927.8254\n",
      "Epoch : 1200/2000 data_batch_4,  Train_loss : 4759.1060  Test_loss : 4842.1045, Time/batch_file : 2.3346, Training time: 13930.1602\n",
      "Epoch : 1200/2000 data_batch_5,  Train_loss : 4551.9097  Test_loss : 4815.9702, Time/batch_file : 2.2890, Training time: 13932.4494\n",
      "[./nets/net-1200.ckpt] SAVED\n",
      "Epoch : 1201/2000 data_batch_1,  Train_loss : 4715.4541  Test_loss : 5434.4380, Time/batch_file : 2.3344, Training time: 13936.0628\n",
      "Epoch : 1201/2000 data_batch_2,  Train_loss : 4864.9580  Test_loss : 5484.3926, Time/batch_file : 2.3366, Training time: 13938.3995\n",
      "Epoch : 1201/2000 data_batch_3,  Train_loss : 5056.0850  Test_loss : 5430.7505, Time/batch_file : 2.3266, Training time: 13940.7263\n",
      "Epoch : 1201/2000 data_batch_4,  Train_loss : 4740.4087  Test_loss : 5420.6064, Time/batch_file : 2.3133, Training time: 13943.0399\n",
      "Epoch : 1201/2000 data_batch_5,  Train_loss : 4575.9380  Test_loss : 5356.3213, Time/batch_file : 2.3308, Training time: 13945.3710\n",
      "Epoch : 1202/2000 data_batch_1,  Train_loss : 4810.4092  Test_loss : 5441.7183, Time/batch_file : 2.3121, Training time: 13947.6833\n",
      "Epoch : 1202/2000 data_batch_2,  Train_loss : 4947.9004  Test_loss : 5264.4375, Time/batch_file : 2.2983, Training time: 13949.9818\n",
      "Epoch : 1202/2000 data_batch_3,  Train_loss : 4839.3408  Test_loss : 5489.3652, Time/batch_file : 2.3052, Training time: 13952.2872\n",
      "Epoch : 1202/2000 data_batch_4,  Train_loss : 5087.0596  Test_loss : 5210.3931, Time/batch_file : 2.2804, Training time: 13954.5678\n",
      "Epoch : 1202/2000 data_batch_5,  Train_loss : 4990.6338  Test_loss : 5582.6152, Time/batch_file : 2.3143, Training time: 13956.8823\n",
      "Epoch : 1203/2000 data_batch_1,  Train_loss : 4806.7324  Test_loss : 5169.5039, Time/batch_file : 2.2763, Training time: 13959.1588\n",
      "Epoch : 1203/2000 data_batch_2,  Train_loss : 4461.0820  Test_loss : 5253.2656, Time/batch_file : 2.3019, Training time: 13961.4608\n",
      "Epoch : 1203/2000 data_batch_3,  Train_loss : 4705.2559  Test_loss : 5312.0415, Time/batch_file : 2.2768, Training time: 13963.7378\n",
      "Epoch : 1203/2000 data_batch_4,  Train_loss : 4608.3794  Test_loss : 5205.3623, Time/batch_file : 2.3011, Training time: 13966.0391\n",
      "Epoch : 1203/2000 data_batch_5,  Train_loss : 4624.3179  Test_loss : 5092.1758, Time/batch_file : 2.2782, Training time: 13968.3176\n",
      "Epoch : 1204/2000 data_batch_1,  Train_loss : 5018.7383  Test_loss : 4891.5410, Time/batch_file : 2.3185, Training time: 13970.6363\n",
      "Epoch : 1204/2000 data_batch_2,  Train_loss : 4999.9033  Test_loss : 4810.1982, Time/batch_file : 2.2848, Training time: 13972.9214\n",
      "Epoch : 1204/2000 data_batch_3,  Train_loss : 4920.1333  Test_loss : 4617.4399, Time/batch_file : 2.3248, Training time: 13975.2464\n",
      "Epoch : 1204/2000 data_batch_4,  Train_loss : 4995.8560  Test_loss : 4571.6899, Time/batch_file : 2.3000, Training time: 13977.5466\n",
      "Epoch : 1204/2000 data_batch_5,  Train_loss : 4971.0933  Test_loss : 4763.2666, Time/batch_file : 2.3211, Training time: 13979.8679\n",
      "Epoch : 1205/2000 data_batch_1,  Train_loss : 4759.4429  Test_loss : 5081.5938, Time/batch_file : 2.2770, Training time: 13982.1450\n",
      "Epoch : 1205/2000 data_batch_2,  Train_loss : 4630.8267  Test_loss : 4631.5234, Time/batch_file : 2.3053, Training time: 13984.4507\n",
      "Epoch : 1205/2000 data_batch_3,  Train_loss : 4508.9238  Test_loss : 4765.0762, Time/batch_file : 2.2808, Training time: 13986.7317\n",
      "Epoch : 1205/2000 data_batch_4,  Train_loss : 4711.0273  Test_loss : 5246.3149, Time/batch_file : 2.3046, Training time: 13989.0364\n",
      "Epoch : 1205/2000 data_batch_5,  Train_loss : 4892.1421  Test_loss : 5013.1592, Time/batch_file : 2.2805, Training time: 13991.3172\n",
      "Epoch : 1206/2000 data_batch_1,  Train_loss : 4459.6548  Test_loss : 4911.2930, Time/batch_file : 2.2927, Training time: 13993.6101\n",
      "Epoch : 1206/2000 data_batch_2,  Train_loss : 4538.1392  Test_loss : 4665.8232, Time/batch_file : 2.2697, Training time: 13995.8801\n",
      "Epoch : 1206/2000 data_batch_3,  Train_loss : 4334.9580  Test_loss : 5220.6050, Time/batch_file : 2.2945, Training time: 13998.1748\n",
      "Epoch : 1206/2000 data_batch_4,  Train_loss : 4702.8853  Test_loss : 4680.0962, Time/batch_file : 2.2685, Training time: 14000.4435\n",
      "Epoch : 1206/2000 data_batch_5,  Train_loss : 4418.2285  Test_loss : 4948.1226, Time/batch_file : 2.2881, Training time: 14002.7317\n",
      "Epoch : 1207/2000 data_batch_1,  Train_loss : 5348.3154  Test_loss : 4682.1074, Time/batch_file : 2.2815, Training time: 14005.0133\n",
      "Epoch : 1207/2000 data_batch_2,  Train_loss : 5070.7979  Test_loss : 4607.0728, Time/batch_file : 2.3092, Training time: 14007.3227\n",
      "Epoch : 1207/2000 data_batch_3,  Train_loss : 5319.9849  Test_loss : 4658.1704, Time/batch_file : 2.2785, Training time: 14009.6014\n",
      "Epoch : 1207/2000 data_batch_4,  Train_loss : 5050.7466  Test_loss : 4740.6895, Time/batch_file : 2.3015, Training time: 14011.9031\n",
      "Epoch : 1207/2000 data_batch_5,  Train_loss : 5006.8906  Test_loss : 5106.3159, Time/batch_file : 2.2732, Training time: 14014.1765\n",
      "Epoch : 1208/2000 data_batch_1,  Train_loss : 5054.2935  Test_loss : 5121.6445, Time/batch_file : 2.3065, Training time: 14016.4833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1208/2000 data_batch_2,  Train_loss : 4883.8662  Test_loss : 5133.9336, Time/batch_file : 2.2626, Training time: 14018.7460\n",
      "Epoch : 1208/2000 data_batch_3,  Train_loss : 4558.0752  Test_loss : 5276.0283, Time/batch_file : 2.3081, Training time: 14021.0543\n",
      "Epoch : 1208/2000 data_batch_4,  Train_loss : 4777.3076  Test_loss : 5118.9756, Time/batch_file : 2.2793, Training time: 14023.3338\n",
      "Epoch : 1208/2000 data_batch_5,  Train_loss : 4834.5811  Test_loss : 5379.9023, Time/batch_file : 2.3062, Training time: 14025.6402\n",
      "Epoch : 1209/2000 data_batch_1,  Train_loss : 5037.3262  Test_loss : 5025.9702, Time/batch_file : 2.2706, Training time: 14027.9111\n",
      "Epoch : 1209/2000 data_batch_2,  Train_loss : 4981.3276  Test_loss : 5140.2744, Time/batch_file : 2.2964, Training time: 14030.2077\n",
      "Epoch : 1209/2000 data_batch_3,  Train_loss : 4990.6240  Test_loss : 5049.1943, Time/batch_file : 2.2696, Training time: 14032.4776\n",
      "Epoch : 1209/2000 data_batch_4,  Train_loss : 4847.8271  Test_loss : 4917.8525, Time/batch_file : 2.3055, Training time: 14034.7832\n",
      "Epoch : 1209/2000 data_batch_5,  Train_loss : 4967.4751  Test_loss : 5336.4473, Time/batch_file : 2.2813, Training time: 14037.0647\n",
      "Epoch : 1210/2000 data_batch_1,  Train_loss : 4311.7012  Test_loss : 4967.5957, Time/batch_file : 2.3024, Training time: 14039.3673\n",
      "Epoch : 1210/2000 data_batch_2,  Train_loss : 4609.6167  Test_loss : 5174.3833, Time/batch_file : 2.2650, Training time: 14041.6325\n",
      "Epoch : 1210/2000 data_batch_3,  Train_loss : 4518.5303  Test_loss : 4675.2383, Time/batch_file : 2.3059, Training time: 14043.9386\n",
      "Epoch : 1210/2000 data_batch_4,  Train_loss : 4314.9585  Test_loss : 4845.4277, Time/batch_file : 2.2688, Training time: 14046.2076\n",
      "Epoch : 1210/2000 data_batch_5,  Train_loss : 4138.3696  Test_loss : 4954.6694, Time/batch_file : 2.3128, Training time: 14048.5206\n",
      "[./nets/net-1210.ckpt] SAVED\n",
      "Epoch : 1211/2000 data_batch_1,  Train_loss : 4802.8413  Test_loss : 5588.0923, Time/batch_file : 2.2979, Training time: 14052.1016\n",
      "Epoch : 1211/2000 data_batch_2,  Train_loss : 4637.1782  Test_loss : 5921.5576, Time/batch_file : 2.3018, Training time: 14054.4036\n",
      "Epoch : 1211/2000 data_batch_3,  Train_loss : 4506.3506  Test_loss : 5588.5664, Time/batch_file : 2.3112, Training time: 14056.7151\n",
      "Epoch : 1211/2000 data_batch_4,  Train_loss : 4472.3750  Test_loss : 5748.5225, Time/batch_file : 2.3008, Training time: 14059.0161\n",
      "Epoch : 1211/2000 data_batch_5,  Train_loss : 4837.4634  Test_loss : 5594.9355, Time/batch_file : 2.2858, Training time: 14061.3021\n",
      "Epoch : 1212/2000 data_batch_1,  Train_loss : 4747.2998  Test_loss : 5074.0024, Time/batch_file : 2.3024, Training time: 14063.6047\n",
      "Epoch : 1212/2000 data_batch_2,  Train_loss : 5158.4004  Test_loss : 5541.6982, Time/batch_file : 2.2870, Training time: 14065.8919\n",
      "Epoch : 1212/2000 data_batch_3,  Train_loss : 4878.1621  Test_loss : 5144.1016, Time/batch_file : 2.2944, Training time: 14068.1864\n",
      "Epoch : 1212/2000 data_batch_4,  Train_loss : 4892.1377  Test_loss : 5441.5381, Time/batch_file : 2.2799, Training time: 14070.4666\n",
      "Epoch : 1212/2000 data_batch_5,  Train_loss : 4773.3428  Test_loss : 5197.5645, Time/batch_file : 2.3017, Training time: 14072.7686\n",
      "Epoch : 1213/2000 data_batch_1,  Train_loss : 4910.3584  Test_loss : 5022.3867, Time/batch_file : 2.2881, Training time: 14075.0570\n",
      "Epoch : 1213/2000 data_batch_2,  Train_loss : 4744.7451  Test_loss : 5375.2998, Time/batch_file : 2.3077, Training time: 14077.3649\n",
      "Epoch : 1213/2000 data_batch_3,  Train_loss : 4981.4434  Test_loss : 5593.1094, Time/batch_file : 2.2867, Training time: 14079.6517\n",
      "Epoch : 1213/2000 data_batch_4,  Train_loss : 5028.5708  Test_loss : 5214.4053, Time/batch_file : 2.3009, Training time: 14081.9528\n",
      "Epoch : 1213/2000 data_batch_5,  Train_loss : 4872.7144  Test_loss : 5428.3975, Time/batch_file : 2.2867, Training time: 14084.2397\n",
      "Epoch : 1214/2000 data_batch_1,  Train_loss : 5426.7227  Test_loss : 4882.1929, Time/batch_file : 2.3011, Training time: 14086.5410\n",
      "Epoch : 1214/2000 data_batch_2,  Train_loss : 5465.7510  Test_loss : 5099.2539, Time/batch_file : 2.2709, Training time: 14088.8121\n",
      "Epoch : 1214/2000 data_batch_3,  Train_loss : 4969.8633  Test_loss : 5077.3555, Time/batch_file : 2.3045, Training time: 14091.1168\n",
      "Epoch : 1214/2000 data_batch_4,  Train_loss : 5504.9131  Test_loss : 4602.2695, Time/batch_file : 2.2796, Training time: 14093.3965\n",
      "Epoch : 1214/2000 data_batch_5,  Train_loss : 5366.4600  Test_loss : 5066.2251, Time/batch_file : 2.3041, Training time: 14095.7008\n",
      "Epoch : 1215/2000 data_batch_1,  Train_loss : 4734.1416  Test_loss : 5117.0283, Time/batch_file : 2.3039, Training time: 14098.0050\n",
      "Epoch : 1215/2000 data_batch_2,  Train_loss : 5118.8125  Test_loss : 4872.9102, Time/batch_file : 2.3253, Training time: 14100.3305\n",
      "Epoch : 1215/2000 data_batch_3,  Train_loss : 4820.9922  Test_loss : 4961.9902, Time/batch_file : 2.2817, Training time: 14102.6125\n",
      "Epoch : 1215/2000 data_batch_4,  Train_loss : 4893.3091  Test_loss : 4848.8984, Time/batch_file : 2.3171, Training time: 14104.9298\n",
      "Epoch : 1215/2000 data_batch_5,  Train_loss : 4932.1631  Test_loss : 4728.7563, Time/batch_file : 2.2872, Training time: 14107.2172\n",
      "Epoch : 1216/2000 data_batch_1,  Train_loss : 5048.2402  Test_loss : 4940.0972, Time/batch_file : 2.2981, Training time: 14109.5155\n",
      "Epoch : 1216/2000 data_batch_2,  Train_loss : 4924.5371  Test_loss : 5145.7725, Time/batch_file : 2.2767, Training time: 14111.7924\n",
      "Epoch : 1216/2000 data_batch_3,  Train_loss : 4724.2017  Test_loss : 5043.7549, Time/batch_file : 2.2875, Training time: 14114.0800\n",
      "Epoch : 1216/2000 data_batch_4,  Train_loss : 5215.0996  Test_loss : 5212.6807, Time/batch_file : 2.2666, Training time: 14116.3468\n",
      "Epoch : 1216/2000 data_batch_5,  Train_loss : 4507.7490  Test_loss : 5396.3447, Time/batch_file : 2.2882, Training time: 14118.6352\n",
      "Epoch : 1217/2000 data_batch_1,  Train_loss : 4930.9932  Test_loss : 5243.0933, Time/batch_file : 2.3196, Training time: 14120.9551\n",
      "Epoch : 1217/2000 data_batch_2,  Train_loss : 4822.1641  Test_loss : 5526.6606, Time/batch_file : 2.3023, Training time: 14123.2575\n",
      "Epoch : 1217/2000 data_batch_3,  Train_loss : 4993.0630  Test_loss : 5629.4248, Time/batch_file : 2.2842, Training time: 14125.5420\n",
      "Epoch : 1217/2000 data_batch_4,  Train_loss : 4654.8608  Test_loss : 5176.8457, Time/batch_file : 2.2988, Training time: 14127.8410\n",
      "Epoch : 1217/2000 data_batch_5,  Train_loss : 4857.5342  Test_loss : 5395.1362, Time/batch_file : 2.2828, Training time: 14130.1241\n",
      "Epoch : 1218/2000 data_batch_1,  Train_loss : 4452.3027  Test_loss : 5167.3076, Time/batch_file : 2.2995, Training time: 14132.4239\n",
      "Epoch : 1218/2000 data_batch_2,  Train_loss : 4585.8154  Test_loss : 4904.7051, Time/batch_file : 2.2739, Training time: 14134.6980\n",
      "Epoch : 1218/2000 data_batch_3,  Train_loss : 4494.6924  Test_loss : 5081.7383, Time/batch_file : 2.2988, Training time: 14136.9969\n",
      "Epoch : 1218/2000 data_batch_4,  Train_loss : 4382.5942  Test_loss : 5247.8057, Time/batch_file : 2.2847, Training time: 14139.2818\n",
      "Epoch : 1218/2000 data_batch_5,  Train_loss : 4603.6152  Test_loss : 4865.5605, Time/batch_file : 2.3194, Training time: 14141.6015\n",
      "Epoch : 1219/2000 data_batch_1,  Train_loss : 4738.7090  Test_loss : 5154.0054, Time/batch_file : 2.2894, Training time: 14143.8911\n",
      "Epoch : 1219/2000 data_batch_2,  Train_loss : 4819.8848  Test_loss : 5326.9932, Time/batch_file : 2.3213, Training time: 14146.2126\n",
      "Epoch : 1219/2000 data_batch_3,  Train_loss : 4667.5381  Test_loss : 5331.3457, Time/batch_file : 2.2976, Training time: 14148.5105\n",
      "Epoch : 1219/2000 data_batch_4,  Train_loss : 4884.4678  Test_loss : 5183.4834, Time/batch_file : 2.3314, Training time: 14150.8421\n",
      "Epoch : 1219/2000 data_batch_5,  Train_loss : 4703.7886  Test_loss : 5138.0103, Time/batch_file : 2.2888, Training time: 14153.1311\n",
      "Epoch : 1220/2000 data_batch_1,  Train_loss : 4485.9224  Test_loss : 4846.9863, Time/batch_file : 2.3005, Training time: 14155.4317\n",
      "Epoch : 1220/2000 data_batch_2,  Train_loss : 4561.1221  Test_loss : 4945.8179, Time/batch_file : 2.2746, Training time: 14157.7065\n",
      "Epoch : 1220/2000 data_batch_3,  Train_loss : 4675.5562  Test_loss : 5207.9697, Time/batch_file : 2.3058, Training time: 14160.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1220/2000 data_batch_4,  Train_loss : 4516.3579  Test_loss : 4921.4785, Time/batch_file : 2.2767, Training time: 14162.2894\n",
      "Epoch : 1220/2000 data_batch_5,  Train_loss : 4562.3662  Test_loss : 5343.3379, Time/batch_file : 2.3005, Training time: 14164.5901\n",
      "[./nets/net-1220.ckpt] SAVED\n",
      "Epoch : 1221/2000 data_batch_1,  Train_loss : 4609.9219  Test_loss : 4836.1221, Time/batch_file : 2.2988, Training time: 14168.1695\n",
      "Epoch : 1221/2000 data_batch_2,  Train_loss : 5173.3105  Test_loss : 5085.4453, Time/batch_file : 2.2930, Training time: 14170.4627\n",
      "Epoch : 1221/2000 data_batch_3,  Train_loss : 5095.2593  Test_loss : 4883.0098, Time/batch_file : 2.2941, Training time: 14172.7570\n",
      "Epoch : 1221/2000 data_batch_4,  Train_loss : 4776.0991  Test_loss : 5029.5122, Time/batch_file : 2.2873, Training time: 14175.0445\n",
      "Epoch : 1221/2000 data_batch_5,  Train_loss : 4814.0259  Test_loss : 4903.6587, Time/batch_file : 2.3143, Training time: 14177.3590\n",
      "Epoch : 1222/2000 data_batch_1,  Train_loss : 4812.9429  Test_loss : 4935.7739, Time/batch_file : 2.2913, Training time: 14179.6505\n",
      "Epoch : 1222/2000 data_batch_2,  Train_loss : 5091.1426  Test_loss : 5089.0425, Time/batch_file : 2.3082, Training time: 14181.9589\n",
      "Epoch : 1222/2000 data_batch_3,  Train_loss : 5061.5156  Test_loss : 4981.2344, Time/batch_file : 2.2838, Training time: 14184.2430\n",
      "Epoch : 1222/2000 data_batch_4,  Train_loss : 5095.0674  Test_loss : 5086.4102, Time/batch_file : 2.3023, Training time: 14186.5454\n",
      "Epoch : 1222/2000 data_batch_5,  Train_loss : 5103.7979  Test_loss : 4986.1411, Time/batch_file : 2.2970, Training time: 14188.8426\n",
      "Epoch : 1223/2000 data_batch_1,  Train_loss : 5541.3916  Test_loss : 4635.7007, Time/batch_file : 2.2894, Training time: 14191.1322\n",
      "Epoch : 1223/2000 data_batch_2,  Train_loss : 5751.0703  Test_loss : 4740.9844, Time/batch_file : 2.2592, Training time: 14193.3915\n",
      "Epoch : 1223/2000 data_batch_3,  Train_loss : 5688.6191  Test_loss : 4544.5117, Time/batch_file : 2.2879, Training time: 14195.6796\n",
      "Epoch : 1223/2000 data_batch_4,  Train_loss : 5500.3833  Test_loss : 4673.6250, Time/batch_file : 2.2655, Training time: 14197.9454\n",
      "Epoch : 1223/2000 data_batch_5,  Train_loss : 5464.1313  Test_loss : 4403.9565, Time/batch_file : 2.2861, Training time: 14200.2316\n",
      "Epoch : 1224/2000 data_batch_1,  Train_loss : 4592.1133  Test_loss : 5423.7324, Time/batch_file : 2.2759, Training time: 14202.5077\n",
      "Epoch : 1224/2000 data_batch_2,  Train_loss : 4339.6079  Test_loss : 5419.4692, Time/batch_file : 2.3019, Training time: 14204.8098\n",
      "Epoch : 1224/2000 data_batch_3,  Train_loss : 4417.9126  Test_loss : 5290.7002, Time/batch_file : 2.2689, Training time: 14207.0789\n",
      "Epoch : 1224/2000 data_batch_4,  Train_loss : 4391.1997  Test_loss : 5213.6006, Time/batch_file : 2.3074, Training time: 14209.3865\n",
      "Epoch : 1224/2000 data_batch_5,  Train_loss : 4470.4844  Test_loss : 5308.5898, Time/batch_file : 2.2744, Training time: 14211.6612\n",
      "Epoch : 1225/2000 data_batch_1,  Train_loss : 4875.1934  Test_loss : 5707.3794, Time/batch_file : 2.3316, Training time: 14213.9930\n",
      "Epoch : 1225/2000 data_batch_2,  Train_loss : 4955.4556  Test_loss : 5220.4375, Time/batch_file : 2.2935, Training time: 14216.2868\n",
      "Epoch : 1225/2000 data_batch_3,  Train_loss : 4744.7744  Test_loss : 5507.6265, Time/batch_file : 2.3433, Training time: 14218.6303\n",
      "Epoch : 1225/2000 data_batch_4,  Train_loss : 4844.4751  Test_loss : 5307.7812, Time/batch_file : 2.2990, Training time: 14220.9295\n",
      "Epoch : 1225/2000 data_batch_5,  Train_loss : 4644.5054  Test_loss : 5360.5767, Time/batch_file : 2.3195, Training time: 14223.2492\n",
      "Epoch : 1226/2000 data_batch_1,  Train_loss : 4486.8540  Test_loss : 4938.2007, Time/batch_file : 2.2727, Training time: 14225.5220\n",
      "Epoch : 1226/2000 data_batch_2,  Train_loss : 4439.7842  Test_loss : 4887.0664, Time/batch_file : 2.2935, Training time: 14227.8157\n",
      "Epoch : 1226/2000 data_batch_3,  Train_loss : 4578.0801  Test_loss : 4863.2334, Time/batch_file : 2.2770, Training time: 14230.0928\n",
      "Epoch : 1226/2000 data_batch_4,  Train_loss : 4616.2656  Test_loss : 5093.6055, Time/batch_file : 2.3006, Training time: 14232.3935\n",
      "Epoch : 1226/2000 data_batch_5,  Train_loss : 4326.1016  Test_loss : 5090.1104, Time/batch_file : 2.2769, Training time: 14234.6706\n",
      "Epoch : 1227/2000 data_batch_1,  Train_loss : 4889.0625  Test_loss : 4685.8301, Time/batch_file : 2.2974, Training time: 14236.9681\n",
      "Epoch : 1227/2000 data_batch_2,  Train_loss : 4573.1279  Test_loss : 4721.5703, Time/batch_file : 2.2747, Training time: 14239.2430\n",
      "Epoch : 1227/2000 data_batch_3,  Train_loss : 4996.4404  Test_loss : 4768.0493, Time/batch_file : 2.3001, Training time: 14241.5433\n",
      "Epoch : 1227/2000 data_batch_4,  Train_loss : 4756.4932  Test_loss : 5036.8799, Time/batch_file : 2.2753, Training time: 14243.8188\n",
      "Epoch : 1227/2000 data_batch_5,  Train_loss : 4682.3926  Test_loss : 4803.2642, Time/batch_file : 2.2947, Training time: 14246.1137\n",
      "Epoch : 1228/2000 data_batch_1,  Train_loss : 4978.1387  Test_loss : 4903.8848, Time/batch_file : 2.2968, Training time: 14248.4108\n",
      "Epoch : 1228/2000 data_batch_2,  Train_loss : 4649.1841  Test_loss : 5033.7036, Time/batch_file : 2.3161, Training time: 14250.7270\n",
      "Epoch : 1228/2000 data_batch_3,  Train_loss : 4817.2178  Test_loss : 4981.1177, Time/batch_file : 2.2916, Training time: 14253.0188\n",
      "Epoch : 1228/2000 data_batch_4,  Train_loss : 5002.6396  Test_loss : 5076.9824, Time/batch_file : 2.3136, Training time: 14255.3327\n",
      "Epoch : 1228/2000 data_batch_5,  Train_loss : 4696.9980  Test_loss : 4734.2471, Time/batch_file : 2.2916, Training time: 14257.6245\n",
      "Epoch : 1229/2000 data_batch_1,  Train_loss : 4840.4854  Test_loss : 5313.5195, Time/batch_file : 2.3157, Training time: 14259.9404\n",
      "Epoch : 1229/2000 data_batch_2,  Train_loss : 4571.3892  Test_loss : 5492.7065, Time/batch_file : 2.2847, Training time: 14262.2252\n",
      "Epoch : 1229/2000 data_batch_3,  Train_loss : 5182.9736  Test_loss : 4882.8223, Time/batch_file : 2.3092, Training time: 14264.5346\n",
      "Epoch : 1229/2000 data_batch_4,  Train_loss : 5075.1318  Test_loss : 5343.9453, Time/batch_file : 2.2894, Training time: 14266.8242\n",
      "Epoch : 1229/2000 data_batch_5,  Train_loss : 4903.8101  Test_loss : 5257.6577, Time/batch_file : 2.3208, Training time: 14269.1452\n",
      "Epoch : 1230/2000 data_batch_1,  Train_loss : 4370.2256  Test_loss : 5058.9194, Time/batch_file : 2.2816, Training time: 14271.4270\n",
      "Epoch : 1230/2000 data_batch_2,  Train_loss : 4391.5791  Test_loss : 4772.4287, Time/batch_file : 2.3148, Training time: 14273.7422\n",
      "Epoch : 1230/2000 data_batch_3,  Train_loss : 4621.1348  Test_loss : 4626.2773, Time/batch_file : 2.2901, Training time: 14276.0325\n",
      "Epoch : 1230/2000 data_batch_4,  Train_loss : 4309.1235  Test_loss : 4760.3105, Time/batch_file : 2.3046, Training time: 14278.3373\n",
      "Epoch : 1230/2000 data_batch_5,  Train_loss : 4524.1089  Test_loss : 4953.0649, Time/batch_file : 2.2814, Training time: 14280.6190\n",
      "[./nets/net-1230.ckpt] SAVED\n",
      "Epoch : 1231/2000 data_batch_1,  Train_loss : 4838.1406  Test_loss : 4458.7202, Time/batch_file : 2.3005, Training time: 14284.2239\n",
      "Epoch : 1231/2000 data_batch_2,  Train_loss : 4797.8281  Test_loss : 4533.5112, Time/batch_file : 2.2583, Training time: 14286.4824\n",
      "Epoch : 1231/2000 data_batch_3,  Train_loss : 5006.4023  Test_loss : 4552.2666, Time/batch_file : 2.2558, Training time: 14288.7384\n",
      "Epoch : 1231/2000 data_batch_4,  Train_loss : 4535.0605  Test_loss : 4515.7944, Time/batch_file : 2.2867, Training time: 14291.0253\n",
      "Epoch : 1231/2000 data_batch_5,  Train_loss : 4925.5361  Test_loss : 4640.9878, Time/batch_file : 2.2469, Training time: 14293.2723\n",
      "Epoch : 1232/2000 data_batch_1,  Train_loss : 5177.8496  Test_loss : 5172.7910, Time/batch_file : 2.2832, Training time: 14295.5557\n",
      "Epoch : 1232/2000 data_batch_2,  Train_loss : 5190.8623  Test_loss : 4925.2529, Time/batch_file : 2.2680, Training time: 14297.8239\n",
      "Epoch : 1232/2000 data_batch_3,  Train_loss : 4766.8179  Test_loss : 5114.0317, Time/batch_file : 2.2760, Training time: 14300.1001\n",
      "Epoch : 1232/2000 data_batch_4,  Train_loss : 5046.4219  Test_loss : 5415.3740, Time/batch_file : 2.2689, Training time: 14302.3691\n",
      "Epoch : 1232/2000 data_batch_5,  Train_loss : 4992.1450  Test_loss : 5165.4375, Time/batch_file : 2.2709, Training time: 14304.6403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1233/2000 data_batch_1,  Train_loss : 4914.3574  Test_loss : 5167.2168, Time/batch_file : 2.2591, Training time: 14306.8996\n",
      "Epoch : 1233/2000 data_batch_2,  Train_loss : 4869.0571  Test_loss : 4970.7554, Time/batch_file : 2.2742, Training time: 14309.1741\n",
      "Epoch : 1233/2000 data_batch_3,  Train_loss : 4771.6670  Test_loss : 4984.5957, Time/batch_file : 2.2626, Training time: 14311.4369\n",
      "Epoch : 1233/2000 data_batch_4,  Train_loss : 5017.8281  Test_loss : 5026.1084, Time/batch_file : 2.2672, Training time: 14313.7042\n",
      "Epoch : 1233/2000 data_batch_5,  Train_loss : 4893.1294  Test_loss : 5202.4844, Time/batch_file : 2.2690, Training time: 14315.9734\n",
      "Epoch : 1234/2000 data_batch_1,  Train_loss : 4834.7505  Test_loss : 5099.8828, Time/batch_file : 2.2715, Training time: 14318.2452\n",
      "Epoch : 1234/2000 data_batch_2,  Train_loss : 5079.2822  Test_loss : 4963.4292, Time/batch_file : 2.2568, Training time: 14320.5021\n",
      "Epoch : 1234/2000 data_batch_3,  Train_loss : 4980.0659  Test_loss : 5249.6406, Time/batch_file : 2.2693, Training time: 14322.7715\n",
      "Epoch : 1234/2000 data_batch_4,  Train_loss : 4646.9780  Test_loss : 5377.3252, Time/batch_file : 2.2697, Training time: 14325.0414\n",
      "Epoch : 1234/2000 data_batch_5,  Train_loss : 4926.3682  Test_loss : 5090.8477, Time/batch_file : 2.2698, Training time: 14327.3115\n",
      "Epoch : 1235/2000 data_batch_1,  Train_loss : 5085.5005  Test_loss : 5020.1587, Time/batch_file : 2.2596, Training time: 14329.5714\n",
      "Epoch : 1235/2000 data_batch_2,  Train_loss : 4678.4277  Test_loss : 5373.2124, Time/batch_file : 2.2666, Training time: 14331.8383\n",
      "Epoch : 1235/2000 data_batch_3,  Train_loss : 4722.5576  Test_loss : 5202.3174, Time/batch_file : 2.2650, Training time: 14334.1034\n",
      "Epoch : 1235/2000 data_batch_4,  Train_loss : 4756.7349  Test_loss : 5114.5039, Time/batch_file : 2.2750, Training time: 14336.3786\n",
      "Epoch : 1235/2000 data_batch_5,  Train_loss : 4409.3594  Test_loss : 5232.0298, Time/batch_file : 2.2722, Training time: 14338.6511\n",
      "Epoch : 1236/2000 data_batch_1,  Train_loss : 4794.6406  Test_loss : 4708.0664, Time/batch_file : 2.2625, Training time: 14340.9138\n",
      "Epoch : 1236/2000 data_batch_2,  Train_loss : 4617.8950  Test_loss : 4750.7344, Time/batch_file : 2.2630, Training time: 14343.1770\n",
      "Epoch : 1236/2000 data_batch_3,  Train_loss : 5123.1646  Test_loss : 5042.8438, Time/batch_file : 2.2899, Training time: 14345.4671\n",
      "Epoch : 1236/2000 data_batch_4,  Train_loss : 4889.2485  Test_loss : 4970.6001, Time/batch_file : 2.2611, Training time: 14347.7283\n",
      "Epoch : 1236/2000 data_batch_5,  Train_loss : 4810.2793  Test_loss : 5152.9531, Time/batch_file : 2.2792, Training time: 14350.0078\n",
      "Epoch : 1237/2000 data_batch_1,  Train_loss : 4934.5903  Test_loss : 4819.8857, Time/batch_file : 2.2700, Training time: 14352.2780\n",
      "Epoch : 1237/2000 data_batch_2,  Train_loss : 4710.5957  Test_loss : 4693.1162, Time/batch_file : 2.2753, Training time: 14354.5535\n",
      "Epoch : 1237/2000 data_batch_3,  Train_loss : 4606.6470  Test_loss : 4800.5459, Time/batch_file : 2.2804, Training time: 14356.8342\n",
      "Epoch : 1237/2000 data_batch_4,  Train_loss : 4872.5986  Test_loss : 4851.3379, Time/batch_file : 2.2905, Training time: 14359.1249\n",
      "Epoch : 1237/2000 data_batch_5,  Train_loss : 4663.7500  Test_loss : 5225.4927, Time/batch_file : 2.2671, Training time: 14361.3921\n",
      "Epoch : 1238/2000 data_batch_1,  Train_loss : 4840.9902  Test_loss : 4615.5762, Time/batch_file : 2.2586, Training time: 14363.6509\n",
      "Epoch : 1238/2000 data_batch_2,  Train_loss : 5136.7129  Test_loss : 5064.1738, Time/batch_file : 2.2649, Training time: 14365.9160\n",
      "Epoch : 1238/2000 data_batch_3,  Train_loss : 5157.7524  Test_loss : 4844.5654, Time/batch_file : 2.2621, Training time: 14368.1783\n",
      "Epoch : 1238/2000 data_batch_4,  Train_loss : 4934.1099  Test_loss : 5011.4268, Time/batch_file : 2.2656, Training time: 14370.4441\n",
      "Epoch : 1238/2000 data_batch_5,  Train_loss : 4891.2285  Test_loss : 4814.6465, Time/batch_file : 2.2704, Training time: 14372.7147\n",
      "Epoch : 1239/2000 data_batch_1,  Train_loss : 4553.4980  Test_loss : 5355.4492, Time/batch_file : 2.2716, Training time: 14374.9865\n",
      "Epoch : 1239/2000 data_batch_2,  Train_loss : 4407.5869  Test_loss : 5378.7808, Time/batch_file : 2.2697, Training time: 14377.2564\n",
      "Epoch : 1239/2000 data_batch_3,  Train_loss : 4496.7617  Test_loss : 5578.8062, Time/batch_file : 2.2731, Training time: 14379.5297\n",
      "Epoch : 1239/2000 data_batch_4,  Train_loss : 4749.4507  Test_loss : 5308.6611, Time/batch_file : 2.2671, Training time: 14381.7970\n",
      "Epoch : 1239/2000 data_batch_5,  Train_loss : 4515.3457  Test_loss : 5147.1309, Time/batch_file : 2.2638, Training time: 14384.0609\n",
      "Epoch : 1240/2000 data_batch_1,  Train_loss : 5082.1099  Test_loss : 5333.0415, Time/batch_file : 2.2771, Training time: 14386.3383\n",
      "Epoch : 1240/2000 data_batch_2,  Train_loss : 4646.7642  Test_loss : 5235.0098, Time/batch_file : 2.2684, Training time: 14388.6069\n",
      "Epoch : 1240/2000 data_batch_3,  Train_loss : 4852.9258  Test_loss : 5142.8330, Time/batch_file : 2.2721, Training time: 14390.8792\n",
      "Epoch : 1240/2000 data_batch_4,  Train_loss : 4879.4531  Test_loss : 5390.6646, Time/batch_file : 2.2672, Training time: 14393.1466\n",
      "Epoch : 1240/2000 data_batch_5,  Train_loss : 4893.6265  Test_loss : 5207.4673, Time/batch_file : 2.2663, Training time: 14395.4130\n",
      "[./nets/net-1240.ckpt] SAVED\n",
      "Epoch : 1241/2000 data_batch_1,  Train_loss : 4989.8584  Test_loss : 4399.6768, Time/batch_file : 2.3054, Training time: 14399.0066\n",
      "Epoch : 1241/2000 data_batch_2,  Train_loss : 4807.6309  Test_loss : 4620.4473, Time/batch_file : 2.2796, Training time: 14401.2864\n",
      "Epoch : 1241/2000 data_batch_3,  Train_loss : 4679.2783  Test_loss : 4536.3008, Time/batch_file : 2.2749, Training time: 14403.5615\n",
      "Epoch : 1241/2000 data_batch_4,  Train_loss : 4790.0298  Test_loss : 4575.3921, Time/batch_file : 2.2761, Training time: 14405.8378\n",
      "Epoch : 1241/2000 data_batch_5,  Train_loss : 4804.9619  Test_loss : 4397.4019, Time/batch_file : 2.2800, Training time: 14408.1180\n",
      "Epoch : 1242/2000 data_batch_1,  Train_loss : 4542.3999  Test_loss : 4714.1855, Time/batch_file : 2.2873, Training time: 14410.4054\n",
      "Epoch : 1242/2000 data_batch_2,  Train_loss : 4435.9883  Test_loss : 4505.5571, Time/batch_file : 2.2766, Training time: 14412.6822\n",
      "Epoch : 1242/2000 data_batch_3,  Train_loss : 4440.3076  Test_loss : 4487.4307, Time/batch_file : 2.2765, Training time: 14414.9590\n",
      "Epoch : 1242/2000 data_batch_4,  Train_loss : 4429.6406  Test_loss : 4452.0566, Time/batch_file : 2.2858, Training time: 14417.2449\n",
      "Epoch : 1242/2000 data_batch_5,  Train_loss : 4463.4414  Test_loss : 4628.5161, Time/batch_file : 2.2711, Training time: 14419.5162\n",
      "Epoch : 1243/2000 data_batch_1,  Train_loss : 4954.5176  Test_loss : 5304.6895, Time/batch_file : 2.3062, Training time: 14421.8227\n",
      "Epoch : 1243/2000 data_batch_2,  Train_loss : 4856.4404  Test_loss : 4901.2842, Time/batch_file : 2.2542, Training time: 14424.0771\n",
      "Epoch : 1243/2000 data_batch_3,  Train_loss : 4944.7710  Test_loss : 4838.9531, Time/batch_file : 2.2555, Training time: 14426.3328\n",
      "Epoch : 1243/2000 data_batch_4,  Train_loss : 4552.5859  Test_loss : 5289.6289, Time/batch_file : 2.2516, Training time: 14428.5846\n",
      "Epoch : 1243/2000 data_batch_5,  Train_loss : 4636.5728  Test_loss : 4984.3071, Time/batch_file : 2.2636, Training time: 14430.8485\n",
      "Epoch : 1244/2000 data_batch_1,  Train_loss : 4412.1494  Test_loss : 4718.9365, Time/batch_file : 2.2705, Training time: 14433.1192\n",
      "Epoch : 1244/2000 data_batch_2,  Train_loss : 4426.0366  Test_loss : 5149.2471, Time/batch_file : 2.2724, Training time: 14435.3918\n",
      "Epoch : 1244/2000 data_batch_3,  Train_loss : 4227.9243  Test_loss : 4395.5234, Time/batch_file : 2.2771, Training time: 14437.6691\n",
      "Epoch : 1244/2000 data_batch_4,  Train_loss : 4334.3901  Test_loss : 4635.1094, Time/batch_file : 2.2796, Training time: 14439.9490\n",
      "Epoch : 1244/2000 data_batch_5,  Train_loss : 4547.1548  Test_loss : 4492.5747, Time/batch_file : 2.2746, Training time: 14442.2238\n",
      "Epoch : 1245/2000 data_batch_1,  Train_loss : 4962.4277  Test_loss : 4919.1992, Time/batch_file : 2.2753, Training time: 14444.4994\n",
      "Epoch : 1245/2000 data_batch_2,  Train_loss : 5187.7402  Test_loss : 5020.6665, Time/batch_file : 2.2681, Training time: 14446.7677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1245/2000 data_batch_3,  Train_loss : 4907.4834  Test_loss : 4622.0503, Time/batch_file : 2.2760, Training time: 14449.0439\n",
      "Epoch : 1245/2000 data_batch_4,  Train_loss : 5065.5776  Test_loss : 4768.5054, Time/batch_file : 2.2816, Training time: 14451.3257\n",
      "Epoch : 1245/2000 data_batch_5,  Train_loss : 4863.6313  Test_loss : 4915.5771, Time/batch_file : 2.2604, Training time: 14453.5864\n",
      "Epoch : 1246/2000 data_batch_1,  Train_loss : 4642.4883  Test_loss : 5354.6597, Time/batch_file : 2.2773, Training time: 14455.8639\n",
      "Epoch : 1246/2000 data_batch_2,  Train_loss : 4532.8491  Test_loss : 5557.2856, Time/batch_file : 2.2806, Training time: 14458.1447\n",
      "Epoch : 1246/2000 data_batch_3,  Train_loss : 4802.9014  Test_loss : 5108.1260, Time/batch_file : 2.2694, Training time: 14460.4144\n",
      "Epoch : 1246/2000 data_batch_4,  Train_loss : 4785.1841  Test_loss : 5186.1172, Time/batch_file : 2.2684, Training time: 14462.6830\n",
      "Epoch : 1246/2000 data_batch_5,  Train_loss : 4774.8857  Test_loss : 5600.8125, Time/batch_file : 2.2806, Training time: 14464.9637\n",
      "Epoch : 1247/2000 data_batch_1,  Train_loss : 4614.8682  Test_loss : 4989.5693, Time/batch_file : 2.2644, Training time: 14467.2282\n",
      "Epoch : 1247/2000 data_batch_2,  Train_loss : 4665.5801  Test_loss : 5272.1299, Time/batch_file : 2.2786, Training time: 14469.5070\n",
      "Epoch : 1247/2000 data_batch_3,  Train_loss : 4838.4189  Test_loss : 5089.6602, Time/batch_file : 2.2824, Training time: 14471.7894\n",
      "Epoch : 1247/2000 data_batch_4,  Train_loss : 4856.4395  Test_loss : 4877.4575, Time/batch_file : 2.2727, Training time: 14474.0622\n",
      "Epoch : 1247/2000 data_batch_5,  Train_loss : 4541.5605  Test_loss : 4989.5732, Time/batch_file : 2.2968, Training time: 14476.3592\n",
      "Epoch : 1248/2000 data_batch_1,  Train_loss : 4659.9961  Test_loss : 4408.3838, Time/batch_file : 2.2595, Training time: 14478.6189\n",
      "Epoch : 1248/2000 data_batch_2,  Train_loss : 4539.9072  Test_loss : 4515.7480, Time/batch_file : 2.2789, Training time: 14480.8980\n",
      "Epoch : 1248/2000 data_batch_3,  Train_loss : 4730.6914  Test_loss : 4564.1670, Time/batch_file : 2.2592, Training time: 14483.1574\n",
      "Epoch : 1248/2000 data_batch_4,  Train_loss : 4526.7197  Test_loss : 4600.4009, Time/batch_file : 2.2688, Training time: 14485.4263\n",
      "Epoch : 1248/2000 data_batch_5,  Train_loss : 4683.0723  Test_loss : 4857.9922, Time/batch_file : 2.2653, Training time: 14487.6918\n",
      "Epoch : 1249/2000 data_batch_1,  Train_loss : 4895.6689  Test_loss : 4389.3003, Time/batch_file : 2.2956, Training time: 14489.9876\n",
      "Epoch : 1249/2000 data_batch_2,  Train_loss : 5090.3423  Test_loss : 4420.0537, Time/batch_file : 2.2868, Training time: 14492.2745\n",
      "Epoch : 1249/2000 data_batch_3,  Train_loss : 5033.4082  Test_loss : 4951.1089, Time/batch_file : 2.2893, Training time: 14494.5641\n",
      "Epoch : 1249/2000 data_batch_4,  Train_loss : 4882.9883  Test_loss : 4650.9434, Time/batch_file : 2.2846, Training time: 14496.8489\n",
      "Epoch : 1249/2000 data_batch_5,  Train_loss : 5098.3096  Test_loss : 4766.9795, Time/batch_file : 2.2898, Training time: 14499.1388\n",
      "Epoch : 1250/2000 data_batch_1,  Train_loss : 4476.0869  Test_loss : 5536.9014, Time/batch_file : 2.2714, Training time: 14501.4104\n",
      "Epoch : 1250/2000 data_batch_2,  Train_loss : 4726.9878  Test_loss : 5483.9585, Time/batch_file : 2.2691, Training time: 14503.6797\n",
      "Epoch : 1250/2000 data_batch_3,  Train_loss : 4578.1040  Test_loss : 5146.7280, Time/batch_file : 2.2889, Training time: 14505.9688\n",
      "Epoch : 1250/2000 data_batch_4,  Train_loss : 4818.2969  Test_loss : 5015.2344, Time/batch_file : 2.2612, Training time: 14508.2302\n",
      "Epoch : 1250/2000 data_batch_5,  Train_loss : 4434.3604  Test_loss : 5478.1953, Time/batch_file : 2.2805, Training time: 14510.5108\n",
      "[./nets/net-1250.ckpt] SAVED\n",
      "Epoch : 1251/2000 data_batch_1,  Train_loss : 4865.6152  Test_loss : 4732.6089, Time/batch_file : 2.3553, Training time: 14514.1743\n",
      "Epoch : 1251/2000 data_batch_2,  Train_loss : 4893.4102  Test_loss : 4644.4570, Time/batch_file : 2.2695, Training time: 14516.4440\n",
      "Epoch : 1251/2000 data_batch_3,  Train_loss : 4775.1807  Test_loss : 4865.1030, Time/batch_file : 2.2752, Training time: 14518.7193\n",
      "Epoch : 1251/2000 data_batch_4,  Train_loss : 4926.1611  Test_loss : 4683.0059, Time/batch_file : 2.2772, Training time: 14520.9967\n",
      "Epoch : 1251/2000 data_batch_5,  Train_loss : 5000.4155  Test_loss : 4605.4229, Time/batch_file : 2.2709, Training time: 14523.2678\n",
      "Epoch : 1252/2000 data_batch_1,  Train_loss : 5266.1519  Test_loss : 5142.5796, Time/batch_file : 2.2750, Training time: 14525.5431\n",
      "Epoch : 1252/2000 data_batch_2,  Train_loss : 4839.4956  Test_loss : 5249.0713, Time/batch_file : 2.2753, Training time: 14527.8186\n",
      "Epoch : 1252/2000 data_batch_3,  Train_loss : 5082.3701  Test_loss : 4865.7749, Time/batch_file : 2.2784, Training time: 14530.0971\n",
      "Epoch : 1252/2000 data_batch_4,  Train_loss : 5027.0181  Test_loss : 4990.2324, Time/batch_file : 2.2832, Training time: 14532.3805\n",
      "Epoch : 1252/2000 data_batch_5,  Train_loss : 4866.7939  Test_loss : 4981.5586, Time/batch_file : 2.2787, Training time: 14534.6594\n",
      "Epoch : 1253/2000 data_batch_1,  Train_loss : 4547.7173  Test_loss : 4884.2710, Time/batch_file : 2.2737, Training time: 14536.9334\n",
      "Epoch : 1253/2000 data_batch_2,  Train_loss : 4382.6270  Test_loss : 4715.6309, Time/batch_file : 2.2821, Training time: 14539.2157\n",
      "Epoch : 1253/2000 data_batch_3,  Train_loss : 4201.8047  Test_loss : 4879.2949, Time/batch_file : 2.2861, Training time: 14541.5020\n",
      "Epoch : 1253/2000 data_batch_4,  Train_loss : 4272.9111  Test_loss : 4583.2832, Time/batch_file : 2.2845, Training time: 14543.7867\n",
      "Epoch : 1253/2000 data_batch_5,  Train_loss : 4180.4561  Test_loss : 4662.3677, Time/batch_file : 2.2787, Training time: 14546.0656\n",
      "Epoch : 1254/2000 data_batch_1,  Train_loss : 4619.1084  Test_loss : 5009.4863, Time/batch_file : 2.2818, Training time: 14548.3477\n",
      "Epoch : 1254/2000 data_batch_2,  Train_loss : 4804.8906  Test_loss : 5223.1689, Time/batch_file : 2.2814, Training time: 14550.6292\n",
      "Epoch : 1254/2000 data_batch_3,  Train_loss : 4947.1084  Test_loss : 5145.2212, Time/batch_file : 2.2858, Training time: 14552.9152\n",
      "Epoch : 1254/2000 data_batch_4,  Train_loss : 4792.4146  Test_loss : 4908.3203, Time/batch_file : 2.2739, Training time: 14555.1893\n",
      "Epoch : 1254/2000 data_batch_5,  Train_loss : 4696.7939  Test_loss : 5103.6797, Time/batch_file : 2.2747, Training time: 14557.4642\n",
      "Epoch : 1255/2000 data_batch_1,  Train_loss : 5299.9570  Test_loss : 4743.9648, Time/batch_file : 2.2869, Training time: 14559.7513\n",
      "Epoch : 1255/2000 data_batch_2,  Train_loss : 5430.7651  Test_loss : 4595.7036, Time/batch_file : 2.2860, Training time: 14562.0375\n",
      "Epoch : 1255/2000 data_batch_3,  Train_loss : 5387.3892  Test_loss : 4391.0415, Time/batch_file : 2.2935, Training time: 14564.3312\n",
      "Epoch : 1255/2000 data_batch_4,  Train_loss : 5110.6177  Test_loss : 4445.9087, Time/batch_file : 2.2946, Training time: 14566.6260\n",
      "Epoch : 1255/2000 data_batch_5,  Train_loss : 5327.0088  Test_loss : 4404.9521, Time/batch_file : 2.2907, Training time: 14568.9169\n",
      "Epoch : 1256/2000 data_batch_1,  Train_loss : 5066.8325  Test_loss : 5245.8779, Time/batch_file : 2.2824, Training time: 14571.1995\n",
      "Epoch : 1256/2000 data_batch_2,  Train_loss : 5211.3569  Test_loss : 5012.1846, Time/batch_file : 2.2692, Training time: 14573.4688\n",
      "Epoch : 1256/2000 data_batch_3,  Train_loss : 5144.1489  Test_loss : 5197.7119, Time/batch_file : 2.2932, Training time: 14575.7622\n",
      "Epoch : 1256/2000 data_batch_4,  Train_loss : 5050.8643  Test_loss : 5349.5430, Time/batch_file : 2.2904, Training time: 14578.0528\n",
      "Epoch : 1256/2000 data_batch_5,  Train_loss : 4994.0776  Test_loss : 4928.3491, Time/batch_file : 2.2813, Training time: 14580.3345\n",
      "Epoch : 1257/2000 data_batch_1,  Train_loss : 4443.7939  Test_loss : 4310.5293, Time/batch_file : 2.2668, Training time: 14582.6014\n",
      "Epoch : 1257/2000 data_batch_2,  Train_loss : 4594.0723  Test_loss : 4229.9731, Time/batch_file : 2.2811, Training time: 14584.8827\n",
      "Epoch : 1257/2000 data_batch_3,  Train_loss : 4252.4902  Test_loss : 4623.4004, Time/batch_file : 2.2697, Training time: 14587.1527\n",
      "Epoch : 1257/2000 data_batch_4,  Train_loss : 4298.2515  Test_loss : 4146.6455, Time/batch_file : 2.2894, Training time: 14589.4422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1257/2000 data_batch_5,  Train_loss : 4443.1958  Test_loss : 4454.4805, Time/batch_file : 2.2719, Training time: 14591.7143\n",
      "Epoch : 1258/2000 data_batch_1,  Train_loss : 4235.9316  Test_loss : 4493.0674, Time/batch_file : 2.2791, Training time: 14593.9935\n",
      "Epoch : 1258/2000 data_batch_2,  Train_loss : 4335.0054  Test_loss : 4830.9131, Time/batch_file : 2.2794, Training time: 14596.2733\n",
      "Epoch : 1258/2000 data_batch_3,  Train_loss : 4526.1177  Test_loss : 4546.5879, Time/batch_file : 2.2748, Training time: 14598.5483\n",
      "Epoch : 1258/2000 data_batch_4,  Train_loss : 4495.5576  Test_loss : 4999.9082, Time/batch_file : 2.2665, Training time: 14600.8149\n",
      "Epoch : 1258/2000 data_batch_5,  Train_loss : 4642.8003  Test_loss : 4875.2832, Time/batch_file : 2.2757, Training time: 14603.0908\n",
      "Epoch : 1259/2000 data_batch_1,  Train_loss : 5134.5244  Test_loss : 5124.5918, Time/batch_file : 2.2836, Training time: 14605.3746\n",
      "Epoch : 1259/2000 data_batch_2,  Train_loss : 5115.7505  Test_loss : 5040.7998, Time/batch_file : 2.2791, Training time: 14607.6539\n",
      "Epoch : 1259/2000 data_batch_3,  Train_loss : 5270.8604  Test_loss : 5133.8477, Time/batch_file : 2.2833, Training time: 14609.9374\n",
      "Epoch : 1259/2000 data_batch_4,  Train_loss : 5228.8721  Test_loss : 5076.2988, Time/batch_file : 2.2776, Training time: 14612.2151\n",
      "Epoch : 1259/2000 data_batch_5,  Train_loss : 5126.3418  Test_loss : 5196.1797, Time/batch_file : 2.2743, Training time: 14614.4896\n",
      "Epoch : 1260/2000 data_batch_1,  Train_loss : 4918.0869  Test_loss : 4960.9697, Time/batch_file : 2.2705, Training time: 14616.7604\n",
      "Epoch : 1260/2000 data_batch_2,  Train_loss : 5026.4224  Test_loss : 4973.0771, Time/batch_file : 2.2556, Training time: 14619.0161\n",
      "Epoch : 1260/2000 data_batch_3,  Train_loss : 4874.7676  Test_loss : 4974.8750, Time/batch_file : 2.2665, Training time: 14621.2828\n",
      "Epoch : 1260/2000 data_batch_4,  Train_loss : 4729.8208  Test_loss : 5054.5020, Time/batch_file : 2.2663, Training time: 14623.5494\n",
      "Epoch : 1260/2000 data_batch_5,  Train_loss : 5064.6094  Test_loss : 5258.4380, Time/batch_file : 2.2810, Training time: 14625.8306\n",
      "[./nets/net-1260.ckpt] SAVED\n",
      "Epoch : 1261/2000 data_batch_1,  Train_loss : 4325.5913  Test_loss : 5073.8325, Time/batch_file : 2.4336, Training time: 14629.5287\n",
      "Epoch : 1261/2000 data_batch_2,  Train_loss : 4293.3149  Test_loss : 4944.3081, Time/batch_file : 2.2803, Training time: 14631.8092\n",
      "Epoch : 1261/2000 data_batch_3,  Train_loss : 4560.2197  Test_loss : 5149.1201, Time/batch_file : 2.2676, Training time: 14634.0770\n",
      "Epoch : 1261/2000 data_batch_4,  Train_loss : 4264.5151  Test_loss : 4992.9644, Time/batch_file : 2.2849, Training time: 14636.3621\n",
      "Epoch : 1261/2000 data_batch_5,  Train_loss : 4348.2744  Test_loss : 5137.6060, Time/batch_file : 2.2765, Training time: 14638.6389\n",
      "Epoch : 1262/2000 data_batch_1,  Train_loss : 4568.6943  Test_loss : 4925.2979, Time/batch_file : 2.2774, Training time: 14640.9165\n",
      "Epoch : 1262/2000 data_batch_2,  Train_loss : 4460.7246  Test_loss : 5418.6226, Time/batch_file : 2.2804, Training time: 14643.1971\n",
      "Epoch : 1262/2000 data_batch_3,  Train_loss : 4654.0225  Test_loss : 5180.7871, Time/batch_file : 2.3019, Training time: 14645.4992\n",
      "Epoch : 1262/2000 data_batch_4,  Train_loss : 4291.2305  Test_loss : 4879.2671, Time/batch_file : 2.2884, Training time: 14647.7878\n",
      "Epoch : 1262/2000 data_batch_5,  Train_loss : 4449.7681  Test_loss : 4942.7959, Time/batch_file : 2.2789, Training time: 14650.0670\n",
      "Epoch : 1263/2000 data_batch_1,  Train_loss : 4231.4399  Test_loss : 4943.2930, Time/batch_file : 2.2812, Training time: 14652.3484\n",
      "Epoch : 1263/2000 data_batch_2,  Train_loss : 4132.2886  Test_loss : 4972.2383, Time/batch_file : 2.2941, Training time: 14654.6427\n",
      "Epoch : 1263/2000 data_batch_3,  Train_loss : 4596.1655  Test_loss : 5041.5117, Time/batch_file : 2.2687, Training time: 14656.9115\n",
      "Epoch : 1263/2000 data_batch_4,  Train_loss : 4264.5488  Test_loss : 5099.1191, Time/batch_file : 2.2774, Training time: 14659.1892\n",
      "Epoch : 1263/2000 data_batch_5,  Train_loss : 4200.5552  Test_loss : 4757.3428, Time/batch_file : 2.2813, Training time: 14661.4707\n",
      "Epoch : 1264/2000 data_batch_1,  Train_loss : 4562.9224  Test_loss : 5681.0312, Time/batch_file : 2.2877, Training time: 14663.7586\n",
      "Epoch : 1264/2000 data_batch_2,  Train_loss : 4774.2344  Test_loss : 5534.5464, Time/batch_file : 2.2965, Training time: 14666.0553\n",
      "Epoch : 1264/2000 data_batch_3,  Train_loss : 4726.1719  Test_loss : 5917.9131, Time/batch_file : 2.2785, Training time: 14668.3339\n",
      "Epoch : 1264/2000 data_batch_4,  Train_loss : 4685.7520  Test_loss : 5448.5498, Time/batch_file : 2.2933, Training time: 14670.6273\n",
      "Epoch : 1264/2000 data_batch_5,  Train_loss : 4682.8242  Test_loss : 5888.7036, Time/batch_file : 2.2959, Training time: 14672.9234\n",
      "Epoch : 1265/2000 data_batch_1,  Train_loss : 4967.2295  Test_loss : 5153.9629, Time/batch_file : 2.2883, Training time: 14675.2119\n",
      "Epoch : 1265/2000 data_batch_2,  Train_loss : 5002.4668  Test_loss : 5249.8438, Time/batch_file : 2.2892, Training time: 14677.5013\n",
      "Epoch : 1265/2000 data_batch_3,  Train_loss : 4664.8647  Test_loss : 4935.8086, Time/batch_file : 2.3067, Training time: 14679.8083\n",
      "Epoch : 1265/2000 data_batch_4,  Train_loss : 5019.9043  Test_loss : 4974.3193, Time/batch_file : 2.2978, Training time: 14682.1061\n",
      "Epoch : 1265/2000 data_batch_5,  Train_loss : 5307.2598  Test_loss : 5159.4268, Time/batch_file : 2.2887, Training time: 14684.3951\n",
      "Epoch : 1266/2000 data_batch_1,  Train_loss : 4868.6245  Test_loss : 4857.5835, Time/batch_file : 2.2640, Training time: 14686.6593\n",
      "Epoch : 1266/2000 data_batch_2,  Train_loss : 5080.6587  Test_loss : 4982.7642, Time/batch_file : 2.2764, Training time: 14688.9359\n",
      "Epoch : 1266/2000 data_batch_3,  Train_loss : 4828.1855  Test_loss : 4897.5957, Time/batch_file : 2.2674, Training time: 14691.2035\n",
      "Epoch : 1266/2000 data_batch_4,  Train_loss : 4897.5703  Test_loss : 4937.9268, Time/batch_file : 2.2717, Training time: 14693.4753\n",
      "Epoch : 1266/2000 data_batch_5,  Train_loss : 4745.1240  Test_loss : 4905.1514, Time/batch_file : 2.2690, Training time: 14695.7445\n",
      "Epoch : 1267/2000 data_batch_1,  Train_loss : 5025.9697  Test_loss : 5281.7666, Time/batch_file : 2.2754, Training time: 14698.0201\n",
      "Epoch : 1267/2000 data_batch_2,  Train_loss : 4922.4463  Test_loss : 4869.2656, Time/batch_file : 2.2726, Training time: 14700.2930\n",
      "Epoch : 1267/2000 data_batch_3,  Train_loss : 4938.1553  Test_loss : 5161.1616, Time/batch_file : 2.2883, Training time: 14702.5815\n",
      "Epoch : 1267/2000 data_batch_4,  Train_loss : 4924.8384  Test_loss : 5266.5137, Time/batch_file : 2.2656, Training time: 14704.8473\n",
      "Epoch : 1267/2000 data_batch_5,  Train_loss : 5051.1982  Test_loss : 5406.2783, Time/batch_file : 2.2675, Training time: 14707.1150\n",
      "Epoch : 1268/2000 data_batch_1,  Train_loss : 4649.0020  Test_loss : 5776.9741, Time/batch_file : 2.2749, Training time: 14709.3901\n",
      "Epoch : 1268/2000 data_batch_2,  Train_loss : 4930.1187  Test_loss : 5442.6758, Time/batch_file : 2.2688, Training time: 14711.6591\n",
      "Epoch : 1268/2000 data_batch_3,  Train_loss : 4869.6499  Test_loss : 5519.9512, Time/batch_file : 2.2769, Training time: 14713.9363\n",
      "Epoch : 1268/2000 data_batch_4,  Train_loss : 4728.4277  Test_loss : 5575.3794, Time/batch_file : 2.2795, Training time: 14716.2160\n",
      "Epoch : 1268/2000 data_batch_5,  Train_loss : 4835.2764  Test_loss : 5698.0024, Time/batch_file : 2.2998, Training time: 14718.5161\n",
      "Epoch : 1269/2000 data_batch_1,  Train_loss : 5173.6665  Test_loss : 4832.1025, Time/batch_file : 2.2996, Training time: 14720.8159\n",
      "Epoch : 1269/2000 data_batch_2,  Train_loss : 4958.4551  Test_loss : 4951.2080, Time/batch_file : 2.2743, Training time: 14723.0904\n",
      "Epoch : 1269/2000 data_batch_3,  Train_loss : 5013.8193  Test_loss : 4675.2534, Time/batch_file : 2.2782, Training time: 14725.3689\n",
      "Epoch : 1269/2000 data_batch_4,  Train_loss : 4913.2275  Test_loss : 4818.6416, Time/batch_file : 2.2939, Training time: 14727.6631\n",
      "Epoch : 1269/2000 data_batch_5,  Train_loss : 4803.5859  Test_loss : 4754.3276, Time/batch_file : 2.2724, Training time: 14729.9357\n",
      "Epoch : 1270/2000 data_batch_1,  Train_loss : 4650.6973  Test_loss : 5193.4854, Time/batch_file : 2.2769, Training time: 14732.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1270/2000 data_batch_2,  Train_loss : 4368.6943  Test_loss : 5062.5830, Time/batch_file : 2.2825, Training time: 14734.4955\n",
      "Epoch : 1270/2000 data_batch_3,  Train_loss : 4545.4771  Test_loss : 5114.3252, Time/batch_file : 2.2759, Training time: 14736.7716\n",
      "Epoch : 1270/2000 data_batch_4,  Train_loss : 4509.5605  Test_loss : 4914.5605, Time/batch_file : 2.2783, Training time: 14739.0500\n",
      "Epoch : 1270/2000 data_batch_5,  Train_loss : 4822.7891  Test_loss : 4967.1733, Time/batch_file : 2.2710, Training time: 14741.3212\n",
      "[./nets/net-1270.ckpt] SAVED\n",
      "Epoch : 1271/2000 data_batch_1,  Train_loss : 4924.5669  Test_loss : 5180.6079, Time/batch_file : 2.3039, Training time: 14744.9060\n",
      "Epoch : 1271/2000 data_batch_2,  Train_loss : 5000.4346  Test_loss : 5225.9595, Time/batch_file : 2.2826, Training time: 14747.1889\n",
      "Epoch : 1271/2000 data_batch_3,  Train_loss : 5081.8848  Test_loss : 5166.4507, Time/batch_file : 2.3077, Training time: 14749.4967\n",
      "Epoch : 1271/2000 data_batch_4,  Train_loss : 4941.1094  Test_loss : 5369.9907, Time/batch_file : 2.2732, Training time: 14751.7701\n",
      "Epoch : 1271/2000 data_batch_5,  Train_loss : 4954.5654  Test_loss : 5393.2969, Time/batch_file : 2.2853, Training time: 14754.0555\n",
      "Epoch : 1272/2000 data_batch_1,  Train_loss : 4722.7466  Test_loss : 5303.0029, Time/batch_file : 2.2852, Training time: 14756.3409\n",
      "Epoch : 1272/2000 data_batch_2,  Train_loss : 4588.6484  Test_loss : 4887.2803, Time/batch_file : 2.2901, Training time: 14758.6312\n",
      "Epoch : 1272/2000 data_batch_3,  Train_loss : 4683.4980  Test_loss : 5032.2080, Time/batch_file : 2.2829, Training time: 14760.9143\n",
      "Epoch : 1272/2000 data_batch_4,  Train_loss : 4881.9194  Test_loss : 5038.4097, Time/batch_file : 2.2932, Training time: 14763.2076\n",
      "Epoch : 1272/2000 data_batch_5,  Train_loss : 4821.6401  Test_loss : 4973.1235, Time/batch_file : 2.2862, Training time: 14765.4941\n",
      "Epoch : 1273/2000 data_batch_1,  Train_loss : 4518.5898  Test_loss : 4869.7773, Time/batch_file : 2.2831, Training time: 14767.7773\n",
      "Epoch : 1273/2000 data_batch_2,  Train_loss : 4385.0483  Test_loss : 4784.2632, Time/batch_file : 2.2740, Training time: 14770.0516\n",
      "Epoch : 1273/2000 data_batch_3,  Train_loss : 4246.7295  Test_loss : 4733.5151, Time/batch_file : 2.2864, Training time: 14772.3381\n",
      "Epoch : 1273/2000 data_batch_4,  Train_loss : 4384.8271  Test_loss : 5130.4150, Time/batch_file : 2.2884, Training time: 14774.6268\n",
      "Epoch : 1273/2000 data_batch_5,  Train_loss : 4329.8496  Test_loss : 4905.8770, Time/batch_file : 2.2892, Training time: 14776.9162\n",
      "Epoch : 1274/2000 data_batch_1,  Train_loss : 5161.7148  Test_loss : 5046.0308, Time/batch_file : 2.2807, Training time: 14779.1971\n",
      "Epoch : 1274/2000 data_batch_2,  Train_loss : 4868.2109  Test_loss : 4933.7866, Time/batch_file : 2.2833, Training time: 14781.4805\n",
      "Epoch : 1274/2000 data_batch_3,  Train_loss : 4956.3159  Test_loss : 5077.0679, Time/batch_file : 2.3073, Training time: 14783.7880\n",
      "Epoch : 1274/2000 data_batch_4,  Train_loss : 4947.4009  Test_loss : 5027.2852, Time/batch_file : 2.2989, Training time: 14786.0871\n",
      "Epoch : 1274/2000 data_batch_5,  Train_loss : 4919.4292  Test_loss : 5049.4878, Time/batch_file : 2.2851, Training time: 14788.3723\n",
      "Epoch : 1275/2000 data_batch_1,  Train_loss : 5077.4229  Test_loss : 5179.7231, Time/batch_file : 2.2845, Training time: 14790.6570\n",
      "Epoch : 1275/2000 data_batch_2,  Train_loss : 4989.5161  Test_loss : 5269.0366, Time/batch_file : 2.3031, Training time: 14792.9602\n",
      "Epoch : 1275/2000 data_batch_3,  Train_loss : 5146.6255  Test_loss : 5357.4946, Time/batch_file : 2.2968, Training time: 14795.2571\n",
      "Epoch : 1275/2000 data_batch_4,  Train_loss : 5530.6265  Test_loss : 5124.7773, Time/batch_file : 2.2905, Training time: 14797.5479\n",
      "Epoch : 1275/2000 data_batch_5,  Train_loss : 5291.1431  Test_loss : 5019.6045, Time/batch_file : 2.2866, Training time: 14799.8347\n",
      "Epoch : 1276/2000 data_batch_1,  Train_loss : 4491.0122  Test_loss : 5657.5225, Time/batch_file : 2.2825, Training time: 14802.1174\n",
      "Epoch : 1276/2000 data_batch_2,  Train_loss : 4574.5820  Test_loss : 5576.6113, Time/batch_file : 2.2749, Training time: 14804.3925\n",
      "Epoch : 1276/2000 data_batch_3,  Train_loss : 4876.8149  Test_loss : 5336.7354, Time/batch_file : 2.2720, Training time: 14806.6646\n",
      "Epoch : 1276/2000 data_batch_4,  Train_loss : 4888.5381  Test_loss : 5237.6836, Time/batch_file : 2.2943, Training time: 14808.9591\n",
      "Epoch : 1276/2000 data_batch_5,  Train_loss : 4657.1270  Test_loss : 5513.6025, Time/batch_file : 2.3014, Training time: 14811.2606\n",
      "Epoch : 1277/2000 data_batch_1,  Train_loss : 5052.9956  Test_loss : 4977.4023, Time/batch_file : 2.2833, Training time: 14813.5441\n",
      "Epoch : 1277/2000 data_batch_2,  Train_loss : 4843.6445  Test_loss : 5104.1826, Time/batch_file : 2.2770, Training time: 14815.8213\n",
      "Epoch : 1277/2000 data_batch_3,  Train_loss : 4924.1885  Test_loss : 5236.0151, Time/batch_file : 2.2942, Training time: 14818.1157\n",
      "Epoch : 1277/2000 data_batch_4,  Train_loss : 5083.7373  Test_loss : 5090.4980, Time/batch_file : 2.2987, Training time: 14820.4146\n",
      "Epoch : 1277/2000 data_batch_5,  Train_loss : 4960.7983  Test_loss : 5066.1973, Time/batch_file : 2.2940, Training time: 14822.7089\n",
      "Epoch : 1278/2000 data_batch_1,  Train_loss : 4141.5439  Test_loss : 4973.7720, Time/batch_file : 2.2773, Training time: 14824.9865\n",
      "Epoch : 1278/2000 data_batch_2,  Train_loss : 4320.3960  Test_loss : 5020.8408, Time/batch_file : 2.2850, Training time: 14827.2718\n",
      "Epoch : 1278/2000 data_batch_3,  Train_loss : 4357.5249  Test_loss : 4966.7646, Time/batch_file : 2.2890, Training time: 14829.5609\n",
      "Epoch : 1278/2000 data_batch_4,  Train_loss : 4266.7856  Test_loss : 5148.4648, Time/batch_file : 2.2726, Training time: 14831.8336\n",
      "Epoch : 1278/2000 data_batch_5,  Train_loss : 4210.9204  Test_loss : 5011.6895, Time/batch_file : 2.2825, Training time: 14834.1164\n",
      "Epoch : 1279/2000 data_batch_1,  Train_loss : 4752.7324  Test_loss : 5021.3965, Time/batch_file : 2.2910, Training time: 14836.4075\n",
      "Epoch : 1279/2000 data_batch_2,  Train_loss : 4907.6094  Test_loss : 5045.2720, Time/batch_file : 2.2905, Training time: 14838.6983\n",
      "Epoch : 1279/2000 data_batch_3,  Train_loss : 4896.7124  Test_loss : 5112.7700, Time/batch_file : 2.2832, Training time: 14840.9818\n",
      "Epoch : 1279/2000 data_batch_4,  Train_loss : 4742.3320  Test_loss : 5069.8457, Time/batch_file : 2.2776, Training time: 14843.2595\n",
      "Epoch : 1279/2000 data_batch_5,  Train_loss : 4835.8867  Test_loss : 5037.7354, Time/batch_file : 2.2858, Training time: 14845.5455\n",
      "Epoch : 1280/2000 data_batch_1,  Train_loss : 5000.8203  Test_loss : 4785.4609, Time/batch_file : 2.3031, Training time: 14847.8487\n",
      "Epoch : 1280/2000 data_batch_2,  Train_loss : 5236.3213  Test_loss : 5023.2344, Time/batch_file : 2.2933, Training time: 14850.1421\n",
      "Epoch : 1280/2000 data_batch_3,  Train_loss : 5214.1392  Test_loss : 5036.9570, Time/batch_file : 2.2851, Training time: 14852.4275\n",
      "Epoch : 1280/2000 data_batch_4,  Train_loss : 5119.3799  Test_loss : 5285.4141, Time/batch_file : 2.2987, Training time: 14854.7264\n",
      "Epoch : 1280/2000 data_batch_5,  Train_loss : 5103.0288  Test_loss : 5000.1372, Time/batch_file : 2.2934, Training time: 14857.0200\n",
      "[./nets/net-1280.ckpt] SAVED\n",
      "Epoch : 1281/2000 data_batch_1,  Train_loss : 5101.3613  Test_loss : 5143.5571, Time/batch_file : 2.3574, Training time: 14860.6578\n",
      "Epoch : 1281/2000 data_batch_2,  Train_loss : 5184.6074  Test_loss : 5230.0337, Time/batch_file : 2.3037, Training time: 14862.9618\n",
      "Epoch : 1281/2000 data_batch_3,  Train_loss : 4980.2949  Test_loss : 5133.6372, Time/batch_file : 2.3072, Training time: 14865.2693\n",
      "Epoch : 1281/2000 data_batch_4,  Train_loss : 4914.6831  Test_loss : 5157.1924, Time/batch_file : 2.2724, Training time: 14867.5419\n",
      "Epoch : 1281/2000 data_batch_5,  Train_loss : 5224.0757  Test_loss : 5280.3467, Time/batch_file : 2.2839, Training time: 14869.8259\n",
      "Epoch : 1282/2000 data_batch_1,  Train_loss : 4649.6992  Test_loss : 4796.9541, Time/batch_file : 2.2826, Training time: 14872.1086\n",
      "Epoch : 1282/2000 data_batch_2,  Train_loss : 5167.1982  Test_loss : 4953.1992, Time/batch_file : 2.3000, Training time: 14874.4089\n",
      "Epoch : 1282/2000 data_batch_3,  Train_loss : 5061.6128  Test_loss : 4913.2266, Time/batch_file : 2.2738, Training time: 14876.6829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1282/2000 data_batch_4,  Train_loss : 4755.5430  Test_loss : 4642.5801, Time/batch_file : 2.2699, Training time: 14878.9530\n",
      "Epoch : 1282/2000 data_batch_5,  Train_loss : 4671.9395  Test_loss : 4977.2207, Time/batch_file : 2.2811, Training time: 14881.2343\n",
      "Epoch : 1283/2000 data_batch_1,  Train_loss : 5033.4263  Test_loss : 5511.9316, Time/batch_file : 2.2879, Training time: 14883.5225\n",
      "Epoch : 1283/2000 data_batch_2,  Train_loss : 5320.6494  Test_loss : 5161.3398, Time/batch_file : 2.2760, Training time: 14885.7988\n",
      "Epoch : 1283/2000 data_batch_3,  Train_loss : 5140.3691  Test_loss : 5229.7642, Time/batch_file : 2.2898, Training time: 14888.0888\n",
      "Epoch : 1283/2000 data_batch_4,  Train_loss : 5036.9053  Test_loss : 5154.8906, Time/batch_file : 2.2738, Training time: 14890.3628\n",
      "Epoch : 1283/2000 data_batch_5,  Train_loss : 5039.3711  Test_loss : 5401.5566, Time/batch_file : 2.2864, Training time: 14892.6495\n",
      "Epoch : 1284/2000 data_batch_1,  Train_loss : 5365.0928  Test_loss : 5289.0820, Time/batch_file : 2.2871, Training time: 14894.9368\n",
      "Epoch : 1284/2000 data_batch_2,  Train_loss : 5586.1533  Test_loss : 5305.7656, Time/batch_file : 2.2719, Training time: 14897.2090\n",
      "Epoch : 1284/2000 data_batch_3,  Train_loss : 5174.3535  Test_loss : 5289.6738, Time/batch_file : 2.2795, Training time: 14899.4888\n",
      "Epoch : 1284/2000 data_batch_4,  Train_loss : 5154.6387  Test_loss : 5317.3066, Time/batch_file : 2.2828, Training time: 14901.7718\n",
      "Epoch : 1284/2000 data_batch_5,  Train_loss : 5347.4541  Test_loss : 5516.6123, Time/batch_file : 2.2745, Training time: 14904.0465\n",
      "Epoch : 1285/2000 data_batch_1,  Train_loss : 4950.2588  Test_loss : 5364.3960, Time/batch_file : 2.2719, Training time: 14906.3186\n",
      "Epoch : 1285/2000 data_batch_2,  Train_loss : 4960.8779  Test_loss : 5538.1909, Time/batch_file : 2.2634, Training time: 14908.5821\n",
      "Epoch : 1285/2000 data_batch_3,  Train_loss : 4655.5146  Test_loss : 5201.5454, Time/batch_file : 2.2696, Training time: 14910.8519\n",
      "Epoch : 1285/2000 data_batch_4,  Train_loss : 5002.0967  Test_loss : 5342.6738, Time/batch_file : 2.2680, Training time: 14913.1201\n",
      "Epoch : 1285/2000 data_batch_5,  Train_loss : 5029.1011  Test_loss : 5259.2900, Time/batch_file : 2.2700, Training time: 14915.3903\n",
      "Epoch : 1286/2000 data_batch_1,  Train_loss : 4581.8745  Test_loss : 5365.9248, Time/batch_file : 2.2634, Training time: 14917.6539\n",
      "Epoch : 1286/2000 data_batch_2,  Train_loss : 4564.4502  Test_loss : 5282.8716, Time/batch_file : 2.2705, Training time: 14919.9246\n",
      "Epoch : 1286/2000 data_batch_3,  Train_loss : 4597.4941  Test_loss : 5139.3818, Time/batch_file : 2.2632, Training time: 14922.1880\n",
      "Epoch : 1286/2000 data_batch_4,  Train_loss : 4513.4775  Test_loss : 5123.6401, Time/batch_file : 2.2643, Training time: 14924.4524\n",
      "Epoch : 1286/2000 data_batch_5,  Train_loss : 4712.5166  Test_loss : 5211.9634, Time/batch_file : 2.2765, Training time: 14926.7291\n",
      "Epoch : 1287/2000 data_batch_1,  Train_loss : 5194.9526  Test_loss : 4974.1074, Time/batch_file : 2.2805, Training time: 14929.0098\n",
      "Epoch : 1287/2000 data_batch_2,  Train_loss : 5233.3203  Test_loss : 5200.7031, Time/batch_file : 2.2829, Training time: 14931.2930\n",
      "Epoch : 1287/2000 data_batch_3,  Train_loss : 4980.0640  Test_loss : 5111.6533, Time/batch_file : 2.2764, Training time: 14933.5696\n",
      "Epoch : 1287/2000 data_batch_4,  Train_loss : 5079.9185  Test_loss : 5021.6133, Time/batch_file : 2.2916, Training time: 14935.8615\n",
      "Epoch : 1287/2000 data_batch_5,  Train_loss : 5054.2827  Test_loss : 5154.2075, Time/batch_file : 2.2975, Training time: 14938.1591\n",
      "Epoch : 1288/2000 data_batch_1,  Train_loss : 4929.2329  Test_loss : 4908.6372, Time/batch_file : 2.2879, Training time: 14940.4472\n",
      "Epoch : 1288/2000 data_batch_2,  Train_loss : 4862.9834  Test_loss : 4727.4277, Time/batch_file : 2.2872, Training time: 14942.7347\n",
      "Epoch : 1288/2000 data_batch_3,  Train_loss : 4810.1475  Test_loss : 4879.9189, Time/batch_file : 2.2843, Training time: 14945.0192\n",
      "Epoch : 1288/2000 data_batch_4,  Train_loss : 4977.5142  Test_loss : 5062.1826, Time/batch_file : 2.2997, Training time: 14947.3191\n",
      "Epoch : 1288/2000 data_batch_5,  Train_loss : 5053.8633  Test_loss : 4907.6763, Time/batch_file : 2.2835, Training time: 14949.6028\n",
      "Epoch : 1289/2000 data_batch_1,  Train_loss : 4918.4580  Test_loss : 4669.0830, Time/batch_file : 2.2682, Training time: 14951.8712\n",
      "Epoch : 1289/2000 data_batch_2,  Train_loss : 5050.3262  Test_loss : 5023.2441, Time/batch_file : 2.2708, Training time: 14954.1422\n",
      "Epoch : 1289/2000 data_batch_3,  Train_loss : 4937.5977  Test_loss : 5070.9668, Time/batch_file : 2.2724, Training time: 14956.4148\n",
      "Epoch : 1289/2000 data_batch_4,  Train_loss : 4949.5586  Test_loss : 4910.6904, Time/batch_file : 2.2625, Training time: 14958.6775\n",
      "Epoch : 1289/2000 data_batch_5,  Train_loss : 5009.5322  Test_loss : 4927.0845, Time/batch_file : 2.2737, Training time: 14960.9513\n",
      "Epoch : 1290/2000 data_batch_1,  Train_loss : 4524.8491  Test_loss : 5327.4995, Time/batch_file : 2.2648, Training time: 14963.2163\n",
      "Epoch : 1290/2000 data_batch_2,  Train_loss : 4490.7236  Test_loss : 5046.2998, Time/batch_file : 2.2781, Training time: 14965.4946\n",
      "Epoch : 1290/2000 data_batch_3,  Train_loss : 4221.6602  Test_loss : 4826.1030, Time/batch_file : 2.2643, Training time: 14967.7592\n",
      "Epoch : 1290/2000 data_batch_4,  Train_loss : 4467.8438  Test_loss : 5132.1436, Time/batch_file : 2.2615, Training time: 14970.0210\n",
      "Epoch : 1290/2000 data_batch_5,  Train_loss : 4330.8218  Test_loss : 5047.3950, Time/batch_file : 2.2688, Training time: 14972.2899\n",
      "[./nets/net-1290.ckpt] SAVED\n",
      "Epoch : 1291/2000 data_batch_1,  Train_loss : 5052.2036  Test_loss : 4908.5674, Time/batch_file : 2.3025, Training time: 14975.8822\n",
      "Epoch : 1291/2000 data_batch_2,  Train_loss : 5188.2808  Test_loss : 4673.8047, Time/batch_file : 2.2746, Training time: 14978.1570\n",
      "Epoch : 1291/2000 data_batch_3,  Train_loss : 5099.7935  Test_loss : 4701.3076, Time/batch_file : 2.2668, Training time: 14980.4240\n",
      "Epoch : 1291/2000 data_batch_4,  Train_loss : 5063.5327  Test_loss : 4744.6250, Time/batch_file : 2.2572, Training time: 14982.6814\n",
      "Epoch : 1291/2000 data_batch_5,  Train_loss : 4985.7896  Test_loss : 4815.4111, Time/batch_file : 2.2598, Training time: 14984.9414\n",
      "Epoch : 1292/2000 data_batch_1,  Train_loss : 4777.9844  Test_loss : 5251.8921, Time/batch_file : 2.2636, Training time: 14987.2052\n",
      "Epoch : 1292/2000 data_batch_2,  Train_loss : 4823.0767  Test_loss : 5133.6494, Time/batch_file : 2.2781, Training time: 14989.4836\n",
      "Epoch : 1292/2000 data_batch_3,  Train_loss : 5033.7339  Test_loss : 5135.1387, Time/batch_file : 2.2738, Training time: 14991.7576\n",
      "Epoch : 1292/2000 data_batch_4,  Train_loss : 4778.4648  Test_loss : 5095.5342, Time/batch_file : 2.2708, Training time: 14994.0287\n",
      "Epoch : 1292/2000 data_batch_5,  Train_loss : 4760.8828  Test_loss : 5453.8740, Time/batch_file : 2.2759, Training time: 14996.3049\n",
      "Epoch : 1293/2000 data_batch_1,  Train_loss : 4565.4463  Test_loss : 4815.9736, Time/batch_file : 2.2638, Training time: 14998.5689\n",
      "Epoch : 1293/2000 data_batch_2,  Train_loss : 4549.8384  Test_loss : 5018.6592, Time/batch_file : 2.2737, Training time: 15000.8427\n",
      "Epoch : 1293/2000 data_batch_3,  Train_loss : 4337.2480  Test_loss : 5035.3623, Time/batch_file : 2.2646, Training time: 15003.1075\n",
      "Epoch : 1293/2000 data_batch_4,  Train_loss : 4591.2324  Test_loss : 4839.8105, Time/batch_file : 2.2732, Training time: 15005.3809\n",
      "Epoch : 1293/2000 data_batch_5,  Train_loss : 4581.9883  Test_loss : 5094.3301, Time/batch_file : 2.2740, Training time: 15007.6551\n",
      "Epoch : 1294/2000 data_batch_1,  Train_loss : 4983.8613  Test_loss : 5490.7725, Time/batch_file : 2.2820, Training time: 15009.9373\n",
      "Epoch : 1294/2000 data_batch_2,  Train_loss : 5072.5137  Test_loss : 5583.7139, Time/batch_file : 2.2756, Training time: 15012.2133\n",
      "Epoch : 1294/2000 data_batch_3,  Train_loss : 5198.2026  Test_loss : 5289.1245, Time/batch_file : 2.2779, Training time: 15014.4913\n",
      "Epoch : 1294/2000 data_batch_4,  Train_loss : 5026.9893  Test_loss : 5423.5249, Time/batch_file : 2.2798, Training time: 15016.7713\n",
      "Epoch : 1294/2000 data_batch_5,  Train_loss : 4954.5630  Test_loss : 5523.1992, Time/batch_file : 2.2745, Training time: 15019.0460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1295/2000 data_batch_1,  Train_loss : 4661.6104  Test_loss : 5137.8945, Time/batch_file : 2.3004, Training time: 15021.3467\n",
      "Epoch : 1295/2000 data_batch_2,  Train_loss : 4792.5776  Test_loss : 5201.0332, Time/batch_file : 2.2613, Training time: 15023.6081\n",
      "Epoch : 1295/2000 data_batch_3,  Train_loss : 4614.0977  Test_loss : 5259.4043, Time/batch_file : 2.2621, Training time: 15025.8705\n",
      "Epoch : 1295/2000 data_batch_4,  Train_loss : 4632.8062  Test_loss : 5198.9536, Time/batch_file : 2.2676, Training time: 15028.1383\n",
      "Epoch : 1295/2000 data_batch_5,  Train_loss : 4746.5820  Test_loss : 5273.5898, Time/batch_file : 2.2706, Training time: 15030.4090\n",
      "Epoch : 1296/2000 data_batch_1,  Train_loss : 4651.6372  Test_loss : 5397.5498, Time/batch_file : 2.2749, Training time: 15032.6842\n",
      "Epoch : 1296/2000 data_batch_2,  Train_loss : 4673.1475  Test_loss : 5305.8726, Time/batch_file : 2.2781, Training time: 15034.9624\n",
      "Epoch : 1296/2000 data_batch_3,  Train_loss : 4746.8555  Test_loss : 5106.2471, Time/batch_file : 2.2786, Training time: 15037.2412\n",
      "Epoch : 1296/2000 data_batch_4,  Train_loss : 4499.3584  Test_loss : 5254.6641, Time/batch_file : 2.2811, Training time: 15039.5225\n",
      "Epoch : 1296/2000 data_batch_5,  Train_loss : 4499.6797  Test_loss : 4728.3838, Time/batch_file : 2.2701, Training time: 15041.7928\n",
      "Epoch : 1297/2000 data_batch_1,  Train_loss : 4356.5762  Test_loss : 4986.1387, Time/batch_file : 2.2708, Training time: 15044.0639\n",
      "Epoch : 1297/2000 data_batch_2,  Train_loss : 4593.0356  Test_loss : 5092.5854, Time/batch_file : 2.2669, Training time: 15046.3310\n",
      "Epoch : 1297/2000 data_batch_3,  Train_loss : 4442.3501  Test_loss : 4933.8950, Time/batch_file : 2.2631, Training time: 15048.5943\n",
      "Epoch : 1297/2000 data_batch_4,  Train_loss : 4552.1235  Test_loss : 4871.8555, Time/batch_file : 2.2633, Training time: 15050.8579\n",
      "Epoch : 1297/2000 data_batch_5,  Train_loss : 4434.2754  Test_loss : 4991.0176, Time/batch_file : 2.2591, Training time: 15053.1172\n",
      "Epoch : 1298/2000 data_batch_1,  Train_loss : 4594.2495  Test_loss : 4866.8408, Time/batch_file : 2.2668, Training time: 15055.3842\n",
      "Epoch : 1298/2000 data_batch_2,  Train_loss : 4670.2119  Test_loss : 4874.6221, Time/batch_file : 2.2901, Training time: 15057.6744\n",
      "Epoch : 1298/2000 data_batch_3,  Train_loss : 4612.4565  Test_loss : 4917.7197, Time/batch_file : 2.2780, Training time: 15059.9526\n",
      "Epoch : 1298/2000 data_batch_4,  Train_loss : 4612.1382  Test_loss : 4811.8423, Time/batch_file : 2.2701, Training time: 15062.2230\n",
      "Epoch : 1298/2000 data_batch_5,  Train_loss : 4247.8574  Test_loss : 4717.0039, Time/batch_file : 2.2656, Training time: 15064.4888\n",
      "Epoch : 1299/2000 data_batch_1,  Train_loss : 5019.7065  Test_loss : 5132.2524, Time/batch_file : 2.2788, Training time: 15066.7678\n",
      "Epoch : 1299/2000 data_batch_2,  Train_loss : 4739.6807  Test_loss : 4920.1128, Time/batch_file : 2.2747, Training time: 15069.0427\n",
      "Epoch : 1299/2000 data_batch_3,  Train_loss : 4914.9233  Test_loss : 5132.6035, Time/batch_file : 2.2838, Training time: 15071.3267\n",
      "Epoch : 1299/2000 data_batch_4,  Train_loss : 5066.9062  Test_loss : 4970.7871, Time/batch_file : 2.2692, Training time: 15073.5960\n",
      "Epoch : 1299/2000 data_batch_5,  Train_loss : 4743.2549  Test_loss : 4907.3330, Time/batch_file : 2.2754, Training time: 15075.8715\n",
      "Epoch : 1300/2000 data_batch_1,  Train_loss : 5239.5581  Test_loss : 4840.8882, Time/batch_file : 2.2660, Training time: 15078.1378\n",
      "Epoch : 1300/2000 data_batch_2,  Train_loss : 5260.1650  Test_loss : 4721.7148, Time/batch_file : 2.2599, Training time: 15080.3978\n",
      "Epoch : 1300/2000 data_batch_3,  Train_loss : 5374.6118  Test_loss : 5007.4380, Time/batch_file : 2.2629, Training time: 15082.6610\n",
      "Epoch : 1300/2000 data_batch_4,  Train_loss : 5249.1362  Test_loss : 4584.2466, Time/batch_file : 2.2640, Training time: 15084.9252\n",
      "Epoch : 1300/2000 data_batch_5,  Train_loss : 5144.6074  Test_loss : 4871.8384, Time/batch_file : 2.2697, Training time: 15087.1951\n",
      "[./nets/net-1300.ckpt] SAVED\n",
      "Epoch : 1301/2000 data_batch_1,  Train_loss : 4870.2456  Test_loss : 5387.5181, Time/batch_file : 2.2781, Training time: 15090.7710\n",
      "Epoch : 1301/2000 data_batch_2,  Train_loss : 5014.7783  Test_loss : 5442.6738, Time/batch_file : 2.2674, Training time: 15093.0385\n",
      "Epoch : 1301/2000 data_batch_3,  Train_loss : 4502.3164  Test_loss : 5404.3359, Time/batch_file : 2.2513, Training time: 15095.2899\n",
      "Epoch : 1301/2000 data_batch_4,  Train_loss : 4686.4956  Test_loss : 5532.0522, Time/batch_file : 2.2624, Training time: 15097.5525\n",
      "Epoch : 1301/2000 data_batch_5,  Train_loss : 4991.2979  Test_loss : 5571.2559, Time/batch_file : 2.2800, Training time: 15099.8327\n",
      "Epoch : 1302/2000 data_batch_1,  Train_loss : 4523.9370  Test_loss : 5531.2881, Time/batch_file : 2.2591, Training time: 15102.0920\n",
      "Epoch : 1302/2000 data_batch_2,  Train_loss : 4405.6279  Test_loss : 5217.5635, Time/batch_file : 2.2680, Training time: 15104.3602\n",
      "Epoch : 1302/2000 data_batch_3,  Train_loss : 4553.7100  Test_loss : 5374.3569, Time/batch_file : 2.2518, Training time: 15106.6121\n",
      "Epoch : 1302/2000 data_batch_4,  Train_loss : 4516.5825  Test_loss : 5283.3936, Time/batch_file : 2.2695, Training time: 15108.8818\n",
      "Epoch : 1302/2000 data_batch_5,  Train_loss : 4408.6201  Test_loss : 5454.5410, Time/batch_file : 2.2531, Training time: 15111.1351\n",
      "Epoch : 1303/2000 data_batch_1,  Train_loss : 4845.9707  Test_loss : 5550.3340, Time/batch_file : 2.2650, Training time: 15113.4004\n",
      "Epoch : 1303/2000 data_batch_2,  Train_loss : 4728.3804  Test_loss : 5177.6685, Time/batch_file : 2.2770, Training time: 15115.6775\n",
      "Epoch : 1303/2000 data_batch_3,  Train_loss : 4866.9946  Test_loss : 5164.6187, Time/batch_file : 2.2876, Training time: 15117.9653\n",
      "Epoch : 1303/2000 data_batch_4,  Train_loss : 4749.9082  Test_loss : 5263.0137, Time/batch_file : 2.2662, Training time: 15120.2316\n",
      "Epoch : 1303/2000 data_batch_5,  Train_loss : 4820.7773  Test_loss : 5330.3096, Time/batch_file : 2.2692, Training time: 15122.5011\n",
      "Epoch : 1304/2000 data_batch_1,  Train_loss : 4664.3906  Test_loss : 4992.9492, Time/batch_file : 2.2732, Training time: 15124.7745\n",
      "Epoch : 1304/2000 data_batch_2,  Train_loss : 4393.3037  Test_loss : 4708.3447, Time/batch_file : 2.2665, Training time: 15127.0412\n",
      "Epoch : 1304/2000 data_batch_3,  Train_loss : 4435.6885  Test_loss : 5161.5469, Time/batch_file : 2.2532, Training time: 15129.2946\n",
      "Epoch : 1304/2000 data_batch_4,  Train_loss : 4500.9556  Test_loss : 4856.5088, Time/batch_file : 2.2720, Training time: 15131.5668\n",
      "Epoch : 1304/2000 data_batch_5,  Train_loss : 4512.3965  Test_loss : 4988.9180, Time/batch_file : 2.2700, Training time: 15133.8370\n",
      "Epoch : 1305/2000 data_batch_1,  Train_loss : 4662.7539  Test_loss : 5547.8594, Time/batch_file : 2.2641, Training time: 15136.1014\n",
      "Epoch : 1305/2000 data_batch_2,  Train_loss : 4555.4541  Test_loss : 5186.5781, Time/batch_file : 2.2559, Training time: 15138.3575\n",
      "Epoch : 1305/2000 data_batch_3,  Train_loss : 4453.1309  Test_loss : 5304.6699, Time/batch_file : 2.2681, Training time: 15140.6259\n",
      "Epoch : 1305/2000 data_batch_4,  Train_loss : 4591.3208  Test_loss : 5381.0845, Time/batch_file : 2.2615, Training time: 15142.8875\n",
      "Epoch : 1305/2000 data_batch_5,  Train_loss : 4459.1099  Test_loss : 5125.3940, Time/batch_file : 2.2667, Training time: 15145.1544\n",
      "Epoch : 1306/2000 data_batch_1,  Train_loss : 5257.3989  Test_loss : 4974.2656, Time/batch_file : 2.2488, Training time: 15147.4034\n",
      "Epoch : 1306/2000 data_batch_2,  Train_loss : 5182.4546  Test_loss : 4769.0723, Time/batch_file : 2.2567, Training time: 15149.6603\n",
      "Epoch : 1306/2000 data_batch_3,  Train_loss : 5007.6260  Test_loss : 5274.1392, Time/batch_file : 2.2635, Training time: 15151.9240\n",
      "Epoch : 1306/2000 data_batch_4,  Train_loss : 4846.0737  Test_loss : 4994.5283, Time/batch_file : 2.2446, Training time: 15154.1687\n",
      "Epoch : 1306/2000 data_batch_5,  Train_loss : 5146.1304  Test_loss : 5107.9399, Time/batch_file : 2.2589, Training time: 15156.4279\n",
      "Epoch : 1307/2000 data_batch_1,  Train_loss : 4805.6465  Test_loss : 4594.2065, Time/batch_file : 2.2582, Training time: 15158.6863\n",
      "Epoch : 1307/2000 data_batch_2,  Train_loss : 4648.8042  Test_loss : 4628.7070, Time/batch_file : 2.2618, Training time: 15160.9484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1307/2000 data_batch_3,  Train_loss : 4829.2334  Test_loss : 4743.3188, Time/batch_file : 2.2631, Training time: 15163.2117\n",
      "Epoch : 1307/2000 data_batch_4,  Train_loss : 4877.7139  Test_loss : 4698.3350, Time/batch_file : 2.2679, Training time: 15165.4797\n",
      "Epoch : 1307/2000 data_batch_5,  Train_loss : 4718.5215  Test_loss : 4715.5356, Time/batch_file : 2.2723, Training time: 15167.7523\n",
      "Epoch : 1308/2000 data_batch_1,  Train_loss : 5032.1616  Test_loss : 5259.1680, Time/batch_file : 2.2682, Training time: 15170.0207\n",
      "Epoch : 1308/2000 data_batch_2,  Train_loss : 4846.1445  Test_loss : 5142.7231, Time/batch_file : 2.2801, Training time: 15172.3009\n",
      "Epoch : 1308/2000 data_batch_3,  Train_loss : 4958.7881  Test_loss : 4879.6016, Time/batch_file : 2.2650, Training time: 15174.5660\n",
      "Epoch : 1308/2000 data_batch_4,  Train_loss : 4858.8452  Test_loss : 4915.4263, Time/batch_file : 2.2761, Training time: 15176.8423\n",
      "Epoch : 1308/2000 data_batch_5,  Train_loss : 4688.3740  Test_loss : 5077.6807, Time/batch_file : 2.2726, Training time: 15179.1151\n",
      "Epoch : 1309/2000 data_batch_1,  Train_loss : 5064.8516  Test_loss : 5509.9878, Time/batch_file : 2.2748, Training time: 15181.3901\n",
      "Epoch : 1309/2000 data_batch_2,  Train_loss : 5006.5898  Test_loss : 5429.0913, Time/batch_file : 2.2633, Training time: 15183.6537\n",
      "Epoch : 1309/2000 data_batch_3,  Train_loss : 5012.3389  Test_loss : 5195.0127, Time/batch_file : 2.2774, Training time: 15185.9312\n",
      "Epoch : 1309/2000 data_batch_4,  Train_loss : 5028.2378  Test_loss : 4932.8271, Time/batch_file : 2.2645, Training time: 15188.1959\n",
      "Epoch : 1309/2000 data_batch_5,  Train_loss : 5041.5586  Test_loss : 5530.2109, Time/batch_file : 2.2804, Training time: 15190.4765\n",
      "Epoch : 1310/2000 data_batch_1,  Train_loss : 4682.9268  Test_loss : 5115.8057, Time/batch_file : 2.2655, Training time: 15192.7422\n",
      "Epoch : 1310/2000 data_batch_2,  Train_loss : 4779.3799  Test_loss : 5259.3696, Time/batch_file : 2.2766, Training time: 15195.0191\n",
      "Epoch : 1310/2000 data_batch_3,  Train_loss : 4927.2729  Test_loss : 5122.7480, Time/batch_file : 2.2628, Training time: 15197.2820\n",
      "Epoch : 1310/2000 data_batch_4,  Train_loss : 4848.6973  Test_loss : 5289.3755, Time/batch_file : 2.2771, Training time: 15199.5593\n",
      "Epoch : 1310/2000 data_batch_5,  Train_loss : 4784.5752  Test_loss : 5274.5781, Time/batch_file : 2.2652, Training time: 15201.8248\n",
      "[./nets/net-1310.ckpt] SAVED\n",
      "Epoch : 1311/2000 data_batch_1,  Train_loss : 4379.7412  Test_loss : 4727.0728, Time/batch_file : 2.5601, Training time: 15205.6540\n",
      "Epoch : 1311/2000 data_batch_2,  Train_loss : 4297.0830  Test_loss : 4615.7305, Time/batch_file : 2.2592, Training time: 15207.9135\n",
      "Epoch : 1311/2000 data_batch_3,  Train_loss : 4513.4336  Test_loss : 4951.3857, Time/batch_file : 2.2707, Training time: 15210.1843\n",
      "Epoch : 1311/2000 data_batch_4,  Train_loss : 4373.6431  Test_loss : 5001.5879, Time/batch_file : 2.2691, Training time: 15212.4535\n",
      "Epoch : 1311/2000 data_batch_5,  Train_loss : 4476.9805  Test_loss : 4828.9878, Time/batch_file : 2.2726, Training time: 15214.7263\n",
      "Epoch : 1312/2000 data_batch_1,  Train_loss : 5036.0938  Test_loss : 5011.6479, Time/batch_file : 2.2742, Training time: 15217.0007\n",
      "Epoch : 1312/2000 data_batch_2,  Train_loss : 4731.8115  Test_loss : 4986.1035, Time/batch_file : 2.2784, Training time: 15219.2793\n",
      "Epoch : 1312/2000 data_batch_3,  Train_loss : 4891.1758  Test_loss : 4807.0190, Time/batch_file : 2.2683, Training time: 15221.5478\n",
      "Epoch : 1312/2000 data_batch_4,  Train_loss : 4862.3267  Test_loss : 5273.0845, Time/batch_file : 2.2647, Training time: 15223.8128\n",
      "Epoch : 1312/2000 data_batch_5,  Train_loss : 4912.0083  Test_loss : 4746.3130, Time/batch_file : 2.2730, Training time: 15226.0859\n",
      "Epoch : 1313/2000 data_batch_1,  Train_loss : 4628.5874  Test_loss : 4854.8359, Time/batch_file : 2.2660, Training time: 15228.3522\n",
      "Epoch : 1313/2000 data_batch_2,  Train_loss : 4825.7817  Test_loss : 4920.9634, Time/batch_file : 2.2761, Training time: 15230.6285\n",
      "Epoch : 1313/2000 data_batch_3,  Train_loss : 4371.3257  Test_loss : 4912.7871, Time/batch_file : 2.2712, Training time: 15232.8999\n",
      "Epoch : 1313/2000 data_batch_4,  Train_loss : 4712.9521  Test_loss : 5286.1973, Time/batch_file : 2.2453, Training time: 15235.1454\n",
      "Epoch : 1313/2000 data_batch_5,  Train_loss : 4525.0059  Test_loss : 4985.4951, Time/batch_file : 2.2683, Training time: 15237.4139\n",
      "Epoch : 1314/2000 data_batch_1,  Train_loss : 4674.9116  Test_loss : 5206.3691, Time/batch_file : 2.2665, Training time: 15239.6807\n",
      "Epoch : 1314/2000 data_batch_2,  Train_loss : 4586.5977  Test_loss : 5038.7061, Time/batch_file : 2.2778, Training time: 15241.9587\n",
      "Epoch : 1314/2000 data_batch_3,  Train_loss : 4608.3906  Test_loss : 4807.5879, Time/batch_file : 2.2767, Training time: 15244.2357\n",
      "Epoch : 1314/2000 data_batch_4,  Train_loss : 4698.2632  Test_loss : 5209.9980, Time/batch_file : 2.2704, Training time: 15246.5063\n",
      "Epoch : 1314/2000 data_batch_5,  Train_loss : 4584.3330  Test_loss : 4839.5229, Time/batch_file : 2.2726, Training time: 15248.7790\n",
      "Epoch : 1315/2000 data_batch_1,  Train_loss : 4822.5410  Test_loss : 4828.2500, Time/batch_file : 2.2889, Training time: 15251.0682\n",
      "Epoch : 1315/2000 data_batch_2,  Train_loss : 4899.5410  Test_loss : 4923.6182, Time/batch_file : 2.2729, Training time: 15253.3413\n",
      "Epoch : 1315/2000 data_batch_3,  Train_loss : 5050.0874  Test_loss : 5028.5498, Time/batch_file : 2.2764, Training time: 15255.6179\n",
      "Epoch : 1315/2000 data_batch_4,  Train_loss : 5148.4614  Test_loss : 5221.0845, Time/batch_file : 2.2877, Training time: 15257.9059\n",
      "Epoch : 1315/2000 data_batch_5,  Train_loss : 4987.2612  Test_loss : 5066.4526, Time/batch_file : 2.2812, Training time: 15260.1874\n",
      "Epoch : 1316/2000 data_batch_1,  Train_loss : 4848.7241  Test_loss : 4716.4170, Time/batch_file : 2.2668, Training time: 15262.4544\n",
      "Epoch : 1316/2000 data_batch_2,  Train_loss : 5119.1162  Test_loss : 4769.8154, Time/batch_file : 2.2682, Training time: 15264.7229\n",
      "Epoch : 1316/2000 data_batch_3,  Train_loss : 4957.6328  Test_loss : 4861.0869, Time/batch_file : 2.2732, Training time: 15266.9963\n",
      "Epoch : 1316/2000 data_batch_4,  Train_loss : 5070.1162  Test_loss : 4498.8594, Time/batch_file : 2.2742, Training time: 15269.2706\n",
      "Epoch : 1316/2000 data_batch_5,  Train_loss : 5079.4346  Test_loss : 4856.3311, Time/batch_file : 2.2766, Training time: 15271.5474\n",
      "Epoch : 1317/2000 data_batch_1,  Train_loss : 4545.7656  Test_loss : 4955.0713, Time/batch_file : 2.2720, Training time: 15273.8196\n",
      "Epoch : 1317/2000 data_batch_2,  Train_loss : 4241.8218  Test_loss : 5061.0840, Time/batch_file : 2.2546, Training time: 15276.0745\n",
      "Epoch : 1317/2000 data_batch_3,  Train_loss : 4488.4595  Test_loss : 5032.0391, Time/batch_file : 2.2770, Training time: 15278.3516\n",
      "Epoch : 1317/2000 data_batch_4,  Train_loss : 4514.2349  Test_loss : 5077.0894, Time/batch_file : 2.2866, Training time: 15280.6384\n",
      "Epoch : 1317/2000 data_batch_5,  Train_loss : 4180.4048  Test_loss : 4886.8828, Time/batch_file : 2.2667, Training time: 15282.9052\n",
      "Epoch : 1318/2000 data_batch_1,  Train_loss : 4822.4453  Test_loss : 5117.5918, Time/batch_file : 2.2660, Training time: 15285.1715\n",
      "Epoch : 1318/2000 data_batch_2,  Train_loss : 4379.6699  Test_loss : 5314.9521, Time/batch_file : 2.2827, Training time: 15287.4545\n",
      "Epoch : 1318/2000 data_batch_3,  Train_loss : 4631.2026  Test_loss : 5263.9653, Time/batch_file : 2.2687, Training time: 15289.7235\n",
      "Epoch : 1318/2000 data_batch_4,  Train_loss : 4794.4653  Test_loss : 5216.2080, Time/batch_file : 2.2616, Training time: 15291.9853\n",
      "Epoch : 1318/2000 data_batch_5,  Train_loss : 4691.8179  Test_loss : 4776.8999, Time/batch_file : 2.2727, Training time: 15294.2582\n",
      "Epoch : 1319/2000 data_batch_1,  Train_loss : 4887.8193  Test_loss : 5613.9878, Time/batch_file : 2.2603, Training time: 15296.5186\n",
      "Epoch : 1319/2000 data_batch_2,  Train_loss : 5033.0825  Test_loss : 5537.0503, Time/batch_file : 2.2914, Training time: 15298.8102\n",
      "Epoch : 1319/2000 data_batch_3,  Train_loss : 4717.7056  Test_loss : 5593.8291, Time/batch_file : 2.2578, Training time: 15301.0682\n",
      "Epoch : 1319/2000 data_batch_4,  Train_loss : 4843.5171  Test_loss : 5406.4316, Time/batch_file : 2.2640, Training time: 15303.3326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1319/2000 data_batch_5,  Train_loss : 4787.2749  Test_loss : 5196.4185, Time/batch_file : 2.2422, Training time: 15305.5749\n",
      "Epoch : 1320/2000 data_batch_1,  Train_loss : 4628.0557  Test_loss : 5606.7266, Time/batch_file : 2.2723, Training time: 15307.8474\n",
      "Epoch : 1320/2000 data_batch_2,  Train_loss : 4667.0532  Test_loss : 5541.1636, Time/batch_file : 2.2596, Training time: 15310.1072\n",
      "Epoch : 1320/2000 data_batch_3,  Train_loss : 4787.3862  Test_loss : 5707.8154, Time/batch_file : 2.2916, Training time: 15312.3989\n",
      "Epoch : 1320/2000 data_batch_4,  Train_loss : 4791.0698  Test_loss : 5534.6826, Time/batch_file : 2.2608, Training time: 15314.6600\n",
      "Epoch : 1320/2000 data_batch_5,  Train_loss : 4758.8306  Test_loss : 5315.7783, Time/batch_file : 2.2683, Training time: 15316.9285\n",
      "[./nets/net-1320.ckpt] SAVED\n",
      "Epoch : 1321/2000 data_batch_1,  Train_loss : 5003.4414  Test_loss : 5126.7974, Time/batch_file : 2.5721, Training time: 15320.7892\n",
      "Epoch : 1321/2000 data_batch_2,  Train_loss : 4917.1094  Test_loss : 5068.3027, Time/batch_file : 2.2916, Training time: 15323.0810\n",
      "Epoch : 1321/2000 data_batch_3,  Train_loss : 4723.2886  Test_loss : 5330.5938, Time/batch_file : 2.2770, Training time: 15325.3582\n",
      "Epoch : 1321/2000 data_batch_4,  Train_loss : 4722.1523  Test_loss : 4969.3887, Time/batch_file : 2.2661, Training time: 15327.6245\n",
      "Epoch : 1321/2000 data_batch_5,  Train_loss : 4827.6323  Test_loss : 5074.3936, Time/batch_file : 2.2923, Training time: 15329.9169\n",
      "Epoch : 1322/2000 data_batch_1,  Train_loss : 5209.9385  Test_loss : 5285.8911, Time/batch_file : 2.2928, Training time: 15332.2099\n",
      "Epoch : 1322/2000 data_batch_2,  Train_loss : 5178.6675  Test_loss : 5216.9199, Time/batch_file : 2.2898, Training time: 15334.4999\n",
      "Epoch : 1322/2000 data_batch_3,  Train_loss : 4984.7852  Test_loss : 5181.1431, Time/batch_file : 2.2687, Training time: 15336.7688\n",
      "Epoch : 1322/2000 data_batch_4,  Train_loss : 4987.7012  Test_loss : 4922.9775, Time/batch_file : 2.3010, Training time: 15339.0700\n",
      "Epoch : 1322/2000 data_batch_5,  Train_loss : 5010.6016  Test_loss : 5244.2417, Time/batch_file : 2.2864, Training time: 15341.3566\n",
      "Epoch : 1323/2000 data_batch_1,  Train_loss : 5242.8066  Test_loss : 5316.2437, Time/batch_file : 2.2765, Training time: 15343.6334\n",
      "Epoch : 1323/2000 data_batch_2,  Train_loss : 5528.7246  Test_loss : 5357.3584, Time/batch_file : 2.2940, Training time: 15345.9276\n",
      "Epoch : 1323/2000 data_batch_3,  Train_loss : 5141.1484  Test_loss : 5398.3291, Time/batch_file : 2.2658, Training time: 15348.1936\n",
      "Epoch : 1323/2000 data_batch_4,  Train_loss : 5238.4336  Test_loss : 5310.9248, Time/batch_file : 2.3162, Training time: 15350.5100\n",
      "Epoch : 1323/2000 data_batch_5,  Train_loss : 5519.8618  Test_loss : 5504.6982, Time/batch_file : 2.2817, Training time: 15352.7919\n",
      "Epoch : 1324/2000 data_batch_1,  Train_loss : 4418.9438  Test_loss : 5587.3682, Time/batch_file : 2.2976, Training time: 15355.0898\n",
      "Epoch : 1324/2000 data_batch_2,  Train_loss : 4569.4746  Test_loss : 5121.7798, Time/batch_file : 2.2648, Training time: 15357.3548\n",
      "Epoch : 1324/2000 data_batch_3,  Train_loss : 4636.3369  Test_loss : 5159.6641, Time/batch_file : 2.2882, Training time: 15359.6431\n",
      "Epoch : 1324/2000 data_batch_4,  Train_loss : 4858.1997  Test_loss : 5262.2080, Time/batch_file : 2.2821, Training time: 15361.9254\n",
      "Epoch : 1324/2000 data_batch_5,  Train_loss : 4507.7852  Test_loss : 5192.8477, Time/batch_file : 2.2930, Training time: 15364.2185\n",
      "Epoch : 1325/2000 data_batch_1,  Train_loss : 5275.1362  Test_loss : 4641.0664, Time/batch_file : 2.2926, Training time: 15366.5115\n",
      "Epoch : 1325/2000 data_batch_2,  Train_loss : 5085.9282  Test_loss : 4402.4146, Time/batch_file : 2.2825, Training time: 15368.7941\n",
      "Epoch : 1325/2000 data_batch_3,  Train_loss : 5010.9370  Test_loss : 4618.7871, Time/batch_file : 2.2875, Training time: 15371.0818\n",
      "Epoch : 1325/2000 data_batch_4,  Train_loss : 4811.4209  Test_loss : 4558.8389, Time/batch_file : 2.3125, Training time: 15373.3945\n",
      "Epoch : 1325/2000 data_batch_5,  Train_loss : 4677.0093  Test_loss : 4917.1157, Time/batch_file : 2.2828, Training time: 15375.6775\n",
      "Epoch : 1326/2000 data_batch_1,  Train_loss : 4624.8584  Test_loss : 5178.0537, Time/batch_file : 2.2846, Training time: 15377.9622\n",
      "Epoch : 1326/2000 data_batch_2,  Train_loss : 4766.2524  Test_loss : 5187.6055, Time/batch_file : 2.2724, Training time: 15380.2348\n",
      "Epoch : 1326/2000 data_batch_3,  Train_loss : 4583.9531  Test_loss : 5021.7417, Time/batch_file : 2.2601, Training time: 15382.4952\n",
      "Epoch : 1326/2000 data_batch_4,  Train_loss : 4729.5659  Test_loss : 5111.7354, Time/batch_file : 2.2660, Training time: 15384.7613\n",
      "Epoch : 1326/2000 data_batch_5,  Train_loss : 4588.8433  Test_loss : 5020.2393, Time/batch_file : 2.2909, Training time: 15387.0525\n",
      "Epoch : 1327/2000 data_batch_1,  Train_loss : 5041.0386  Test_loss : 4521.5474, Time/batch_file : 2.2801, Training time: 15389.3327\n",
      "Epoch : 1327/2000 data_batch_2,  Train_loss : 5030.7827  Test_loss : 4776.7129, Time/batch_file : 2.2637, Training time: 15391.5966\n",
      "Epoch : 1327/2000 data_batch_3,  Train_loss : 4982.9648  Test_loss : 4569.8105, Time/batch_file : 2.2751, Training time: 15393.8719\n",
      "Epoch : 1327/2000 data_batch_4,  Train_loss : 4656.2080  Test_loss : 4491.1812, Time/batch_file : 2.2775, Training time: 15396.1495\n",
      "Epoch : 1327/2000 data_batch_5,  Train_loss : 4875.9023  Test_loss : 4796.4165, Time/batch_file : 2.2741, Training time: 15398.4238\n",
      "Epoch : 1328/2000 data_batch_1,  Train_loss : 4559.6338  Test_loss : 4829.8276, Time/batch_file : 2.2736, Training time: 15400.6976\n",
      "Epoch : 1328/2000 data_batch_2,  Train_loss : 4541.6294  Test_loss : 4390.8413, Time/batch_file : 2.2837, Training time: 15402.9814\n",
      "Epoch : 1328/2000 data_batch_3,  Train_loss : 4650.4111  Test_loss : 4584.7207, Time/batch_file : 2.2701, Training time: 15405.2518\n",
      "Epoch : 1328/2000 data_batch_4,  Train_loss : 4736.6626  Test_loss : 4720.8574, Time/batch_file : 2.2709, Training time: 15407.5229\n",
      "Epoch : 1328/2000 data_batch_5,  Train_loss : 4359.2402  Test_loss : 4612.4087, Time/batch_file : 2.2824, Training time: 15409.8055\n",
      "Epoch : 1329/2000 data_batch_1,  Train_loss : 4708.0498  Test_loss : 4850.3271, Time/batch_file : 2.2779, Training time: 15412.0836\n",
      "Epoch : 1329/2000 data_batch_2,  Train_loss : 4312.3442  Test_loss : 4880.4561, Time/batch_file : 2.2664, Training time: 15414.3502\n",
      "Epoch : 1329/2000 data_batch_3,  Train_loss : 4550.6118  Test_loss : 4679.2437, Time/batch_file : 2.2655, Training time: 15416.6160\n",
      "Epoch : 1329/2000 data_batch_4,  Train_loss : 4642.3262  Test_loss : 4668.3838, Time/batch_file : 2.3025, Training time: 15418.9186\n",
      "Epoch : 1329/2000 data_batch_5,  Train_loss : 4493.5864  Test_loss : 4851.1665, Time/batch_file : 2.2733, Training time: 15421.1922\n",
      "Epoch : 1330/2000 data_batch_1,  Train_loss : 4908.8701  Test_loss : 4664.1221, Time/batch_file : 2.2824, Training time: 15423.4748\n",
      "Epoch : 1330/2000 data_batch_2,  Train_loss : 5099.6914  Test_loss : 4832.3198, Time/batch_file : 2.2836, Training time: 15425.7585\n",
      "Epoch : 1330/2000 data_batch_3,  Train_loss : 5127.4307  Test_loss : 4837.9790, Time/batch_file : 2.2836, Training time: 15428.0422\n",
      "Epoch : 1330/2000 data_batch_4,  Train_loss : 5027.4683  Test_loss : 4671.4390, Time/batch_file : 2.2880, Training time: 15430.3303\n",
      "Epoch : 1330/2000 data_batch_5,  Train_loss : 4876.4985  Test_loss : 4680.7261, Time/batch_file : 2.2712, Training time: 15432.6017\n",
      "[./nets/net-1330.ckpt] SAVED\n",
      "Epoch : 1331/2000 data_batch_1,  Train_loss : 5143.9082  Test_loss : 5287.5752, Time/batch_file : 2.3735, Training time: 15436.2396\n",
      "Epoch : 1331/2000 data_batch_2,  Train_loss : 5094.9717  Test_loss : 5368.5151, Time/batch_file : 2.2762, Training time: 15438.5161\n",
      "Epoch : 1331/2000 data_batch_3,  Train_loss : 4939.2090  Test_loss : 5362.7412, Time/batch_file : 2.2556, Training time: 15440.7719\n",
      "Epoch : 1331/2000 data_batch_4,  Train_loss : 5284.4375  Test_loss : 5486.5869, Time/batch_file : 2.2721, Training time: 15443.0443\n",
      "Epoch : 1331/2000 data_batch_5,  Train_loss : 5098.4336  Test_loss : 5239.9629, Time/batch_file : 2.2710, Training time: 15445.3155\n",
      "Epoch : 1332/2000 data_batch_1,  Train_loss : 4882.8604  Test_loss : 5101.6113, Time/batch_file : 2.2769, Training time: 15447.5925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1332/2000 data_batch_2,  Train_loss : 5094.0464  Test_loss : 4961.1187, Time/batch_file : 2.2780, Training time: 15449.8707\n",
      "Epoch : 1332/2000 data_batch_3,  Train_loss : 4927.9087  Test_loss : 5030.7754, Time/batch_file : 2.2698, Training time: 15452.1407\n",
      "Epoch : 1332/2000 data_batch_4,  Train_loss : 5143.1299  Test_loss : 4949.2695, Time/batch_file : 2.2848, Training time: 15454.4258\n",
      "Epoch : 1332/2000 data_batch_5,  Train_loss : 5041.8213  Test_loss : 5184.3677, Time/batch_file : 2.2920, Training time: 15456.7179\n",
      "Epoch : 1333/2000 data_batch_1,  Train_loss : 5391.1748  Test_loss : 4611.7964, Time/batch_file : 2.2837, Training time: 15459.0018\n",
      "Epoch : 1333/2000 data_batch_2,  Train_loss : 5099.5791  Test_loss : 4584.2495, Time/batch_file : 2.2719, Training time: 15461.2740\n",
      "Epoch : 1333/2000 data_batch_3,  Train_loss : 5182.8159  Test_loss : 4503.6367, Time/batch_file : 2.2847, Training time: 15463.5589\n",
      "Epoch : 1333/2000 data_batch_4,  Train_loss : 4954.5645  Test_loss : 4546.3003, Time/batch_file : 2.2812, Training time: 15465.8404\n",
      "Epoch : 1333/2000 data_batch_5,  Train_loss : 5493.1689  Test_loss : 4625.1997, Time/batch_file : 2.3085, Training time: 15468.1491\n",
      "Epoch : 1334/2000 data_batch_1,  Train_loss : 5595.8960  Test_loss : 4583.9668, Time/batch_file : 2.2939, Training time: 15470.4432\n",
      "Epoch : 1334/2000 data_batch_2,  Train_loss : 5435.4829  Test_loss : 4695.2451, Time/batch_file : 2.2928, Training time: 15472.7362\n",
      "Epoch : 1334/2000 data_batch_3,  Train_loss : 5424.3730  Test_loss : 4676.5103, Time/batch_file : 2.2994, Training time: 15475.0358\n",
      "Epoch : 1334/2000 data_batch_4,  Train_loss : 5457.1362  Test_loss : 4606.0859, Time/batch_file : 2.2988, Training time: 15477.3347\n",
      "Epoch : 1334/2000 data_batch_5,  Train_loss : 5486.2275  Test_loss : 4394.0938, Time/batch_file : 2.2890, Training time: 15479.6239\n",
      "Epoch : 1335/2000 data_batch_1,  Train_loss : 4947.9956  Test_loss : 4896.9526, Time/batch_file : 2.2697, Training time: 15481.8937\n",
      "Epoch : 1335/2000 data_batch_2,  Train_loss : 5086.6709  Test_loss : 4702.7002, Time/batch_file : 2.2686, Training time: 15484.1624\n",
      "Epoch : 1335/2000 data_batch_3,  Train_loss : 5044.6035  Test_loss : 4779.3994, Time/batch_file : 2.2767, Training time: 15486.4393\n",
      "Epoch : 1335/2000 data_batch_4,  Train_loss : 4932.7710  Test_loss : 4833.5996, Time/batch_file : 2.2757, Training time: 15488.7152\n",
      "Epoch : 1335/2000 data_batch_5,  Train_loss : 4968.2168  Test_loss : 4651.9312, Time/batch_file : 2.2869, Training time: 15491.0022\n",
      "Epoch : 1336/2000 data_batch_1,  Train_loss : 5083.7300  Test_loss : 5037.5762, Time/batch_file : 2.2621, Training time: 15493.2646\n",
      "Epoch : 1336/2000 data_batch_2,  Train_loss : 5091.8247  Test_loss : 5261.2041, Time/batch_file : 2.2611, Training time: 15495.5259\n",
      "Epoch : 1336/2000 data_batch_3,  Train_loss : 4849.8408  Test_loss : 4943.9590, Time/batch_file : 2.2694, Training time: 15497.7955\n",
      "Epoch : 1336/2000 data_batch_4,  Train_loss : 5131.4268  Test_loss : 5283.9380, Time/batch_file : 2.2548, Training time: 15500.0505\n",
      "Epoch : 1336/2000 data_batch_5,  Train_loss : 5119.1187  Test_loss : 5237.1836, Time/batch_file : 2.2593, Training time: 15502.3100\n",
      "Epoch : 1337/2000 data_batch_1,  Train_loss : 4864.4116  Test_loss : 5006.9263, Time/batch_file : 2.2956, Training time: 15504.6057\n",
      "Epoch : 1337/2000 data_batch_2,  Train_loss : 4621.2085  Test_loss : 5015.5869, Time/batch_file : 2.2741, Training time: 15506.8799\n",
      "Epoch : 1337/2000 data_batch_3,  Train_loss : 4739.3916  Test_loss : 5305.3823, Time/batch_file : 2.2708, Training time: 15509.1508\n",
      "Epoch : 1337/2000 data_batch_4,  Train_loss : 4619.9653  Test_loss : 5164.5820, Time/batch_file : 2.2643, Training time: 15511.4154\n",
      "Epoch : 1337/2000 data_batch_5,  Train_loss : 4714.9902  Test_loss : 4820.9326, Time/batch_file : 2.2691, Training time: 15513.6848\n",
      "Epoch : 1338/2000 data_batch_1,  Train_loss : 4439.7490  Test_loss : 5069.5879, Time/batch_file : 2.2686, Training time: 15515.9537\n",
      "Epoch : 1338/2000 data_batch_2,  Train_loss : 4461.2368  Test_loss : 5166.5869, Time/batch_file : 2.2728, Training time: 15518.2267\n",
      "Epoch : 1338/2000 data_batch_3,  Train_loss : 4767.2861  Test_loss : 5263.5967, Time/batch_file : 2.2701, Training time: 15520.4970\n",
      "Epoch : 1338/2000 data_batch_4,  Train_loss : 4750.4893  Test_loss : 5164.1250, Time/batch_file : 2.2879, Training time: 15522.7851\n",
      "Epoch : 1338/2000 data_batch_5,  Train_loss : 4821.5239  Test_loss : 4899.9292, Time/batch_file : 2.2780, Training time: 15525.0633\n",
      "Epoch : 1339/2000 data_batch_1,  Train_loss : 4492.7939  Test_loss : 4859.7070, Time/batch_file : 2.2659, Training time: 15527.3295\n",
      "Epoch : 1339/2000 data_batch_2,  Train_loss : 4621.0288  Test_loss : 5055.2432, Time/batch_file : 2.2660, Training time: 15529.5958\n",
      "Epoch : 1339/2000 data_batch_3,  Train_loss : 4709.0996  Test_loss : 4917.4780, Time/batch_file : 2.2685, Training time: 15531.8645\n",
      "Epoch : 1339/2000 data_batch_4,  Train_loss : 4685.5449  Test_loss : 4886.5063, Time/batch_file : 2.2644, Training time: 15534.1291\n",
      "Epoch : 1339/2000 data_batch_5,  Train_loss : 4967.4990  Test_loss : 4952.1230, Time/batch_file : 2.2801, Training time: 15536.4093\n",
      "Epoch : 1340/2000 data_batch_1,  Train_loss : 4812.2930  Test_loss : 5204.6797, Time/batch_file : 2.2834, Training time: 15538.6928\n",
      "Epoch : 1340/2000 data_batch_2,  Train_loss : 4721.2915  Test_loss : 4810.6157, Time/batch_file : 2.2640, Training time: 15540.9571\n",
      "Epoch : 1340/2000 data_batch_3,  Train_loss : 4837.9541  Test_loss : 4725.2739, Time/batch_file : 2.2829, Training time: 15543.2402\n",
      "Epoch : 1340/2000 data_batch_4,  Train_loss : 4649.5967  Test_loss : 4829.9785, Time/batch_file : 2.2719, Training time: 15545.5123\n",
      "Epoch : 1340/2000 data_batch_5,  Train_loss : 4622.8564  Test_loss : 5196.5371, Time/batch_file : 2.2643, Training time: 15547.7768\n",
      "[./nets/net-1340.ckpt] SAVED\n",
      "Epoch : 1341/2000 data_batch_1,  Train_loss : 4644.0371  Test_loss : 4732.7163, Time/batch_file : 2.8275, Training time: 15551.8967\n",
      "Epoch : 1341/2000 data_batch_2,  Train_loss : 4814.7827  Test_loss : 5145.2344, Time/batch_file : 2.2914, Training time: 15554.1884\n",
      "Epoch : 1341/2000 data_batch_3,  Train_loss : 4945.9468  Test_loss : 5081.7715, Time/batch_file : 2.2716, Training time: 15556.4602\n",
      "Epoch : 1341/2000 data_batch_4,  Train_loss : 4760.2939  Test_loss : 4845.4556, Time/batch_file : 2.2727, Training time: 15558.7332\n",
      "Epoch : 1341/2000 data_batch_5,  Train_loss : 4682.5195  Test_loss : 5027.3613, Time/batch_file : 2.2627, Training time: 15560.9960\n",
      "Epoch : 1342/2000 data_batch_1,  Train_loss : 4904.6265  Test_loss : 5376.4463, Time/batch_file : 2.2671, Training time: 15563.2633\n",
      "Epoch : 1342/2000 data_batch_2,  Train_loss : 4710.6538  Test_loss : 5424.6548, Time/batch_file : 2.2746, Training time: 15565.5381\n",
      "Epoch : 1342/2000 data_batch_3,  Train_loss : 4719.8755  Test_loss : 5056.6758, Time/batch_file : 2.2814, Training time: 15567.8197\n",
      "Epoch : 1342/2000 data_batch_4,  Train_loss : 4731.9321  Test_loss : 5099.6406, Time/batch_file : 2.2734, Training time: 15570.0932\n",
      "Epoch : 1342/2000 data_batch_5,  Train_loss : 4785.1982  Test_loss : 5170.4839, Time/batch_file : 2.2689, Training time: 15572.3623\n",
      "Epoch : 1343/2000 data_batch_1,  Train_loss : 4980.1416  Test_loss : 5525.4644, Time/batch_file : 2.2710, Training time: 15574.6336\n",
      "Epoch : 1343/2000 data_batch_2,  Train_loss : 4978.6914  Test_loss : 5299.5415, Time/batch_file : 2.2945, Training time: 15576.9282\n",
      "Epoch : 1343/2000 data_batch_3,  Train_loss : 5097.6851  Test_loss : 5052.0537, Time/batch_file : 2.2706, Training time: 15579.1990\n",
      "Epoch : 1343/2000 data_batch_4,  Train_loss : 4973.2275  Test_loss : 5327.1973, Time/batch_file : 2.2647, Training time: 15581.4639\n",
      "Epoch : 1343/2000 data_batch_5,  Train_loss : 5112.5264  Test_loss : 5252.8975, Time/batch_file : 2.2761, Training time: 15583.7405\n",
      "Epoch : 1344/2000 data_batch_1,  Train_loss : 4747.8203  Test_loss : 5008.0415, Time/batch_file : 2.2939, Training time: 15586.0346\n",
      "Epoch : 1344/2000 data_batch_2,  Train_loss : 4601.6367  Test_loss : 4881.2666, Time/batch_file : 2.2886, Training time: 15588.3234\n",
      "Epoch : 1344/2000 data_batch_3,  Train_loss : 4640.8945  Test_loss : 5143.6870, Time/batch_file : 2.2823, Training time: 15590.6058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1344/2000 data_batch_4,  Train_loss : 4561.4800  Test_loss : 4915.3340, Time/batch_file : 2.2960, Training time: 15592.9021\n",
      "Epoch : 1344/2000 data_batch_5,  Train_loss : 4549.0474  Test_loss : 4871.0117, Time/batch_file : 2.2821, Training time: 15595.1844\n",
      "Epoch : 1345/2000 data_batch_1,  Train_loss : 4744.9351  Test_loss : 4784.8379, Time/batch_file : 2.3015, Training time: 15597.4861\n",
      "Epoch : 1345/2000 data_batch_2,  Train_loss : 4762.1865  Test_loss : 4878.2959, Time/batch_file : 2.2938, Training time: 15599.7801\n",
      "Epoch : 1345/2000 data_batch_3,  Train_loss : 4586.1045  Test_loss : 4758.2124, Time/batch_file : 2.3124, Training time: 15602.0926\n",
      "Epoch : 1345/2000 data_batch_4,  Train_loss : 4516.3525  Test_loss : 4722.8618, Time/batch_file : 2.3069, Training time: 15604.3998\n",
      "Epoch : 1345/2000 data_batch_5,  Train_loss : 4545.6670  Test_loss : 4959.0474, Time/batch_file : 2.2917, Training time: 15606.6917\n",
      "Epoch : 1346/2000 data_batch_1,  Train_loss : 4454.8359  Test_loss : 4766.2632, Time/batch_file : 2.2704, Training time: 15608.9623\n",
      "Epoch : 1346/2000 data_batch_2,  Train_loss : 4369.0244  Test_loss : 4652.1045, Time/batch_file : 2.2854, Training time: 15611.2479\n",
      "Epoch : 1346/2000 data_batch_3,  Train_loss : 4456.6709  Test_loss : 4360.7212, Time/batch_file : 2.2781, Training time: 15613.5262\n",
      "Epoch : 1346/2000 data_batch_4,  Train_loss : 4307.8594  Test_loss : 4262.7490, Time/batch_file : 2.2846, Training time: 15615.8110\n",
      "Epoch : 1346/2000 data_batch_5,  Train_loss : 4552.0635  Test_loss : 4854.9727, Time/batch_file : 2.2714, Training time: 15618.0825\n",
      "Epoch : 1347/2000 data_batch_1,  Train_loss : 4768.8926  Test_loss : 4841.0645, Time/batch_file : 2.2759, Training time: 15620.3586\n",
      "Epoch : 1347/2000 data_batch_2,  Train_loss : 5038.4414  Test_loss : 5064.5249, Time/batch_file : 2.2650, Training time: 15622.6238\n",
      "Epoch : 1347/2000 data_batch_3,  Train_loss : 4777.1646  Test_loss : 4949.9248, Time/batch_file : 2.2803, Training time: 15624.9043\n",
      "Epoch : 1347/2000 data_batch_4,  Train_loss : 4687.7959  Test_loss : 4938.9209, Time/batch_file : 2.2632, Training time: 15627.1676\n",
      "Epoch : 1347/2000 data_batch_5,  Train_loss : 4848.2544  Test_loss : 5316.0088, Time/batch_file : 2.2811, Training time: 15629.4489\n",
      "Epoch : 1348/2000 data_batch_1,  Train_loss : 4027.0879  Test_loss : 4985.4619, Time/batch_file : 2.2573, Training time: 15631.7063\n",
      "Epoch : 1348/2000 data_batch_2,  Train_loss : 4297.5820  Test_loss : 5032.7368, Time/batch_file : 2.2605, Training time: 15633.9671\n",
      "Epoch : 1348/2000 data_batch_3,  Train_loss : 4303.2261  Test_loss : 4884.5767, Time/batch_file : 2.2584, Training time: 15636.2257\n",
      "Epoch : 1348/2000 data_batch_4,  Train_loss : 4372.1924  Test_loss : 4861.1230, Time/batch_file : 2.2627, Training time: 15638.4887\n",
      "Epoch : 1348/2000 data_batch_5,  Train_loss : 4106.0723  Test_loss : 4913.0117, Time/batch_file : 2.2723, Training time: 15640.7612\n",
      "Epoch : 1349/2000 data_batch_1,  Train_loss : 4584.9644  Test_loss : 4731.6099, Time/batch_file : 2.2838, Training time: 15643.0451\n",
      "Epoch : 1349/2000 data_batch_2,  Train_loss : 4430.0562  Test_loss : 4876.2729, Time/batch_file : 2.2825, Training time: 15645.3278\n",
      "Epoch : 1349/2000 data_batch_3,  Train_loss : 4450.7793  Test_loss : 4845.8936, Time/batch_file : 2.2859, Training time: 15647.6139\n",
      "Epoch : 1349/2000 data_batch_4,  Train_loss : 4155.1914  Test_loss : 4885.3960, Time/batch_file : 2.2943, Training time: 15649.9083\n",
      "Epoch : 1349/2000 data_batch_5,  Train_loss : 4536.4639  Test_loss : 4878.1748, Time/batch_file : 2.2756, Training time: 15652.1842\n",
      "Epoch : 1350/2000 data_batch_1,  Train_loss : 4499.3291  Test_loss : 4394.8481, Time/batch_file : 2.2663, Training time: 15654.4507\n",
      "Epoch : 1350/2000 data_batch_2,  Train_loss : 4498.1411  Test_loss : 4416.4565, Time/batch_file : 2.2721, Training time: 15656.7231\n",
      "Epoch : 1350/2000 data_batch_3,  Train_loss : 4626.5195  Test_loss : 4615.8965, Time/batch_file : 2.3006, Training time: 15659.0240\n",
      "Epoch : 1350/2000 data_batch_4,  Train_loss : 4692.5889  Test_loss : 4510.0605, Time/batch_file : 2.2794, Training time: 15661.3036\n",
      "Epoch : 1350/2000 data_batch_5,  Train_loss : 4585.3945  Test_loss : 4775.3706, Time/batch_file : 2.2586, Training time: 15663.5624\n",
      "[./nets/net-1350.ckpt] SAVED\n",
      "Epoch : 1351/2000 data_batch_1,  Train_loss : 4787.3101  Test_loss : 4662.6040, Time/batch_file : 2.9373, Training time: 15667.8216\n",
      "Epoch : 1351/2000 data_batch_2,  Train_loss : 4841.1553  Test_loss : 4900.3135, Time/batch_file : 2.2941, Training time: 15670.1159\n",
      "Epoch : 1351/2000 data_batch_3,  Train_loss : 4759.7021  Test_loss : 4938.9429, Time/batch_file : 2.2886, Training time: 15672.4046\n",
      "Epoch : 1351/2000 data_batch_4,  Train_loss : 4541.0327  Test_loss : 4686.2847, Time/batch_file : 2.2676, Training time: 15674.6724\n",
      "Epoch : 1351/2000 data_batch_5,  Train_loss : 4680.1826  Test_loss : 5225.4541, Time/batch_file : 2.2907, Training time: 15676.9632\n",
      "Epoch : 1352/2000 data_batch_1,  Train_loss : 4549.5791  Test_loss : 5788.6240, Time/batch_file : 2.2721, Training time: 15679.2356\n",
      "Epoch : 1352/2000 data_batch_2,  Train_loss : 4613.2500  Test_loss : 5594.3013, Time/batch_file : 2.2567, Training time: 15681.4925\n",
      "Epoch : 1352/2000 data_batch_3,  Train_loss : 4351.4775  Test_loss : 5511.6606, Time/batch_file : 2.2621, Training time: 15683.7548\n",
      "Epoch : 1352/2000 data_batch_4,  Train_loss : 4438.2095  Test_loss : 5262.6216, Time/batch_file : 2.2708, Training time: 15686.0258\n",
      "Epoch : 1352/2000 data_batch_5,  Train_loss : 4585.2432  Test_loss : 5463.7114, Time/batch_file : 2.2633, Training time: 15688.2893\n",
      "Epoch : 1353/2000 data_batch_1,  Train_loss : 4444.4878  Test_loss : 4959.8867, Time/batch_file : 2.3016, Training time: 15690.5910\n",
      "Epoch : 1353/2000 data_batch_2,  Train_loss : 4378.4111  Test_loss : 5121.5576, Time/batch_file : 2.2851, Training time: 15692.8763\n",
      "Epoch : 1353/2000 data_batch_3,  Train_loss : 4812.5928  Test_loss : 4951.1123, Time/batch_file : 2.2867, Training time: 15695.1631\n",
      "Epoch : 1353/2000 data_batch_4,  Train_loss : 4417.8091  Test_loss : 4788.1299, Time/batch_file : 2.2772, Training time: 15697.4406\n",
      "Epoch : 1353/2000 data_batch_5,  Train_loss : 4494.7954  Test_loss : 5067.4507, Time/batch_file : 2.2899, Training time: 15699.7308\n",
      "Epoch : 1354/2000 data_batch_1,  Train_loss : 5016.4233  Test_loss : 4794.3213, Time/batch_file : 2.2705, Training time: 15702.0015\n",
      "Epoch : 1354/2000 data_batch_2,  Train_loss : 5156.8989  Test_loss : 4837.6333, Time/batch_file : 2.2766, Training time: 15704.2783\n",
      "Epoch : 1354/2000 data_batch_3,  Train_loss : 4959.4663  Test_loss : 4997.6846, Time/batch_file : 2.2974, Training time: 15706.5759\n",
      "Epoch : 1354/2000 data_batch_4,  Train_loss : 4769.7310  Test_loss : 4757.1084, Time/batch_file : 2.2779, Training time: 15708.8540\n",
      "Epoch : 1354/2000 data_batch_5,  Train_loss : 5056.9014  Test_loss : 4509.6045, Time/batch_file : 2.2671, Training time: 15711.1212\n",
      "Epoch : 1355/2000 data_batch_1,  Train_loss : 4450.0596  Test_loss : 4890.4043, Time/batch_file : 2.2886, Training time: 15713.4100\n",
      "Epoch : 1355/2000 data_batch_2,  Train_loss : 4381.1938  Test_loss : 4750.7749, Time/batch_file : 2.2887, Training time: 15715.6989\n",
      "Epoch : 1355/2000 data_batch_3,  Train_loss : 4327.2705  Test_loss : 4572.6133, Time/batch_file : 2.2776, Training time: 15717.9767\n",
      "Epoch : 1355/2000 data_batch_4,  Train_loss : 4359.7515  Test_loss : 4751.0889, Time/batch_file : 2.2797, Training time: 15720.2567\n",
      "Epoch : 1355/2000 data_batch_5,  Train_loss : 4512.0747  Test_loss : 4965.8149, Time/batch_file : 2.2896, Training time: 15722.5466\n",
      "Epoch : 1356/2000 data_batch_1,  Train_loss : 4440.0239  Test_loss : 5600.5146, Time/batch_file : 2.2688, Training time: 15724.8157\n",
      "Epoch : 1356/2000 data_batch_2,  Train_loss : 4694.7998  Test_loss : 5555.1069, Time/batch_file : 2.2925, Training time: 15727.1083\n",
      "Epoch : 1356/2000 data_batch_3,  Train_loss : 4377.7544  Test_loss : 5762.9668, Time/batch_file : 2.2702, Training time: 15729.3787\n",
      "Epoch : 1356/2000 data_batch_4,  Train_loss : 4155.0698  Test_loss : 5396.7144, Time/batch_file : 2.2760, Training time: 15731.6549\n",
      "Epoch : 1356/2000 data_batch_5,  Train_loss : 4394.6650  Test_loss : 5585.7637, Time/batch_file : 2.2694, Training time: 15733.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1357/2000 data_batch_1,  Train_loss : 4448.9736  Test_loss : 5382.3770, Time/batch_file : 2.2734, Training time: 15736.1981\n",
      "Epoch : 1357/2000 data_batch_2,  Train_loss : 4466.5317  Test_loss : 5810.2944, Time/batch_file : 2.2821, Training time: 15738.4804\n",
      "Epoch : 1357/2000 data_batch_3,  Train_loss : 4359.4893  Test_loss : 5454.8652, Time/batch_file : 2.2855, Training time: 15740.7661\n",
      "Epoch : 1357/2000 data_batch_4,  Train_loss : 4505.5142  Test_loss : 5438.5200, Time/batch_file : 2.2611, Training time: 15743.0274\n",
      "Epoch : 1357/2000 data_batch_5,  Train_loss : 4532.1992  Test_loss : 5580.4229, Time/batch_file : 2.2782, Training time: 15745.3057\n",
      "Epoch : 1358/2000 data_batch_1,  Train_loss : 4631.7383  Test_loss : 5035.3555, Time/batch_file : 2.2745, Training time: 15747.5804\n",
      "Epoch : 1358/2000 data_batch_2,  Train_loss : 4373.1348  Test_loss : 5249.3447, Time/batch_file : 2.2915, Training time: 15749.8721\n",
      "Epoch : 1358/2000 data_batch_3,  Train_loss : 4616.6831  Test_loss : 5072.8584, Time/batch_file : 2.2869, Training time: 15752.1592\n",
      "Epoch : 1358/2000 data_batch_4,  Train_loss : 4524.8770  Test_loss : 4738.4863, Time/batch_file : 2.2829, Training time: 15754.4423\n",
      "Epoch : 1358/2000 data_batch_5,  Train_loss : 4513.1387  Test_loss : 5045.3716, Time/batch_file : 2.2774, Training time: 15756.7199\n",
      "Epoch : 1359/2000 data_batch_1,  Train_loss : 4896.6821  Test_loss : 4824.0854, Time/batch_file : 2.2835, Training time: 15759.0037\n",
      "Epoch : 1359/2000 data_batch_2,  Train_loss : 4765.1172  Test_loss : 4785.5596, Time/batch_file : 2.2858, Training time: 15761.2897\n",
      "Epoch : 1359/2000 data_batch_3,  Train_loss : 4839.2871  Test_loss : 5170.5293, Time/batch_file : 2.2910, Training time: 15763.5809\n",
      "Epoch : 1359/2000 data_batch_4,  Train_loss : 4726.8711  Test_loss : 5225.2529, Time/batch_file : 2.2873, Training time: 15765.8684\n",
      "Epoch : 1359/2000 data_batch_5,  Train_loss : 4906.6465  Test_loss : 4943.8857, Time/batch_file : 2.2906, Training time: 15768.1592\n",
      "Epoch : 1360/2000 data_batch_1,  Train_loss : 4572.7339  Test_loss : 4734.1602, Time/batch_file : 2.2820, Training time: 15770.4415\n",
      "Epoch : 1360/2000 data_batch_2,  Train_loss : 4870.3403  Test_loss : 4897.6328, Time/batch_file : 2.2814, Training time: 15772.7231\n",
      "Epoch : 1360/2000 data_batch_3,  Train_loss : 4781.9819  Test_loss : 4924.5068, Time/batch_file : 2.2796, Training time: 15775.0030\n",
      "Epoch : 1360/2000 data_batch_4,  Train_loss : 4730.6406  Test_loss : 4938.2798, Time/batch_file : 2.2978, Training time: 15777.3009\n",
      "Epoch : 1360/2000 data_batch_5,  Train_loss : 4738.7397  Test_loss : 4963.8457, Time/batch_file : 2.2669, Training time: 15779.5680\n",
      "[./nets/net-1360.ckpt] SAVED\n",
      "Epoch : 1361/2000 data_batch_1,  Train_loss : 5115.7461  Test_loss : 5011.3066, Time/batch_file : 2.3850, Training time: 15783.2293\n",
      "Epoch : 1361/2000 data_batch_2,  Train_loss : 4776.5068  Test_loss : 5009.3438, Time/batch_file : 2.2741, Training time: 15785.5037\n",
      "Epoch : 1361/2000 data_batch_3,  Train_loss : 4996.8232  Test_loss : 5135.7490, Time/batch_file : 2.2819, Training time: 15787.7858\n",
      "Epoch : 1361/2000 data_batch_4,  Train_loss : 4913.8750  Test_loss : 4676.4717, Time/batch_file : 2.2631, Training time: 15790.0491\n",
      "Epoch : 1361/2000 data_batch_5,  Train_loss : 4957.2695  Test_loss : 4939.8013, Time/batch_file : 2.2634, Training time: 15792.3128\n",
      "Epoch : 1362/2000 data_batch_1,  Train_loss : 4293.8193  Test_loss : 4914.5566, Time/batch_file : 2.2868, Training time: 15794.5997\n",
      "Epoch : 1362/2000 data_batch_2,  Train_loss : 4079.8384  Test_loss : 4969.9961, Time/batch_file : 2.2887, Training time: 15796.8886\n",
      "Epoch : 1362/2000 data_batch_3,  Train_loss : 4353.8862  Test_loss : 4914.5049, Time/batch_file : 2.2815, Training time: 15799.1704\n",
      "Epoch : 1362/2000 data_batch_4,  Train_loss : 4085.7629  Test_loss : 4955.7832, Time/batch_file : 2.2784, Training time: 15801.4491\n",
      "Epoch : 1362/2000 data_batch_5,  Train_loss : 4216.8735  Test_loss : 5189.3867, Time/batch_file : 2.2853, Training time: 15803.7345\n",
      "Epoch : 1363/2000 data_batch_1,  Train_loss : 4881.4238  Test_loss : 5239.1074, Time/batch_file : 2.2595, Training time: 15805.9943\n",
      "Epoch : 1363/2000 data_batch_2,  Train_loss : 4270.2773  Test_loss : 5327.9077, Time/batch_file : 2.2559, Training time: 15808.2504\n",
      "Epoch : 1363/2000 data_batch_3,  Train_loss : 4561.3281  Test_loss : 5035.3960, Time/batch_file : 2.2580, Training time: 15810.5086\n",
      "Epoch : 1363/2000 data_batch_4,  Train_loss : 4872.4834  Test_loss : 5278.1748, Time/batch_file : 2.2597, Training time: 15812.7685\n",
      "Epoch : 1363/2000 data_batch_5,  Train_loss : 4823.2368  Test_loss : 5102.1875, Time/batch_file : 2.2633, Training time: 15815.0320\n",
      "Epoch : 1364/2000 data_batch_1,  Train_loss : 4902.8291  Test_loss : 5537.1787, Time/batch_file : 2.2717, Training time: 15817.3040\n",
      "Epoch : 1364/2000 data_batch_2,  Train_loss : 4731.3291  Test_loss : 5484.7480, Time/batch_file : 2.2716, Training time: 15819.5758\n",
      "Epoch : 1364/2000 data_batch_3,  Train_loss : 4862.1548  Test_loss : 5614.4414, Time/batch_file : 2.2848, Training time: 15821.8608\n",
      "Epoch : 1364/2000 data_batch_4,  Train_loss : 4989.4941  Test_loss : 5461.0571, Time/batch_file : 2.2767, Training time: 15824.1377\n",
      "Epoch : 1364/2000 data_batch_5,  Train_loss : 5110.2007  Test_loss : 5596.3374, Time/batch_file : 2.2677, Training time: 15826.4056\n",
      "Epoch : 1365/2000 data_batch_1,  Train_loss : 4342.1426  Test_loss : 4873.6431, Time/batch_file : 2.2764, Training time: 15828.6822\n",
      "Epoch : 1365/2000 data_batch_2,  Train_loss : 4672.8296  Test_loss : 4916.1567, Time/batch_file : 2.2830, Training time: 15830.9653\n",
      "Epoch : 1365/2000 data_batch_3,  Train_loss : 4863.6558  Test_loss : 4646.5190, Time/batch_file : 2.2845, Training time: 15833.2500\n",
      "Epoch : 1365/2000 data_batch_4,  Train_loss : 4580.1851  Test_loss : 4641.9805, Time/batch_file : 2.2621, Training time: 15835.5123\n",
      "Epoch : 1365/2000 data_batch_5,  Train_loss : 4678.7295  Test_loss : 5046.5723, Time/batch_file : 2.2656, Training time: 15837.7780\n",
      "Epoch : 1366/2000 data_batch_1,  Train_loss : 4583.3491  Test_loss : 5179.9888, Time/batch_file : 2.2609, Training time: 15840.0393\n",
      "Epoch : 1366/2000 data_batch_2,  Train_loss : 4599.8413  Test_loss : 5316.1006, Time/batch_file : 2.2599, Training time: 15842.2994\n",
      "Epoch : 1366/2000 data_batch_3,  Train_loss : 4515.2344  Test_loss : 4961.1846, Time/batch_file : 2.2746, Training time: 15844.5742\n",
      "Epoch : 1366/2000 data_batch_4,  Train_loss : 4253.5137  Test_loss : 4991.3599, Time/batch_file : 2.2704, Training time: 15846.8448\n",
      "Epoch : 1366/2000 data_batch_5,  Train_loss : 4654.7852  Test_loss : 5117.9385, Time/batch_file : 2.2698, Training time: 15849.1149\n",
      "Epoch : 1367/2000 data_batch_1,  Train_loss : 5394.4746  Test_loss : 4664.2061, Time/batch_file : 2.2853, Training time: 15851.4004\n",
      "Epoch : 1367/2000 data_batch_2,  Train_loss : 5382.4150  Test_loss : 5076.7129, Time/batch_file : 2.2712, Training time: 15853.6718\n",
      "Epoch : 1367/2000 data_batch_3,  Train_loss : 5060.7520  Test_loss : 4890.5049, Time/batch_file : 2.2903, Training time: 15855.9622\n",
      "Epoch : 1367/2000 data_batch_4,  Train_loss : 5063.9990  Test_loss : 4612.7842, Time/batch_file : 2.2771, Training time: 15858.2395\n",
      "Epoch : 1367/2000 data_batch_5,  Train_loss : 5270.8960  Test_loss : 5187.4360, Time/batch_file : 2.2870, Training time: 15860.5268\n",
      "Epoch : 1368/2000 data_batch_1,  Train_loss : 4813.9526  Test_loss : 5133.6670, Time/batch_file : 2.2749, Training time: 15862.8019\n",
      "Epoch : 1368/2000 data_batch_2,  Train_loss : 4931.7725  Test_loss : 4862.3794, Time/batch_file : 2.2679, Training time: 15865.0700\n",
      "Epoch : 1368/2000 data_batch_3,  Train_loss : 4728.9170  Test_loss : 4930.5825, Time/batch_file : 2.2726, Training time: 15867.3428\n",
      "Epoch : 1368/2000 data_batch_4,  Train_loss : 4563.7427  Test_loss : 5169.3032, Time/batch_file : 2.2750, Training time: 15869.6180\n",
      "Epoch : 1368/2000 data_batch_5,  Train_loss : 4548.8003  Test_loss : 5180.9399, Time/batch_file : 2.2782, Training time: 15871.8965\n",
      "Epoch : 1369/2000 data_batch_1,  Train_loss : 4104.3198  Test_loss : 4979.7832, Time/batch_file : 2.2660, Training time: 15874.1627\n",
      "Epoch : 1369/2000 data_batch_2,  Train_loss : 4255.4688  Test_loss : 5093.6426, Time/batch_file : 2.2784, Training time: 15876.4413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1369/2000 data_batch_3,  Train_loss : 4490.1733  Test_loss : 4838.0674, Time/batch_file : 2.2790, Training time: 15878.7205\n",
      "Epoch : 1369/2000 data_batch_4,  Train_loss : 4277.4336  Test_loss : 4984.7642, Time/batch_file : 2.2763, Training time: 15880.9971\n",
      "Epoch : 1369/2000 data_batch_5,  Train_loss : 4207.0776  Test_loss : 5069.7803, Time/batch_file : 2.2689, Training time: 15883.2663\n",
      "Epoch : 1370/2000 data_batch_1,  Train_loss : 4487.9668  Test_loss : 4699.8159, Time/batch_file : 2.2733, Training time: 15885.5398\n",
      "Epoch : 1370/2000 data_batch_2,  Train_loss : 4586.8335  Test_loss : 4543.6963, Time/batch_file : 2.2769, Training time: 15887.8170\n",
      "Epoch : 1370/2000 data_batch_3,  Train_loss : 4724.4546  Test_loss : 4643.3481, Time/batch_file : 2.2725, Training time: 15890.0896\n",
      "Epoch : 1370/2000 data_batch_4,  Train_loss : 4457.6157  Test_loss : 4805.9126, Time/batch_file : 2.2715, Training time: 15892.3613\n",
      "Epoch : 1370/2000 data_batch_5,  Train_loss : 4390.8198  Test_loss : 4595.0439, Time/batch_file : 2.2746, Training time: 15894.6363\n",
      "[./nets/net-1370.ckpt] SAVED\n",
      "Epoch : 1371/2000 data_batch_1,  Train_loss : 4931.5674  Test_loss : 5055.6372, Time/batch_file : 2.4086, Training time: 15898.3163\n",
      "Epoch : 1371/2000 data_batch_2,  Train_loss : 4686.2876  Test_loss : 4946.5674, Time/batch_file : 2.2666, Training time: 15900.5831\n",
      "Epoch : 1371/2000 data_batch_3,  Train_loss : 4940.8979  Test_loss : 4995.0771, Time/batch_file : 2.2747, Training time: 15902.8580\n",
      "Epoch : 1371/2000 data_batch_4,  Train_loss : 5022.9487  Test_loss : 5042.3726, Time/batch_file : 2.2624, Training time: 15905.1207\n",
      "Epoch : 1371/2000 data_batch_5,  Train_loss : 4979.8125  Test_loss : 4727.3779, Time/batch_file : 2.2894, Training time: 15907.4104\n",
      "Epoch : 1372/2000 data_batch_1,  Train_loss : 4743.8652  Test_loss : 4425.3315, Time/batch_file : 2.2498, Training time: 15909.6603\n",
      "Epoch : 1372/2000 data_batch_2,  Train_loss : 4632.2666  Test_loss : 4304.9341, Time/batch_file : 2.2571, Training time: 15911.9177\n",
      "Epoch : 1372/2000 data_batch_3,  Train_loss : 4643.5361  Test_loss : 4602.3809, Time/batch_file : 2.2482, Training time: 15914.1662\n",
      "Epoch : 1372/2000 data_batch_4,  Train_loss : 4773.2656  Test_loss : 4500.1094, Time/batch_file : 2.2737, Training time: 15916.4401\n",
      "Epoch : 1372/2000 data_batch_5,  Train_loss : 4394.6387  Test_loss : 4437.2437, Time/batch_file : 2.2525, Training time: 15918.6928\n",
      "Epoch : 1373/2000 data_batch_1,  Train_loss : 5094.4932  Test_loss : 4918.2061, Time/batch_file : 2.3146, Training time: 15921.0076\n",
      "Epoch : 1373/2000 data_batch_2,  Train_loss : 5180.5669  Test_loss : 4830.0752, Time/batch_file : 2.2524, Training time: 15923.2603\n",
      "Epoch : 1373/2000 data_batch_3,  Train_loss : 5156.3613  Test_loss : 5004.1660, Time/batch_file : 2.2713, Training time: 15925.5318\n",
      "Epoch : 1373/2000 data_batch_4,  Train_loss : 5064.2822  Test_loss : 4945.6401, Time/batch_file : 2.2763, Training time: 15927.8082\n",
      "Epoch : 1373/2000 data_batch_5,  Train_loss : 5249.3701  Test_loss : 4906.5894, Time/batch_file : 2.2741, Training time: 15930.0826\n",
      "Epoch : 1374/2000 data_batch_1,  Train_loss : 4319.2715  Test_loss : 5159.6851, Time/batch_file : 2.2553, Training time: 15932.3382\n",
      "Epoch : 1374/2000 data_batch_2,  Train_loss : 4302.9385  Test_loss : 5157.3389, Time/batch_file : 2.2754, Training time: 15934.6138\n",
      "Epoch : 1374/2000 data_batch_3,  Train_loss : 4552.0410  Test_loss : 4954.5801, Time/batch_file : 2.2619, Training time: 15936.8759\n",
      "Epoch : 1374/2000 data_batch_4,  Train_loss : 4134.6943  Test_loss : 4902.4512, Time/batch_file : 2.2721, Training time: 15939.1482\n",
      "Epoch : 1374/2000 data_batch_5,  Train_loss : 4353.9736  Test_loss : 5010.1123, Time/batch_file : 2.2631, Training time: 15941.4115\n",
      "Epoch : 1375/2000 data_batch_1,  Train_loss : 4613.4150  Test_loss : 4369.3696, Time/batch_file : 2.2784, Training time: 15943.6901\n",
      "Epoch : 1375/2000 data_batch_2,  Train_loss : 4821.0156  Test_loss : 4565.2676, Time/batch_file : 2.2764, Training time: 15945.9667\n",
      "Epoch : 1375/2000 data_batch_3,  Train_loss : 4576.7393  Test_loss : 4402.9409, Time/batch_file : 2.2820, Training time: 15948.2489\n",
      "Epoch : 1375/2000 data_batch_4,  Train_loss : 4794.8916  Test_loss : 4533.2793, Time/batch_file : 2.2628, Training time: 15950.5119\n",
      "Epoch : 1375/2000 data_batch_5,  Train_loss : 4654.6494  Test_loss : 4221.5439, Time/batch_file : 2.2857, Training time: 15952.7978\n",
      "Epoch : 1376/2000 data_batch_1,  Train_loss : 4544.4785  Test_loss : 4730.4346, Time/batch_file : 2.2785, Training time: 15955.0765\n",
      "Epoch : 1376/2000 data_batch_2,  Train_loss : 4529.8936  Test_loss : 4991.7915, Time/batch_file : 2.2904, Training time: 15957.3671\n",
      "Epoch : 1376/2000 data_batch_3,  Train_loss : 4905.1475  Test_loss : 4974.7227, Time/batch_file : 2.2701, Training time: 15959.6374\n",
      "Epoch : 1376/2000 data_batch_4,  Train_loss : 4816.5352  Test_loss : 4988.1001, Time/batch_file : 2.2849, Training time: 15961.9225\n",
      "Epoch : 1376/2000 data_batch_5,  Train_loss : 4575.8936  Test_loss : 4946.5444, Time/batch_file : 2.2752, Training time: 15964.1979\n",
      "Epoch : 1377/2000 data_batch_1,  Train_loss : 4979.2266  Test_loss : 4989.1113, Time/batch_file : 2.2633, Training time: 15966.4614\n",
      "Epoch : 1377/2000 data_batch_2,  Train_loss : 4554.7334  Test_loss : 4496.8911, Time/batch_file : 2.2525, Training time: 15968.7141\n",
      "Epoch : 1377/2000 data_batch_3,  Train_loss : 4354.5708  Test_loss : 4627.0586, Time/batch_file : 2.2808, Training time: 15970.9951\n",
      "Epoch : 1377/2000 data_batch_4,  Train_loss : 4569.5146  Test_loss : 4636.3140, Time/batch_file : 2.2644, Training time: 15973.2598\n",
      "Epoch : 1377/2000 data_batch_5,  Train_loss : 4684.4805  Test_loss : 4536.3311, Time/batch_file : 2.2640, Training time: 15975.5240\n",
      "Epoch : 1378/2000 data_batch_1,  Train_loss : 4809.4995  Test_loss : 4473.6670, Time/batch_file : 2.2607, Training time: 15977.7850\n",
      "Epoch : 1378/2000 data_batch_2,  Train_loss : 4946.0581  Test_loss : 4782.8848, Time/batch_file : 2.2795, Training time: 15980.0647\n",
      "Epoch : 1378/2000 data_batch_3,  Train_loss : 5024.2109  Test_loss : 4801.4561, Time/batch_file : 2.2670, Training time: 15982.3318\n",
      "Epoch : 1378/2000 data_batch_4,  Train_loss : 4723.6904  Test_loss : 4887.0562, Time/batch_file : 2.2799, Training time: 15984.6119\n",
      "Epoch : 1378/2000 data_batch_5,  Train_loss : 4889.8916  Test_loss : 4899.1353, Time/batch_file : 2.2577, Training time: 15986.8698\n",
      "Epoch : 1379/2000 data_batch_1,  Train_loss : 4802.2578  Test_loss : 4907.4175, Time/batch_file : 2.2771, Training time: 15989.1471\n",
      "Epoch : 1379/2000 data_batch_2,  Train_loss : 4456.7500  Test_loss : 4840.2998, Time/batch_file : 2.2519, Training time: 15991.3992\n",
      "Epoch : 1379/2000 data_batch_3,  Train_loss : 4674.2822  Test_loss : 4669.7412, Time/batch_file : 2.2658, Training time: 15993.6652\n",
      "Epoch : 1379/2000 data_batch_4,  Train_loss : 4868.3057  Test_loss : 4924.9248, Time/batch_file : 2.2581, Training time: 15995.9236\n",
      "Epoch : 1379/2000 data_batch_5,  Train_loss : 4626.5215  Test_loss : 4921.9443, Time/batch_file : 2.2692, Training time: 15998.1930\n",
      "Epoch : 1380/2000 data_batch_1,  Train_loss : 4820.7588  Test_loss : 5126.5371, Time/batch_file : 2.2819, Training time: 16000.4751\n",
      "Epoch : 1380/2000 data_batch_2,  Train_loss : 4722.2832  Test_loss : 5162.7773, Time/batch_file : 2.2931, Training time: 16002.7683\n",
      "Epoch : 1380/2000 data_batch_3,  Train_loss : 4520.0713  Test_loss : 5274.9307, Time/batch_file : 2.2771, Training time: 16005.0455\n",
      "Epoch : 1380/2000 data_batch_4,  Train_loss : 4667.2319  Test_loss : 5148.0693, Time/batch_file : 2.2981, Training time: 16007.3438\n",
      "Epoch : 1380/2000 data_batch_5,  Train_loss : 4670.7041  Test_loss : 5203.0933, Time/batch_file : 2.2814, Training time: 16009.6255\n",
      "[./nets/net-1380.ckpt] SAVED\n",
      "Epoch : 1381/2000 data_batch_1,  Train_loss : 4603.3633  Test_loss : 4851.9028, Time/batch_file : 2.4611, Training time: 16013.4710\n",
      "Epoch : 1381/2000 data_batch_2,  Train_loss : 4671.7129  Test_loss : 4853.1753, Time/batch_file : 2.2764, Training time: 16015.7475\n",
      "Epoch : 1381/2000 data_batch_3,  Train_loss : 4615.6157  Test_loss : 4705.9463, Time/batch_file : 2.2823, Training time: 16018.0301\n",
      "Epoch : 1381/2000 data_batch_4,  Train_loss : 4461.2178  Test_loss : 4668.0527, Time/batch_file : 2.2894, Training time: 16020.3197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1381/2000 data_batch_5,  Train_loss : 4657.6880  Test_loss : 5029.4941, Time/batch_file : 2.2712, Training time: 16022.5911\n",
      "Epoch : 1382/2000 data_batch_1,  Train_loss : 4792.6528  Test_loss : 4929.4590, Time/batch_file : 2.2805, Training time: 16024.8718\n",
      "Epoch : 1382/2000 data_batch_2,  Train_loss : 4481.0244  Test_loss : 4946.6216, Time/batch_file : 2.2596, Training time: 16027.1316\n",
      "Epoch : 1382/2000 data_batch_3,  Train_loss : 4447.5220  Test_loss : 5234.4658, Time/batch_file : 2.2622, Training time: 16029.3940\n",
      "Epoch : 1382/2000 data_batch_4,  Train_loss : 4572.5220  Test_loss : 5137.7939, Time/batch_file : 2.2599, Training time: 16031.6540\n",
      "Epoch : 1382/2000 data_batch_5,  Train_loss : 4407.7651  Test_loss : 5286.6064, Time/batch_file : 2.2622, Training time: 16033.9164\n",
      "Epoch : 1383/2000 data_batch_1,  Train_loss : 4212.9531  Test_loss : 4663.0630, Time/batch_file : 2.2645, Training time: 16036.1811\n",
      "Epoch : 1383/2000 data_batch_2,  Train_loss : 4458.4766  Test_loss : 4799.7939, Time/batch_file : 2.2726, Training time: 16038.4540\n",
      "Epoch : 1383/2000 data_batch_3,  Train_loss : 4414.7104  Test_loss : 4573.9033, Time/batch_file : 2.2922, Training time: 16040.7464\n",
      "Epoch : 1383/2000 data_batch_4,  Train_loss : 4556.4692  Test_loss : 4876.2915, Time/batch_file : 2.2605, Training time: 16043.0072\n",
      "Epoch : 1383/2000 data_batch_5,  Train_loss : 4566.3672  Test_loss : 4677.1235, Time/batch_file : 2.2959, Training time: 16045.3033\n",
      "Epoch : 1384/2000 data_batch_1,  Train_loss : 4425.9355  Test_loss : 5116.0537, Time/batch_file : 2.2581, Training time: 16047.5615\n",
      "Epoch : 1384/2000 data_batch_2,  Train_loss : 4666.7393  Test_loss : 4798.3330, Time/batch_file : 2.2786, Training time: 16049.8403\n",
      "Epoch : 1384/2000 data_batch_3,  Train_loss : 4480.3662  Test_loss : 5167.3408, Time/batch_file : 2.2516, Training time: 16052.0922\n",
      "Epoch : 1384/2000 data_batch_4,  Train_loss : 4590.3789  Test_loss : 5299.0386, Time/batch_file : 2.2672, Training time: 16054.3597\n",
      "Epoch : 1384/2000 data_batch_5,  Train_loss : 4636.7500  Test_loss : 4837.8843, Time/batch_file : 2.2591, Training time: 16056.6189\n",
      "Epoch : 1385/2000 data_batch_1,  Train_loss : 4623.0474  Test_loss : 5463.7070, Time/batch_file : 2.2449, Training time: 16058.8639\n",
      "Epoch : 1385/2000 data_batch_2,  Train_loss : 5016.1807  Test_loss : 5229.3730, Time/batch_file : 2.2640, Training time: 16061.1281\n",
      "Epoch : 1385/2000 data_batch_3,  Train_loss : 4842.9131  Test_loss : 5564.9829, Time/batch_file : 2.2625, Training time: 16063.3908\n",
      "Epoch : 1385/2000 data_batch_4,  Train_loss : 4866.8062  Test_loss : 5230.7207, Time/batch_file : 2.2683, Training time: 16065.6594\n",
      "Epoch : 1385/2000 data_batch_5,  Train_loss : 5043.5698  Test_loss : 5477.4575, Time/batch_file : 2.2533, Training time: 16067.9128\n",
      "Epoch : 1386/2000 data_batch_1,  Train_loss : 4655.5371  Test_loss : 5230.4463, Time/batch_file : 2.2780, Training time: 16070.1911\n",
      "Epoch : 1386/2000 data_batch_2,  Train_loss : 4809.9414  Test_loss : 5081.8838, Time/batch_file : 2.2816, Training time: 16072.4729\n",
      "Epoch : 1386/2000 data_batch_3,  Train_loss : 4827.0991  Test_loss : 4696.2715, Time/batch_file : 2.2638, Training time: 16074.7369\n",
      "Epoch : 1386/2000 data_batch_4,  Train_loss : 4700.9331  Test_loss : 4948.8545, Time/batch_file : 2.2779, Training time: 16077.0150\n",
      "Epoch : 1386/2000 data_batch_5,  Train_loss : 4770.4619  Test_loss : 5116.7119, Time/batch_file : 2.2819, Training time: 16079.2973\n",
      "Epoch : 1387/2000 data_batch_1,  Train_loss : 4674.7383  Test_loss : 5299.2285, Time/batch_file : 2.2715, Training time: 16081.5691\n",
      "Epoch : 1387/2000 data_batch_2,  Train_loss : 4715.9873  Test_loss : 5032.7690, Time/batch_file : 2.2873, Training time: 16083.8566\n",
      "Epoch : 1387/2000 data_batch_3,  Train_loss : 4789.0371  Test_loss : 5199.6895, Time/batch_file : 2.2659, Training time: 16086.1227\n",
      "Epoch : 1387/2000 data_batch_4,  Train_loss : 4566.5479  Test_loss : 5033.3047, Time/batch_file : 2.2801, Training time: 16088.4030\n",
      "Epoch : 1387/2000 data_batch_5,  Train_loss : 4750.0566  Test_loss : 4982.8745, Time/batch_file : 2.2764, Training time: 16090.6795\n",
      "Epoch : 1388/2000 data_batch_1,  Train_loss : 5117.3555  Test_loss : 4623.0840, Time/batch_file : 2.2851, Training time: 16092.9649\n",
      "Epoch : 1388/2000 data_batch_2,  Train_loss : 5087.4473  Test_loss : 4871.7686, Time/batch_file : 2.2937, Training time: 16095.2587\n",
      "Epoch : 1388/2000 data_batch_3,  Train_loss : 5251.2773  Test_loss : 5116.4697, Time/batch_file : 2.2577, Training time: 16097.5167\n",
      "Epoch : 1388/2000 data_batch_4,  Train_loss : 5071.0522  Test_loss : 5013.9697, Time/batch_file : 2.2750, Training time: 16099.7920\n",
      "Epoch : 1388/2000 data_batch_5,  Train_loss : 5258.2866  Test_loss : 5033.1543, Time/batch_file : 2.2669, Training time: 16102.0591\n",
      "Epoch : 1389/2000 data_batch_1,  Train_loss : 4491.9941  Test_loss : 5284.4668, Time/batch_file : 2.2538, Training time: 16104.3132\n",
      "Epoch : 1389/2000 data_batch_2,  Train_loss : 4617.3340  Test_loss : 5179.5879, Time/batch_file : 2.2625, Training time: 16106.5760\n",
      "Epoch : 1389/2000 data_batch_3,  Train_loss : 4766.6997  Test_loss : 5237.1274, Time/batch_file : 2.2517, Training time: 16108.8279\n",
      "Epoch : 1389/2000 data_batch_4,  Train_loss : 4493.8301  Test_loss : 5191.0938, Time/batch_file : 2.2683, Training time: 16111.0965\n",
      "Epoch : 1389/2000 data_batch_5,  Train_loss : 4632.7290  Test_loss : 5078.3066, Time/batch_file : 2.2656, Training time: 16113.3624\n",
      "Epoch : 1390/2000 data_batch_1,  Train_loss : 4969.7588  Test_loss : 5024.0986, Time/batch_file : 2.2876, Training time: 16115.6502\n",
      "Epoch : 1390/2000 data_batch_2,  Train_loss : 4758.1968  Test_loss : 5131.2671, Time/batch_file : 2.3034, Training time: 16117.9538\n",
      "Epoch : 1390/2000 data_batch_3,  Train_loss : 5050.7998  Test_loss : 4983.3042, Time/batch_file : 2.2716, Training time: 16120.2256\n",
      "Epoch : 1390/2000 data_batch_4,  Train_loss : 4897.8765  Test_loss : 5199.7563, Time/batch_file : 2.2946, Training time: 16122.5203\n",
      "Epoch : 1390/2000 data_batch_5,  Train_loss : 4888.3335  Test_loss : 5073.1948, Time/batch_file : 2.2999, Training time: 16124.8204\n",
      "[./nets/net-1390.ckpt] SAVED\n",
      "Epoch : 1391/2000 data_batch_1,  Train_loss : 4596.1851  Test_loss : 4782.1152, Time/batch_file : 2.3504, Training time: 16128.4515\n",
      "Epoch : 1391/2000 data_batch_2,  Train_loss : 4872.9521  Test_loss : 4978.8872, Time/batch_file : 2.2656, Training time: 16130.7173\n",
      "Epoch : 1391/2000 data_batch_3,  Train_loss : 4562.0796  Test_loss : 4885.2256, Time/batch_file : 2.3003, Training time: 16133.0179\n",
      "Epoch : 1391/2000 data_batch_4,  Train_loss : 4982.6953  Test_loss : 4720.1675, Time/batch_file : 2.2753, Training time: 16135.2934\n",
      "Epoch : 1391/2000 data_batch_5,  Train_loss : 4473.7490  Test_loss : 4942.3042, Time/batch_file : 2.3075, Training time: 16137.6011\n",
      "Epoch : 1392/2000 data_batch_1,  Train_loss : 5013.7578  Test_loss : 5220.0400, Time/batch_file : 2.2744, Training time: 16139.8757\n",
      "Epoch : 1392/2000 data_batch_2,  Train_loss : 4763.7339  Test_loss : 5032.6387, Time/batch_file : 2.2884, Training time: 16142.1643\n",
      "Epoch : 1392/2000 data_batch_3,  Train_loss : 4761.3750  Test_loss : 5186.9321, Time/batch_file : 2.2783, Training time: 16144.4428\n",
      "Epoch : 1392/2000 data_batch_4,  Train_loss : 4706.8301  Test_loss : 5085.2852, Time/batch_file : 2.2935, Training time: 16146.7364\n",
      "Epoch : 1392/2000 data_batch_5,  Train_loss : 4925.5776  Test_loss : 5317.6611, Time/batch_file : 2.2720, Training time: 16149.0085\n",
      "Epoch : 1393/2000 data_batch_1,  Train_loss : 4829.2812  Test_loss : 4929.3960, Time/batch_file : 2.2890, Training time: 16151.2976\n",
      "Epoch : 1393/2000 data_batch_2,  Train_loss : 4821.7739  Test_loss : 4940.4673, Time/batch_file : 2.2778, Training time: 16153.5756\n",
      "Epoch : 1393/2000 data_batch_3,  Train_loss : 4640.1265  Test_loss : 5185.7788, Time/batch_file : 2.3083, Training time: 16155.8843\n",
      "Epoch : 1393/2000 data_batch_4,  Train_loss : 4643.4946  Test_loss : 5035.7114, Time/batch_file : 2.2667, Training time: 16158.1511\n",
      "Epoch : 1393/2000 data_batch_5,  Train_loss : 4605.3125  Test_loss : 5256.0093, Time/batch_file : 2.2911, Training time: 16160.4424\n",
      "Epoch : 1394/2000 data_batch_1,  Train_loss : 5032.8027  Test_loss : 4697.9209, Time/batch_file : 2.2793, Training time: 16162.7219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1394/2000 data_batch_2,  Train_loss : 4915.1055  Test_loss : 4694.3120, Time/batch_file : 2.2942, Training time: 16165.0163\n",
      "Epoch : 1394/2000 data_batch_3,  Train_loss : 4835.3096  Test_loss : 4888.4990, Time/batch_file : 2.2649, Training time: 16167.2814\n",
      "Epoch : 1394/2000 data_batch_4,  Train_loss : 4918.9072  Test_loss : 4836.5850, Time/batch_file : 2.2895, Training time: 16169.5712\n",
      "Epoch : 1394/2000 data_batch_5,  Train_loss : 5025.4990  Test_loss : 5195.3169, Time/batch_file : 2.2868, Training time: 16171.8582\n",
      "Epoch : 1395/2000 data_batch_1,  Train_loss : 4576.8335  Test_loss : 5275.8618, Time/batch_file : 2.3206, Training time: 16174.1790\n",
      "Epoch : 1395/2000 data_batch_2,  Train_loss : 4721.6392  Test_loss : 5320.6704, Time/batch_file : 2.2912, Training time: 16176.4704\n",
      "Epoch : 1395/2000 data_batch_3,  Train_loss : 4689.7686  Test_loss : 5020.1162, Time/batch_file : 2.3011, Training time: 16178.7717\n",
      "Epoch : 1395/2000 data_batch_4,  Train_loss : 4604.9883  Test_loss : 5235.2637, Time/batch_file : 2.2870, Training time: 16181.0589\n",
      "Epoch : 1395/2000 data_batch_5,  Train_loss : 4378.4165  Test_loss : 5232.0083, Time/batch_file : 2.2932, Training time: 16183.3523\n",
      "Epoch : 1396/2000 data_batch_1,  Train_loss : 4047.8838  Test_loss : 4705.9307, Time/batch_file : 2.2722, Training time: 16185.6247\n",
      "Epoch : 1396/2000 data_batch_2,  Train_loss : 4063.8018  Test_loss : 4566.8999, Time/batch_file : 2.2982, Training time: 16187.9231\n",
      "Epoch : 1396/2000 data_batch_3,  Train_loss : 4311.4526  Test_loss : 4796.8252, Time/batch_file : 2.2839, Training time: 16190.2071\n",
      "Epoch : 1396/2000 data_batch_4,  Train_loss : 4291.9282  Test_loss : 4731.6821, Time/batch_file : 2.3091, Training time: 16192.5163\n",
      "Epoch : 1396/2000 data_batch_5,  Train_loss : 4221.6831  Test_loss : 4498.0400, Time/batch_file : 2.2918, Training time: 16194.8082\n",
      "Epoch : 1397/2000 data_batch_1,  Train_loss : 4630.7437  Test_loss : 4505.9316, Time/batch_file : 2.2947, Training time: 16197.1032\n",
      "Epoch : 1397/2000 data_batch_2,  Train_loss : 4761.6846  Test_loss : 4690.7334, Time/batch_file : 2.2938, Training time: 16199.3971\n",
      "Epoch : 1397/2000 data_batch_3,  Train_loss : 4689.0439  Test_loss : 4380.8975, Time/batch_file : 2.3026, Training time: 16201.7000\n",
      "Epoch : 1397/2000 data_batch_4,  Train_loss : 5012.4961  Test_loss : 4592.8745, Time/batch_file : 2.2837, Training time: 16203.9839\n",
      "Epoch : 1397/2000 data_batch_5,  Train_loss : 4624.2461  Test_loss : 4643.5879, Time/batch_file : 2.3090, Training time: 16206.2930\n",
      "Epoch : 1398/2000 data_batch_1,  Train_loss : 4748.0776  Test_loss : 4588.6934, Time/batch_file : 2.2678, Training time: 16208.5611\n",
      "Epoch : 1398/2000 data_batch_2,  Train_loss : 4848.9443  Test_loss : 5082.0845, Time/batch_file : 2.2974, Training time: 16210.8587\n",
      "Epoch : 1398/2000 data_batch_3,  Train_loss : 4836.8330  Test_loss : 4609.2700, Time/batch_file : 2.2758, Training time: 16213.1347\n",
      "Epoch : 1398/2000 data_batch_4,  Train_loss : 4759.3247  Test_loss : 4675.5186, Time/batch_file : 2.2964, Training time: 16215.4313\n",
      "Epoch : 1398/2000 data_batch_5,  Train_loss : 4549.5166  Test_loss : 4644.1050, Time/batch_file : 2.2768, Training time: 16217.7084\n",
      "Epoch : 1399/2000 data_batch_1,  Train_loss : 4570.9238  Test_loss : 5149.7773, Time/batch_file : 2.3020, Training time: 16220.0106\n",
      "Epoch : 1399/2000 data_batch_2,  Train_loss : 4286.3931  Test_loss : 4828.6899, Time/batch_file : 2.2883, Training time: 16222.2991\n",
      "Epoch : 1399/2000 data_batch_3,  Train_loss : 4557.2505  Test_loss : 4949.0835, Time/batch_file : 2.2907, Training time: 16224.5901\n",
      "Epoch : 1399/2000 data_batch_4,  Train_loss : 4306.0312  Test_loss : 4970.2266, Time/batch_file : 2.2867, Training time: 16226.8771\n",
      "Epoch : 1399/2000 data_batch_5,  Train_loss : 4341.0835  Test_loss : 5207.7441, Time/batch_file : 2.2970, Training time: 16229.1742\n",
      "Epoch : 1400/2000 data_batch_1,  Train_loss : 5132.8940  Test_loss : 4842.2290, Time/batch_file : 2.2782, Training time: 16231.4527\n",
      "Epoch : 1400/2000 data_batch_2,  Train_loss : 5282.9009  Test_loss : 4870.4033, Time/batch_file : 2.3047, Training time: 16233.7575\n",
      "Epoch : 1400/2000 data_batch_3,  Train_loss : 5083.7466  Test_loss : 4801.5879, Time/batch_file : 2.2884, Training time: 16236.0461\n",
      "Epoch : 1400/2000 data_batch_4,  Train_loss : 5188.7002  Test_loss : 4581.4160, Time/batch_file : 2.2987, Training time: 16238.3451\n",
      "Epoch : 1400/2000 data_batch_5,  Train_loss : 5207.0898  Test_loss : 4957.5703, Time/batch_file : 2.2936, Training time: 16240.6389\n",
      "[./nets/net-1400.ckpt] SAVED\n",
      "Epoch : 1401/2000 data_batch_1,  Train_loss : 4755.2588  Test_loss : 5317.0044, Time/batch_file : 2.3012, Training time: 16248.7412\n",
      "Epoch : 1401/2000 data_batch_2,  Train_loss : 4913.4497  Test_loss : 5520.7832, Time/batch_file : 2.2944, Training time: 16251.0357\n",
      "Epoch : 1401/2000 data_batch_3,  Train_loss : 4870.3999  Test_loss : 5310.2451, Time/batch_file : 2.3016, Training time: 16253.3376\n",
      "Epoch : 1401/2000 data_batch_4,  Train_loss : 4996.4004  Test_loss : 5416.6499, Time/batch_file : 2.2811, Training time: 16255.6189\n",
      "Epoch : 1401/2000 data_batch_5,  Train_loss : 4948.3848  Test_loss : 5445.2725, Time/batch_file : 2.3330, Training time: 16257.9522\n",
      "Epoch : 1402/2000 data_batch_1,  Train_loss : 4805.2573  Test_loss : 4988.6201, Time/batch_file : 2.2793, Training time: 16260.2317\n",
      "Epoch : 1402/2000 data_batch_2,  Train_loss : 4591.4824  Test_loss : 5083.9111, Time/batch_file : 2.3045, Training time: 16262.5364\n",
      "Epoch : 1402/2000 data_batch_3,  Train_loss : 4606.8594  Test_loss : 4975.7471, Time/batch_file : 2.2810, Training time: 16264.8178\n",
      "Epoch : 1402/2000 data_batch_4,  Train_loss : 4671.0337  Test_loss : 5052.7671, Time/batch_file : 2.3040, Training time: 16267.1219\n",
      "Epoch : 1402/2000 data_batch_5,  Train_loss : 4701.1992  Test_loss : 5135.8271, Time/batch_file : 2.2864, Training time: 16269.4085\n",
      "Epoch : 1403/2000 data_batch_1,  Train_loss : 4260.0830  Test_loss : 4963.2666, Time/batch_file : 2.3125, Training time: 16271.7212\n",
      "Epoch : 1403/2000 data_batch_2,  Train_loss : 4159.4790  Test_loss : 4668.7202, Time/batch_file : 2.2863, Training time: 16274.0078\n",
      "Epoch : 1403/2000 data_batch_3,  Train_loss : 4380.7031  Test_loss : 5079.4795, Time/batch_file : 2.3002, Training time: 16276.3082\n",
      "Epoch : 1403/2000 data_batch_4,  Train_loss : 4148.9146  Test_loss : 4633.7280, Time/batch_file : 2.2932, Training time: 16278.6017\n",
      "Epoch : 1403/2000 data_batch_5,  Train_loss : 4304.1699  Test_loss : 5101.4019, Time/batch_file : 2.3063, Training time: 16280.9082\n",
      "Epoch : 1404/2000 data_batch_1,  Train_loss : 5089.0215  Test_loss : 5191.7490, Time/batch_file : 2.2779, Training time: 16283.1863\n",
      "Epoch : 1404/2000 data_batch_2,  Train_loss : 5063.6445  Test_loss : 5099.9014, Time/batch_file : 2.3125, Training time: 16285.4991\n",
      "Epoch : 1404/2000 data_batch_3,  Train_loss : 5198.9619  Test_loss : 4907.2715, Time/batch_file : 2.2849, Training time: 16287.7842\n",
      "Epoch : 1404/2000 data_batch_4,  Train_loss : 5158.3320  Test_loss : 5464.6689, Time/batch_file : 2.3082, Training time: 16290.0927\n",
      "Epoch : 1404/2000 data_batch_5,  Train_loss : 5186.4658  Test_loss : 5082.5542, Time/batch_file : 2.2882, Training time: 16292.3811\n",
      "Epoch : 1405/2000 data_batch_1,  Train_loss : 4750.5298  Test_loss : 5422.6465, Time/batch_file : 2.3171, Training time: 16294.6987\n",
      "Epoch : 1405/2000 data_batch_2,  Train_loss : 4758.4609  Test_loss : 5433.6992, Time/batch_file : 2.2919, Training time: 16296.9908\n",
      "Epoch : 1405/2000 data_batch_3,  Train_loss : 4734.6284  Test_loss : 5103.7944, Time/batch_file : 2.3190, Training time: 16299.3099\n",
      "Epoch : 1405/2000 data_batch_4,  Train_loss : 4763.8096  Test_loss : 4931.8677, Time/batch_file : 2.2913, Training time: 16301.6014\n",
      "Epoch : 1405/2000 data_batch_5,  Train_loss : 4865.8594  Test_loss : 5730.3540, Time/batch_file : 2.3152, Training time: 16303.9168\n",
      "Epoch : 1406/2000 data_batch_1,  Train_loss : 4451.4385  Test_loss : 5328.3950, Time/batch_file : 2.2732, Training time: 16306.1902\n",
      "Epoch : 1406/2000 data_batch_2,  Train_loss : 4473.6748  Test_loss : 5279.3955, Time/batch_file : 2.2952, Training time: 16308.4856\n",
      "Epoch : 1406/2000 data_batch_3,  Train_loss : 4484.8965  Test_loss : 5346.4312, Time/batch_file : 2.2827, Training time: 16310.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1406/2000 data_batch_4,  Train_loss : 4418.2295  Test_loss : 5253.9741, Time/batch_file : 2.2997, Training time: 16313.0684\n",
      "Epoch : 1406/2000 data_batch_5,  Train_loss : 4425.5776  Test_loss : 5193.4297, Time/batch_file : 2.2802, Training time: 16315.3487\n",
      "Epoch : 1407/2000 data_batch_1,  Train_loss : 4308.2549  Test_loss : 4903.5576, Time/batch_file : 2.3018, Training time: 16317.6506\n",
      "Epoch : 1407/2000 data_batch_2,  Train_loss : 4252.2651  Test_loss : 4945.6240, Time/batch_file : 2.2870, Training time: 16319.9379\n",
      "Epoch : 1407/2000 data_batch_3,  Train_loss : 4772.3940  Test_loss : 4756.2705, Time/batch_file : 2.3023, Training time: 16322.2404\n",
      "Epoch : 1407/2000 data_batch_4,  Train_loss : 4412.5747  Test_loss : 4695.6714, Time/batch_file : 2.2874, Training time: 16324.5280\n",
      "Epoch : 1407/2000 data_batch_5,  Train_loss : 4179.6621  Test_loss : 4957.4810, Time/batch_file : 2.2971, Training time: 16326.8254\n",
      "Epoch : 1408/2000 data_batch_1,  Train_loss : 4957.1494  Test_loss : 5106.0986, Time/batch_file : 2.2775, Training time: 16329.1031\n",
      "Epoch : 1408/2000 data_batch_2,  Train_loss : 5157.1782  Test_loss : 5172.1211, Time/batch_file : 2.2989, Training time: 16331.4022\n",
      "Epoch : 1408/2000 data_batch_3,  Train_loss : 4831.0020  Test_loss : 5132.2314, Time/batch_file : 2.2786, Training time: 16333.6809\n",
      "Epoch : 1408/2000 data_batch_4,  Train_loss : 4886.6538  Test_loss : 5030.9487, Time/batch_file : 2.3067, Training time: 16335.9878\n",
      "Epoch : 1408/2000 data_batch_5,  Train_loss : 5170.1685  Test_loss : 5201.8896, Time/batch_file : 2.2827, Training time: 16338.2708\n",
      "Epoch : 1409/2000 data_batch_1,  Train_loss : 5389.0830  Test_loss : 4939.0479, Time/batch_file : 2.2974, Training time: 16340.5685\n",
      "Epoch : 1409/2000 data_batch_2,  Train_loss : 4963.4414  Test_loss : 4780.0234, Time/batch_file : 2.2760, Training time: 16342.8446\n",
      "Epoch : 1409/2000 data_batch_3,  Train_loss : 5410.8350  Test_loss : 4664.2744, Time/batch_file : 2.2965, Training time: 16345.1413\n",
      "Epoch : 1409/2000 data_batch_4,  Train_loss : 5490.1489  Test_loss : 4719.0981, Time/batch_file : 2.2728, Training time: 16347.4143\n",
      "Epoch : 1409/2000 data_batch_5,  Train_loss : 5315.1934  Test_loss : 4423.0889, Time/batch_file : 2.3008, Training time: 16349.7154\n",
      "Epoch : 1410/2000 data_batch_1,  Train_loss : 4447.9590  Test_loss : 5092.7842, Time/batch_file : 2.2844, Training time: 16352.0000\n",
      "Epoch : 1410/2000 data_batch_2,  Train_loss : 4521.8330  Test_loss : 5198.9248, Time/batch_file : 2.3108, Training time: 16354.3110\n",
      "Epoch : 1410/2000 data_batch_3,  Train_loss : 4482.4531  Test_loss : 5030.6763, Time/batch_file : 2.2893, Training time: 16356.6005\n",
      "Epoch : 1410/2000 data_batch_4,  Train_loss : 4586.6538  Test_loss : 5408.6514, Time/batch_file : 2.3114, Training time: 16358.9121\n",
      "Epoch : 1410/2000 data_batch_5,  Train_loss : 4631.8877  Test_loss : 5111.5518, Time/batch_file : 2.2866, Training time: 16361.1989\n",
      "[./nets/net-1410.ckpt] SAVED\n",
      "Epoch : 1411/2000 data_batch_1,  Train_loss : 4532.0400  Test_loss : 4822.8594, Time/batch_file : 2.3993, Training time: 16364.8834\n",
      "Epoch : 1411/2000 data_batch_2,  Train_loss : 4299.0972  Test_loss : 5019.6055, Time/batch_file : 2.2718, Training time: 16367.1553\n",
      "Epoch : 1411/2000 data_batch_3,  Train_loss : 4550.7588  Test_loss : 4942.0630, Time/batch_file : 2.2701, Training time: 16369.4256\n",
      "Epoch : 1411/2000 data_batch_4,  Train_loss : 4467.4487  Test_loss : 5160.0913, Time/batch_file : 2.2728, Training time: 16371.6986\n",
      "Epoch : 1411/2000 data_batch_5,  Train_loss : 4342.6577  Test_loss : 4975.2168, Time/batch_file : 2.2800, Training time: 16373.9787\n",
      "Epoch : 1412/2000 data_batch_1,  Train_loss : 4417.1973  Test_loss : 4834.6904, Time/batch_file : 2.2696, Training time: 16376.2485\n",
      "Epoch : 1412/2000 data_batch_2,  Train_loss : 4629.1309  Test_loss : 4858.9160, Time/batch_file : 2.2921, Training time: 16378.5409\n",
      "Epoch : 1412/2000 data_batch_3,  Train_loss : 4946.0913  Test_loss : 5171.2764, Time/batch_file : 2.2742, Training time: 16380.8153\n",
      "Epoch : 1412/2000 data_batch_4,  Train_loss : 4455.3848  Test_loss : 5089.7354, Time/batch_file : 2.2719, Training time: 16383.0874\n",
      "Epoch : 1412/2000 data_batch_5,  Train_loss : 4499.1011  Test_loss : 4713.4263, Time/batch_file : 2.2710, Training time: 16385.3585\n",
      "Epoch : 1413/2000 data_batch_1,  Train_loss : 4714.3667  Test_loss : 4880.3315, Time/batch_file : 2.2962, Training time: 16387.6550\n",
      "Epoch : 1413/2000 data_batch_2,  Train_loss : 4947.1309  Test_loss : 5221.6919, Time/batch_file : 2.2929, Training time: 16389.9482\n",
      "Epoch : 1413/2000 data_batch_3,  Train_loss : 4656.9741  Test_loss : 5164.2163, Time/batch_file : 2.3021, Training time: 16392.2505\n",
      "Epoch : 1413/2000 data_batch_4,  Train_loss : 4601.5796  Test_loss : 4743.2627, Time/batch_file : 2.2885, Training time: 16394.5392\n",
      "Epoch : 1413/2000 data_batch_5,  Train_loss : 4716.3765  Test_loss : 5053.4326, Time/batch_file : 2.2965, Training time: 16396.8359\n",
      "Epoch : 1414/2000 data_batch_1,  Train_loss : 4164.2876  Test_loss : 4939.8643, Time/batch_file : 2.2839, Training time: 16399.1200\n",
      "Epoch : 1414/2000 data_batch_2,  Train_loss : 4252.3320  Test_loss : 4914.4941, Time/batch_file : 2.2803, Training time: 16401.4006\n",
      "Epoch : 1414/2000 data_batch_3,  Train_loss : 4542.1606  Test_loss : 4962.3574, Time/batch_file : 2.2845, Training time: 16403.6852\n",
      "Epoch : 1414/2000 data_batch_4,  Train_loss : 4272.2695  Test_loss : 4890.1250, Time/batch_file : 2.2843, Training time: 16405.9697\n",
      "Epoch : 1414/2000 data_batch_5,  Train_loss : 4171.6665  Test_loss : 4686.1035, Time/batch_file : 2.2821, Training time: 16408.2521\n",
      "Epoch : 1415/2000 data_batch_1,  Train_loss : 4205.3594  Test_loss : 5007.9775, Time/batch_file : 2.2870, Training time: 16410.5392\n",
      "Epoch : 1415/2000 data_batch_2,  Train_loss : 4061.3110  Test_loss : 5215.5991, Time/batch_file : 2.2831, Training time: 16412.8228\n",
      "Epoch : 1415/2000 data_batch_3,  Train_loss : 4265.8486  Test_loss : 5240.0283, Time/batch_file : 2.2803, Training time: 16415.1034\n",
      "Epoch : 1415/2000 data_batch_4,  Train_loss : 4339.8994  Test_loss : 5057.9941, Time/batch_file : 2.2844, Training time: 16417.3880\n",
      "Epoch : 1415/2000 data_batch_5,  Train_loss : 3846.0815  Test_loss : 5318.0723, Time/batch_file : 2.2849, Training time: 16419.6731\n",
      "Epoch : 1416/2000 data_batch_1,  Train_loss : 5271.5518  Test_loss : 4928.5962, Time/batch_file : 2.2816, Training time: 16421.9549\n",
      "Epoch : 1416/2000 data_batch_2,  Train_loss : 5187.6299  Test_loss : 4932.3174, Time/batch_file : 2.2893, Training time: 16424.2444\n",
      "Epoch : 1416/2000 data_batch_3,  Train_loss : 5221.7979  Test_loss : 5149.8008, Time/batch_file : 2.2796, Training time: 16426.5243\n",
      "Epoch : 1416/2000 data_batch_4,  Train_loss : 5143.1836  Test_loss : 4872.2920, Time/batch_file : 2.2804, Training time: 16428.8050\n",
      "Epoch : 1416/2000 data_batch_5,  Train_loss : 5296.4600  Test_loss : 4916.9468, Time/batch_file : 2.2884, Training time: 16431.0937\n",
      "Epoch : 1417/2000 data_batch_1,  Train_loss : 4917.6616  Test_loss : 5316.2524, Time/batch_file : 2.2673, Training time: 16433.3612\n",
      "Epoch : 1417/2000 data_batch_2,  Train_loss : 5041.7725  Test_loss : 5012.6436, Time/batch_file : 2.2781, Training time: 16435.6396\n",
      "Epoch : 1417/2000 data_batch_3,  Train_loss : 4788.8467  Test_loss : 5007.2031, Time/batch_file : 2.2728, Training time: 16437.9125\n",
      "Epoch : 1417/2000 data_batch_4,  Train_loss : 4984.9175  Test_loss : 5221.1318, Time/batch_file : 2.2749, Training time: 16440.1877\n",
      "Epoch : 1417/2000 data_batch_5,  Train_loss : 5091.8271  Test_loss : 5099.5986, Time/batch_file : 2.2686, Training time: 16442.4564\n",
      "Epoch : 1418/2000 data_batch_1,  Train_loss : 4487.4307  Test_loss : 4806.6904, Time/batch_file : 2.2845, Training time: 16444.7411\n",
      "Epoch : 1418/2000 data_batch_2,  Train_loss : 4805.4131  Test_loss : 4972.5059, Time/batch_file : 2.2720, Training time: 16447.0133\n",
      "Epoch : 1418/2000 data_batch_3,  Train_loss : 4806.8384  Test_loss : 4717.0410, Time/batch_file : 2.2803, Training time: 16449.2939\n",
      "Epoch : 1418/2000 data_batch_4,  Train_loss : 5007.4775  Test_loss : 4851.3423, Time/batch_file : 2.2773, Training time: 16451.5714\n",
      "Epoch : 1418/2000 data_batch_5,  Train_loss : 4943.9810  Test_loss : 4931.3022, Time/batch_file : 2.2738, Training time: 16453.8454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1419/2000 data_batch_1,  Train_loss : 4763.6680  Test_loss : 5315.9414, Time/batch_file : 2.2718, Training time: 16456.1173\n",
      "Epoch : 1419/2000 data_batch_2,  Train_loss : 4996.5498  Test_loss : 4919.5962, Time/batch_file : 2.2769, Training time: 16458.3944\n",
      "Epoch : 1419/2000 data_batch_3,  Train_loss : 4984.1094  Test_loss : 5317.6367, Time/batch_file : 2.2746, Training time: 16460.6693\n",
      "Epoch : 1419/2000 data_batch_4,  Train_loss : 4779.2510  Test_loss : 5262.4102, Time/batch_file : 2.2692, Training time: 16462.9386\n",
      "Epoch : 1419/2000 data_batch_5,  Train_loss : 5038.0298  Test_loss : 5073.3330, Time/batch_file : 2.2849, Training time: 16465.2238\n",
      "Epoch : 1420/2000 data_batch_1,  Train_loss : 4716.5293  Test_loss : 4943.2861, Time/batch_file : 2.2793, Training time: 16467.5033\n",
      "Epoch : 1420/2000 data_batch_2,  Train_loss : 4746.8892  Test_loss : 4718.0078, Time/batch_file : 2.2799, Training time: 16469.7833\n",
      "Epoch : 1420/2000 data_batch_3,  Train_loss : 4969.9609  Test_loss : 4557.7031, Time/batch_file : 2.2783, Training time: 16472.0618\n",
      "Epoch : 1420/2000 data_batch_4,  Train_loss : 4756.5781  Test_loss : 4909.6924, Time/batch_file : 2.2834, Training time: 16474.3455\n",
      "Epoch : 1420/2000 data_batch_5,  Train_loss : 4578.7041  Test_loss : 4667.4668, Time/batch_file : 2.2852, Training time: 16476.6310\n",
      "[./nets/net-1420.ckpt] SAVED\n",
      "Epoch : 1421/2000 data_batch_1,  Train_loss : 4865.1362  Test_loss : 4879.5317, Time/batch_file : 2.2971, Training time: 16480.2227\n",
      "Epoch : 1421/2000 data_batch_2,  Train_loss : 4768.7954  Test_loss : 5165.9751, Time/batch_file : 2.2776, Training time: 16482.5005\n",
      "Epoch : 1421/2000 data_batch_3,  Train_loss : 4856.5640  Test_loss : 5185.4258, Time/batch_file : 2.2763, Training time: 16484.7770\n",
      "Epoch : 1421/2000 data_batch_4,  Train_loss : 4958.0576  Test_loss : 4882.5005, Time/batch_file : 2.2757, Training time: 16487.0530\n",
      "Epoch : 1421/2000 data_batch_5,  Train_loss : 4694.7251  Test_loss : 4976.5640, Time/batch_file : 2.2619, Training time: 16489.3151\n",
      "Epoch : 1422/2000 data_batch_1,  Train_loss : 5318.3706  Test_loss : 5425.2041, Time/batch_file : 2.2764, Training time: 16491.5918\n",
      "Epoch : 1422/2000 data_batch_2,  Train_loss : 4956.7549  Test_loss : 5269.7700, Time/batch_file : 2.2526, Training time: 16493.8445\n",
      "Epoch : 1422/2000 data_batch_3,  Train_loss : 5208.5308  Test_loss : 5381.4653, Time/batch_file : 2.2803, Training time: 16496.1250\n",
      "Epoch : 1422/2000 data_batch_4,  Train_loss : 5037.1006  Test_loss : 5509.9087, Time/batch_file : 2.2718, Training time: 16498.3970\n",
      "Epoch : 1422/2000 data_batch_5,  Train_loss : 5053.5186  Test_loss : 5433.4775, Time/batch_file : 2.2659, Training time: 16500.6632\n",
      "Epoch : 1423/2000 data_batch_1,  Train_loss : 4839.1196  Test_loss : 4678.4082, Time/batch_file : 2.2928, Training time: 16502.9561\n",
      "Epoch : 1423/2000 data_batch_2,  Train_loss : 4903.7866  Test_loss : 5030.7090, Time/batch_file : 2.3094, Training time: 16505.2658\n",
      "Epoch : 1423/2000 data_batch_3,  Train_loss : 5031.7119  Test_loss : 4811.5693, Time/batch_file : 2.2722, Training time: 16507.5382\n",
      "Epoch : 1423/2000 data_batch_4,  Train_loss : 5059.4619  Test_loss : 5105.7173, Time/batch_file : 2.2858, Training time: 16509.8242\n",
      "Epoch : 1423/2000 data_batch_5,  Train_loss : 4929.9678  Test_loss : 4913.5889, Time/batch_file : 2.2807, Training time: 16512.1050\n",
      "Epoch : 1424/2000 data_batch_1,  Train_loss : 3995.2461  Test_loss : 4677.8516, Time/batch_file : 2.2922, Training time: 16514.3974\n",
      "Epoch : 1424/2000 data_batch_2,  Train_loss : 3918.4082  Test_loss : 4869.9873, Time/batch_file : 2.2641, Training time: 16516.6616\n",
      "Epoch : 1424/2000 data_batch_3,  Train_loss : 3885.1963  Test_loss : 4913.2017, Time/batch_file : 2.2761, Training time: 16518.9379\n",
      "Epoch : 1424/2000 data_batch_4,  Train_loss : 4154.3130  Test_loss : 4882.3369, Time/batch_file : 2.3004, Training time: 16521.2386\n",
      "Epoch : 1424/2000 data_batch_5,  Train_loss : 4061.1924  Test_loss : 4581.1689, Time/batch_file : 2.2903, Training time: 16523.5291\n",
      "Epoch : 1425/2000 data_batch_1,  Train_loss : 5274.3833  Test_loss : 4832.4438, Time/batch_file : 2.2791, Training time: 16525.8085\n",
      "Epoch : 1425/2000 data_batch_2,  Train_loss : 5479.8535  Test_loss : 5143.8555, Time/batch_file : 2.2876, Training time: 16528.0963\n",
      "Epoch : 1425/2000 data_batch_3,  Train_loss : 5324.9336  Test_loss : 5091.7437, Time/batch_file : 2.2800, Training time: 16530.3765\n",
      "Epoch : 1425/2000 data_batch_4,  Train_loss : 5487.0635  Test_loss : 5145.5278, Time/batch_file : 2.2848, Training time: 16532.6615\n",
      "Epoch : 1425/2000 data_batch_5,  Train_loss : 5013.7568  Test_loss : 5087.1050, Time/batch_file : 2.2767, Training time: 16534.9385\n",
      "Epoch : 1426/2000 data_batch_1,  Train_loss : 4786.4482  Test_loss : 5446.7544, Time/batch_file : 2.2948, Training time: 16537.2335\n",
      "Epoch : 1426/2000 data_batch_2,  Train_loss : 5108.7412  Test_loss : 5274.3813, Time/batch_file : 2.2918, Training time: 16539.5256\n",
      "Epoch : 1426/2000 data_batch_3,  Train_loss : 5037.6226  Test_loss : 5426.8169, Time/batch_file : 2.3033, Training time: 16541.8290\n",
      "Epoch : 1426/2000 data_batch_4,  Train_loss : 4766.4727  Test_loss : 5359.2363, Time/batch_file : 2.2777, Training time: 16544.1070\n",
      "Epoch : 1426/2000 data_batch_5,  Train_loss : 4991.1641  Test_loss : 5194.1553, Time/batch_file : 2.2877, Training time: 16546.3949\n",
      "Epoch : 1427/2000 data_batch_1,  Train_loss : 4487.3989  Test_loss : 4810.1685, Time/batch_file : 2.2764, Training time: 16548.6714\n",
      "Epoch : 1427/2000 data_batch_2,  Train_loss : 4482.0757  Test_loss : 4585.8149, Time/batch_file : 2.3114, Training time: 16550.9831\n",
      "Epoch : 1427/2000 data_batch_3,  Train_loss : 4606.4009  Test_loss : 4939.0127, Time/batch_file : 2.2635, Training time: 16553.2468\n",
      "Epoch : 1427/2000 data_batch_4,  Train_loss : 4757.4199  Test_loss : 4949.9326, Time/batch_file : 2.2978, Training time: 16555.5449\n",
      "Epoch : 1427/2000 data_batch_5,  Train_loss : 4702.3267  Test_loss : 4755.0981, Time/batch_file : 2.2807, Training time: 16557.8258\n",
      "Epoch : 1428/2000 data_batch_1,  Train_loss : 4615.9287  Test_loss : 4907.6694, Time/batch_file : 2.2970, Training time: 16560.1231\n",
      "Epoch : 1428/2000 data_batch_2,  Train_loss : 4779.3857  Test_loss : 5141.8320, Time/batch_file : 2.2738, Training time: 16562.3970\n",
      "Epoch : 1428/2000 data_batch_3,  Train_loss : 4425.5396  Test_loss : 4904.1992, Time/batch_file : 2.2808, Training time: 16564.6780\n",
      "Epoch : 1428/2000 data_batch_4,  Train_loss : 4587.7285  Test_loss : 5331.8848, Time/batch_file : 2.2730, Training time: 16566.9512\n",
      "Epoch : 1428/2000 data_batch_5,  Train_loss : 4557.0439  Test_loss : 5104.9473, Time/batch_file : 2.2907, Training time: 16569.2421\n",
      "Epoch : 1429/2000 data_batch_1,  Train_loss : 4150.5898  Test_loss : 5191.0410, Time/batch_file : 2.2605, Training time: 16571.5028\n",
      "Epoch : 1429/2000 data_batch_2,  Train_loss : 4341.0854  Test_loss : 5020.3462, Time/batch_file : 2.2780, Training time: 16573.7810\n",
      "Epoch : 1429/2000 data_batch_3,  Train_loss : 4145.8320  Test_loss : 5401.4600, Time/batch_file : 2.2781, Training time: 16576.0592\n",
      "Epoch : 1429/2000 data_batch_4,  Train_loss : 4193.6250  Test_loss : 5135.1987, Time/batch_file : 2.2992, Training time: 16578.3587\n",
      "Epoch : 1429/2000 data_batch_5,  Train_loss : 4103.3042  Test_loss : 5082.7324, Time/batch_file : 2.2624, Training time: 16580.6214\n",
      "Epoch : 1430/2000 data_batch_1,  Train_loss : 4394.8926  Test_loss : 4990.3481, Time/batch_file : 2.2723, Training time: 16582.8940\n",
      "Epoch : 1430/2000 data_batch_2,  Train_loss : 4491.1758  Test_loss : 5121.6299, Time/batch_file : 2.2739, Training time: 16585.1680\n",
      "Epoch : 1430/2000 data_batch_3,  Train_loss : 4483.4097  Test_loss : 4906.7134, Time/batch_file : 2.2999, Training time: 16587.4681\n",
      "Epoch : 1430/2000 data_batch_4,  Train_loss : 4287.5225  Test_loss : 5304.0166, Time/batch_file : 2.2801, Training time: 16589.7483\n",
      "Epoch : 1430/2000 data_batch_5,  Train_loss : 4677.3340  Test_loss : 5296.3604, Time/batch_file : 2.2729, Training time: 16592.0214\n",
      "[./nets/net-1430.ckpt] SAVED\n",
      "Epoch : 1431/2000 data_batch_1,  Train_loss : 4410.1177  Test_loss : 4972.2881, Time/batch_file : 2.3210, Training time: 16595.6079\n",
      "Epoch : 1431/2000 data_batch_2,  Train_loss : 4755.0068  Test_loss : 4988.3574, Time/batch_file : 2.2878, Training time: 16597.8958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1431/2000 data_batch_3,  Train_loss : 4482.5420  Test_loss : 5198.4180, Time/batch_file : 2.2817, Training time: 16600.1776\n",
      "Epoch : 1431/2000 data_batch_4,  Train_loss : 4549.1729  Test_loss : 5133.3774, Time/batch_file : 2.2981, Training time: 16602.4759\n",
      "Epoch : 1431/2000 data_batch_5,  Train_loss : 4221.6064  Test_loss : 5095.2524, Time/batch_file : 2.2890, Training time: 16604.7651\n",
      "Epoch : 1432/2000 data_batch_1,  Train_loss : 4513.9551  Test_loss : 5300.9131, Time/batch_file : 2.2796, Training time: 16607.0449\n",
      "Epoch : 1432/2000 data_batch_2,  Train_loss : 4641.6919  Test_loss : 4725.4463, Time/batch_file : 2.3044, Training time: 16609.3495\n",
      "Epoch : 1432/2000 data_batch_3,  Train_loss : 4587.5596  Test_loss : 4869.7148, Time/batch_file : 2.2679, Training time: 16611.6175\n",
      "Epoch : 1432/2000 data_batch_4,  Train_loss : 4320.7563  Test_loss : 5016.4863, Time/batch_file : 2.2962, Training time: 16613.9138\n",
      "Epoch : 1432/2000 data_batch_5,  Train_loss : 4314.0830  Test_loss : 4839.4341, Time/batch_file : 2.2868, Training time: 16616.2009\n",
      "Epoch : 1433/2000 data_batch_1,  Train_loss : 4156.3179  Test_loss : 4853.7329, Time/batch_file : 2.3194, Training time: 16618.5205\n",
      "Epoch : 1433/2000 data_batch_2,  Train_loss : 4246.0654  Test_loss : 4918.8467, Time/batch_file : 2.2867, Training time: 16620.8075\n",
      "Epoch : 1433/2000 data_batch_3,  Train_loss : 4017.5935  Test_loss : 4957.5503, Time/batch_file : 2.3131, Training time: 16623.1208\n",
      "Epoch : 1433/2000 data_batch_4,  Train_loss : 4235.7471  Test_loss : 4939.5645, Time/batch_file : 2.3003, Training time: 16625.4213\n",
      "Epoch : 1433/2000 data_batch_5,  Train_loss : 4182.9531  Test_loss : 5112.3696, Time/batch_file : 2.2819, Training time: 16627.7034\n",
      "Epoch : 1434/2000 data_batch_1,  Train_loss : 4721.7207  Test_loss : 4495.5435, Time/batch_file : 2.2894, Training time: 16629.9931\n",
      "Epoch : 1434/2000 data_batch_2,  Train_loss : 4825.7280  Test_loss : 4576.0879, Time/batch_file : 2.2653, Training time: 16632.2586\n",
      "Epoch : 1434/2000 data_batch_3,  Train_loss : 4676.7749  Test_loss : 4290.0327, Time/batch_file : 2.2687, Training time: 16634.5276\n",
      "Epoch : 1434/2000 data_batch_4,  Train_loss : 4880.5293  Test_loss : 4965.2783, Time/batch_file : 2.2639, Training time: 16636.7916\n",
      "Epoch : 1434/2000 data_batch_5,  Train_loss : 4551.9111  Test_loss : 4698.1411, Time/batch_file : 2.2892, Training time: 16639.0810\n",
      "Epoch : 1435/2000 data_batch_1,  Train_loss : 4892.3369  Test_loss : 5085.7495, Time/batch_file : 2.2818, Training time: 16641.3630\n",
      "Epoch : 1435/2000 data_batch_2,  Train_loss : 4729.8745  Test_loss : 5349.7666, Time/batch_file : 2.3046, Training time: 16643.6677\n",
      "Epoch : 1435/2000 data_batch_3,  Train_loss : 5002.8818  Test_loss : 5269.8184, Time/batch_file : 2.2927, Training time: 16645.9607\n",
      "Epoch : 1435/2000 data_batch_4,  Train_loss : 4872.3193  Test_loss : 5214.1064, Time/batch_file : 2.2937, Training time: 16648.2546\n",
      "Epoch : 1435/2000 data_batch_5,  Train_loss : 4951.1885  Test_loss : 5313.0469, Time/batch_file : 2.3067, Training time: 16650.5616\n",
      "Epoch : 1436/2000 data_batch_1,  Train_loss : 5527.0571  Test_loss : 5087.7363, Time/batch_file : 2.2867, Training time: 16652.8486\n",
      "Epoch : 1436/2000 data_batch_2,  Train_loss : 5169.5376  Test_loss : 5057.8237, Time/batch_file : 2.3129, Training time: 16655.1617\n",
      "Epoch : 1436/2000 data_batch_3,  Train_loss : 5314.3452  Test_loss : 4964.9258, Time/batch_file : 2.2997, Training time: 16657.4616\n",
      "Epoch : 1436/2000 data_batch_4,  Train_loss : 5273.7676  Test_loss : 5041.4268, Time/batch_file : 2.3162, Training time: 16659.7780\n",
      "Epoch : 1436/2000 data_batch_5,  Train_loss : 5015.6484  Test_loss : 4898.9443, Time/batch_file : 2.3006, Training time: 16662.0787\n",
      "Epoch : 1437/2000 data_batch_1,  Train_loss : 4438.5479  Test_loss : 4887.0889, Time/batch_file : 2.3006, Training time: 16664.3797\n",
      "Epoch : 1437/2000 data_batch_2,  Train_loss : 4417.7666  Test_loss : 4784.7681, Time/batch_file : 2.2692, Training time: 16666.6490\n",
      "Epoch : 1437/2000 data_batch_3,  Train_loss : 4520.8921  Test_loss : 4665.7012, Time/batch_file : 2.2777, Training time: 16668.9269\n",
      "Epoch : 1437/2000 data_batch_4,  Train_loss : 4559.6538  Test_loss : 4619.8950, Time/batch_file : 2.2925, Training time: 16671.2196\n",
      "Epoch : 1437/2000 data_batch_5,  Train_loss : 4629.7983  Test_loss : 4838.3496, Time/batch_file : 2.2514, Training time: 16673.4711\n",
      "Epoch : 1438/2000 data_batch_1,  Train_loss : 4800.8560  Test_loss : 4977.2900, Time/batch_file : 2.2952, Training time: 16675.7665\n",
      "Epoch : 1438/2000 data_batch_2,  Train_loss : 5143.1333  Test_loss : 5098.3052, Time/batch_file : 2.2939, Training time: 16678.0607\n",
      "Epoch : 1438/2000 data_batch_3,  Train_loss : 4979.6489  Test_loss : 4725.1670, Time/batch_file : 2.3093, Training time: 16680.3703\n",
      "Epoch : 1438/2000 data_batch_4,  Train_loss : 5006.5352  Test_loss : 5216.1396, Time/batch_file : 2.3087, Training time: 16682.6792\n",
      "Epoch : 1438/2000 data_batch_5,  Train_loss : 5406.7363  Test_loss : 4939.5918, Time/batch_file : 2.3167, Training time: 16684.9961\n",
      "Epoch : 1439/2000 data_batch_1,  Train_loss : 4672.6870  Test_loss : 5085.0415, Time/batch_file : 2.2778, Training time: 16687.2741\n",
      "Epoch : 1439/2000 data_batch_2,  Train_loss : 4826.2651  Test_loss : 5465.5815, Time/batch_file : 2.2788, Training time: 16689.5531\n",
      "Epoch : 1439/2000 data_batch_3,  Train_loss : 4558.9199  Test_loss : 5061.3433, Time/batch_file : 2.2987, Training time: 16691.8520\n",
      "Epoch : 1439/2000 data_batch_4,  Train_loss : 4684.4961  Test_loss : 5264.6016, Time/batch_file : 2.2682, Training time: 16694.1204\n",
      "Epoch : 1439/2000 data_batch_5,  Train_loss : 4773.8945  Test_loss : 5342.2803, Time/batch_file : 2.3047, Training time: 16696.4253\n",
      "Epoch : 1440/2000 data_batch_1,  Train_loss : 4805.1602  Test_loss : 4431.1128, Time/batch_file : 2.2871, Training time: 16698.7127\n",
      "Epoch : 1440/2000 data_batch_2,  Train_loss : 4559.4805  Test_loss : 4591.8413, Time/batch_file : 2.3182, Training time: 16701.0311\n",
      "Epoch : 1440/2000 data_batch_3,  Train_loss : 4711.7832  Test_loss : 4756.2974, Time/batch_file : 2.2875, Training time: 16703.3189\n",
      "Epoch : 1440/2000 data_batch_4,  Train_loss : 5101.0796  Test_loss : 4706.2959, Time/batch_file : 2.3164, Training time: 16705.6354\n",
      "Epoch : 1440/2000 data_batch_5,  Train_loss : 4854.8755  Test_loss : 4651.0620, Time/batch_file : 2.2908, Training time: 16707.9264\n",
      "[./nets/net-1440.ckpt] SAVED\n",
      "Epoch : 1441/2000 data_batch_1,  Train_loss : 5018.6211  Test_loss : 5214.5850, Time/batch_file : 2.4666, Training time: 16711.6672\n",
      "Epoch : 1441/2000 data_batch_2,  Train_loss : 4877.9644  Test_loss : 5325.5552, Time/batch_file : 2.2908, Training time: 16713.9581\n",
      "Epoch : 1441/2000 data_batch_3,  Train_loss : 4873.1958  Test_loss : 5370.9360, Time/batch_file : 2.2688, Training time: 16716.2271\n",
      "Epoch : 1441/2000 data_batch_4,  Train_loss : 4816.8916  Test_loss : 5192.4512, Time/batch_file : 2.2766, Training time: 16718.5039\n",
      "Epoch : 1441/2000 data_batch_5,  Train_loss : 5000.5435  Test_loss : 5222.0752, Time/batch_file : 2.2849, Training time: 16720.7890\n",
      "Epoch : 1442/2000 data_batch_1,  Train_loss : 4476.4834  Test_loss : 5182.9170, Time/batch_file : 2.2558, Training time: 16723.0452\n",
      "Epoch : 1442/2000 data_batch_2,  Train_loss : 4135.7231  Test_loss : 4822.8140, Time/batch_file : 2.2531, Training time: 16725.2985\n",
      "Epoch : 1442/2000 data_batch_3,  Train_loss : 4267.2949  Test_loss : 4938.9004, Time/batch_file : 2.2532, Training time: 16727.5519\n",
      "Epoch : 1442/2000 data_batch_4,  Train_loss : 4075.9617  Test_loss : 5214.4692, Time/batch_file : 2.2791, Training time: 16729.8312\n",
      "Epoch : 1442/2000 data_batch_5,  Train_loss : 4416.4551  Test_loss : 4956.8501, Time/batch_file : 2.2599, Training time: 16732.0913\n",
      "Epoch : 1443/2000 data_batch_1,  Train_loss : 4643.7432  Test_loss : 5154.5293, Time/batch_file : 2.2964, Training time: 16734.3879\n",
      "Epoch : 1443/2000 data_batch_2,  Train_loss : 4535.6128  Test_loss : 4989.9873, Time/batch_file : 2.2524, Training time: 16736.6405\n",
      "Epoch : 1443/2000 data_batch_3,  Train_loss : 5018.8633  Test_loss : 5022.0586, Time/batch_file : 2.3057, Training time: 16738.9463\n",
      "Epoch : 1443/2000 data_batch_4,  Train_loss : 4845.4756  Test_loss : 5016.0508, Time/batch_file : 2.2751, Training time: 16741.2216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1443/2000 data_batch_5,  Train_loss : 4703.1436  Test_loss : 5191.6602, Time/batch_file : 2.3036, Training time: 16743.5255\n",
      "Epoch : 1444/2000 data_batch_1,  Train_loss : 4762.8677  Test_loss : 4816.6533, Time/batch_file : 2.2889, Training time: 16745.8147\n",
      "Epoch : 1444/2000 data_batch_2,  Train_loss : 4975.0879  Test_loss : 4753.1338, Time/batch_file : 2.2633, Training time: 16748.0781\n",
      "Epoch : 1444/2000 data_batch_3,  Train_loss : 4544.0596  Test_loss : 4853.3291, Time/batch_file : 2.2880, Training time: 16750.3663\n",
      "Epoch : 1444/2000 data_batch_4,  Train_loss : 4797.3101  Test_loss : 4934.6104, Time/batch_file : 2.2742, Training time: 16752.6407\n",
      "Epoch : 1444/2000 data_batch_5,  Train_loss : 4579.6406  Test_loss : 5076.8770, Time/batch_file : 2.2634, Training time: 16754.9042\n",
      "Epoch : 1445/2000 data_batch_1,  Train_loss : 4559.9043  Test_loss : 5243.0864, Time/batch_file : 2.2392, Training time: 16757.1435\n",
      "Epoch : 1445/2000 data_batch_2,  Train_loss : 4483.6836  Test_loss : 4981.2227, Time/batch_file : 2.2755, Training time: 16759.4191\n",
      "Epoch : 1445/2000 data_batch_3,  Train_loss : 4881.0396  Test_loss : 5018.8403, Time/batch_file : 2.2541, Training time: 16761.6734\n",
      "Epoch : 1445/2000 data_batch_4,  Train_loss : 4785.1377  Test_loss : 4902.5752, Time/batch_file : 2.2796, Training time: 16763.9532\n",
      "Epoch : 1445/2000 data_batch_5,  Train_loss : 4464.7329  Test_loss : 4542.2290, Time/batch_file : 2.2610, Training time: 16766.2144\n",
      "Epoch : 1446/2000 data_batch_1,  Train_loss : 5235.2734  Test_loss : 4827.6660, Time/batch_file : 2.2587, Training time: 16768.4734\n",
      "Epoch : 1446/2000 data_batch_2,  Train_loss : 4916.4888  Test_loss : 4641.3955, Time/batch_file : 2.2784, Training time: 16770.7521\n",
      "Epoch : 1446/2000 data_batch_3,  Train_loss : 5197.5366  Test_loss : 4851.9653, Time/batch_file : 2.2629, Training time: 16773.0151\n",
      "Epoch : 1446/2000 data_batch_4,  Train_loss : 5038.1187  Test_loss : 4836.2505, Time/batch_file : 2.2647, Training time: 16775.2800\n",
      "Epoch : 1446/2000 data_batch_5,  Train_loss : 5263.0703  Test_loss : 4632.0586, Time/batch_file : 2.2749, Training time: 16777.5550\n",
      "Epoch : 1447/2000 data_batch_1,  Train_loss : 4419.8584  Test_loss : 5354.5342, Time/batch_file : 2.2536, Training time: 16779.8088\n",
      "Epoch : 1447/2000 data_batch_2,  Train_loss : 4606.8848  Test_loss : 5164.7124, Time/batch_file : 2.2592, Training time: 16782.0682\n",
      "Epoch : 1447/2000 data_batch_3,  Train_loss : 4532.0688  Test_loss : 5264.6475, Time/batch_file : 2.2572, Training time: 16784.3256\n",
      "Epoch : 1447/2000 data_batch_4,  Train_loss : 4538.4307  Test_loss : 5502.8960, Time/batch_file : 2.2456, Training time: 16786.5715\n",
      "Epoch : 1447/2000 data_batch_5,  Train_loss : 4654.4468  Test_loss : 5006.6055, Time/batch_file : 2.2637, Training time: 16788.8354\n",
      "Epoch : 1448/2000 data_batch_1,  Train_loss : 5071.1558  Test_loss : 5015.7676, Time/batch_file : 2.2681, Training time: 16791.1039\n",
      "Epoch : 1448/2000 data_batch_2,  Train_loss : 5036.4688  Test_loss : 4948.4600, Time/batch_file : 2.2699, Training time: 16793.3740\n",
      "Epoch : 1448/2000 data_batch_3,  Train_loss : 4934.9033  Test_loss : 5125.6348, Time/batch_file : 2.2721, Training time: 16795.6734\n",
      "Epoch : 1448/2000 data_batch_4,  Train_loss : 5092.6987  Test_loss : 4925.3818, Time/batch_file : 2.2591, Training time: 16797.9327\n",
      "Epoch : 1448/2000 data_batch_5,  Train_loss : 5060.8076  Test_loss : 4777.8691, Time/batch_file : 2.2799, Training time: 16800.2128\n",
      "Epoch : 1449/2000 data_batch_1,  Train_loss : 4900.1890  Test_loss : 4595.7539, Time/batch_file : 2.2600, Training time: 16802.4729\n",
      "Epoch : 1449/2000 data_batch_2,  Train_loss : 4701.6655  Test_loss : 4862.4814, Time/batch_file : 2.2779, Training time: 16804.7509\n",
      "Epoch : 1449/2000 data_batch_3,  Train_loss : 4939.4727  Test_loss : 4873.6006, Time/batch_file : 2.2590, Training time: 16807.0102\n",
      "Epoch : 1449/2000 data_batch_4,  Train_loss : 4897.2744  Test_loss : 4691.3081, Time/batch_file : 2.2711, Training time: 16809.2816\n",
      "Epoch : 1449/2000 data_batch_5,  Train_loss : 4947.3125  Test_loss : 4742.4834, Time/batch_file : 2.2654, Training time: 16811.5473\n",
      "Epoch : 1450/2000 data_batch_1,  Train_loss : 4649.0718  Test_loss : 4953.5723, Time/batch_file : 2.2606, Training time: 16813.8080\n",
      "Epoch : 1450/2000 data_batch_2,  Train_loss : 4916.3936  Test_loss : 5240.8735, Time/batch_file : 2.2608, Training time: 16816.0690\n",
      "Epoch : 1450/2000 data_batch_3,  Train_loss : 4997.9131  Test_loss : 5167.4238, Time/batch_file : 2.2582, Training time: 16818.3274\n",
      "Epoch : 1450/2000 data_batch_4,  Train_loss : 5072.7324  Test_loss : 4809.4351, Time/batch_file : 2.2930, Training time: 16820.6205\n",
      "Epoch : 1450/2000 data_batch_5,  Train_loss : 4658.9570  Test_loss : 5154.4253, Time/batch_file : 2.2577, Training time: 16822.8785\n",
      "[./nets/net-1450.ckpt] SAVED\n",
      "Epoch : 1451/2000 data_batch_1,  Train_loss : 4394.1235  Test_loss : 5388.4468, Time/batch_file : 2.2838, Training time: 16826.4406\n",
      "Epoch : 1451/2000 data_batch_2,  Train_loss : 4478.0645  Test_loss : 5485.7764, Time/batch_file : 2.2499, Training time: 16828.6908\n",
      "Epoch : 1451/2000 data_batch_3,  Train_loss : 4341.9688  Test_loss : 5339.1436, Time/batch_file : 2.2489, Training time: 16830.9399\n",
      "Epoch : 1451/2000 data_batch_4,  Train_loss : 4343.0400  Test_loss : 5258.9932, Time/batch_file : 2.2427, Training time: 16833.1828\n",
      "Epoch : 1451/2000 data_batch_5,  Train_loss : 4616.0039  Test_loss : 5235.0928, Time/batch_file : 2.2473, Training time: 16835.4303\n",
      "Epoch : 1452/2000 data_batch_1,  Train_loss : 4768.4941  Test_loss : 5179.4180, Time/batch_file : 2.2673, Training time: 16837.6979\n",
      "Epoch : 1452/2000 data_batch_2,  Train_loss : 4448.3818  Test_loss : 4758.4287, Time/batch_file : 2.2729, Training time: 16839.9709\n",
      "Epoch : 1452/2000 data_batch_3,  Train_loss : 4418.5615  Test_loss : 4911.8154, Time/batch_file : 2.2591, Training time: 16842.2303\n",
      "Epoch : 1452/2000 data_batch_4,  Train_loss : 4500.3389  Test_loss : 4994.3027, Time/batch_file : 2.2762, Training time: 16844.5066\n",
      "Epoch : 1452/2000 data_batch_5,  Train_loss : 4651.9272  Test_loss : 5038.2393, Time/batch_file : 2.2528, Training time: 16846.7596\n",
      "Epoch : 1453/2000 data_batch_1,  Train_loss : 4708.6729  Test_loss : 4810.1753, Time/batch_file : 2.2488, Training time: 16849.0085\n",
      "Epoch : 1453/2000 data_batch_2,  Train_loss : 4996.1211  Test_loss : 4862.5366, Time/batch_file : 2.2474, Training time: 16851.2561\n",
      "Epoch : 1453/2000 data_batch_3,  Train_loss : 4757.8501  Test_loss : 4694.8936, Time/batch_file : 2.2563, Training time: 16853.5126\n",
      "Epoch : 1453/2000 data_batch_4,  Train_loss : 4637.1846  Test_loss : 4490.4023, Time/batch_file : 2.2541, Training time: 16855.7669\n",
      "Epoch : 1453/2000 data_batch_5,  Train_loss : 4848.7271  Test_loss : 4502.7500, Time/batch_file : 2.2890, Training time: 16858.0561\n",
      "Epoch : 1454/2000 data_batch_1,  Train_loss : 4728.0933  Test_loss : 4733.6577, Time/batch_file : 2.2526, Training time: 16860.3088\n",
      "Epoch : 1454/2000 data_batch_2,  Train_loss : 4658.4102  Test_loss : 4894.0435, Time/batch_file : 2.2502, Training time: 16862.5592\n",
      "Epoch : 1454/2000 data_batch_3,  Train_loss : 4877.8418  Test_loss : 5061.0923, Time/batch_file : 2.2452, Training time: 16864.8047\n",
      "Epoch : 1454/2000 data_batch_4,  Train_loss : 4636.5278  Test_loss : 5066.6304, Time/batch_file : 2.2379, Training time: 16867.0428\n",
      "Epoch : 1454/2000 data_batch_5,  Train_loss : 4731.0488  Test_loss : 4809.8027, Time/batch_file : 2.2501, Training time: 16869.2931\n",
      "Epoch : 1455/2000 data_batch_1,  Train_loss : 4491.5093  Test_loss : 4776.5601, Time/batch_file : 2.2574, Training time: 16871.5507\n",
      "Epoch : 1455/2000 data_batch_2,  Train_loss : 4541.4746  Test_loss : 5062.2720, Time/batch_file : 2.2503, Training time: 16873.8012\n",
      "Epoch : 1455/2000 data_batch_3,  Train_loss : 4322.2441  Test_loss : 4752.2002, Time/batch_file : 2.2537, Training time: 16876.0551\n",
      "Epoch : 1455/2000 data_batch_4,  Train_loss : 4404.0396  Test_loss : 4557.0771, Time/batch_file : 2.2482, Training time: 16878.3036\n",
      "Epoch : 1455/2000 data_batch_5,  Train_loss : 4413.6982  Test_loss : 4626.7939, Time/batch_file : 2.2514, Training time: 16880.5551\n",
      "Epoch : 1456/2000 data_batch_1,  Train_loss : 5180.1328  Test_loss : 4940.6021, Time/batch_file : 2.2565, Training time: 16882.8118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1456/2000 data_batch_2,  Train_loss : 5317.1191  Test_loss : 5180.4795, Time/batch_file : 2.2524, Training time: 16885.0645\n",
      "Epoch : 1456/2000 data_batch_3,  Train_loss : 5249.1250  Test_loss : 5477.5684, Time/batch_file : 2.2487, Training time: 16887.3134\n",
      "Epoch : 1456/2000 data_batch_4,  Train_loss : 5202.5156  Test_loss : 5107.3599, Time/batch_file : 2.2524, Training time: 16889.5660\n",
      "Epoch : 1456/2000 data_batch_5,  Train_loss : 5231.8271  Test_loss : 5132.5669, Time/batch_file : 2.2488, Training time: 16891.8151\n",
      "Epoch : 1457/2000 data_batch_1,  Train_loss : 4482.3735  Test_loss : 5046.2744, Time/batch_file : 2.2620, Training time: 16894.0772\n",
      "Epoch : 1457/2000 data_batch_2,  Train_loss : 4515.0991  Test_loss : 4676.8584, Time/batch_file : 2.2514, Training time: 16896.3288\n",
      "Epoch : 1457/2000 data_batch_3,  Train_loss : 4335.9873  Test_loss : 5235.5000, Time/batch_file : 2.2538, Training time: 16898.5828\n",
      "Epoch : 1457/2000 data_batch_4,  Train_loss : 4161.2764  Test_loss : 4768.9775, Time/batch_file : 2.2564, Training time: 16900.8393\n",
      "Epoch : 1457/2000 data_batch_5,  Train_loss : 4045.9985  Test_loss : 4890.0386, Time/batch_file : 2.2533, Training time: 16903.0928\n",
      "Epoch : 1458/2000 data_batch_1,  Train_loss : 4101.4106  Test_loss : 5234.1885, Time/batch_file : 2.2542, Training time: 16905.3472\n",
      "Epoch : 1458/2000 data_batch_2,  Train_loss : 4225.9238  Test_loss : 5336.6123, Time/batch_file : 2.2616, Training time: 16907.6090\n",
      "Epoch : 1458/2000 data_batch_3,  Train_loss : 4270.4512  Test_loss : 5031.9561, Time/batch_file : 2.2584, Training time: 16909.8676\n",
      "Epoch : 1458/2000 data_batch_4,  Train_loss : 4144.8154  Test_loss : 5077.2388, Time/batch_file : 2.2521, Training time: 16912.1199\n",
      "Epoch : 1458/2000 data_batch_5,  Train_loss : 4173.7168  Test_loss : 4937.6470, Time/batch_file : 2.2574, Training time: 16914.3775\n",
      "Epoch : 1459/2000 data_batch_1,  Train_loss : 4860.2573  Test_loss : 4840.3701, Time/batch_file : 2.2642, Training time: 16916.6418\n",
      "Epoch : 1459/2000 data_batch_2,  Train_loss : 4940.1880  Test_loss : 4910.2124, Time/batch_file : 2.2805, Training time: 16918.9224\n",
      "Epoch : 1459/2000 data_batch_3,  Train_loss : 4910.5884  Test_loss : 5127.5127, Time/batch_file : 2.2727, Training time: 16921.1954\n",
      "Epoch : 1459/2000 data_batch_4,  Train_loss : 5053.2671  Test_loss : 4926.6885, Time/batch_file : 2.2723, Training time: 16923.4678\n",
      "Epoch : 1459/2000 data_batch_5,  Train_loss : 4920.6074  Test_loss : 5074.6543, Time/batch_file : 2.2664, Training time: 16925.7344\n",
      "Epoch : 1460/2000 data_batch_1,  Train_loss : 4496.7261  Test_loss : 4762.9346, Time/batch_file : 2.2549, Training time: 16927.9895\n",
      "Epoch : 1460/2000 data_batch_2,  Train_loss : 4313.5376  Test_loss : 4672.5239, Time/batch_file : 2.2611, Training time: 16930.2509\n",
      "Epoch : 1460/2000 data_batch_3,  Train_loss : 4590.5254  Test_loss : 4722.6094, Time/batch_file : 2.2545, Training time: 16932.5056\n",
      "Epoch : 1460/2000 data_batch_4,  Train_loss : 4200.5488  Test_loss : 4695.8984, Time/batch_file : 2.2617, Training time: 16934.7675\n",
      "Epoch : 1460/2000 data_batch_5,  Train_loss : 4371.3291  Test_loss : 4547.7808, Time/batch_file : 2.2562, Training time: 16937.0239\n",
      "[./nets/net-1460.ckpt] SAVED\n",
      "Epoch : 1461/2000 data_batch_1,  Train_loss : 4676.9424  Test_loss : 4571.8521, Time/batch_file : 2.3111, Training time: 16940.6259\n",
      "Epoch : 1461/2000 data_batch_2,  Train_loss : 4608.5762  Test_loss : 4772.2656, Time/batch_file : 2.2601, Training time: 16942.8862\n",
      "Epoch : 1461/2000 data_batch_3,  Train_loss : 4540.9194  Test_loss : 4670.7324, Time/batch_file : 2.2643, Training time: 16945.1507\n",
      "Epoch : 1461/2000 data_batch_4,  Train_loss : 4737.7344  Test_loss : 4746.1162, Time/batch_file : 2.2583, Training time: 16947.4091\n",
      "Epoch : 1461/2000 data_batch_5,  Train_loss : 4639.4062  Test_loss : 4632.0947, Time/batch_file : 2.2735, Training time: 16949.6828\n",
      "Epoch : 1462/2000 data_batch_1,  Train_loss : 4625.6953  Test_loss : 4766.4810, Time/batch_file : 2.2734, Training time: 16951.9564\n",
      "Epoch : 1462/2000 data_batch_2,  Train_loss : 4668.0562  Test_loss : 4939.8984, Time/batch_file : 2.2741, Training time: 16954.2306\n",
      "Epoch : 1462/2000 data_batch_3,  Train_loss : 4749.7959  Test_loss : 4805.2959, Time/batch_file : 2.2628, Training time: 16956.4935\n",
      "Epoch : 1462/2000 data_batch_4,  Train_loss : 4849.3784  Test_loss : 4905.8760, Time/batch_file : 2.2622, Training time: 16958.7559\n",
      "Epoch : 1462/2000 data_batch_5,  Train_loss : 4894.3613  Test_loss : 4845.6279, Time/batch_file : 2.2905, Training time: 16961.0466\n",
      "Epoch : 1463/2000 data_batch_1,  Train_loss : 4924.1611  Test_loss : 5038.4951, Time/batch_file : 2.2525, Training time: 16963.2993\n",
      "Epoch : 1463/2000 data_batch_2,  Train_loss : 4973.6387  Test_loss : 5048.1421, Time/batch_file : 2.2598, Training time: 16965.5593\n",
      "Epoch : 1463/2000 data_batch_3,  Train_loss : 4755.5142  Test_loss : 5295.9214, Time/batch_file : 2.2565, Training time: 16967.8160\n",
      "Epoch : 1463/2000 data_batch_4,  Train_loss : 4814.4731  Test_loss : 4872.9287, Time/batch_file : 2.2657, Training time: 16970.0819\n",
      "Epoch : 1463/2000 data_batch_5,  Train_loss : 4588.7842  Test_loss : 5013.2476, Time/batch_file : 2.2593, Training time: 16972.3414\n",
      "Epoch : 1464/2000 data_batch_1,  Train_loss : 4988.6006  Test_loss : 4996.0024, Time/batch_file : 2.2743, Training time: 16974.6158\n",
      "Epoch : 1464/2000 data_batch_2,  Train_loss : 4965.8755  Test_loss : 4795.1387, Time/batch_file : 2.2737, Training time: 16976.8897\n",
      "Epoch : 1464/2000 data_batch_3,  Train_loss : 4884.5059  Test_loss : 4516.3169, Time/batch_file : 2.2859, Training time: 16979.1757\n",
      "Epoch : 1464/2000 data_batch_4,  Train_loss : 4636.6533  Test_loss : 4784.7344, Time/batch_file : 2.2780, Training time: 16981.4538\n",
      "Epoch : 1464/2000 data_batch_5,  Train_loss : 4713.0435  Test_loss : 4877.1328, Time/batch_file : 2.2620, Training time: 16983.7160\n",
      "Epoch : 1465/2000 data_batch_1,  Train_loss : 4328.1084  Test_loss : 4811.5898, Time/batch_file : 2.2683, Training time: 16985.9846\n",
      "Epoch : 1465/2000 data_batch_2,  Train_loss : 4413.4165  Test_loss : 4877.2803, Time/batch_file : 2.2519, Training time: 16988.2367\n",
      "Epoch : 1465/2000 data_batch_3,  Train_loss : 4335.5874  Test_loss : 4850.7622, Time/batch_file : 2.2729, Training time: 16990.5098\n",
      "Epoch : 1465/2000 data_batch_4,  Train_loss : 4350.4219  Test_loss : 4605.7056, Time/batch_file : 2.2664, Training time: 16992.7763\n",
      "Epoch : 1465/2000 data_batch_5,  Train_loss : 4312.7935  Test_loss : 4778.0186, Time/batch_file : 2.2625, Training time: 16995.0390\n",
      "Epoch : 1466/2000 data_batch_1,  Train_loss : 4789.2471  Test_loss : 5441.7461, Time/batch_file : 2.2617, Training time: 16997.3008\n",
      "Epoch : 1466/2000 data_batch_2,  Train_loss : 4535.4053  Test_loss : 5167.0034, Time/batch_file : 2.2721, Training time: 16999.5731\n",
      "Epoch : 1466/2000 data_batch_3,  Train_loss : 4578.9131  Test_loss : 5191.5098, Time/batch_file : 2.2728, Training time: 17001.8462\n",
      "Epoch : 1466/2000 data_batch_4,  Train_loss : 4387.4976  Test_loss : 5165.0776, Time/batch_file : 2.2747, Training time: 17004.1210\n",
      "Epoch : 1466/2000 data_batch_5,  Train_loss : 4421.4409  Test_loss : 5113.7012, Time/batch_file : 2.2643, Training time: 17006.3855\n",
      "Epoch : 1467/2000 data_batch_1,  Train_loss : 4550.6909  Test_loss : 5232.1313, Time/batch_file : 2.2738, Training time: 17008.6594\n",
      "Epoch : 1467/2000 data_batch_2,  Train_loss : 4506.1025  Test_loss : 5228.4961, Time/batch_file : 2.2744, Training time: 17010.9340\n",
      "Epoch : 1467/2000 data_batch_3,  Train_loss : 4554.1885  Test_loss : 5297.2354, Time/batch_file : 2.2686, Training time: 17013.2029\n",
      "Epoch : 1467/2000 data_batch_4,  Train_loss : 4680.1445  Test_loss : 5067.1147, Time/batch_file : 2.2800, Training time: 17015.4831\n",
      "Epoch : 1467/2000 data_batch_5,  Train_loss : 4629.7676  Test_loss : 5078.1045, Time/batch_file : 2.2751, Training time: 17017.7584\n",
      "Epoch : 1468/2000 data_batch_1,  Train_loss : 4595.1743  Test_loss : 4604.5776, Time/batch_file : 2.2703, Training time: 17020.0289\n",
      "Epoch : 1468/2000 data_batch_2,  Train_loss : 4665.1064  Test_loss : 4779.0303, Time/batch_file : 2.2676, Training time: 17022.2968\n",
      "Epoch : 1468/2000 data_batch_3,  Train_loss : 4551.6621  Test_loss : 4717.0034, Time/batch_file : 2.2671, Training time: 17024.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1468/2000 data_batch_4,  Train_loss : 4462.2002  Test_loss : 4811.8687, Time/batch_file : 2.2685, Training time: 17026.8327\n",
      "Epoch : 1468/2000 data_batch_5,  Train_loss : 4758.8657  Test_loss : 4822.4155, Time/batch_file : 2.2638, Training time: 17029.0967\n",
      "Epoch : 1469/2000 data_batch_1,  Train_loss : 4596.6577  Test_loss : 5054.5791, Time/batch_file : 2.2603, Training time: 17031.3571\n",
      "Epoch : 1469/2000 data_batch_2,  Train_loss : 4731.9922  Test_loss : 4862.6958, Time/batch_file : 2.2562, Training time: 17033.6134\n",
      "Epoch : 1469/2000 data_batch_3,  Train_loss : 4813.3179  Test_loss : 4971.5938, Time/batch_file : 2.2591, Training time: 17035.8727\n",
      "Epoch : 1469/2000 data_batch_4,  Train_loss : 4957.6089  Test_loss : 4990.3428, Time/batch_file : 2.2484, Training time: 17038.1213\n",
      "Epoch : 1469/2000 data_batch_5,  Train_loss : 4736.7275  Test_loss : 5103.7842, Time/batch_file : 2.2529, Training time: 17040.3744\n",
      "Epoch : 1470/2000 data_batch_1,  Train_loss : 5068.1934  Test_loss : 5087.4160, Time/batch_file : 2.2761, Training time: 17042.6508\n",
      "Epoch : 1470/2000 data_batch_2,  Train_loss : 5021.1562  Test_loss : 5156.8145, Time/batch_file : 2.2794, Training time: 17044.9304\n",
      "Epoch : 1470/2000 data_batch_3,  Train_loss : 4928.8887  Test_loss : 4813.5918, Time/batch_file : 2.2756, Training time: 17047.2063\n",
      "Epoch : 1470/2000 data_batch_4,  Train_loss : 4750.5083  Test_loss : 5009.0117, Time/batch_file : 2.2811, Training time: 17049.4877\n",
      "Epoch : 1470/2000 data_batch_5,  Train_loss : 5029.6606  Test_loss : 4924.0713, Time/batch_file : 2.2715, Training time: 17051.7593\n",
      "[./nets/net-1470.ckpt] SAVED\n",
      "Epoch : 1471/2000 data_batch_1,  Train_loss : 4371.2134  Test_loss : 4895.0459, Time/batch_file : 2.3000, Training time: 17055.3551\n",
      "Epoch : 1471/2000 data_batch_2,  Train_loss : 4332.8818  Test_loss : 4978.2466, Time/batch_file : 2.2990, Training time: 17057.6543\n",
      "Epoch : 1471/2000 data_batch_3,  Train_loss : 4477.1875  Test_loss : 4890.0103, Time/batch_file : 2.2869, Training time: 17059.9414\n",
      "Epoch : 1471/2000 data_batch_4,  Train_loss : 4228.2959  Test_loss : 4813.4199, Time/batch_file : 2.2608, Training time: 17062.2024\n",
      "Epoch : 1471/2000 data_batch_5,  Train_loss : 4476.3779  Test_loss : 4640.8989, Time/batch_file : 2.2856, Training time: 17064.4883\n",
      "Epoch : 1472/2000 data_batch_1,  Train_loss : 4516.5674  Test_loss : 5160.2085, Time/batch_file : 2.2621, Training time: 17066.7506\n",
      "Epoch : 1472/2000 data_batch_2,  Train_loss : 4326.5947  Test_loss : 5153.8975, Time/batch_file : 2.2790, Training time: 17069.0299\n",
      "Epoch : 1472/2000 data_batch_3,  Train_loss : 4235.2773  Test_loss : 5422.6587, Time/batch_file : 2.2544, Training time: 17071.2845\n",
      "Epoch : 1472/2000 data_batch_4,  Train_loss : 4325.5293  Test_loss : 5343.4849, Time/batch_file : 2.2721, Training time: 17073.5568\n",
      "Epoch : 1472/2000 data_batch_5,  Train_loss : 4342.8950  Test_loss : 5363.5352, Time/batch_file : 2.2963, Training time: 17075.8533\n",
      "Epoch : 1473/2000 data_batch_1,  Train_loss : 4994.9521  Test_loss : 4813.2070, Time/batch_file : 2.2756, Training time: 17078.1291\n",
      "Epoch : 1473/2000 data_batch_2,  Train_loss : 5223.4956  Test_loss : 4730.4600, Time/batch_file : 2.2675, Training time: 17080.3968\n",
      "Epoch : 1473/2000 data_batch_3,  Train_loss : 5327.6616  Test_loss : 4771.7285, Time/batch_file : 2.2611, Training time: 17082.6581\n",
      "Epoch : 1473/2000 data_batch_4,  Train_loss : 5068.2119  Test_loss : 4913.3608, Time/batch_file : 2.2986, Training time: 17084.9569\n",
      "Epoch : 1473/2000 data_batch_5,  Train_loss : 5044.6787  Test_loss : 4610.4067, Time/batch_file : 2.2754, Training time: 17087.2326\n",
      "Epoch : 1474/2000 data_batch_1,  Train_loss : 4615.0957  Test_loss : 5620.5571, Time/batch_file : 2.2960, Training time: 17089.5288\n",
      "Epoch : 1474/2000 data_batch_2,  Train_loss : 4673.6987  Test_loss : 5734.3149, Time/batch_file : 2.3001, Training time: 17091.8291\n",
      "Epoch : 1474/2000 data_batch_3,  Train_loss : 4832.5342  Test_loss : 5769.5303, Time/batch_file : 2.3051, Training time: 17094.1344\n",
      "Epoch : 1474/2000 data_batch_4,  Train_loss : 4607.6025  Test_loss : 5681.3975, Time/batch_file : 2.3074, Training time: 17096.4419\n",
      "Epoch : 1474/2000 data_batch_5,  Train_loss : 4601.5576  Test_loss : 5415.0249, Time/batch_file : 2.3280, Training time: 17098.7702\n",
      "Epoch : 1475/2000 data_batch_1,  Train_loss : 4744.8564  Test_loss : 5452.6030, Time/batch_file : 2.3138, Training time: 17101.0841\n",
      "Epoch : 1475/2000 data_batch_2,  Train_loss : 4770.0996  Test_loss : 5167.3286, Time/batch_file : 2.3010, Training time: 17103.3854\n",
      "Epoch : 1475/2000 data_batch_3,  Train_loss : 4857.1216  Test_loss : 5193.0962, Time/batch_file : 2.3097, Training time: 17105.6953\n",
      "Epoch : 1475/2000 data_batch_4,  Train_loss : 5020.3745  Test_loss : 5208.7261, Time/batch_file : 2.3035, Training time: 17107.9990\n",
      "Epoch : 1475/2000 data_batch_5,  Train_loss : 4687.8618  Test_loss : 5304.4282, Time/batch_file : 2.3113, Training time: 17110.3105\n",
      "Epoch : 1476/2000 data_batch_1,  Train_loss : 5087.6572  Test_loss : 4387.2397, Time/batch_file : 2.2739, Training time: 17112.5847\n",
      "Epoch : 1476/2000 data_batch_2,  Train_loss : 4986.9531  Test_loss : 4505.3271, Time/batch_file : 2.2856, Training time: 17114.8705\n",
      "Epoch : 1476/2000 data_batch_3,  Train_loss : 4869.0742  Test_loss : 4422.2549, Time/batch_file : 2.2896, Training time: 17117.1603\n",
      "Epoch : 1476/2000 data_batch_4,  Train_loss : 5133.5117  Test_loss : 4405.0288, Time/batch_file : 2.2926, Training time: 17119.4530\n",
      "Epoch : 1476/2000 data_batch_5,  Train_loss : 5211.6616  Test_loss : 4388.2124, Time/batch_file : 2.3386, Training time: 17121.7919\n",
      "Epoch : 1477/2000 data_batch_1,  Train_loss : 4526.6606  Test_loss : 4770.4473, Time/batch_file : 2.2766, Training time: 17124.0688\n",
      "Epoch : 1477/2000 data_batch_2,  Train_loss : 4604.8091  Test_loss : 5109.4473, Time/batch_file : 2.2747, Training time: 17126.3437\n",
      "Epoch : 1477/2000 data_batch_3,  Train_loss : 4546.7593  Test_loss : 5120.6875, Time/batch_file : 2.2789, Training time: 17128.6227\n",
      "Epoch : 1477/2000 data_batch_4,  Train_loss : 4534.1602  Test_loss : 5084.6494, Time/batch_file : 2.2725, Training time: 17130.8954\n",
      "Epoch : 1477/2000 data_batch_5,  Train_loss : 4613.7861  Test_loss : 5247.0854, Time/batch_file : 2.2786, Training time: 17133.1742\n",
      "Epoch : 1478/2000 data_batch_1,  Train_loss : 4547.6577  Test_loss : 4945.6309, Time/batch_file : 2.3033, Training time: 17135.4777\n",
      "Epoch : 1478/2000 data_batch_2,  Train_loss : 4899.4619  Test_loss : 4669.6621, Time/batch_file : 2.2957, Training time: 17137.7736\n",
      "Epoch : 1478/2000 data_batch_3,  Train_loss : 4591.1274  Test_loss : 4811.8140, Time/batch_file : 2.2902, Training time: 17140.0638\n",
      "Epoch : 1478/2000 data_batch_4,  Train_loss : 4613.4131  Test_loss : 4535.3672, Time/batch_file : 2.2884, Training time: 17142.3524\n",
      "Epoch : 1478/2000 data_batch_5,  Train_loss : 4631.2603  Test_loss : 4724.2881, Time/batch_file : 2.2908, Training time: 17144.6434\n",
      "Epoch : 1479/2000 data_batch_1,  Train_loss : 4925.4902  Test_loss : 4795.2139, Time/batch_file : 2.3046, Training time: 17146.9482\n",
      "Epoch : 1479/2000 data_batch_2,  Train_loss : 5071.1431  Test_loss : 5007.0513, Time/batch_file : 2.2948, Training time: 17149.2432\n",
      "Epoch : 1479/2000 data_batch_3,  Train_loss : 4852.8945  Test_loss : 4885.9502, Time/batch_file : 2.3008, Training time: 17151.5443\n",
      "Epoch : 1479/2000 data_batch_4,  Train_loss : 4916.8516  Test_loss : 4910.8438, Time/batch_file : 2.2935, Training time: 17153.8380\n",
      "Epoch : 1479/2000 data_batch_5,  Train_loss : 4946.2544  Test_loss : 4931.2676, Time/batch_file : 2.2960, Training time: 17156.1341\n",
      "Epoch : 1480/2000 data_batch_1,  Train_loss : 5017.0908  Test_loss : 4943.0396, Time/batch_file : 2.2905, Training time: 17158.4249\n",
      "Epoch : 1480/2000 data_batch_2,  Train_loss : 5035.9775  Test_loss : 4785.1689, Time/batch_file : 2.2943, Training time: 17160.7194\n",
      "Epoch : 1480/2000 data_batch_3,  Train_loss : 5247.4951  Test_loss : 4894.4971, Time/batch_file : 2.3030, Training time: 17163.0227\n",
      "Epoch : 1480/2000 data_batch_4,  Train_loss : 5144.4536  Test_loss : 4960.7134, Time/batch_file : 2.2928, Training time: 17165.3158\n",
      "Epoch : 1480/2000 data_batch_5,  Train_loss : 4811.3350  Test_loss : 4989.3062, Time/batch_file : 2.2988, Training time: 17167.6148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[./nets/net-1480.ckpt] SAVED\n",
      "Epoch : 1481/2000 data_batch_1,  Train_loss : 4876.2764  Test_loss : 4797.6538, Time/batch_file : 2.3964, Training time: 17171.2863\n",
      "Epoch : 1481/2000 data_batch_2,  Train_loss : 4864.8066  Test_loss : 4723.9253, Time/batch_file : 2.2672, Training time: 17173.5538\n",
      "Epoch : 1481/2000 data_batch_3,  Train_loss : 4951.5850  Test_loss : 4944.2915, Time/batch_file : 2.2709, Training time: 17175.8250\n",
      "Epoch : 1481/2000 data_batch_4,  Train_loss : 4968.2998  Test_loss : 4885.0400, Time/batch_file : 2.2899, Training time: 17178.1150\n",
      "Epoch : 1481/2000 data_batch_5,  Train_loss : 4818.3516  Test_loss : 4826.1763, Time/batch_file : 2.2727, Training time: 17180.3879\n",
      "Epoch : 1482/2000 data_batch_1,  Train_loss : 5405.7573  Test_loss : 4746.4941, Time/batch_file : 2.2869, Training time: 17182.6750\n",
      "Epoch : 1482/2000 data_batch_2,  Train_loss : 5384.3604  Test_loss : 4749.5601, Time/batch_file : 2.2844, Training time: 17184.9596\n",
      "Epoch : 1482/2000 data_batch_3,  Train_loss : 5541.8833  Test_loss : 4982.7959, Time/batch_file : 2.2679, Training time: 17187.2278\n",
      "Epoch : 1482/2000 data_batch_4,  Train_loss : 5311.2646  Test_loss : 4947.1943, Time/batch_file : 2.3045, Training time: 17189.5324\n",
      "Epoch : 1482/2000 data_batch_5,  Train_loss : 5072.3140  Test_loss : 4859.9653, Time/batch_file : 2.2846, Training time: 17191.8172\n",
      "Epoch : 1483/2000 data_batch_1,  Train_loss : 4383.3838  Test_loss : 4432.2041, Time/batch_file : 2.2870, Training time: 17194.1045\n",
      "Epoch : 1483/2000 data_batch_2,  Train_loss : 4309.7070  Test_loss : 4511.3760, Time/batch_file : 2.2838, Training time: 17196.3884\n",
      "Epoch : 1483/2000 data_batch_3,  Train_loss : 4508.3574  Test_loss : 4532.7178, Time/batch_file : 2.2808, Training time: 17198.6694\n",
      "Epoch : 1483/2000 data_batch_4,  Train_loss : 4925.4971  Test_loss : 4631.6211, Time/batch_file : 2.2900, Training time: 17200.9597\n",
      "Epoch : 1483/2000 data_batch_5,  Train_loss : 4549.1299  Test_loss : 4663.1328, Time/batch_file : 2.2920, Training time: 17203.2519\n",
      "Epoch : 1484/2000 data_batch_1,  Train_loss : 4529.8486  Test_loss : 5492.4102, Time/batch_file : 2.2639, Training time: 17205.5160\n",
      "Epoch : 1484/2000 data_batch_2,  Train_loss : 4511.0938  Test_loss : 5597.9062, Time/batch_file : 2.2683, Training time: 17207.7845\n",
      "Epoch : 1484/2000 data_batch_3,  Train_loss : 4433.8179  Test_loss : 5391.7285, Time/batch_file : 2.2804, Training time: 17210.0651\n",
      "Epoch : 1484/2000 data_batch_4,  Train_loss : 4816.9258  Test_loss : 4866.8867, Time/batch_file : 2.2714, Training time: 17212.3367\n",
      "Epoch : 1484/2000 data_batch_5,  Train_loss : 4621.5596  Test_loss : 4961.3364, Time/batch_file : 2.2780, Training time: 17214.6150\n",
      "Epoch : 1485/2000 data_batch_1,  Train_loss : 4747.5903  Test_loss : 5330.6099, Time/batch_file : 2.2521, Training time: 17216.8673\n",
      "Epoch : 1485/2000 data_batch_2,  Train_loss : 4762.9932  Test_loss : 5037.7271, Time/batch_file : 2.3045, Training time: 17219.1720\n",
      "Epoch : 1485/2000 data_batch_3,  Train_loss : 4682.9429  Test_loss : 5016.7949, Time/batch_file : 2.2548, Training time: 17221.4270\n",
      "Epoch : 1485/2000 data_batch_4,  Train_loss : 4781.3364  Test_loss : 4754.3252, Time/batch_file : 2.2512, Training time: 17223.6783\n",
      "Epoch : 1485/2000 data_batch_5,  Train_loss : 4602.5107  Test_loss : 5067.1221, Time/batch_file : 2.2586, Training time: 17225.9371\n",
      "Epoch : 1486/2000 data_batch_1,  Train_loss : 5029.9419  Test_loss : 4798.0669, Time/batch_file : 2.2761, Training time: 17228.2134\n",
      "Epoch : 1486/2000 data_batch_2,  Train_loss : 5035.1367  Test_loss : 4552.1592, Time/batch_file : 2.2734, Training time: 17230.4870\n",
      "Epoch : 1486/2000 data_batch_3,  Train_loss : 4886.7822  Test_loss : 4521.5986, Time/batch_file : 2.2708, Training time: 17232.7580\n",
      "Epoch : 1486/2000 data_batch_4,  Train_loss : 4988.4819  Test_loss : 4671.6953, Time/batch_file : 2.2815, Training time: 17235.0397\n",
      "Epoch : 1486/2000 data_batch_5,  Train_loss : 5074.9287  Test_loss : 4510.9819, Time/batch_file : 2.2558, Training time: 17237.2956\n",
      "Epoch : 1487/2000 data_batch_1,  Train_loss : 4752.7241  Test_loss : 5079.3262, Time/batch_file : 2.2592, Training time: 17239.5550\n",
      "Epoch : 1487/2000 data_batch_2,  Train_loss : 4855.0249  Test_loss : 5123.5732, Time/batch_file : 2.2792, Training time: 17241.8345\n",
      "Epoch : 1487/2000 data_batch_3,  Train_loss : 4491.3438  Test_loss : 4896.6206, Time/batch_file : 2.2682, Training time: 17244.1030\n",
      "Epoch : 1487/2000 data_batch_4,  Train_loss : 4679.9468  Test_loss : 5383.1772, Time/batch_file : 2.2602, Training time: 17246.3634\n",
      "Epoch : 1487/2000 data_batch_5,  Train_loss : 4519.0449  Test_loss : 5091.2158, Time/batch_file : 2.2606, Training time: 17248.6241\n",
      "Epoch : 1488/2000 data_batch_1,  Train_loss : 4768.0771  Test_loss : 5111.2451, Time/batch_file : 2.2885, Training time: 17250.9128\n",
      "Epoch : 1488/2000 data_batch_2,  Train_loss : 4689.0298  Test_loss : 4946.5166, Time/batch_file : 2.2722, Training time: 17253.1852\n",
      "Epoch : 1488/2000 data_batch_3,  Train_loss : 4545.3013  Test_loss : 4979.6592, Time/batch_file : 2.2869, Training time: 17255.4723\n",
      "Epoch : 1488/2000 data_batch_4,  Train_loss : 4760.8525  Test_loss : 5110.3242, Time/batch_file : 2.2765, Training time: 17257.7490\n",
      "Epoch : 1488/2000 data_batch_5,  Train_loss : 4585.8271  Test_loss : 5058.8579, Time/batch_file : 2.2924, Training time: 17260.0416\n",
      "Epoch : 1489/2000 data_batch_1,  Train_loss : 4861.9165  Test_loss : 4993.6567, Time/batch_file : 2.2690, Training time: 17262.3106\n",
      "Epoch : 1489/2000 data_batch_2,  Train_loss : 4706.2812  Test_loss : 5195.1655, Time/batch_file : 2.2821, Training time: 17264.5930\n",
      "Epoch : 1489/2000 data_batch_3,  Train_loss : 4739.7603  Test_loss : 5179.2417, Time/batch_file : 2.2752, Training time: 17266.8684\n",
      "Epoch : 1489/2000 data_batch_4,  Train_loss : 4923.4033  Test_loss : 4708.1982, Time/batch_file : 2.2724, Training time: 17269.1409\n",
      "Epoch : 1489/2000 data_batch_5,  Train_loss : 4716.3560  Test_loss : 4948.9688, Time/batch_file : 2.2907, Training time: 17271.4318\n",
      "Epoch : 1490/2000 data_batch_1,  Train_loss : 4780.7920  Test_loss : 4891.2080, Time/batch_file : 2.2689, Training time: 17273.7010\n",
      "Epoch : 1490/2000 data_batch_2,  Train_loss : 4856.3042  Test_loss : 4632.5078, Time/batch_file : 2.2823, Training time: 17275.9835\n",
      "Epoch : 1490/2000 data_batch_3,  Train_loss : 4584.8594  Test_loss : 4849.3408, Time/batch_file : 2.2737, Training time: 17278.2575\n",
      "Epoch : 1490/2000 data_batch_4,  Train_loss : 4715.8359  Test_loss : 4756.4414, Time/batch_file : 2.2693, Training time: 17280.5270\n",
      "Epoch : 1490/2000 data_batch_5,  Train_loss : 4712.6260  Test_loss : 4952.7905, Time/batch_file : 2.2807, Training time: 17282.8079\n",
      "[./nets/net-1490.ckpt] SAVED\n",
      "Epoch : 1491/2000 data_batch_1,  Train_loss : 4420.4736  Test_loss : 5239.4961, Time/batch_file : 2.2757, Training time: 17286.3504\n",
      "Epoch : 1491/2000 data_batch_2,  Train_loss : 4783.3457  Test_loss : 5218.8340, Time/batch_file : 2.2744, Training time: 17288.6250\n",
      "Epoch : 1491/2000 data_batch_3,  Train_loss : 4863.8745  Test_loss : 5360.4678, Time/batch_file : 2.2727, Training time: 17290.8979\n",
      "Epoch : 1491/2000 data_batch_4,  Train_loss : 4707.9312  Test_loss : 5339.7549, Time/batch_file : 2.2621, Training time: 17293.1602\n",
      "Epoch : 1491/2000 data_batch_5,  Train_loss : 4612.4683  Test_loss : 5143.6680, Time/batch_file : 2.2747, Training time: 17295.4350\n",
      "Epoch : 1492/2000 data_batch_1,  Train_loss : 4611.6904  Test_loss : 4027.4946, Time/batch_file : 2.2714, Training time: 17297.7067\n",
      "Epoch : 1492/2000 data_batch_2,  Train_loss : 4643.2241  Test_loss : 4083.9177, Time/batch_file : 2.2753, Training time: 17299.9822\n",
      "Epoch : 1492/2000 data_batch_3,  Train_loss : 4639.5566  Test_loss : 4045.5996, Time/batch_file : 2.2878, Training time: 17302.2702\n",
      "Epoch : 1492/2000 data_batch_4,  Train_loss : 4806.6895  Test_loss : 4041.2681, Time/batch_file : 2.2817, Training time: 17304.5520\n",
      "Epoch : 1492/2000 data_batch_5,  Train_loss : 4751.2510  Test_loss : 4423.2441, Time/batch_file : 2.2881, Training time: 17306.8404\n",
      "Epoch : 1493/2000 data_batch_1,  Train_loss : 4868.6733  Test_loss : 4895.4004, Time/batch_file : 2.2844, Training time: 17309.1251\n",
      "Epoch : 1493/2000 data_batch_2,  Train_loss : 4858.0918  Test_loss : 4835.2266, Time/batch_file : 2.2697, Training time: 17311.3950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1493/2000 data_batch_3,  Train_loss : 5105.3887  Test_loss : 4652.6416, Time/batch_file : 2.2781, Training time: 17313.6733\n",
      "Epoch : 1493/2000 data_batch_4,  Train_loss : 5006.3579  Test_loss : 4839.9883, Time/batch_file : 2.2778, Training time: 17315.9514\n",
      "Epoch : 1493/2000 data_batch_5,  Train_loss : 4978.8604  Test_loss : 4639.7705, Time/batch_file : 2.2796, Training time: 17318.2312\n",
      "Epoch : 1494/2000 data_batch_1,  Train_loss : 4801.3613  Test_loss : 4558.4502, Time/batch_file : 2.2735, Training time: 17320.5048\n",
      "Epoch : 1494/2000 data_batch_2,  Train_loss : 4578.8687  Test_loss : 4549.5234, Time/batch_file : 2.2634, Training time: 17322.7685\n",
      "Epoch : 1494/2000 data_batch_3,  Train_loss : 4724.4707  Test_loss : 4943.1128, Time/batch_file : 2.2694, Training time: 17325.0380\n",
      "Epoch : 1494/2000 data_batch_4,  Train_loss : 4531.4507  Test_loss : 4713.8550, Time/batch_file : 2.2653, Training time: 17327.3035\n",
      "Epoch : 1494/2000 data_batch_5,  Train_loss : 4478.0205  Test_loss : 4709.0674, Time/batch_file : 2.2580, Training time: 17329.5617\n",
      "Epoch : 1495/2000 data_batch_1,  Train_loss : 4785.5161  Test_loss : 5528.3281, Time/batch_file : 2.2768, Training time: 17331.8387\n",
      "Epoch : 1495/2000 data_batch_2,  Train_loss : 4929.3008  Test_loss : 5399.9551, Time/batch_file : 2.2849, Training time: 17334.1238\n",
      "Epoch : 1495/2000 data_batch_3,  Train_loss : 4826.6450  Test_loss : 5294.3911, Time/batch_file : 2.2847, Training time: 17336.4088\n",
      "Epoch : 1495/2000 data_batch_4,  Train_loss : 4624.6191  Test_loss : 5064.1211, Time/batch_file : 2.3050, Training time: 17338.7141\n",
      "Epoch : 1495/2000 data_batch_5,  Train_loss : 4655.5527  Test_loss : 5382.9111, Time/batch_file : 2.2828, Training time: 17340.9972\n",
      "Epoch : 1496/2000 data_batch_1,  Train_loss : 4867.9766  Test_loss : 5601.1343, Time/batch_file : 2.2745, Training time: 17343.2719\n",
      "Epoch : 1496/2000 data_batch_2,  Train_loss : 5251.1621  Test_loss : 5668.5063, Time/batch_file : 2.2757, Training time: 17345.5477\n",
      "Epoch : 1496/2000 data_batch_3,  Train_loss : 4838.8594  Test_loss : 5366.9858, Time/batch_file : 2.2677, Training time: 17347.8156\n",
      "Epoch : 1496/2000 data_batch_4,  Train_loss : 4877.5693  Test_loss : 5666.3130, Time/batch_file : 2.2601, Training time: 17350.0759\n",
      "Epoch : 1496/2000 data_batch_5,  Train_loss : 4927.6304  Test_loss : 5233.1299, Time/batch_file : 2.2771, Training time: 17352.3532\n",
      "Epoch : 1497/2000 data_batch_1,  Train_loss : 4682.4312  Test_loss : 4246.1021, Time/batch_file : 2.2602, Training time: 17354.6136\n",
      "Epoch : 1497/2000 data_batch_2,  Train_loss : 4436.0615  Test_loss : 4646.8076, Time/batch_file : 2.2602, Training time: 17356.8740\n",
      "Epoch : 1497/2000 data_batch_3,  Train_loss : 4801.7173  Test_loss : 4530.5430, Time/batch_file : 2.2674, Training time: 17359.1416\n",
      "Epoch : 1497/2000 data_batch_4,  Train_loss : 4504.5288  Test_loss : 4771.0786, Time/batch_file : 2.2691, Training time: 17361.4108\n",
      "Epoch : 1497/2000 data_batch_5,  Train_loss : 4533.0107  Test_loss : 4494.1167, Time/batch_file : 2.2653, Training time: 17363.6763\n",
      "Epoch : 1498/2000 data_batch_1,  Train_loss : 4768.8291  Test_loss : 5023.3457, Time/batch_file : 2.2806, Training time: 17365.9571\n",
      "Epoch : 1498/2000 data_batch_2,  Train_loss : 4445.6494  Test_loss : 5349.1929, Time/batch_file : 2.2669, Training time: 17368.2241\n",
      "Epoch : 1498/2000 data_batch_3,  Train_loss : 4638.8057  Test_loss : 4961.6553, Time/batch_file : 2.2730, Training time: 17370.4974\n",
      "Epoch : 1498/2000 data_batch_4,  Train_loss : 4901.0259  Test_loss : 4990.5684, Time/batch_file : 2.2682, Training time: 17372.7658\n",
      "Epoch : 1498/2000 data_batch_5,  Train_loss : 4779.9365  Test_loss : 5123.2651, Time/batch_file : 2.2785, Training time: 17375.0445\n",
      "Epoch : 1499/2000 data_batch_1,  Train_loss : 4793.1411  Test_loss : 5308.3438, Time/batch_file : 2.2644, Training time: 17377.3091\n",
      "Epoch : 1499/2000 data_batch_2,  Train_loss : 4430.0845  Test_loss : 5261.1406, Time/batch_file : 2.2749, Training time: 17379.5844\n",
      "Epoch : 1499/2000 data_batch_3,  Train_loss : 4501.8154  Test_loss : 5131.7275, Time/batch_file : 2.2684, Training time: 17381.8529\n",
      "Epoch : 1499/2000 data_batch_4,  Train_loss : 4554.7114  Test_loss : 5205.1270, Time/batch_file : 2.2784, Training time: 17384.1315\n",
      "Epoch : 1499/2000 data_batch_5,  Train_loss : 4292.1553  Test_loss : 5296.5889, Time/batch_file : 2.2609, Training time: 17386.3927\n",
      "Epoch : 1500/2000 data_batch_1,  Train_loss : 4383.0068  Test_loss : 5116.6025, Time/batch_file : 2.2759, Training time: 17388.6688\n",
      "Epoch : 1500/2000 data_batch_2,  Train_loss : 4242.1533  Test_loss : 5169.2393, Time/batch_file : 2.2672, Training time: 17390.9362\n",
      "Epoch : 1500/2000 data_batch_3,  Train_loss : 4328.8789  Test_loss : 5290.9824, Time/batch_file : 2.2644, Training time: 17393.2009\n",
      "Epoch : 1500/2000 data_batch_4,  Train_loss : 4463.3242  Test_loss : 5294.0601, Time/batch_file : 2.2639, Training time: 17395.4651\n",
      "Epoch : 1500/2000 data_batch_5,  Train_loss : 4306.0127  Test_loss : 5201.2769, Time/batch_file : 2.2666, Training time: 17397.7318\n",
      "[./nets/net-1500.ckpt] SAVED\n",
      "Epoch : 1501/2000 data_batch_1,  Train_loss : 4912.2686  Test_loss : 4896.6006, Time/batch_file : 2.2971, Training time: 17401.3230\n",
      "Epoch : 1501/2000 data_batch_2,  Train_loss : 4564.7720  Test_loss : 5022.8623, Time/batch_file : 2.2715, Training time: 17403.5947\n",
      "Epoch : 1501/2000 data_batch_3,  Train_loss : 4805.7544  Test_loss : 5134.3926, Time/batch_file : 2.2663, Training time: 17405.8613\n",
      "Epoch : 1501/2000 data_batch_4,  Train_loss : 4805.8574  Test_loss : 4688.4102, Time/batch_file : 2.2626, Training time: 17408.1240\n",
      "Epoch : 1501/2000 data_batch_5,  Train_loss : 4723.1123  Test_loss : 4873.0615, Time/batch_file : 2.2647, Training time: 17410.3889\n",
      "Epoch : 1502/2000 data_batch_1,  Train_loss : 4762.2856  Test_loss : 5114.4053, Time/batch_file : 2.2629, Training time: 17412.6521\n",
      "Epoch : 1502/2000 data_batch_2,  Train_loss : 4395.4170  Test_loss : 5235.3735, Time/batch_file : 2.2576, Training time: 17414.9099\n",
      "Epoch : 1502/2000 data_batch_3,  Train_loss : 4699.7144  Test_loss : 5312.4829, Time/batch_file : 2.2603, Training time: 17417.1703\n",
      "Epoch : 1502/2000 data_batch_4,  Train_loss : 4567.7866  Test_loss : 5117.2583, Time/batch_file : 2.2682, Training time: 17419.4387\n",
      "Epoch : 1502/2000 data_batch_5,  Train_loss : 4805.1279  Test_loss : 4839.9180, Time/batch_file : 2.2838, Training time: 17421.7227\n",
      "Epoch : 1503/2000 data_batch_1,  Train_loss : 4587.6899  Test_loss : 4458.0122, Time/batch_file : 2.2673, Training time: 17423.9903\n",
      "Epoch : 1503/2000 data_batch_2,  Train_loss : 4699.8770  Test_loss : 4759.4595, Time/batch_file : 2.2617, Training time: 17426.2522\n",
      "Epoch : 1503/2000 data_batch_3,  Train_loss : 4807.2695  Test_loss : 4647.7036, Time/batch_file : 2.2714, Training time: 17428.5238\n",
      "Epoch : 1503/2000 data_batch_4,  Train_loss : 4726.2783  Test_loss : 4521.0835, Time/batch_file : 2.2705, Training time: 17430.7946\n",
      "Epoch : 1503/2000 data_batch_5,  Train_loss : 4800.2295  Test_loss : 4314.2441, Time/batch_file : 2.2623, Training time: 17433.0571\n",
      "Epoch : 1504/2000 data_batch_1,  Train_loss : 4601.5396  Test_loss : 4714.3975, Time/batch_file : 2.2674, Training time: 17435.3247\n",
      "Epoch : 1504/2000 data_batch_2,  Train_loss : 4612.7490  Test_loss : 4458.2666, Time/batch_file : 2.2677, Training time: 17437.5925\n",
      "Epoch : 1504/2000 data_batch_3,  Train_loss : 4381.3936  Test_loss : 4715.0923, Time/batch_file : 2.2679, Training time: 17439.8607\n",
      "Epoch : 1504/2000 data_batch_4,  Train_loss : 4714.4795  Test_loss : 4924.0957, Time/batch_file : 2.2632, Training time: 17442.1241\n",
      "Epoch : 1504/2000 data_batch_5,  Train_loss : 4638.8350  Test_loss : 4996.2900, Time/batch_file : 2.2612, Training time: 17444.3855\n",
      "Epoch : 1505/2000 data_batch_1,  Train_loss : 4609.3076  Test_loss : 4856.4688, Time/batch_file : 2.2619, Training time: 17446.6476\n",
      "Epoch : 1505/2000 data_batch_2,  Train_loss : 4707.8647  Test_loss : 4829.9150, Time/batch_file : 2.2560, Training time: 17448.9038\n",
      "Epoch : 1505/2000 data_batch_3,  Train_loss : 4580.1855  Test_loss : 4806.5693, Time/batch_file : 2.2542, Training time: 17451.1582\n",
      "Epoch : 1505/2000 data_batch_4,  Train_loss : 4497.9053  Test_loss : 4886.7871, Time/batch_file : 2.2558, Training time: 17453.4143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1505/2000 data_batch_5,  Train_loss : 4430.8350  Test_loss : 4925.8032, Time/batch_file : 2.2511, Training time: 17455.6656\n",
      "Epoch : 1506/2000 data_batch_1,  Train_loss : 4884.0352  Test_loss : 4984.4307, Time/batch_file : 2.2842, Training time: 17457.9499\n",
      "Epoch : 1506/2000 data_batch_2,  Train_loss : 4702.6709  Test_loss : 4619.9912, Time/batch_file : 2.2606, Training time: 17460.2108\n",
      "Epoch : 1506/2000 data_batch_3,  Train_loss : 4506.9800  Test_loss : 4753.3145, Time/batch_file : 2.2586, Training time: 17462.4696\n",
      "Epoch : 1506/2000 data_batch_4,  Train_loss : 4660.9150  Test_loss : 4756.7451, Time/batch_file : 2.2581, Training time: 17464.7280\n",
      "Epoch : 1506/2000 data_batch_5,  Train_loss : 4540.2959  Test_loss : 4966.0615, Time/batch_file : 2.2664, Training time: 17466.9946\n",
      "Epoch : 1507/2000 data_batch_1,  Train_loss : 5161.5059  Test_loss : 4947.4756, Time/batch_file : 2.2666, Training time: 17469.2615\n",
      "Epoch : 1507/2000 data_batch_2,  Train_loss : 5175.4722  Test_loss : 4886.3809, Time/batch_file : 2.2583, Training time: 17471.5200\n",
      "Epoch : 1507/2000 data_batch_3,  Train_loss : 5149.3320  Test_loss : 5181.0439, Time/batch_file : 2.2682, Training time: 17473.7885\n",
      "Epoch : 1507/2000 data_batch_4,  Train_loss : 4954.9375  Test_loss : 4951.5010, Time/batch_file : 2.2701, Training time: 17476.0588\n",
      "Epoch : 1507/2000 data_batch_5,  Train_loss : 4852.1694  Test_loss : 5001.0122, Time/batch_file : 2.2578, Training time: 17478.3168\n",
      "Epoch : 1508/2000 data_batch_1,  Train_loss : 4624.6982  Test_loss : 4832.5332, Time/batch_file : 2.2695, Training time: 17480.5866\n",
      "Epoch : 1508/2000 data_batch_2,  Train_loss : 4675.8667  Test_loss : 5015.1836, Time/batch_file : 2.2681, Training time: 17482.8548\n",
      "Epoch : 1508/2000 data_batch_3,  Train_loss : 4497.5107  Test_loss : 4882.8428, Time/batch_file : 2.2726, Training time: 17485.1276\n",
      "Epoch : 1508/2000 data_batch_4,  Train_loss : 4645.7827  Test_loss : 5088.6558, Time/batch_file : 2.2687, Training time: 17487.3965\n",
      "Epoch : 1508/2000 data_batch_5,  Train_loss : 4786.1406  Test_loss : 4915.2563, Time/batch_file : 2.2715, Training time: 17489.6683\n",
      "Epoch : 1509/2000 data_batch_1,  Train_loss : 4898.4243  Test_loss : 5079.3716, Time/batch_file : 2.2687, Training time: 17491.9371\n",
      "Epoch : 1509/2000 data_batch_2,  Train_loss : 4772.9658  Test_loss : 5070.4517, Time/batch_file : 2.2651, Training time: 17494.2024\n",
      "Epoch : 1509/2000 data_batch_3,  Train_loss : 4761.2910  Test_loss : 5025.7031, Time/batch_file : 2.2612, Training time: 17496.4638\n",
      "Epoch : 1509/2000 data_batch_4,  Train_loss : 4837.9766  Test_loss : 5070.8838, Time/batch_file : 2.2642, Training time: 17498.7282\n",
      "Epoch : 1509/2000 data_batch_5,  Train_loss : 5069.8701  Test_loss : 5078.1265, Time/batch_file : 2.2624, Training time: 17500.9909\n",
      "Epoch : 1510/2000 data_batch_1,  Train_loss : 4834.0234  Test_loss : 5169.2109, Time/batch_file : 2.2715, Training time: 17503.2627\n",
      "Epoch : 1510/2000 data_batch_2,  Train_loss : 4653.9253  Test_loss : 5073.7163, Time/batch_file : 2.2718, Training time: 17505.5348\n",
      "Epoch : 1510/2000 data_batch_3,  Train_loss : 4701.8291  Test_loss : 5228.2500, Time/batch_file : 2.2757, Training time: 17507.8107\n",
      "Epoch : 1510/2000 data_batch_4,  Train_loss : 4798.4590  Test_loss : 5292.0854, Time/batch_file : 2.2769, Training time: 17510.0878\n",
      "Epoch : 1510/2000 data_batch_5,  Train_loss : 4699.4736  Test_loss : 5080.1504, Time/batch_file : 2.2665, Training time: 17512.3545\n",
      "[./nets/net-1510.ckpt] SAVED\n",
      "Epoch : 1511/2000 data_batch_1,  Train_loss : 4516.3604  Test_loss : 5012.9434, Time/batch_file : 2.3007, Training time: 17515.9432\n",
      "Epoch : 1511/2000 data_batch_2,  Train_loss : 4842.9561  Test_loss : 5314.7803, Time/batch_file : 2.2607, Training time: 17518.2043\n",
      "Epoch : 1511/2000 data_batch_3,  Train_loss : 4626.8398  Test_loss : 4931.2632, Time/batch_file : 2.2595, Training time: 17520.4639\n",
      "Epoch : 1511/2000 data_batch_4,  Train_loss : 4597.9146  Test_loss : 4966.9893, Time/batch_file : 2.2824, Training time: 17522.7464\n",
      "Epoch : 1511/2000 data_batch_5,  Train_loss : 4452.1646  Test_loss : 4967.4385, Time/batch_file : 2.2497, Training time: 17524.9963\n",
      "Epoch : 1512/2000 data_batch_1,  Train_loss : 4468.5435  Test_loss : 4880.5732, Time/batch_file : 2.2798, Training time: 17527.2763\n",
      "Epoch : 1512/2000 data_batch_2,  Train_loss : 4277.3892  Test_loss : 5116.5522, Time/batch_file : 2.2703, Training time: 17529.5468\n",
      "Epoch : 1512/2000 data_batch_3,  Train_loss : 4498.7510  Test_loss : 4964.7197, Time/batch_file : 2.2669, Training time: 17531.8139\n",
      "Epoch : 1512/2000 data_batch_4,  Train_loss : 4501.5049  Test_loss : 5235.8154, Time/batch_file : 2.2843, Training time: 17534.0983\n",
      "Epoch : 1512/2000 data_batch_5,  Train_loss : 4423.7266  Test_loss : 5045.9619, Time/batch_file : 2.2718, Training time: 17536.3703\n",
      "Epoch : 1513/2000 data_batch_1,  Train_loss : 4523.6465  Test_loss : 4586.3599, Time/batch_file : 2.2694, Training time: 17538.6400\n",
      "Epoch : 1513/2000 data_batch_2,  Train_loss : 4370.6094  Test_loss : 4207.6455, Time/batch_file : 2.2754, Training time: 17540.9157\n",
      "Epoch : 1513/2000 data_batch_3,  Train_loss : 4707.9736  Test_loss : 4304.5684, Time/batch_file : 2.2643, Training time: 17543.1802\n",
      "Epoch : 1513/2000 data_batch_4,  Train_loss : 4377.7822  Test_loss : 4722.2944, Time/batch_file : 2.2883, Training time: 17545.4687\n",
      "Epoch : 1513/2000 data_batch_5,  Train_loss : 4473.5786  Test_loss : 4480.4893, Time/batch_file : 2.2881, Training time: 17547.7570\n",
      "Epoch : 1514/2000 data_batch_1,  Train_loss : 4650.5146  Test_loss : 4697.0977, Time/batch_file : 2.3084, Training time: 17550.0655\n",
      "Epoch : 1514/2000 data_batch_2,  Train_loss : 4677.6738  Test_loss : 4716.9639, Time/batch_file : 2.2861, Training time: 17552.3519\n",
      "Epoch : 1514/2000 data_batch_3,  Train_loss : 4769.8584  Test_loss : 4890.5059, Time/batch_file : 2.2777, Training time: 17554.6298\n",
      "Epoch : 1514/2000 data_batch_4,  Train_loss : 4853.3203  Test_loss : 4597.9795, Time/batch_file : 2.2739, Training time: 17556.9039\n",
      "Epoch : 1514/2000 data_batch_5,  Train_loss : 4452.0571  Test_loss : 4719.9766, Time/batch_file : 2.2700, Training time: 17559.1742\n",
      "Epoch : 1515/2000 data_batch_1,  Train_loss : 4772.7832  Test_loss : 4859.0439, Time/batch_file : 2.2982, Training time: 17561.4726\n",
      "Epoch : 1515/2000 data_batch_2,  Train_loss : 4738.0356  Test_loss : 4859.6963, Time/batch_file : 2.2807, Training time: 17563.7534\n",
      "Epoch : 1515/2000 data_batch_3,  Train_loss : 4570.7852  Test_loss : 5087.8853, Time/batch_file : 2.2839, Training time: 17566.0376\n",
      "Epoch : 1515/2000 data_batch_4,  Train_loss : 4534.4312  Test_loss : 4907.8516, Time/batch_file : 2.2725, Training time: 17568.3103\n",
      "Epoch : 1515/2000 data_batch_5,  Train_loss : 4725.1665  Test_loss : 5125.8647, Time/batch_file : 2.2732, Training time: 17570.5837\n",
      "Epoch : 1516/2000 data_batch_1,  Train_loss : 5079.9712  Test_loss : 4912.4297, Time/batch_file : 2.2875, Training time: 17572.8715\n",
      "Epoch : 1516/2000 data_batch_2,  Train_loss : 5098.0542  Test_loss : 4680.3164, Time/batch_file : 2.2765, Training time: 17575.1483\n",
      "Epoch : 1516/2000 data_batch_3,  Train_loss : 5107.0420  Test_loss : 4980.9038, Time/batch_file : 2.3026, Training time: 17577.4511\n",
      "Epoch : 1516/2000 data_batch_4,  Train_loss : 4898.0049  Test_loss : 4878.9248, Time/batch_file : 2.2832, Training time: 17579.7345\n",
      "Epoch : 1516/2000 data_batch_5,  Train_loss : 5056.0410  Test_loss : 4775.3135, Time/batch_file : 2.2892, Training time: 17582.0238\n",
      "Epoch : 1517/2000 data_batch_1,  Train_loss : 4586.6396  Test_loss : 5345.0088, Time/batch_file : 2.2634, Training time: 17584.2875\n",
      "Epoch : 1517/2000 data_batch_2,  Train_loss : 4656.4229  Test_loss : 5139.7480, Time/batch_file : 2.2851, Training time: 17586.5728\n",
      "Epoch : 1517/2000 data_batch_3,  Train_loss : 4637.8252  Test_loss : 5444.2700, Time/batch_file : 2.3002, Training time: 17588.8732\n",
      "Epoch : 1517/2000 data_batch_4,  Train_loss : 4753.0317  Test_loss : 5324.6748, Time/batch_file : 2.2669, Training time: 17591.1404\n",
      "Epoch : 1517/2000 data_batch_5,  Train_loss : 4642.5859  Test_loss : 5312.4766, Time/batch_file : 2.2678, Training time: 17593.4085\n",
      "Epoch : 1518/2000 data_batch_1,  Train_loss : 5292.1958  Test_loss : 4434.1426, Time/batch_file : 2.2809, Training time: 17595.6895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1518/2000 data_batch_2,  Train_loss : 5460.4785  Test_loss : 4373.6123, Time/batch_file : 2.2786, Training time: 17597.9683\n",
      "Epoch : 1518/2000 data_batch_3,  Train_loss : 5258.5952  Test_loss : 4227.1060, Time/batch_file : 2.3188, Training time: 17600.2874\n",
      "Epoch : 1518/2000 data_batch_4,  Train_loss : 5046.6924  Test_loss : 4523.7490, Time/batch_file : 2.2802, Training time: 17602.5678\n",
      "Epoch : 1518/2000 data_batch_5,  Train_loss : 5241.1191  Test_loss : 4454.3525, Time/batch_file : 2.3053, Training time: 17604.8734\n",
      "Epoch : 1519/2000 data_batch_1,  Train_loss : 4319.4019  Test_loss : 4616.1699, Time/batch_file : 2.2829, Training time: 17607.1565\n",
      "Epoch : 1519/2000 data_batch_2,  Train_loss : 4197.1670  Test_loss : 4820.6396, Time/batch_file : 2.2711, Training time: 17609.4279\n",
      "Epoch : 1519/2000 data_batch_3,  Train_loss : 4365.9951  Test_loss : 5160.4805, Time/batch_file : 2.2750, Training time: 17611.7030\n",
      "Epoch : 1519/2000 data_batch_4,  Train_loss : 4075.5781  Test_loss : 4951.4966, Time/batch_file : 2.2817, Training time: 17613.9850\n",
      "Epoch : 1519/2000 data_batch_5,  Train_loss : 4293.2275  Test_loss : 5076.6562, Time/batch_file : 2.2936, Training time: 17616.2788\n",
      "Epoch : 1520/2000 data_batch_1,  Train_loss : 5038.9395  Test_loss : 5210.9712, Time/batch_file : 2.2827, Training time: 17618.5616\n",
      "Epoch : 1520/2000 data_batch_2,  Train_loss : 4975.6846  Test_loss : 5019.0547, Time/batch_file : 2.2743, Training time: 17620.8361\n",
      "Epoch : 1520/2000 data_batch_3,  Train_loss : 5142.5708  Test_loss : 5140.3818, Time/batch_file : 2.2944, Training time: 17623.1308\n",
      "Epoch : 1520/2000 data_batch_4,  Train_loss : 5058.9751  Test_loss : 5170.2168, Time/batch_file : 2.2761, Training time: 17625.4070\n",
      "Epoch : 1520/2000 data_batch_5,  Train_loss : 5119.8047  Test_loss : 5045.4946, Time/batch_file : 2.2899, Training time: 17627.6971\n",
      "[./nets/net-1520.ckpt] SAVED\n",
      "Epoch : 1521/2000 data_batch_1,  Train_loss : 4825.9370  Test_loss : 4758.5601, Time/batch_file : 2.3636, Training time: 17631.3558\n",
      "Epoch : 1521/2000 data_batch_2,  Train_loss : 4519.4707  Test_loss : 4613.5693, Time/batch_file : 2.2650, Training time: 17633.6210\n",
      "Epoch : 1521/2000 data_batch_3,  Train_loss : 5039.8784  Test_loss : 4764.1875, Time/batch_file : 2.2877, Training time: 17635.9089\n",
      "Epoch : 1521/2000 data_batch_4,  Train_loss : 5092.0210  Test_loss : 5097.0342, Time/batch_file : 2.2702, Training time: 17638.1794\n",
      "Epoch : 1521/2000 data_batch_5,  Train_loss : 4891.2573  Test_loss : 4748.8418, Time/batch_file : 2.2674, Training time: 17640.4471\n",
      "Epoch : 1522/2000 data_batch_1,  Train_loss : 5013.2617  Test_loss : 4913.6011, Time/batch_file : 2.2966, Training time: 17642.7439\n",
      "Epoch : 1522/2000 data_batch_2,  Train_loss : 5237.6958  Test_loss : 5048.0293, Time/batch_file : 2.3277, Training time: 17645.0718\n",
      "Epoch : 1522/2000 data_batch_3,  Train_loss : 5262.6377  Test_loss : 4975.3823, Time/batch_file : 2.2841, Training time: 17647.3560\n",
      "Epoch : 1522/2000 data_batch_4,  Train_loss : 5123.7212  Test_loss : 4851.8623, Time/batch_file : 2.2761, Training time: 17649.6324\n",
      "Epoch : 1522/2000 data_batch_5,  Train_loss : 5203.6426  Test_loss : 4999.1377, Time/batch_file : 2.2970, Training time: 17651.9296\n",
      "Epoch : 1523/2000 data_batch_1,  Train_loss : 4597.0933  Test_loss : 5667.6338, Time/batch_file : 2.2614, Training time: 17654.1912\n",
      "Epoch : 1523/2000 data_batch_2,  Train_loss : 4832.7051  Test_loss : 5460.1372, Time/batch_file : 2.2724, Training time: 17656.4638\n",
      "Epoch : 1523/2000 data_batch_3,  Train_loss : 4698.8325  Test_loss : 5477.3564, Time/batch_file : 2.2706, Training time: 17658.7348\n",
      "Epoch : 1523/2000 data_batch_4,  Train_loss : 4804.3223  Test_loss : 5374.8315, Time/batch_file : 2.2891, Training time: 17661.0241\n",
      "Epoch : 1523/2000 data_batch_5,  Train_loss : 4838.2227  Test_loss : 5116.8413, Time/batch_file : 2.2600, Training time: 17663.2842\n",
      "Epoch : 1524/2000 data_batch_1,  Train_loss : 5210.5571  Test_loss : 5311.9155, Time/batch_file : 2.2965, Training time: 17665.5809\n",
      "Epoch : 1524/2000 data_batch_2,  Train_loss : 5219.1289  Test_loss : 5473.4658, Time/batch_file : 2.2873, Training time: 17667.8683\n",
      "Epoch : 1524/2000 data_batch_3,  Train_loss : 5309.7017  Test_loss : 4979.8896, Time/batch_file : 2.2753, Training time: 17670.1438\n",
      "Epoch : 1524/2000 data_batch_4,  Train_loss : 5078.0171  Test_loss : 5183.5151, Time/batch_file : 2.3013, Training time: 17672.4454\n",
      "Epoch : 1524/2000 data_batch_5,  Train_loss : 5268.1436  Test_loss : 4855.3330, Time/batch_file : 2.2859, Training time: 17674.7315\n",
      "Epoch : 1525/2000 data_batch_1,  Train_loss : 4734.5601  Test_loss : 5056.2427, Time/batch_file : 2.2663, Training time: 17676.9980\n",
      "Epoch : 1525/2000 data_batch_2,  Train_loss : 5007.9487  Test_loss : 4889.6499, Time/batch_file : 2.2902, Training time: 17679.2884\n",
      "Epoch : 1525/2000 data_batch_3,  Train_loss : 4655.5181  Test_loss : 4924.7354, Time/batch_file : 2.2877, Training time: 17681.5763\n",
      "Epoch : 1525/2000 data_batch_4,  Train_loss : 4738.7529  Test_loss : 4990.0273, Time/batch_file : 2.2869, Training time: 17683.8633\n",
      "Epoch : 1525/2000 data_batch_5,  Train_loss : 4708.9951  Test_loss : 5337.8774, Time/batch_file : 2.2680, Training time: 17686.1315\n",
      "Epoch : 1526/2000 data_batch_1,  Train_loss : 4528.4717  Test_loss : 4765.9761, Time/batch_file : 2.2706, Training time: 17688.4024\n",
      "Epoch : 1526/2000 data_batch_2,  Train_loss : 4747.8242  Test_loss : 4948.4727, Time/batch_file : 2.2862, Training time: 17690.6888\n",
      "Epoch : 1526/2000 data_batch_3,  Train_loss : 4806.5068  Test_loss : 4973.4409, Time/batch_file : 2.2864, Training time: 17692.9754\n",
      "Epoch : 1526/2000 data_batch_4,  Train_loss : 4590.6323  Test_loss : 5025.3721, Time/batch_file : 2.3020, Training time: 17695.2777\n",
      "Epoch : 1526/2000 data_batch_5,  Train_loss : 4686.0537  Test_loss : 4558.9756, Time/batch_file : 2.2901, Training time: 17697.5680\n",
      "Epoch : 1527/2000 data_batch_1,  Train_loss : 4263.4604  Test_loss : 4975.2769, Time/batch_file : 2.2921, Training time: 17699.8603\n",
      "Epoch : 1527/2000 data_batch_2,  Train_loss : 4396.6021  Test_loss : 5095.1152, Time/batch_file : 2.2957, Training time: 17702.1563\n",
      "Epoch : 1527/2000 data_batch_3,  Train_loss : 4369.4385  Test_loss : 5156.4922, Time/batch_file : 2.3005, Training time: 17704.4570\n",
      "Epoch : 1527/2000 data_batch_4,  Train_loss : 4544.4746  Test_loss : 5377.9302, Time/batch_file : 2.3133, Training time: 17706.7705\n",
      "Epoch : 1527/2000 data_batch_5,  Train_loss : 4232.3599  Test_loss : 5276.5967, Time/batch_file : 2.2889, Training time: 17709.0596\n",
      "Epoch : 1528/2000 data_batch_1,  Train_loss : 4740.5044  Test_loss : 4811.4395, Time/batch_file : 2.2771, Training time: 17711.3369\n",
      "Epoch : 1528/2000 data_batch_2,  Train_loss : 4543.6934  Test_loss : 4556.8320, Time/batch_file : 2.2889, Training time: 17713.6261\n",
      "Epoch : 1528/2000 data_batch_3,  Train_loss : 4455.0464  Test_loss : 4730.7690, Time/batch_file : 2.2920, Training time: 17715.9184\n",
      "Epoch : 1528/2000 data_batch_4,  Train_loss : 4348.9351  Test_loss : 4679.0562, Time/batch_file : 2.2930, Training time: 17718.2116\n",
      "Epoch : 1528/2000 data_batch_5,  Train_loss : 4539.4673  Test_loss : 4366.1777, Time/batch_file : 2.3128, Training time: 17720.5245\n",
      "Epoch : 1529/2000 data_batch_1,  Train_loss : 5457.4233  Test_loss : 4966.1821, Time/batch_file : 2.2821, Training time: 17722.8069\n",
      "Epoch : 1529/2000 data_batch_2,  Train_loss : 5713.0840  Test_loss : 5068.3511, Time/batch_file : 2.2957, Training time: 17725.1029\n",
      "Epoch : 1529/2000 data_batch_3,  Train_loss : 5656.6436  Test_loss : 4955.1553, Time/batch_file : 2.3000, Training time: 17727.4032\n",
      "Epoch : 1529/2000 data_batch_4,  Train_loss : 5503.2227  Test_loss : 4458.4004, Time/batch_file : 2.2974, Training time: 17729.7009\n",
      "Epoch : 1529/2000 data_batch_5,  Train_loss : 5417.9980  Test_loss : 4927.9160, Time/batch_file : 2.2761, Training time: 17731.9772\n",
      "Epoch : 1530/2000 data_batch_1,  Train_loss : 5012.3306  Test_loss : 5153.4639, Time/batch_file : 2.2828, Training time: 17734.2603\n",
      "Epoch : 1530/2000 data_batch_2,  Train_loss : 4960.0532  Test_loss : 5553.0820, Time/batch_file : 2.2903, Training time: 17736.5508\n",
      "Epoch : 1530/2000 data_batch_3,  Train_loss : 4963.7861  Test_loss : 5296.8730, Time/batch_file : 2.2867, Training time: 17738.8378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1530/2000 data_batch_4,  Train_loss : 4904.7070  Test_loss : 5150.4697, Time/batch_file : 2.2922, Training time: 17741.1302\n",
      "Epoch : 1530/2000 data_batch_5,  Train_loss : 4684.7471  Test_loss : 5439.7842, Time/batch_file : 2.2708, Training time: 17743.4012\n",
      "[./nets/net-1530.ckpt] SAVED\n",
      "Epoch : 1531/2000 data_batch_1,  Train_loss : 4489.7993  Test_loss : 4462.9849, Time/batch_file : 2.4278, Training time: 17747.0965\n",
      "Epoch : 1531/2000 data_batch_2,  Train_loss : 4695.5078  Test_loss : 4795.4995, Time/batch_file : 2.2890, Training time: 17749.3856\n",
      "Epoch : 1531/2000 data_batch_3,  Train_loss : 4776.9395  Test_loss : 4819.7466, Time/batch_file : 2.2910, Training time: 17751.6768\n",
      "Epoch : 1531/2000 data_batch_4,  Train_loss : 4766.4858  Test_loss : 4582.4995, Time/batch_file : 2.2863, Training time: 17753.9633\n",
      "Epoch : 1531/2000 data_batch_5,  Train_loss : 4543.9800  Test_loss : 4505.7817, Time/batch_file : 2.2962, Training time: 17756.2598\n",
      "Epoch : 1532/2000 data_batch_1,  Train_loss : 4162.4390  Test_loss : 5132.9199, Time/batch_file : 2.2717, Training time: 17758.5316\n",
      "Epoch : 1532/2000 data_batch_2,  Train_loss : 4118.1562  Test_loss : 5432.1494, Time/batch_file : 2.3113, Training time: 17760.8432\n",
      "Epoch : 1532/2000 data_batch_3,  Train_loss : 4184.5479  Test_loss : 5512.1338, Time/batch_file : 2.3021, Training time: 17763.1456\n",
      "Epoch : 1532/2000 data_batch_4,  Train_loss : 4071.3950  Test_loss : 5231.8076, Time/batch_file : 2.2819, Training time: 17765.4276\n",
      "Epoch : 1532/2000 data_batch_5,  Train_loss : 4361.6987  Test_loss : 4992.5635, Time/batch_file : 2.2825, Training time: 17767.7104\n",
      "Epoch : 1533/2000 data_batch_1,  Train_loss : 4905.4121  Test_loss : 5498.4912, Time/batch_file : 2.2993, Training time: 17770.0099\n",
      "Epoch : 1533/2000 data_batch_2,  Train_loss : 5105.8809  Test_loss : 5288.2705, Time/batch_file : 2.2892, Training time: 17772.2993\n",
      "Epoch : 1533/2000 data_batch_3,  Train_loss : 4864.8423  Test_loss : 5380.8730, Time/batch_file : 2.2755, Training time: 17774.5750\n",
      "Epoch : 1533/2000 data_batch_4,  Train_loss : 4934.0537  Test_loss : 5334.3589, Time/batch_file : 2.2922, Training time: 17776.8675\n",
      "Epoch : 1533/2000 data_batch_5,  Train_loss : 4780.2178  Test_loss : 5525.3140, Time/batch_file : 2.2714, Training time: 17779.1390\n",
      "Epoch : 1534/2000 data_batch_1,  Train_loss : 4593.2051  Test_loss : 5188.0786, Time/batch_file : 2.2842, Training time: 17781.4234\n",
      "Epoch : 1534/2000 data_batch_2,  Train_loss : 4554.2305  Test_loss : 5065.7314, Time/batch_file : 2.2837, Training time: 17783.7074\n",
      "Epoch : 1534/2000 data_batch_3,  Train_loss : 4470.6289  Test_loss : 5337.9517, Time/batch_file : 2.3193, Training time: 17786.0268\n",
      "Epoch : 1534/2000 data_batch_4,  Train_loss : 4420.5811  Test_loss : 5370.4067, Time/batch_file : 2.2813, Training time: 17788.3083\n",
      "Epoch : 1534/2000 data_batch_5,  Train_loss : 4692.3223  Test_loss : 5266.4170, Time/batch_file : 2.2938, Training time: 17790.6023\n",
      "Epoch : 1535/2000 data_batch_1,  Train_loss : 4620.5010  Test_loss : 4989.4404, Time/batch_file : 2.2723, Training time: 17792.8748\n",
      "Epoch : 1535/2000 data_batch_2,  Train_loss : 4760.7661  Test_loss : 5055.3198, Time/batch_file : 2.3394, Training time: 17795.2143\n",
      "Epoch : 1535/2000 data_batch_3,  Train_loss : 4721.6401  Test_loss : 5019.1064, Time/batch_file : 2.2905, Training time: 17797.5050\n",
      "Epoch : 1535/2000 data_batch_4,  Train_loss : 4804.3652  Test_loss : 4894.7368, Time/batch_file : 2.2953, Training time: 17799.8005\n",
      "Epoch : 1535/2000 data_batch_5,  Train_loss : 4749.4639  Test_loss : 5019.4834, Time/batch_file : 2.2905, Training time: 17802.0913\n",
      "Epoch : 1536/2000 data_batch_1,  Train_loss : 5002.5469  Test_loss : 4519.1729, Time/batch_file : 2.2669, Training time: 17804.3584\n",
      "Epoch : 1536/2000 data_batch_2,  Train_loss : 4677.4175  Test_loss : 4654.6582, Time/batch_file : 2.2749, Training time: 17806.6335\n",
      "Epoch : 1536/2000 data_batch_3,  Train_loss : 4562.7871  Test_loss : 4560.6768, Time/batch_file : 2.2807, Training time: 17808.9143\n",
      "Epoch : 1536/2000 data_batch_4,  Train_loss : 4545.7241  Test_loss : 4569.3350, Time/batch_file : 2.2683, Training time: 17811.1829\n",
      "Epoch : 1536/2000 data_batch_5,  Train_loss : 4907.5674  Test_loss : 4680.6318, Time/batch_file : 2.3067, Training time: 17813.4898\n",
      "Epoch : 1537/2000 data_batch_1,  Train_loss : 5231.2871  Test_loss : 5259.2109, Time/batch_file : 2.2974, Training time: 17815.7874\n",
      "Epoch : 1537/2000 data_batch_2,  Train_loss : 4847.1924  Test_loss : 4985.8193, Time/batch_file : 2.3089, Training time: 17818.0965\n",
      "Epoch : 1537/2000 data_batch_3,  Train_loss : 4937.6094  Test_loss : 4898.6499, Time/batch_file : 2.2778, Training time: 17820.3745\n",
      "Epoch : 1537/2000 data_batch_4,  Train_loss : 4870.7832  Test_loss : 4757.7280, Time/batch_file : 2.3062, Training time: 17822.6808\n",
      "Epoch : 1537/2000 data_batch_5,  Train_loss : 4848.7539  Test_loss : 4791.2280, Time/batch_file : 2.2798, Training time: 17824.9608\n",
      "Epoch : 1538/2000 data_batch_1,  Train_loss : 4493.6079  Test_loss : 5570.7773, Time/batch_file : 2.2693, Training time: 17827.2303\n",
      "Epoch : 1538/2000 data_batch_2,  Train_loss : 4583.9629  Test_loss : 4952.2451, Time/batch_file : 2.2628, Training time: 17829.4934\n",
      "Epoch : 1538/2000 data_batch_3,  Train_loss : 4689.4019  Test_loss : 5226.6685, Time/batch_file : 2.2775, Training time: 17831.7713\n",
      "Epoch : 1538/2000 data_batch_4,  Train_loss : 4692.0610  Test_loss : 5616.5874, Time/batch_file : 2.2587, Training time: 17834.0302\n",
      "Epoch : 1538/2000 data_batch_5,  Train_loss : 4479.0718  Test_loss : 5185.4194, Time/batch_file : 2.2616, Training time: 17836.2919\n",
      "Epoch : 1539/2000 data_batch_1,  Train_loss : 4870.9453  Test_loss : 5146.8608, Time/batch_file : 2.2782, Training time: 17838.5703\n",
      "Epoch : 1539/2000 data_batch_2,  Train_loss : 4990.3037  Test_loss : 5221.5918, Time/batch_file : 2.3039, Training time: 17840.8744\n",
      "Epoch : 1539/2000 data_batch_3,  Train_loss : 5160.5317  Test_loss : 4979.3525, Time/batch_file : 2.2725, Training time: 17843.1471\n",
      "Epoch : 1539/2000 data_batch_4,  Train_loss : 5013.3760  Test_loss : 5252.3149, Time/batch_file : 2.2851, Training time: 17845.4324\n",
      "Epoch : 1539/2000 data_batch_5,  Train_loss : 4627.1895  Test_loss : 5196.6982, Time/batch_file : 2.2686, Training time: 17847.7011\n",
      "Epoch : 1540/2000 data_batch_1,  Train_loss : 4424.3638  Test_loss : 5417.2573, Time/batch_file : 2.3232, Training time: 17850.0246\n",
      "Epoch : 1540/2000 data_batch_2,  Train_loss : 4454.6870  Test_loss : 5475.3564, Time/batch_file : 2.2733, Training time: 17852.2980\n",
      "Epoch : 1540/2000 data_batch_3,  Train_loss : 4395.1714  Test_loss : 5363.3740, Time/batch_file : 2.2817, Training time: 17854.5800\n",
      "Epoch : 1540/2000 data_batch_4,  Train_loss : 4461.6323  Test_loss : 5305.2842, Time/batch_file : 2.2680, Training time: 17856.8481\n",
      "Epoch : 1540/2000 data_batch_5,  Train_loss : 4368.7061  Test_loss : 5184.0854, Time/batch_file : 2.2773, Training time: 17859.1255\n",
      "[./nets/net-1540.ckpt] SAVED\n",
      "Epoch : 1541/2000 data_batch_1,  Train_loss : 4660.6323  Test_loss : 4770.8799, Time/batch_file : 2.2930, Training time: 17862.6975\n",
      "Epoch : 1541/2000 data_batch_2,  Train_loss : 4772.0293  Test_loss : 4662.6187, Time/batch_file : 2.2627, Training time: 17864.9604\n",
      "Epoch : 1541/2000 data_batch_3,  Train_loss : 4514.3291  Test_loss : 4968.4307, Time/batch_file : 2.2701, Training time: 17867.2307\n",
      "Epoch : 1541/2000 data_batch_4,  Train_loss : 4657.4561  Test_loss : 4540.5762, Time/batch_file : 2.2778, Training time: 17869.5086\n",
      "Epoch : 1541/2000 data_batch_5,  Train_loss : 4700.7495  Test_loss : 4681.1968, Time/batch_file : 2.2829, Training time: 17871.7917\n",
      "Epoch : 1542/2000 data_batch_1,  Train_loss : 4770.8936  Test_loss : 4684.0859, Time/batch_file : 2.2665, Training time: 17874.0585\n",
      "Epoch : 1542/2000 data_batch_2,  Train_loss : 4736.3276  Test_loss : 4686.1992, Time/batch_file : 2.2585, Training time: 17876.3171\n",
      "Epoch : 1542/2000 data_batch_3,  Train_loss : 4619.3936  Test_loss : 4792.4453, Time/batch_file : 2.2566, Training time: 17878.5739\n",
      "Epoch : 1542/2000 data_batch_4,  Train_loss : 4870.9233  Test_loss : 4747.5947, Time/batch_file : 2.2667, Training time: 17880.8408\n",
      "Epoch : 1542/2000 data_batch_5,  Train_loss : 4495.7285  Test_loss : 4750.3618, Time/batch_file : 2.2810, Training time: 17883.1219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1543/2000 data_batch_1,  Train_loss : 4248.8135  Test_loss : 5109.4561, Time/batch_file : 2.2687, Training time: 17885.3908\n",
      "Epoch : 1543/2000 data_batch_2,  Train_loss : 4469.6611  Test_loss : 5319.9639, Time/batch_file : 2.2615, Training time: 17887.6525\n",
      "Epoch : 1543/2000 data_batch_3,  Train_loss : 4204.9663  Test_loss : 4799.9414, Time/batch_file : 2.2896, Training time: 17889.9423\n",
      "Epoch : 1543/2000 data_batch_4,  Train_loss : 4205.4263  Test_loss : 5181.6797, Time/batch_file : 2.2757, Training time: 17892.2183\n",
      "Epoch : 1543/2000 data_batch_5,  Train_loss : 4087.1521  Test_loss : 5037.9404, Time/batch_file : 2.2724, Training time: 17894.4909\n",
      "Epoch : 1544/2000 data_batch_1,  Train_loss : 4931.9590  Test_loss : 5132.9204, Time/batch_file : 2.2678, Training time: 17896.7589\n",
      "Epoch : 1544/2000 data_batch_2,  Train_loss : 4827.1631  Test_loss : 4715.4702, Time/batch_file : 2.2759, Training time: 17899.0351\n",
      "Epoch : 1544/2000 data_batch_3,  Train_loss : 4725.6172  Test_loss : 4854.9087, Time/batch_file : 2.2686, Training time: 17901.3039\n",
      "Epoch : 1544/2000 data_batch_4,  Train_loss : 4892.8613  Test_loss : 5297.6523, Time/batch_file : 2.2688, Training time: 17903.5728\n",
      "Epoch : 1544/2000 data_batch_5,  Train_loss : 4821.9814  Test_loss : 4906.4536, Time/batch_file : 2.2752, Training time: 17905.8482\n",
      "Epoch : 1545/2000 data_batch_1,  Train_loss : 4265.6826  Test_loss : 4575.3809, Time/batch_file : 2.2653, Training time: 17908.1138\n",
      "Epoch : 1545/2000 data_batch_2,  Train_loss : 3939.2295  Test_loss : 4937.8447, Time/batch_file : 2.2600, Training time: 17910.3740\n",
      "Epoch : 1545/2000 data_batch_3,  Train_loss : 4075.6631  Test_loss : 4678.4023, Time/batch_file : 2.2723, Training time: 17912.6465\n",
      "Epoch : 1545/2000 data_batch_4,  Train_loss : 4130.8086  Test_loss : 4652.7002, Time/batch_file : 2.2693, Training time: 17914.9161\n",
      "Epoch : 1545/2000 data_batch_5,  Train_loss : 4184.0635  Test_loss : 4815.5508, Time/batch_file : 2.2666, Training time: 17917.1828\n",
      "Epoch : 1546/2000 data_batch_1,  Train_loss : 4399.3003  Test_loss : 5369.1133, Time/batch_file : 2.2831, Training time: 17919.4662\n",
      "Epoch : 1546/2000 data_batch_2,  Train_loss : 4367.5703  Test_loss : 5006.2373, Time/batch_file : 2.2761, Training time: 17921.7424\n",
      "Epoch : 1546/2000 data_batch_3,  Train_loss : 4358.3901  Test_loss : 4959.6982, Time/batch_file : 2.2828, Training time: 17924.0253\n",
      "Epoch : 1546/2000 data_batch_4,  Train_loss : 4514.9873  Test_loss : 5197.7637, Time/batch_file : 2.2770, Training time: 17926.3024\n",
      "Epoch : 1546/2000 data_batch_5,  Train_loss : 4379.9209  Test_loss : 4801.4668, Time/batch_file : 2.2690, Training time: 17928.5717\n",
      "Epoch : 1547/2000 data_batch_1,  Train_loss : 5079.6113  Test_loss : 4865.1680, Time/batch_file : 2.2959, Training time: 17930.8677\n",
      "Epoch : 1547/2000 data_batch_2,  Train_loss : 5105.4731  Test_loss : 4663.2026, Time/batch_file : 2.2952, Training time: 17933.1631\n",
      "Epoch : 1547/2000 data_batch_3,  Train_loss : 5131.6221  Test_loss : 4661.5127, Time/batch_file : 2.2964, Training time: 17935.4597\n",
      "Epoch : 1547/2000 data_batch_4,  Train_loss : 4934.4014  Test_loss : 4530.6050, Time/batch_file : 2.3141, Training time: 17937.7741\n",
      "Epoch : 1547/2000 data_batch_5,  Train_loss : 5248.6895  Test_loss : 4582.8125, Time/batch_file : 2.3040, Training time: 17940.0782\n",
      "Epoch : 1548/2000 data_batch_1,  Train_loss : 4746.4375  Test_loss : 4615.6099, Time/batch_file : 2.2815, Training time: 17942.3599\n",
      "Epoch : 1548/2000 data_batch_2,  Train_loss : 4560.2085  Test_loss : 4702.0459, Time/batch_file : 2.2851, Training time: 17944.6452\n",
      "Epoch : 1548/2000 data_batch_3,  Train_loss : 4488.3311  Test_loss : 4788.2139, Time/batch_file : 2.2768, Training time: 17946.9223\n",
      "Epoch : 1548/2000 data_batch_4,  Train_loss : 4746.7451  Test_loss : 4696.7866, Time/batch_file : 2.2811, Training time: 17949.2037\n",
      "Epoch : 1548/2000 data_batch_5,  Train_loss : 4546.0127  Test_loss : 4739.1709, Time/batch_file : 2.2814, Training time: 17951.4852\n",
      "Epoch : 1549/2000 data_batch_1,  Train_loss : 4928.8101  Test_loss : 4780.7783, Time/batch_file : 2.2791, Training time: 17953.7645\n",
      "Epoch : 1549/2000 data_batch_2,  Train_loss : 4953.9419  Test_loss : 4996.8867, Time/batch_file : 2.2716, Training time: 17956.0363\n",
      "Epoch : 1549/2000 data_batch_3,  Train_loss : 4694.8120  Test_loss : 5001.2852, Time/batch_file : 2.2743, Training time: 17958.3109\n",
      "Epoch : 1549/2000 data_batch_4,  Train_loss : 4747.4941  Test_loss : 4811.4590, Time/batch_file : 2.2633, Training time: 17960.5743\n",
      "Epoch : 1549/2000 data_batch_5,  Train_loss : 4963.6562  Test_loss : 4671.6055, Time/batch_file : 2.2836, Training time: 17962.8581\n",
      "Epoch : 1550/2000 data_batch_1,  Train_loss : 4510.5039  Test_loss : 4368.9116, Time/batch_file : 2.2619, Training time: 17965.1203\n",
      "Epoch : 1550/2000 data_batch_2,  Train_loss : 4586.9004  Test_loss : 4653.0879, Time/batch_file : 2.2792, Training time: 17967.3997\n",
      "Epoch : 1550/2000 data_batch_3,  Train_loss : 4746.8740  Test_loss : 4472.9561, Time/batch_file : 2.2682, Training time: 17969.6682\n",
      "Epoch : 1550/2000 data_batch_4,  Train_loss : 4567.3208  Test_loss : 4239.1753, Time/batch_file : 2.2733, Training time: 17971.9416\n",
      "Epoch : 1550/2000 data_batch_5,  Train_loss : 4540.6519  Test_loss : 4430.7344, Time/batch_file : 2.2803, Training time: 17974.2222\n",
      "[./nets/net-1550.ckpt] SAVED\n",
      "Epoch : 1551/2000 data_batch_1,  Train_loss : 4391.0596  Test_loss : 5129.8218, Time/batch_file : 2.3413, Training time: 17977.8217\n",
      "Epoch : 1551/2000 data_batch_2,  Train_loss : 4585.7070  Test_loss : 5046.2183, Time/batch_file : 2.2633, Training time: 17980.0852\n",
      "Epoch : 1551/2000 data_batch_3,  Train_loss : 4271.9785  Test_loss : 4767.2588, Time/batch_file : 2.2735, Training time: 17982.3590\n",
      "Epoch : 1551/2000 data_batch_4,  Train_loss : 4183.0576  Test_loss : 4534.8789, Time/batch_file : 2.2837, Training time: 17984.6429\n",
      "Epoch : 1551/2000 data_batch_5,  Train_loss : 4488.0688  Test_loss : 4656.4341, Time/batch_file : 2.2924, Training time: 17986.9355\n",
      "Epoch : 1552/2000 data_batch_1,  Train_loss : 4630.2578  Test_loss : 5227.3291, Time/batch_file : 2.3059, Training time: 17989.2417\n",
      "Epoch : 1552/2000 data_batch_2,  Train_loss : 4546.4678  Test_loss : 5460.2744, Time/batch_file : 2.2560, Training time: 17991.4980\n",
      "Epoch : 1552/2000 data_batch_3,  Train_loss : 4557.1523  Test_loss : 5131.6953, Time/batch_file : 2.2736, Training time: 17993.7719\n",
      "Epoch : 1552/2000 data_batch_4,  Train_loss : 4422.6484  Test_loss : 4706.9541, Time/batch_file : 2.2794, Training time: 17996.0514\n",
      "Epoch : 1552/2000 data_batch_5,  Train_loss : 4567.4580  Test_loss : 5293.7881, Time/batch_file : 2.2815, Training time: 17998.3332\n",
      "Epoch : 1553/2000 data_batch_1,  Train_loss : 4446.6035  Test_loss : 4557.9160, Time/batch_file : 2.2634, Training time: 18000.5969\n",
      "Epoch : 1553/2000 data_batch_2,  Train_loss : 4348.9644  Test_loss : 4546.6318, Time/batch_file : 2.2767, Training time: 18002.8738\n",
      "Epoch : 1553/2000 data_batch_3,  Train_loss : 4226.7842  Test_loss : 4569.1235, Time/batch_file : 2.2847, Training time: 18005.1587\n",
      "Epoch : 1553/2000 data_batch_4,  Train_loss : 4432.4355  Test_loss : 4390.0015, Time/batch_file : 2.2799, Training time: 18007.4388\n",
      "Epoch : 1553/2000 data_batch_5,  Train_loss : 4434.6982  Test_loss : 4601.1689, Time/batch_file : 2.2699, Training time: 18009.7090\n",
      "Epoch : 1554/2000 data_batch_1,  Train_loss : 4463.8677  Test_loss : 4656.1665, Time/batch_file : 2.3086, Training time: 18012.0177\n",
      "Epoch : 1554/2000 data_batch_2,  Train_loss : 4417.6299  Test_loss : 4747.3550, Time/batch_file : 2.2700, Training time: 18014.2880\n",
      "Epoch : 1554/2000 data_batch_3,  Train_loss : 4456.1006  Test_loss : 4860.2144, Time/batch_file : 2.2897, Training time: 18016.5779\n",
      "Epoch : 1554/2000 data_batch_4,  Train_loss : 4093.8381  Test_loss : 4745.9819, Time/batch_file : 2.2628, Training time: 18018.8409\n",
      "Epoch : 1554/2000 data_batch_5,  Train_loss : 4174.0659  Test_loss : 4786.9160, Time/batch_file : 2.2829, Training time: 18021.1240\n",
      "Epoch : 1555/2000 data_batch_1,  Train_loss : 5199.1665  Test_loss : 4566.3306, Time/batch_file : 2.3604, Training time: 18023.4846\n",
      "Epoch : 1555/2000 data_batch_2,  Train_loss : 5045.1660  Test_loss : 4566.6240, Time/batch_file : 2.2906, Training time: 18025.7755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1555/2000 data_batch_3,  Train_loss : 5063.4600  Test_loss : 4348.5430, Time/batch_file : 2.2734, Training time: 18028.0493\n",
      "Epoch : 1555/2000 data_batch_4,  Train_loss : 4838.8550  Test_loss : 4411.8999, Time/batch_file : 2.2716, Training time: 18030.3211\n",
      "Epoch : 1555/2000 data_batch_5,  Train_loss : 5038.3359  Test_loss : 4390.6724, Time/batch_file : 2.2715, Training time: 18032.5927\n",
      "Epoch : 1556/2000 data_batch_1,  Train_loss : 4774.8418  Test_loss : 4582.3462, Time/batch_file : 2.2984, Training time: 18034.8913\n",
      "Epoch : 1556/2000 data_batch_2,  Train_loss : 4748.1333  Test_loss : 4870.3169, Time/batch_file : 2.2641, Training time: 18037.1555\n",
      "Epoch : 1556/2000 data_batch_3,  Train_loss : 5072.2983  Test_loss : 4997.1084, Time/batch_file : 2.2992, Training time: 18039.4549\n",
      "Epoch : 1556/2000 data_batch_4,  Train_loss : 4858.4629  Test_loss : 4701.4282, Time/batch_file : 2.2739, Training time: 18041.7291\n",
      "Epoch : 1556/2000 data_batch_5,  Train_loss : 4480.0098  Test_loss : 4750.9438, Time/batch_file : 2.2874, Training time: 18044.0167\n",
      "Epoch : 1557/2000 data_batch_1,  Train_loss : 4219.6162  Test_loss : 5061.8750, Time/batch_file : 2.2912, Training time: 18046.3081\n",
      "Epoch : 1557/2000 data_batch_2,  Train_loss : 4561.0586  Test_loss : 5109.5034, Time/batch_file : 2.3027, Training time: 18048.6111\n",
      "Epoch : 1557/2000 data_batch_3,  Train_loss : 4816.9648  Test_loss : 5017.8945, Time/batch_file : 2.2800, Training time: 18050.8912\n",
      "Epoch : 1557/2000 data_batch_4,  Train_loss : 4459.5698  Test_loss : 5166.2993, Time/batch_file : 2.2957, Training time: 18053.1871\n",
      "Epoch : 1557/2000 data_batch_5,  Train_loss : 4248.9922  Test_loss : 5431.4814, Time/batch_file : 2.2866, Training time: 18055.4739\n",
      "Epoch : 1558/2000 data_batch_1,  Train_loss : 4740.0698  Test_loss : 5206.4370, Time/batch_file : 2.3141, Training time: 18057.7882\n",
      "Epoch : 1558/2000 data_batch_2,  Train_loss : 4925.3149  Test_loss : 5623.5225, Time/batch_file : 2.2576, Training time: 18060.0460\n",
      "Epoch : 1558/2000 data_batch_3,  Train_loss : 4592.6255  Test_loss : 5487.9185, Time/batch_file : 2.2914, Training time: 18062.3376\n",
      "Epoch : 1558/2000 data_batch_4,  Train_loss : 4627.8481  Test_loss : 5174.5615, Time/batch_file : 2.2691, Training time: 18064.6068\n",
      "Epoch : 1558/2000 data_batch_5,  Train_loss : 5065.3311  Test_loss : 5261.9985, Time/batch_file : 2.2823, Training time: 18066.8894\n",
      "Epoch : 1559/2000 data_batch_1,  Train_loss : 4895.7554  Test_loss : 4945.7148, Time/batch_file : 2.2715, Training time: 18069.1612\n",
      "Epoch : 1559/2000 data_batch_2,  Train_loss : 4944.2607  Test_loss : 4768.9707, Time/batch_file : 2.2805, Training time: 18071.4419\n",
      "Epoch : 1559/2000 data_batch_3,  Train_loss : 4991.9351  Test_loss : 4992.2031, Time/batch_file : 2.2715, Training time: 18073.7136\n",
      "Epoch : 1559/2000 data_batch_4,  Train_loss : 4899.5581  Test_loss : 4952.0098, Time/batch_file : 2.2825, Training time: 18075.9962\n",
      "Epoch : 1559/2000 data_batch_5,  Train_loss : 4873.8745  Test_loss : 4967.2070, Time/batch_file : 2.2744, Training time: 18078.2709\n",
      "Epoch : 1560/2000 data_batch_1,  Train_loss : 4635.5039  Test_loss : 4865.0557, Time/batch_file : 2.2919, Training time: 18080.5629\n",
      "Epoch : 1560/2000 data_batch_2,  Train_loss : 5021.2842  Test_loss : 4554.1162, Time/batch_file : 2.2563, Training time: 18082.8195\n",
      "Epoch : 1560/2000 data_batch_3,  Train_loss : 4807.0405  Test_loss : 4643.7856, Time/batch_file : 2.2768, Training time: 18085.0965\n",
      "Epoch : 1560/2000 data_batch_4,  Train_loss : 4955.6680  Test_loss : 4586.8164, Time/batch_file : 2.2487, Training time: 18087.3454\n",
      "Epoch : 1560/2000 data_batch_5,  Train_loss : 4799.3486  Test_loss : 4742.6689, Time/batch_file : 2.2672, Training time: 18089.6127\n",
      "[./nets/net-1560.ckpt] SAVED\n",
      "Epoch : 1561/2000 data_batch_1,  Train_loss : 4867.2905  Test_loss : 4953.6284, Time/batch_file : 2.3325, Training time: 18093.2386\n",
      "Epoch : 1561/2000 data_batch_2,  Train_loss : 4737.0068  Test_loss : 4982.6899, Time/batch_file : 2.2487, Training time: 18095.4875\n",
      "Epoch : 1561/2000 data_batch_3,  Train_loss : 4735.9297  Test_loss : 4716.8784, Time/batch_file : 2.2581, Training time: 18097.7458\n",
      "Epoch : 1561/2000 data_batch_4,  Train_loss : 4592.0938  Test_loss : 4850.2832, Time/batch_file : 2.2560, Training time: 18100.0020\n",
      "Epoch : 1561/2000 data_batch_5,  Train_loss : 4572.2188  Test_loss : 4957.0142, Time/batch_file : 2.2514, Training time: 18102.2537\n",
      "Epoch : 1562/2000 data_batch_1,  Train_loss : 4879.4165  Test_loss : 4844.5806, Time/batch_file : 2.2948, Training time: 18104.5488\n",
      "Epoch : 1562/2000 data_batch_2,  Train_loss : 4563.3994  Test_loss : 4968.7383, Time/batch_file : 2.2653, Training time: 18106.8143\n",
      "Epoch : 1562/2000 data_batch_3,  Train_loss : 4989.0630  Test_loss : 4980.8555, Time/batch_file : 2.2873, Training time: 18109.1017\n",
      "Epoch : 1562/2000 data_batch_4,  Train_loss : 4549.6533  Test_loss : 5008.6328, Time/batch_file : 2.2672, Training time: 18111.3692\n",
      "Epoch : 1562/2000 data_batch_5,  Train_loss : 4663.3462  Test_loss : 4974.3857, Time/batch_file : 2.2703, Training time: 18113.6396\n",
      "Epoch : 1563/2000 data_batch_1,  Train_loss : 4262.0254  Test_loss : 4429.1421, Time/batch_file : 2.2747, Training time: 18115.9146\n",
      "Epoch : 1563/2000 data_batch_2,  Train_loss : 4396.5635  Test_loss : 4648.4810, Time/batch_file : 2.2640, Training time: 18118.1787\n",
      "Epoch : 1563/2000 data_batch_3,  Train_loss : 4494.1719  Test_loss : 4705.2339, Time/batch_file : 2.2590, Training time: 18120.4379\n",
      "Epoch : 1563/2000 data_batch_4,  Train_loss : 4479.7627  Test_loss : 4587.7480, Time/batch_file : 2.2551, Training time: 18122.6932\n",
      "Epoch : 1563/2000 data_batch_5,  Train_loss : 4337.3633  Test_loss : 4436.4873, Time/batch_file : 2.2583, Training time: 18124.9517\n",
      "Epoch : 1564/2000 data_batch_1,  Train_loss : 4853.8545  Test_loss : 4986.7959, Time/batch_file : 2.2767, Training time: 18127.2286\n",
      "Epoch : 1564/2000 data_batch_2,  Train_loss : 4881.7842  Test_loss : 5483.2930, Time/batch_file : 2.2761, Training time: 18129.5049\n",
      "Epoch : 1564/2000 data_batch_3,  Train_loss : 4744.7109  Test_loss : 5185.3140, Time/batch_file : 2.2768, Training time: 18131.7819\n",
      "Epoch : 1564/2000 data_batch_4,  Train_loss : 4627.6992  Test_loss : 5030.9575, Time/batch_file : 2.2761, Training time: 18134.0583\n",
      "Epoch : 1564/2000 data_batch_5,  Train_loss : 4850.8198  Test_loss : 4970.8486, Time/batch_file : 2.2768, Training time: 18136.3352\n",
      "Epoch : 1565/2000 data_batch_1,  Train_loss : 4524.4502  Test_loss : 5358.0732, Time/batch_file : 2.2650, Training time: 18138.6005\n",
      "Epoch : 1565/2000 data_batch_2,  Train_loss : 4564.7983  Test_loss : 5338.7480, Time/batch_file : 2.2799, Training time: 18140.8805\n",
      "Epoch : 1565/2000 data_batch_3,  Train_loss : 4550.0591  Test_loss : 5434.7314, Time/batch_file : 2.2587, Training time: 18143.1393\n",
      "Epoch : 1565/2000 data_batch_4,  Train_loss : 4462.9932  Test_loss : 5312.5894, Time/batch_file : 2.2667, Training time: 18145.4063\n",
      "Epoch : 1565/2000 data_batch_5,  Train_loss : 4335.7554  Test_loss : 5347.8457, Time/batch_file : 2.2652, Training time: 18147.6717\n",
      "Epoch : 1566/2000 data_batch_1,  Train_loss : 4502.5225  Test_loss : 5117.2529, Time/batch_file : 2.2709, Training time: 18149.9428\n",
      "Epoch : 1566/2000 data_batch_2,  Train_loss : 4583.3994  Test_loss : 4969.5400, Time/batch_file : 2.2463, Training time: 18152.1893\n",
      "Epoch : 1566/2000 data_batch_3,  Train_loss : 4490.9546  Test_loss : 4914.3721, Time/batch_file : 2.2678, Training time: 18154.4573\n",
      "Epoch : 1566/2000 data_batch_4,  Train_loss : 4340.7271  Test_loss : 5120.7017, Time/batch_file : 2.2705, Training time: 18156.7280\n",
      "Epoch : 1566/2000 data_batch_5,  Train_loss : 4422.1626  Test_loss : 5147.2764, Time/batch_file : 2.2695, Training time: 18158.9976\n",
      "Epoch : 1567/2000 data_batch_1,  Train_loss : 5127.1035  Test_loss : 5314.8926, Time/batch_file : 2.2546, Training time: 18161.2524\n",
      "Epoch : 1567/2000 data_batch_2,  Train_loss : 5340.7485  Test_loss : 5193.2993, Time/batch_file : 2.2599, Training time: 18163.5124\n",
      "Epoch : 1567/2000 data_batch_3,  Train_loss : 5246.8574  Test_loss : 5147.0264, Time/batch_file : 2.2731, Training time: 18165.7858\n",
      "Epoch : 1567/2000 data_batch_4,  Train_loss : 5196.2075  Test_loss : 5189.0449, Time/batch_file : 2.2657, Training time: 18168.0517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1567/2000 data_batch_5,  Train_loss : 5142.8594  Test_loss : 5097.5713, Time/batch_file : 2.2623, Training time: 18170.3142\n",
      "Epoch : 1568/2000 data_batch_1,  Train_loss : 5135.8340  Test_loss : 5052.9604, Time/batch_file : 2.2653, Training time: 18172.5798\n",
      "Epoch : 1568/2000 data_batch_2,  Train_loss : 5334.6475  Test_loss : 4945.1035, Time/batch_file : 2.2592, Training time: 18174.8393\n",
      "Epoch : 1568/2000 data_batch_3,  Train_loss : 4992.2666  Test_loss : 5119.6304, Time/batch_file : 2.2677, Training time: 18177.1073\n",
      "Epoch : 1568/2000 data_batch_4,  Train_loss : 4977.1758  Test_loss : 4931.3013, Time/batch_file : 2.2819, Training time: 18179.3893\n",
      "Epoch : 1568/2000 data_batch_5,  Train_loss : 4891.3872  Test_loss : 5082.1938, Time/batch_file : 2.2566, Training time: 18181.6461\n",
      "Epoch : 1569/2000 data_batch_1,  Train_loss : 4841.7607  Test_loss : 4920.4507, Time/batch_file : 2.2729, Training time: 18183.9191\n",
      "Epoch : 1569/2000 data_batch_2,  Train_loss : 4797.1836  Test_loss : 5029.7256, Time/batch_file : 2.2818, Training time: 18186.2011\n",
      "Epoch : 1569/2000 data_batch_3,  Train_loss : 5055.2236  Test_loss : 4978.6270, Time/batch_file : 2.2581, Training time: 18188.4594\n",
      "Epoch : 1569/2000 data_batch_4,  Train_loss : 4703.9390  Test_loss : 5045.0396, Time/batch_file : 2.2693, Training time: 18190.7289\n",
      "Epoch : 1569/2000 data_batch_5,  Train_loss : 4816.7256  Test_loss : 4863.8110, Time/batch_file : 2.2704, Training time: 18192.9995\n",
      "Epoch : 1570/2000 data_batch_1,  Train_loss : 4666.2974  Test_loss : 4667.4331, Time/batch_file : 2.2610, Training time: 18195.2607\n",
      "Epoch : 1570/2000 data_batch_2,  Train_loss : 4772.7432  Test_loss : 4771.1362, Time/batch_file : 2.2438, Training time: 18197.5048\n",
      "Epoch : 1570/2000 data_batch_3,  Train_loss : 4419.0952  Test_loss : 4683.8022, Time/batch_file : 2.2623, Training time: 18199.7673\n",
      "Epoch : 1570/2000 data_batch_4,  Train_loss : 4723.3633  Test_loss : 4886.7139, Time/batch_file : 2.2497, Training time: 18202.0171\n",
      "Epoch : 1570/2000 data_batch_5,  Train_loss : 4920.3799  Test_loss : 4447.4487, Time/batch_file : 2.2544, Training time: 18204.2718\n",
      "[./nets/net-1570.ckpt] SAVED\n",
      "Epoch : 1571/2000 data_batch_1,  Train_loss : 4035.6721  Test_loss : 5057.9424, Time/batch_file : 2.3090, Training time: 18207.8826\n",
      "Epoch : 1571/2000 data_batch_2,  Train_loss : 4301.8662  Test_loss : 4977.0752, Time/batch_file : 2.2891, Training time: 18210.1719\n",
      "Epoch : 1571/2000 data_batch_3,  Train_loss : 4261.4951  Test_loss : 4741.2764, Time/batch_file : 2.2805, Training time: 18212.4527\n",
      "Epoch : 1571/2000 data_batch_4,  Train_loss : 4156.5942  Test_loss : 4981.8145, Time/batch_file : 2.2844, Training time: 18214.7373\n",
      "Epoch : 1571/2000 data_batch_5,  Train_loss : 4043.2471  Test_loss : 4810.7842, Time/batch_file : 2.2877, Training time: 18217.0252\n",
      "Epoch : 1572/2000 data_batch_1,  Train_loss : 4849.8789  Test_loss : 5123.5811, Time/batch_file : 2.2789, Training time: 18219.3042\n",
      "Epoch : 1572/2000 data_batch_2,  Train_loss : 4625.7993  Test_loss : 4699.4678, Time/batch_file : 2.2761, Training time: 18221.5805\n",
      "Epoch : 1572/2000 data_batch_3,  Train_loss : 4660.2925  Test_loss : 5057.5171, Time/batch_file : 2.2748, Training time: 18223.8556\n",
      "Epoch : 1572/2000 data_batch_4,  Train_loss : 4445.1787  Test_loss : 5331.4756, Time/batch_file : 2.2866, Training time: 18226.1424\n",
      "Epoch : 1572/2000 data_batch_5,  Train_loss : 4771.9521  Test_loss : 4880.6841, Time/batch_file : 2.2789, Training time: 18228.4215\n",
      "Epoch : 1573/2000 data_batch_1,  Train_loss : 4285.6177  Test_loss : 5533.4150, Time/batch_file : 2.2991, Training time: 18230.7208\n",
      "Epoch : 1573/2000 data_batch_2,  Train_loss : 4144.8418  Test_loss : 5439.3496, Time/batch_file : 2.2821, Training time: 18233.0031\n",
      "Epoch : 1573/2000 data_batch_3,  Train_loss : 4217.3286  Test_loss : 5176.4565, Time/batch_file : 2.2829, Training time: 18235.2862\n",
      "Epoch : 1573/2000 data_batch_4,  Train_loss : 4309.9111  Test_loss : 5300.2539, Time/batch_file : 2.2782, Training time: 18237.5647\n",
      "Epoch : 1573/2000 data_batch_5,  Train_loss : 4214.7090  Test_loss : 5150.2417, Time/batch_file : 2.2791, Training time: 18239.8441\n",
      "Epoch : 1574/2000 data_batch_1,  Train_loss : 4853.4468  Test_loss : 5104.6670, Time/batch_file : 2.2711, Training time: 18242.1153\n",
      "Epoch : 1574/2000 data_batch_2,  Train_loss : 4787.5259  Test_loss : 4753.0239, Time/batch_file : 2.2693, Training time: 18244.3849\n",
      "Epoch : 1574/2000 data_batch_3,  Train_loss : 4874.9390  Test_loss : 4899.7188, Time/batch_file : 2.2677, Training time: 18246.6528\n",
      "Epoch : 1574/2000 data_batch_4,  Train_loss : 4929.4585  Test_loss : 5215.0054, Time/batch_file : 2.2712, Training time: 18248.9242\n",
      "Epoch : 1574/2000 data_batch_5,  Train_loss : 4828.8320  Test_loss : 4781.0166, Time/batch_file : 2.2681, Training time: 18251.1925\n",
      "Epoch : 1575/2000 data_batch_1,  Train_loss : 5108.5879  Test_loss : 4790.0459, Time/batch_file : 2.2726, Training time: 18253.4652\n",
      "Epoch : 1575/2000 data_batch_2,  Train_loss : 5099.1787  Test_loss : 4671.1025, Time/batch_file : 2.2652, Training time: 18255.7306\n",
      "Epoch : 1575/2000 data_batch_3,  Train_loss : 5121.9609  Test_loss : 4676.1685, Time/batch_file : 2.2742, Training time: 18258.0051\n",
      "Epoch : 1575/2000 data_batch_4,  Train_loss : 5064.0293  Test_loss : 5015.6724, Time/batch_file : 2.2549, Training time: 18260.2602\n",
      "Epoch : 1575/2000 data_batch_5,  Train_loss : 5013.7876  Test_loss : 5052.9985, Time/batch_file : 2.2608, Training time: 18262.5211\n",
      "Epoch : 1576/2000 data_batch_1,  Train_loss : 4262.4077  Test_loss : 4888.7778, Time/batch_file : 2.2757, Training time: 18264.7971\n",
      "Epoch : 1576/2000 data_batch_2,  Train_loss : 4275.0923  Test_loss : 4915.7236, Time/batch_file : 2.2747, Training time: 18267.0720\n",
      "Epoch : 1576/2000 data_batch_3,  Train_loss : 4501.5312  Test_loss : 4957.6094, Time/batch_file : 2.2780, Training time: 18269.3501\n",
      "Epoch : 1576/2000 data_batch_4,  Train_loss : 4437.6660  Test_loss : 4972.6963, Time/batch_file : 2.2760, Training time: 18271.6263\n",
      "Epoch : 1576/2000 data_batch_5,  Train_loss : 4308.2861  Test_loss : 4957.3105, Time/batch_file : 2.2792, Training time: 18273.9057\n",
      "Epoch : 1577/2000 data_batch_1,  Train_loss : 4691.7812  Test_loss : 5250.0234, Time/batch_file : 2.2760, Training time: 18276.1820\n",
      "Epoch : 1577/2000 data_batch_2,  Train_loss : 4622.2007  Test_loss : 4834.3115, Time/batch_file : 2.2716, Training time: 18278.4538\n",
      "Epoch : 1577/2000 data_batch_3,  Train_loss : 4511.0830  Test_loss : 4893.3843, Time/batch_file : 2.2839, Training time: 18280.7378\n",
      "Epoch : 1577/2000 data_batch_4,  Train_loss : 4409.1191  Test_loss : 5216.3945, Time/batch_file : 2.2645, Training time: 18283.0024\n",
      "Epoch : 1577/2000 data_batch_5,  Train_loss : 4562.1499  Test_loss : 4932.6885, Time/batch_file : 2.2779, Training time: 18285.2805\n",
      "Epoch : 1578/2000 data_batch_1,  Train_loss : 4786.7378  Test_loss : 4814.5029, Time/batch_file : 2.2737, Training time: 18287.5544\n",
      "Epoch : 1578/2000 data_batch_2,  Train_loss : 4907.1567  Test_loss : 4719.9106, Time/batch_file : 2.2884, Training time: 18289.8430\n",
      "Epoch : 1578/2000 data_batch_3,  Train_loss : 4947.8633  Test_loss : 4677.3018, Time/batch_file : 2.2748, Training time: 18292.1181\n",
      "Epoch : 1578/2000 data_batch_4,  Train_loss : 4823.9092  Test_loss : 4666.2793, Time/batch_file : 2.2808, Training time: 18294.3990\n",
      "Epoch : 1578/2000 data_batch_5,  Train_loss : 4797.9111  Test_loss : 4640.7021, Time/batch_file : 2.2805, Training time: 18296.6798\n",
      "Epoch : 1579/2000 data_batch_1,  Train_loss : 4701.6738  Test_loss : 4999.6523, Time/batch_file : 2.2931, Training time: 18298.9730\n",
      "Epoch : 1579/2000 data_batch_2,  Train_loss : 4580.8062  Test_loss : 5578.0220, Time/batch_file : 2.2772, Training time: 18301.2505\n",
      "Epoch : 1579/2000 data_batch_3,  Train_loss : 4606.1079  Test_loss : 4720.3643, Time/batch_file : 2.2782, Training time: 18303.5287\n",
      "Epoch : 1579/2000 data_batch_4,  Train_loss : 4639.9639  Test_loss : 5068.5996, Time/batch_file : 2.2777, Training time: 18305.8066\n",
      "Epoch : 1579/2000 data_batch_5,  Train_loss : 4560.9170  Test_loss : 5207.6377, Time/batch_file : 2.2855, Training time: 18308.0924\n",
      "Epoch : 1580/2000 data_batch_1,  Train_loss : 5283.3735  Test_loss : 4742.4326, Time/batch_file : 2.2865, Training time: 18310.3791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1580/2000 data_batch_2,  Train_loss : 5178.8755  Test_loss : 4328.8975, Time/batch_file : 2.2824, Training time: 18312.6618\n",
      "Epoch : 1580/2000 data_batch_3,  Train_loss : 5232.9814  Test_loss : 4510.4014, Time/batch_file : 2.2765, Training time: 18314.9387\n",
      "Epoch : 1580/2000 data_batch_4,  Train_loss : 5129.5264  Test_loss : 4760.9482, Time/batch_file : 2.2806, Training time: 18317.2194\n",
      "Epoch : 1580/2000 data_batch_5,  Train_loss : 5017.2646  Test_loss : 4244.2056, Time/batch_file : 2.2817, Training time: 18319.5012\n",
      "[./nets/net-1580.ckpt] SAVED\n",
      "Epoch : 1581/2000 data_batch_1,  Train_loss : 4527.3823  Test_loss : 5140.6963, Time/batch_file : 3.7375, Training time: 18324.5582\n",
      "Epoch : 1581/2000 data_batch_2,  Train_loss : 4468.0459  Test_loss : 4933.2012, Time/batch_file : 2.2594, Training time: 18326.8177\n",
      "Epoch : 1581/2000 data_batch_3,  Train_loss : 4375.0942  Test_loss : 5088.9712, Time/batch_file : 2.2457, Training time: 18329.0636\n",
      "Epoch : 1581/2000 data_batch_4,  Train_loss : 4575.8047  Test_loss : 4794.9800, Time/batch_file : 2.2527, Training time: 18331.3165\n",
      "Epoch : 1581/2000 data_batch_5,  Train_loss : 4551.1895  Test_loss : 4837.5957, Time/batch_file : 2.2424, Training time: 18333.5590\n",
      "Epoch : 1582/2000 data_batch_1,  Train_loss : 4430.4810  Test_loss : 4832.7896, Time/batch_file : 2.2688, Training time: 18335.8281\n",
      "Epoch : 1582/2000 data_batch_2,  Train_loss : 4703.4326  Test_loss : 4717.3887, Time/batch_file : 2.2516, Training time: 18338.0799\n",
      "Epoch : 1582/2000 data_batch_3,  Train_loss : 4644.5000  Test_loss : 4866.3735, Time/batch_file : 2.2624, Training time: 18340.3425\n",
      "Epoch : 1582/2000 data_batch_4,  Train_loss : 4869.0391  Test_loss : 4807.6777, Time/batch_file : 2.2576, Training time: 18342.6003\n",
      "Epoch : 1582/2000 data_batch_5,  Train_loss : 4546.5830  Test_loss : 4807.4038, Time/batch_file : 2.2789, Training time: 18344.8794\n",
      "Epoch : 1583/2000 data_batch_1,  Train_loss : 4925.6562  Test_loss : 4767.0742, Time/batch_file : 2.2523, Training time: 18347.1319\n",
      "Epoch : 1583/2000 data_batch_2,  Train_loss : 4952.8955  Test_loss : 4817.6025, Time/batch_file : 2.2619, Training time: 18349.3941\n",
      "Epoch : 1583/2000 data_batch_3,  Train_loss : 4787.9492  Test_loss : 4847.1802, Time/batch_file : 2.2636, Training time: 18351.6579\n",
      "Epoch : 1583/2000 data_batch_4,  Train_loss : 4977.8193  Test_loss : 4908.6172, Time/batch_file : 2.2603, Training time: 18353.9184\n",
      "Epoch : 1583/2000 data_batch_5,  Train_loss : 4956.0088  Test_loss : 4958.4043, Time/batch_file : 2.2604, Training time: 18356.1790\n",
      "Epoch : 1584/2000 data_batch_1,  Train_loss : 4303.4683  Test_loss : 4904.2393, Time/batch_file : 2.2616, Training time: 18358.4408\n",
      "Epoch : 1584/2000 data_batch_2,  Train_loss : 4317.9536  Test_loss : 4640.4541, Time/batch_file : 2.2595, Training time: 18360.7005\n",
      "Epoch : 1584/2000 data_batch_3,  Train_loss : 4462.1865  Test_loss : 4878.0532, Time/batch_file : 2.2628, Training time: 18362.9634\n",
      "Epoch : 1584/2000 data_batch_4,  Train_loss : 4417.8789  Test_loss : 4740.2725, Time/batch_file : 2.2540, Training time: 18365.2176\n",
      "Epoch : 1584/2000 data_batch_5,  Train_loss : 4225.6787  Test_loss : 4791.5684, Time/batch_file : 2.2605, Training time: 18367.4783\n",
      "Epoch : 1585/2000 data_batch_1,  Train_loss : 4423.1494  Test_loss : 5432.1328, Time/batch_file : 2.2675, Training time: 18369.7461\n",
      "Epoch : 1585/2000 data_batch_2,  Train_loss : 4571.4561  Test_loss : 5282.2407, Time/batch_file : 2.2635, Training time: 18372.0097\n",
      "Epoch : 1585/2000 data_batch_3,  Train_loss : 4416.5283  Test_loss : 5156.5684, Time/batch_file : 2.2641, Training time: 18374.2741\n",
      "Epoch : 1585/2000 data_batch_4,  Train_loss : 4692.7222  Test_loss : 5231.9302, Time/batch_file : 2.2630, Training time: 18376.5372\n",
      "Epoch : 1585/2000 data_batch_5,  Train_loss : 4794.3096  Test_loss : 5188.7852, Time/batch_file : 2.2596, Training time: 18378.7971\n",
      "Epoch : 1586/2000 data_batch_1,  Train_loss : 4426.0586  Test_loss : 5346.0210, Time/batch_file : 2.2703, Training time: 18381.0676\n",
      "Epoch : 1586/2000 data_batch_2,  Train_loss : 4316.4634  Test_loss : 5043.1338, Time/batch_file : 2.2680, Training time: 18383.3357\n",
      "Epoch : 1586/2000 data_batch_3,  Train_loss : 4368.9873  Test_loss : 5263.5049, Time/batch_file : 2.2656, Training time: 18385.6015\n",
      "Epoch : 1586/2000 data_batch_4,  Train_loss : 4402.1724  Test_loss : 5242.1738, Time/batch_file : 2.2709, Training time: 18387.8726\n",
      "Epoch : 1586/2000 data_batch_5,  Train_loss : 4381.4971  Test_loss : 5050.8193, Time/batch_file : 2.2750, Training time: 18390.1477\n",
      "Epoch : 1587/2000 data_batch_1,  Train_loss : 4532.5127  Test_loss : 4907.1021, Time/batch_file : 2.2466, Training time: 18392.3945\n",
      "Epoch : 1587/2000 data_batch_2,  Train_loss : 4634.5249  Test_loss : 4640.1060, Time/batch_file : 2.2609, Training time: 18394.6556\n",
      "Epoch : 1587/2000 data_batch_3,  Train_loss : 4700.1338  Test_loss : 4636.1890, Time/batch_file : 2.2556, Training time: 18396.9114\n",
      "Epoch : 1587/2000 data_batch_4,  Train_loss : 4729.0435  Test_loss : 4943.6064, Time/batch_file : 2.2630, Training time: 18399.1747\n",
      "Epoch : 1587/2000 data_batch_5,  Train_loss : 4694.4785  Test_loss : 5032.4893, Time/batch_file : 2.2411, Training time: 18401.4159\n",
      "Epoch : 1588/2000 data_batch_1,  Train_loss : 4556.4678  Test_loss : 4892.5264, Time/batch_file : 2.2664, Training time: 18403.6825\n",
      "Epoch : 1588/2000 data_batch_2,  Train_loss : 4556.3862  Test_loss : 5071.0918, Time/batch_file : 2.2622, Training time: 18405.9449\n",
      "Epoch : 1588/2000 data_batch_3,  Train_loss : 4394.5000  Test_loss : 4941.1104, Time/batch_file : 2.2702, Training time: 18408.2153\n",
      "Epoch : 1588/2000 data_batch_4,  Train_loss : 4461.4980  Test_loss : 5076.3105, Time/batch_file : 2.2562, Training time: 18410.4716\n",
      "Epoch : 1588/2000 data_batch_5,  Train_loss : 4345.9473  Test_loss : 5073.0962, Time/batch_file : 2.2689, Training time: 18412.7408\n",
      "Epoch : 1589/2000 data_batch_1,  Train_loss : 4702.3613  Test_loss : 5089.5869, Time/batch_file : 2.2807, Training time: 18415.0217\n",
      "Epoch : 1589/2000 data_batch_2,  Train_loss : 4728.3394  Test_loss : 4897.2788, Time/batch_file : 2.2778, Training time: 18417.2996\n",
      "Epoch : 1589/2000 data_batch_3,  Train_loss : 4733.8936  Test_loss : 5044.0493, Time/batch_file : 2.3013, Training time: 18419.6011\n",
      "Epoch : 1589/2000 data_batch_4,  Train_loss : 4694.3320  Test_loss : 5148.9385, Time/batch_file : 2.2783, Training time: 18421.8796\n",
      "Epoch : 1589/2000 data_batch_5,  Train_loss : 4667.9658  Test_loss : 5397.8662, Time/batch_file : 2.2844, Training time: 18424.1642\n",
      "Epoch : 1590/2000 data_batch_1,  Train_loss : 4631.8379  Test_loss : 4651.3423, Time/batch_file : 2.2666, Training time: 18426.4309\n",
      "Epoch : 1590/2000 data_batch_2,  Train_loss : 4862.6689  Test_loss : 4523.8359, Time/batch_file : 2.2634, Training time: 18428.6946\n",
      "Epoch : 1590/2000 data_batch_3,  Train_loss : 4852.1118  Test_loss : 4836.9702, Time/batch_file : 2.2745, Training time: 18430.9692\n",
      "Epoch : 1590/2000 data_batch_4,  Train_loss : 4922.6924  Test_loss : 4896.4971, Time/batch_file : 2.2592, Training time: 18433.2286\n",
      "Epoch : 1590/2000 data_batch_5,  Train_loss : 4859.7256  Test_loss : 4819.9360, Time/batch_file : 2.2653, Training time: 18435.4941\n",
      "[./nets/net-1590.ckpt] SAVED\n",
      "Epoch : 1591/2000 data_batch_1,  Train_loss : 4663.5410  Test_loss : 4836.4268, Time/batch_file : 2.2888, Training time: 18439.0732\n",
      "Epoch : 1591/2000 data_batch_2,  Train_loss : 4607.0532  Test_loss : 4947.6367, Time/batch_file : 2.2813, Training time: 18441.3548\n",
      "Epoch : 1591/2000 data_batch_3,  Train_loss : 4389.9058  Test_loss : 4979.9580, Time/batch_file : 2.3146, Training time: 18443.6695\n",
      "Epoch : 1591/2000 data_batch_4,  Train_loss : 4537.7485  Test_loss : 4897.1987, Time/batch_file : 2.2798, Training time: 18445.9495\n",
      "Epoch : 1591/2000 data_batch_5,  Train_loss : 4436.8975  Test_loss : 5046.4766, Time/batch_file : 2.2953, Training time: 18448.2450\n",
      "Epoch : 1592/2000 data_batch_1,  Train_loss : 4762.1333  Test_loss : 4501.5610, Time/batch_file : 2.2893, Training time: 18450.5344\n",
      "Epoch : 1592/2000 data_batch_2,  Train_loss : 4498.1699  Test_loss : 4433.6270, Time/batch_file : 2.3241, Training time: 18452.8587\n",
      "Epoch : 1592/2000 data_batch_3,  Train_loss : 4844.5337  Test_loss : 4626.3823, Time/batch_file : 2.2845, Training time: 18455.1434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1592/2000 data_batch_4,  Train_loss : 4749.5444  Test_loss : 4392.0000, Time/batch_file : 2.2984, Training time: 18457.4420\n",
      "Epoch : 1592/2000 data_batch_5,  Train_loss : 4822.5259  Test_loss : 4237.2690, Time/batch_file : 2.2734, Training time: 18459.7155\n",
      "Epoch : 1593/2000 data_batch_1,  Train_loss : 4410.5215  Test_loss : 4899.9170, Time/batch_file : 2.2869, Training time: 18462.0026\n",
      "Epoch : 1593/2000 data_batch_2,  Train_loss : 4330.6128  Test_loss : 4942.3193, Time/batch_file : 2.2649, Training time: 18464.2677\n",
      "Epoch : 1593/2000 data_batch_3,  Train_loss : 4495.1211  Test_loss : 5074.9541, Time/batch_file : 2.2836, Training time: 18466.5514\n",
      "Epoch : 1593/2000 data_batch_4,  Train_loss : 4452.3887  Test_loss : 4614.9395, Time/batch_file : 2.2733, Training time: 18468.8249\n",
      "Epoch : 1593/2000 data_batch_5,  Train_loss : 4453.2100  Test_loss : 4637.1929, Time/batch_file : 2.3135, Training time: 18471.1385\n",
      "Epoch : 1594/2000 data_batch_1,  Train_loss : 4390.6621  Test_loss : 4764.4902, Time/batch_file : 2.2571, Training time: 18473.3959\n",
      "Epoch : 1594/2000 data_batch_2,  Train_loss : 4497.5415  Test_loss : 4461.2983, Time/batch_file : 2.2923, Training time: 18475.6884\n",
      "Epoch : 1594/2000 data_batch_3,  Train_loss : 4338.8711  Test_loss : 4916.0312, Time/batch_file : 2.2620, Training time: 18477.9506\n",
      "Epoch : 1594/2000 data_batch_4,  Train_loss : 4351.7866  Test_loss : 4550.8564, Time/batch_file : 2.2938, Training time: 18480.2446\n",
      "Epoch : 1594/2000 data_batch_5,  Train_loss : 4440.5352  Test_loss : 4657.0288, Time/batch_file : 2.2592, Training time: 18482.5041\n",
      "Epoch : 1595/2000 data_batch_1,  Train_loss : 5072.0176  Test_loss : 4688.6050, Time/batch_file : 2.3065, Training time: 18484.8108\n",
      "Epoch : 1595/2000 data_batch_2,  Train_loss : 5019.1689  Test_loss : 4768.6133, Time/batch_file : 2.2672, Training time: 18487.0783\n",
      "Epoch : 1595/2000 data_batch_3,  Train_loss : 4997.4233  Test_loss : 4625.5283, Time/batch_file : 2.3217, Training time: 18489.4003\n",
      "Epoch : 1595/2000 data_batch_4,  Train_loss : 4970.7539  Test_loss : 4773.6240, Time/batch_file : 2.2814, Training time: 18491.6818\n",
      "Epoch : 1595/2000 data_batch_5,  Train_loss : 4955.5938  Test_loss : 4631.5132, Time/batch_file : 2.3032, Training time: 18493.9852\n",
      "Epoch : 1596/2000 data_batch_1,  Train_loss : 4798.1997  Test_loss : 4994.0361, Time/batch_file : 2.2674, Training time: 18496.2528\n",
      "Epoch : 1596/2000 data_batch_2,  Train_loss : 4687.7920  Test_loss : 5014.4521, Time/batch_file : 2.2793, Training time: 18498.5323\n",
      "Epoch : 1596/2000 data_batch_3,  Train_loss : 4481.7896  Test_loss : 5206.2827, Time/batch_file : 2.2663, Training time: 18500.7987\n",
      "Epoch : 1596/2000 data_batch_4,  Train_loss : 4830.9556  Test_loss : 4856.4531, Time/batch_file : 2.2863, Training time: 18503.0852\n",
      "Epoch : 1596/2000 data_batch_5,  Train_loss : 4927.0420  Test_loss : 5177.3066, Time/batch_file : 2.2758, Training time: 18505.3612\n",
      "Epoch : 1597/2000 data_batch_1,  Train_loss : 4541.2998  Test_loss : 4772.5928, Time/batch_file : 2.3159, Training time: 18507.6772\n",
      "Epoch : 1597/2000 data_batch_2,  Train_loss : 4698.6797  Test_loss : 5028.2573, Time/batch_file : 2.2683, Training time: 18509.9457\n",
      "Epoch : 1597/2000 data_batch_3,  Train_loss : 4467.6333  Test_loss : 4906.7407, Time/batch_file : 2.2868, Training time: 18512.2327\n",
      "Epoch : 1597/2000 data_batch_4,  Train_loss : 4479.6338  Test_loss : 4648.8892, Time/batch_file : 2.2735, Training time: 18514.5063\n",
      "Epoch : 1597/2000 data_batch_5,  Train_loss : 4476.1187  Test_loss : 5087.4600, Time/batch_file : 2.2799, Training time: 18516.7864\n",
      "Epoch : 1598/2000 data_batch_1,  Train_loss : 4426.9976  Test_loss : 4953.2832, Time/batch_file : 2.2811, Training time: 18519.0677\n",
      "Epoch : 1598/2000 data_batch_2,  Train_loss : 4419.5386  Test_loss : 5149.7202, Time/batch_file : 2.2958, Training time: 18521.3637\n",
      "Epoch : 1598/2000 data_batch_3,  Train_loss : 4455.7051  Test_loss : 4814.8076, Time/batch_file : 2.2786, Training time: 18523.6424\n",
      "Epoch : 1598/2000 data_batch_4,  Train_loss : 4399.7651  Test_loss : 4854.5781, Time/batch_file : 2.3259, Training time: 18525.9684\n",
      "Epoch : 1598/2000 data_batch_5,  Train_loss : 4316.2793  Test_loss : 5150.4307, Time/batch_file : 2.2811, Training time: 18528.2498\n",
      "Epoch : 1599/2000 data_batch_1,  Train_loss : 4054.7913  Test_loss : 4750.1606, Time/batch_file : 2.3150, Training time: 18530.5650\n",
      "Epoch : 1599/2000 data_batch_2,  Train_loss : 4609.9883  Test_loss : 5090.7192, Time/batch_file : 2.2956, Training time: 18532.8608\n",
      "Epoch : 1599/2000 data_batch_3,  Train_loss : 4352.0781  Test_loss : 5078.4277, Time/batch_file : 2.3007, Training time: 18535.1617\n",
      "Epoch : 1599/2000 data_batch_4,  Train_loss : 4004.5151  Test_loss : 5090.0273, Time/batch_file : 2.3016, Training time: 18537.4635\n",
      "Epoch : 1599/2000 data_batch_5,  Train_loss : 4148.7109  Test_loss : 5109.0190, Time/batch_file : 2.3161, Training time: 18539.7798\n",
      "Epoch : 1600/2000 data_batch_1,  Train_loss : 4471.7993  Test_loss : 4935.6787, Time/batch_file : 2.2974, Training time: 18542.0774\n",
      "Epoch : 1600/2000 data_batch_2,  Train_loss : 4424.0342  Test_loss : 4941.6772, Time/batch_file : 2.3339, Training time: 18544.4115\n",
      "Epoch : 1600/2000 data_batch_3,  Train_loss : 4375.9204  Test_loss : 4789.1211, Time/batch_file : 2.2839, Training time: 18546.6955\n",
      "Epoch : 1600/2000 data_batch_4,  Train_loss : 4380.6826  Test_loss : 4846.6680, Time/batch_file : 2.3093, Training time: 18549.0050\n",
      "Epoch : 1600/2000 data_batch_5,  Train_loss : 4570.7583  Test_loss : 5035.4844, Time/batch_file : 2.2874, Training time: 18551.2926\n",
      "[./nets/net-1600.ckpt] SAVED\n",
      "Epoch : 1601/2000 data_batch_1,  Train_loss : 4615.0571  Test_loss : 4784.1182, Time/batch_file : 2.3455, Training time: 18555.1265\n",
      "Epoch : 1601/2000 data_batch_2,  Train_loss : 4804.7842  Test_loss : 4926.8145, Time/batch_file : 2.2637, Training time: 18557.3905\n",
      "Epoch : 1601/2000 data_batch_3,  Train_loss : 4921.5576  Test_loss : 4831.4702, Time/batch_file : 2.2609, Training time: 18559.6517\n",
      "Epoch : 1601/2000 data_batch_4,  Train_loss : 4786.7007  Test_loss : 4944.2910, Time/batch_file : 2.2696, Training time: 18561.9214\n",
      "Epoch : 1601/2000 data_batch_5,  Train_loss : 4968.4854  Test_loss : 5054.2656, Time/batch_file : 2.2782, Training time: 18564.1998\n",
      "Epoch : 1602/2000 data_batch_1,  Train_loss : 4413.3809  Test_loss : 4494.8525, Time/batch_file : 2.2797, Training time: 18566.4797\n",
      "Epoch : 1602/2000 data_batch_2,  Train_loss : 4146.5757  Test_loss : 4468.0181, Time/batch_file : 2.2934, Training time: 18568.7734\n",
      "Epoch : 1602/2000 data_batch_3,  Train_loss : 4261.3491  Test_loss : 4989.7080, Time/batch_file : 2.2841, Training time: 18571.0576\n",
      "Epoch : 1602/2000 data_batch_4,  Train_loss : 4115.4106  Test_loss : 4492.1040, Time/batch_file : 2.2904, Training time: 18573.3483\n",
      "Epoch : 1602/2000 data_batch_5,  Train_loss : 4467.8730  Test_loss : 4555.0469, Time/batch_file : 2.2720, Training time: 18575.6205\n",
      "Epoch : 1603/2000 data_batch_1,  Train_loss : 4330.0327  Test_loss : 4867.2715, Time/batch_file : 2.2924, Training time: 18577.9131\n",
      "Epoch : 1603/2000 data_batch_2,  Train_loss : 4368.6758  Test_loss : 4890.8740, Time/batch_file : 2.2980, Training time: 18580.2112\n",
      "Epoch : 1603/2000 data_batch_3,  Train_loss : 4341.3730  Test_loss : 4612.3936, Time/batch_file : 2.3111, Training time: 18582.5225\n",
      "Epoch : 1603/2000 data_batch_4,  Train_loss : 4339.4600  Test_loss : 4756.0459, Time/batch_file : 2.2854, Training time: 18584.8080\n",
      "Epoch : 1603/2000 data_batch_5,  Train_loss : 4125.4658  Test_loss : 4722.6973, Time/batch_file : 2.3022, Training time: 18587.1105\n",
      "Epoch : 1604/2000 data_batch_1,  Train_loss : 4755.8179  Test_loss : 4483.9307, Time/batch_file : 2.2745, Training time: 18589.3853\n",
      "Epoch : 1604/2000 data_batch_2,  Train_loss : 4740.4697  Test_loss : 4724.6528, Time/batch_file : 2.3017, Training time: 18591.6872\n",
      "Epoch : 1604/2000 data_batch_3,  Train_loss : 4576.1450  Test_loss : 4855.2866, Time/batch_file : 2.2682, Training time: 18593.9557\n",
      "Epoch : 1604/2000 data_batch_4,  Train_loss : 4718.6406  Test_loss : 5012.5503, Time/batch_file : 2.2947, Training time: 18596.2506\n",
      "Epoch : 1604/2000 data_batch_5,  Train_loss : 4762.6880  Test_loss : 4757.3467, Time/batch_file : 2.2707, Training time: 18598.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1605/2000 data_batch_1,  Train_loss : 4328.4424  Test_loss : 4744.6743, Time/batch_file : 2.3054, Training time: 18600.8270\n",
      "Epoch : 1605/2000 data_batch_2,  Train_loss : 4250.9824  Test_loss : 4642.3711, Time/batch_file : 2.2693, Training time: 18603.0966\n",
      "Epoch : 1605/2000 data_batch_3,  Train_loss : 4551.3242  Test_loss : 4726.6035, Time/batch_file : 2.3039, Training time: 18605.4006\n",
      "Epoch : 1605/2000 data_batch_4,  Train_loss : 4253.1113  Test_loss : 4553.2012, Time/batch_file : 2.2750, Training time: 18607.6757\n",
      "Epoch : 1605/2000 data_batch_5,  Train_loss : 4666.9219  Test_loss : 4546.3247, Time/batch_file : 2.3072, Training time: 18609.9832\n",
      "Epoch : 1606/2000 data_batch_1,  Train_loss : 4391.5010  Test_loss : 5061.2397, Time/batch_file : 2.2727, Training time: 18612.2562\n",
      "Epoch : 1606/2000 data_batch_2,  Train_loss : 4600.9580  Test_loss : 4923.0957, Time/batch_file : 2.2971, Training time: 18614.5534\n",
      "Epoch : 1606/2000 data_batch_3,  Train_loss : 4701.1436  Test_loss : 5024.8047, Time/batch_file : 2.2802, Training time: 18616.8337\n",
      "Epoch : 1606/2000 data_batch_4,  Train_loss : 4734.5317  Test_loss : 5004.3364, Time/batch_file : 2.3055, Training time: 18619.1395\n",
      "Epoch : 1606/2000 data_batch_5,  Train_loss : 4543.9062  Test_loss : 4790.0205, Time/batch_file : 2.2977, Training time: 18621.4376\n",
      "Epoch : 1607/2000 data_batch_1,  Train_loss : 4148.4541  Test_loss : 4371.9922, Time/batch_file : 2.2923, Training time: 18623.7301\n",
      "Epoch : 1607/2000 data_batch_2,  Train_loss : 4409.0410  Test_loss : 4447.4907, Time/batch_file : 2.2533, Training time: 18625.9836\n",
      "Epoch : 1607/2000 data_batch_3,  Train_loss : 4344.2275  Test_loss : 4463.3149, Time/batch_file : 2.2775, Training time: 18628.2612\n",
      "Epoch : 1607/2000 data_batch_4,  Train_loss : 4338.6001  Test_loss : 4562.0186, Time/batch_file : 2.2566, Training time: 18630.5180\n",
      "Epoch : 1607/2000 data_batch_5,  Train_loss : 4414.5454  Test_loss : 4452.9072, Time/batch_file : 2.2747, Training time: 18632.7930\n",
      "Epoch : 1608/2000 data_batch_1,  Train_loss : 5050.3906  Test_loss : 4572.2314, Time/batch_file : 2.2920, Training time: 18635.0852\n",
      "Epoch : 1608/2000 data_batch_2,  Train_loss : 5120.9146  Test_loss : 4810.4780, Time/batch_file : 2.3126, Training time: 18637.3980\n",
      "Epoch : 1608/2000 data_batch_3,  Train_loss : 4705.4995  Test_loss : 4775.7148, Time/batch_file : 2.2787, Training time: 18639.6769\n",
      "Epoch : 1608/2000 data_batch_4,  Train_loss : 4733.4438  Test_loss : 4843.9424, Time/batch_file : 2.3116, Training time: 18641.9887\n",
      "Epoch : 1608/2000 data_batch_5,  Train_loss : 4690.3101  Test_loss : 4765.9619, Time/batch_file : 2.2779, Training time: 18644.2668\n",
      "Epoch : 1609/2000 data_batch_1,  Train_loss : 4871.9453  Test_loss : 4937.8560, Time/batch_file : 2.2934, Training time: 18646.5604\n",
      "Epoch : 1609/2000 data_batch_2,  Train_loss : 4859.9175  Test_loss : 4719.4312, Time/batch_file : 2.2535, Training time: 18648.8140\n",
      "Epoch : 1609/2000 data_batch_3,  Train_loss : 4799.2534  Test_loss : 4814.6133, Time/batch_file : 2.2977, Training time: 18651.1119\n",
      "Epoch : 1609/2000 data_batch_4,  Train_loss : 4944.6309  Test_loss : 4946.2793, Time/batch_file : 2.2519, Training time: 18653.3640\n",
      "Epoch : 1609/2000 data_batch_5,  Train_loss : 4775.8789  Test_loss : 4994.6338, Time/batch_file : 2.2855, Training time: 18655.6497\n",
      "Epoch : 1610/2000 data_batch_1,  Train_loss : 4929.6304  Test_loss : 5064.4009, Time/batch_file : 2.2950, Training time: 18657.9449\n",
      "Epoch : 1610/2000 data_batch_2,  Train_loss : 5106.5928  Test_loss : 4862.0083, Time/batch_file : 2.2962, Training time: 18660.2413\n",
      "Epoch : 1610/2000 data_batch_3,  Train_loss : 4891.7593  Test_loss : 4995.9907, Time/batch_file : 2.2679, Training time: 18662.5094\n",
      "Epoch : 1610/2000 data_batch_4,  Train_loss : 4891.2070  Test_loss : 4699.3188, Time/batch_file : 2.2924, Training time: 18664.8020\n",
      "Epoch : 1610/2000 data_batch_5,  Train_loss : 4867.9004  Test_loss : 4793.9985, Time/batch_file : 2.2652, Training time: 18667.0675\n",
      "[./nets/net-1610.ckpt] SAVED\n",
      "Epoch : 1611/2000 data_batch_1,  Train_loss : 4651.6792  Test_loss : 4694.3354, Time/batch_file : 2.3224, Training time: 18670.6640\n",
      "Epoch : 1611/2000 data_batch_2,  Train_loss : 4800.1548  Test_loss : 4996.7080, Time/batch_file : 2.2660, Training time: 18672.9302\n",
      "Epoch : 1611/2000 data_batch_3,  Train_loss : 4589.2607  Test_loss : 4772.8584, Time/batch_file : 2.2679, Training time: 18675.1984\n",
      "Epoch : 1611/2000 data_batch_4,  Train_loss : 4679.6562  Test_loss : 4837.7905, Time/batch_file : 2.2721, Training time: 18677.4707\n",
      "Epoch : 1611/2000 data_batch_5,  Train_loss : 4593.6626  Test_loss : 4811.3418, Time/batch_file : 2.2787, Training time: 18679.7497\n",
      "Epoch : 1612/2000 data_batch_1,  Train_loss : 4719.0952  Test_loss : 4794.9946, Time/batch_file : 2.2829, Training time: 18682.0329\n",
      "Epoch : 1612/2000 data_batch_2,  Train_loss : 4809.7998  Test_loss : 5004.6265, Time/batch_file : 2.2785, Training time: 18684.3116\n",
      "Epoch : 1612/2000 data_batch_3,  Train_loss : 4711.6870  Test_loss : 4825.4609, Time/batch_file : 2.2786, Training time: 18686.5904\n",
      "Epoch : 1612/2000 data_batch_4,  Train_loss : 4974.6763  Test_loss : 4966.2485, Time/batch_file : 2.2796, Training time: 18688.8703\n",
      "Epoch : 1612/2000 data_batch_5,  Train_loss : 4949.7383  Test_loss : 4741.9170, Time/batch_file : 2.2809, Training time: 18691.1513\n",
      "Epoch : 1613/2000 data_batch_1,  Train_loss : 4737.4883  Test_loss : 5177.8608, Time/batch_file : 2.2673, Training time: 18693.4188\n",
      "Epoch : 1613/2000 data_batch_2,  Train_loss : 4553.1602  Test_loss : 5196.0342, Time/batch_file : 2.2646, Training time: 18695.6836\n",
      "Epoch : 1613/2000 data_batch_3,  Train_loss : 4632.1523  Test_loss : 5214.7222, Time/batch_file : 2.2754, Training time: 18697.9591\n",
      "Epoch : 1613/2000 data_batch_4,  Train_loss : 4624.4243  Test_loss : 5094.7246, Time/batch_file : 2.2752, Training time: 18700.2346\n",
      "Epoch : 1613/2000 data_batch_5,  Train_loss : 4752.3779  Test_loss : 5518.4351, Time/batch_file : 2.2804, Training time: 18702.5151\n",
      "Epoch : 1614/2000 data_batch_1,  Train_loss : 4854.1611  Test_loss : 4708.5425, Time/batch_file : 2.2650, Training time: 18704.7803\n",
      "Epoch : 1614/2000 data_batch_2,  Train_loss : 4521.8315  Test_loss : 4326.7666, Time/batch_file : 2.2689, Training time: 18707.0493\n",
      "Epoch : 1614/2000 data_batch_3,  Train_loss : 4807.7329  Test_loss : 4363.9463, Time/batch_file : 2.2551, Training time: 18709.3047\n",
      "Epoch : 1614/2000 data_batch_4,  Train_loss : 4631.6650  Test_loss : 4457.6274, Time/batch_file : 2.2600, Training time: 18711.5649\n",
      "Epoch : 1614/2000 data_batch_5,  Train_loss : 4476.9111  Test_loss : 4771.9883, Time/batch_file : 2.2601, Training time: 18713.8252\n",
      "Epoch : 1615/2000 data_batch_1,  Train_loss : 4425.6494  Test_loss : 4855.5391, Time/batch_file : 2.2651, Training time: 18716.0905\n",
      "Epoch : 1615/2000 data_batch_2,  Train_loss : 4454.8960  Test_loss : 4503.1826, Time/batch_file : 2.2601, Training time: 18718.3509\n",
      "Epoch : 1615/2000 data_batch_3,  Train_loss : 4817.9092  Test_loss : 4479.7812, Time/batch_file : 2.2687, Training time: 18720.6198\n",
      "Epoch : 1615/2000 data_batch_4,  Train_loss : 4532.7935  Test_loss : 4697.9385, Time/batch_file : 2.2549, Training time: 18722.8749\n",
      "Epoch : 1615/2000 data_batch_5,  Train_loss : 4597.9219  Test_loss : 4576.5024, Time/batch_file : 2.2701, Training time: 18725.1452\n",
      "Epoch : 1616/2000 data_batch_1,  Train_loss : 4643.5264  Test_loss : 5236.7217, Time/batch_file : 2.2641, Training time: 18727.4094\n",
      "Epoch : 1616/2000 data_batch_2,  Train_loss : 4884.5259  Test_loss : 5021.4712, Time/batch_file : 2.2883, Training time: 18729.6978\n",
      "Epoch : 1616/2000 data_batch_3,  Train_loss : 4845.7485  Test_loss : 4894.6226, Time/batch_file : 2.2627, Training time: 18731.9607\n",
      "Epoch : 1616/2000 data_batch_4,  Train_loss : 5046.3418  Test_loss : 5050.7788, Time/batch_file : 2.2657, Training time: 18734.2266\n",
      "Epoch : 1616/2000 data_batch_5,  Train_loss : 4919.7759  Test_loss : 5049.2383, Time/batch_file : 2.2628, Training time: 18736.4895\n",
      "Epoch : 1617/2000 data_batch_1,  Train_loss : 4278.3970  Test_loss : 5043.8955, Time/batch_file : 2.2664, Training time: 18738.7561\n",
      "Epoch : 1617/2000 data_batch_2,  Train_loss : 4428.9307  Test_loss : 4935.5854, Time/batch_file : 2.2626, Training time: 18741.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1617/2000 data_batch_3,  Train_loss : 4545.1699  Test_loss : 5413.4355, Time/batch_file : 2.2652, Training time: 18743.2843\n",
      "Epoch : 1617/2000 data_batch_4,  Train_loss : 4311.3066  Test_loss : 5083.7061, Time/batch_file : 2.2622, Training time: 18745.5467\n",
      "Epoch : 1617/2000 data_batch_5,  Train_loss : 4230.8291  Test_loss : 5284.1250, Time/batch_file : 2.2659, Training time: 18747.8128\n",
      "Epoch : 1618/2000 data_batch_1,  Train_loss : 4219.2168  Test_loss : 4757.9150, Time/batch_file : 2.2714, Training time: 18750.0843\n",
      "Epoch : 1618/2000 data_batch_2,  Train_loss : 4480.4678  Test_loss : 5020.8994, Time/batch_file : 2.2729, Training time: 18752.3574\n",
      "Epoch : 1618/2000 data_batch_3,  Train_loss : 4506.2480  Test_loss : 4837.0278, Time/batch_file : 2.2624, Training time: 18754.6200\n",
      "Epoch : 1618/2000 data_batch_4,  Train_loss : 4379.4805  Test_loss : 4787.0703, Time/batch_file : 2.2811, Training time: 18756.9013\n",
      "Epoch : 1618/2000 data_batch_5,  Train_loss : 4284.3896  Test_loss : 4820.1113, Time/batch_file : 2.2798, Training time: 18759.1813\n",
      "Epoch : 1619/2000 data_batch_1,  Train_loss : 4089.4331  Test_loss : 5071.4424, Time/batch_file : 2.2765, Training time: 18761.4580\n",
      "Epoch : 1619/2000 data_batch_2,  Train_loss : 3783.0972  Test_loss : 4682.1924, Time/batch_file : 2.2666, Training time: 18763.7247\n",
      "Epoch : 1619/2000 data_batch_3,  Train_loss : 4081.9624  Test_loss : 5241.1870, Time/batch_file : 2.2853, Training time: 18766.0103\n",
      "Epoch : 1619/2000 data_batch_4,  Train_loss : 3984.6191  Test_loss : 4762.8516, Time/batch_file : 2.2688, Training time: 18768.2793\n",
      "Epoch : 1619/2000 data_batch_5,  Train_loss : 3891.7214  Test_loss : 4918.6846, Time/batch_file : 2.2702, Training time: 18770.5497\n",
      "Epoch : 1620/2000 data_batch_1,  Train_loss : 4685.1328  Test_loss : 5141.8916, Time/batch_file : 2.2750, Training time: 18772.8249\n",
      "Epoch : 1620/2000 data_batch_2,  Train_loss : 4476.5103  Test_loss : 4922.6968, Time/batch_file : 2.2804, Training time: 18775.1056\n",
      "Epoch : 1620/2000 data_batch_3,  Train_loss : 4531.5718  Test_loss : 5046.3896, Time/batch_file : 2.2683, Training time: 18777.3741\n",
      "Epoch : 1620/2000 data_batch_4,  Train_loss : 4354.2407  Test_loss : 4913.4033, Time/batch_file : 2.2878, Training time: 18779.6621\n",
      "Epoch : 1620/2000 data_batch_5,  Train_loss : 4320.8984  Test_loss : 5144.6533, Time/batch_file : 2.2709, Training time: 18781.9331\n",
      "[./nets/net-1620.ckpt] SAVED\n",
      "Epoch : 1621/2000 data_batch_1,  Train_loss : 4484.7505  Test_loss : 4369.1943, Time/batch_file : 2.4296, Training time: 18785.6411\n",
      "Epoch : 1621/2000 data_batch_2,  Train_loss : 4292.1553  Test_loss : 4642.5830, Time/batch_file : 2.2720, Training time: 18787.9132\n",
      "Epoch : 1621/2000 data_batch_3,  Train_loss : 4165.3818  Test_loss : 4498.8701, Time/batch_file : 2.2624, Training time: 18790.1759\n",
      "Epoch : 1621/2000 data_batch_4,  Train_loss : 4453.0044  Test_loss : 4207.8779, Time/batch_file : 2.2745, Training time: 18792.4505\n",
      "Epoch : 1621/2000 data_batch_5,  Train_loss : 4273.8438  Test_loss : 4788.8296, Time/batch_file : 2.2778, Training time: 18794.7284\n",
      "Epoch : 1622/2000 data_batch_1,  Train_loss : 4491.8696  Test_loss : 4727.1953, Time/batch_file : 2.2724, Training time: 18797.0011\n",
      "Epoch : 1622/2000 data_batch_2,  Train_loss : 4709.2871  Test_loss : 4601.9810, Time/batch_file : 2.2712, Training time: 18799.2725\n",
      "Epoch : 1622/2000 data_batch_3,  Train_loss : 4620.8018  Test_loss : 4820.9575, Time/batch_file : 2.2925, Training time: 18801.5652\n",
      "Epoch : 1622/2000 data_batch_4,  Train_loss : 4516.5269  Test_loss : 4803.6211, Time/batch_file : 2.2704, Training time: 18803.8358\n",
      "Epoch : 1622/2000 data_batch_5,  Train_loss : 4631.7534  Test_loss : 4683.7671, Time/batch_file : 2.2782, Training time: 18806.1143\n",
      "Epoch : 1623/2000 data_batch_1,  Train_loss : 4600.9775  Test_loss : 5147.6538, Time/batch_file : 2.2580, Training time: 18808.3723\n",
      "Epoch : 1623/2000 data_batch_2,  Train_loss : 4675.3506  Test_loss : 5304.8125, Time/batch_file : 2.2614, Training time: 18810.6339\n",
      "Epoch : 1623/2000 data_batch_3,  Train_loss : 4800.4731  Test_loss : 5749.8633, Time/batch_file : 2.2605, Training time: 18812.8946\n",
      "Epoch : 1623/2000 data_batch_4,  Train_loss : 4907.8257  Test_loss : 5087.5200, Time/batch_file : 2.2713, Training time: 18815.1660\n",
      "Epoch : 1623/2000 data_batch_5,  Train_loss : 4650.3740  Test_loss : 4973.8232, Time/batch_file : 2.2633, Training time: 18817.4294\n",
      "Epoch : 1624/2000 data_batch_1,  Train_loss : 4906.4434  Test_loss : 5038.3589, Time/batch_file : 2.3047, Training time: 18819.7343\n",
      "Epoch : 1624/2000 data_batch_2,  Train_loss : 5028.5615  Test_loss : 4933.0508, Time/batch_file : 2.2760, Training time: 18822.0105\n",
      "Epoch : 1624/2000 data_batch_3,  Train_loss : 4795.0679  Test_loss : 4893.8340, Time/batch_file : 2.2796, Training time: 18824.2904\n",
      "Epoch : 1624/2000 data_batch_4,  Train_loss : 4959.6475  Test_loss : 4552.6484, Time/batch_file : 2.2755, Training time: 18826.5661\n",
      "Epoch : 1624/2000 data_batch_5,  Train_loss : 4763.6992  Test_loss : 4977.7856, Time/batch_file : 2.2791, Training time: 18828.8454\n",
      "Epoch : 1625/2000 data_batch_1,  Train_loss : 4129.3237  Test_loss : 4720.3887, Time/batch_file : 2.2702, Training time: 18831.1158\n",
      "Epoch : 1625/2000 data_batch_2,  Train_loss : 4232.5581  Test_loss : 4714.5947, Time/batch_file : 2.2738, Training time: 18833.3898\n",
      "Epoch : 1625/2000 data_batch_3,  Train_loss : 4276.4912  Test_loss : 4390.0947, Time/batch_file : 2.2667, Training time: 18835.6567\n",
      "Epoch : 1625/2000 data_batch_4,  Train_loss : 4068.9102  Test_loss : 4667.1357, Time/batch_file : 2.3033, Training time: 18837.9603\n",
      "Epoch : 1625/2000 data_batch_5,  Train_loss : 4032.2993  Test_loss : 4525.4990, Time/batch_file : 2.2684, Training time: 18840.2288\n",
      "Epoch : 1626/2000 data_batch_1,  Train_loss : 4473.5342  Test_loss : 4964.2939, Time/batch_file : 2.2706, Training time: 18842.4996\n",
      "Epoch : 1626/2000 data_batch_2,  Train_loss : 4632.8643  Test_loss : 4986.4546, Time/batch_file : 2.2705, Training time: 18844.7703\n",
      "Epoch : 1626/2000 data_batch_3,  Train_loss : 4551.5225  Test_loss : 5219.5791, Time/batch_file : 2.2533, Training time: 18847.0238\n",
      "Epoch : 1626/2000 data_batch_4,  Train_loss : 4421.0239  Test_loss : 4702.3198, Time/batch_file : 2.2627, Training time: 18849.2866\n",
      "Epoch : 1626/2000 data_batch_5,  Train_loss : 4311.1401  Test_loss : 4995.7310, Time/batch_file : 2.2677, Training time: 18851.5545\n",
      "Epoch : 1627/2000 data_batch_1,  Train_loss : 4733.6392  Test_loss : 4811.1182, Time/batch_file : 2.2784, Training time: 18853.8332\n",
      "Epoch : 1627/2000 data_batch_2,  Train_loss : 4733.3223  Test_loss : 4831.8472, Time/batch_file : 2.2885, Training time: 18856.1219\n",
      "Epoch : 1627/2000 data_batch_3,  Train_loss : 4923.6709  Test_loss : 4665.3691, Time/batch_file : 2.2691, Training time: 18858.3913\n",
      "Epoch : 1627/2000 data_batch_4,  Train_loss : 4628.0713  Test_loss : 4657.0059, Time/batch_file : 2.2809, Training time: 18860.6725\n",
      "Epoch : 1627/2000 data_batch_5,  Train_loss : 4698.7271  Test_loss : 4699.4727, Time/batch_file : 2.2585, Training time: 18862.9312\n",
      "Epoch : 1628/2000 data_batch_1,  Train_loss : 5024.1372  Test_loss : 4564.5332, Time/batch_file : 2.2717, Training time: 18865.2032\n",
      "Epoch : 1628/2000 data_batch_2,  Train_loss : 4875.6406  Test_loss : 4809.5674, Time/batch_file : 2.2594, Training time: 18867.4628\n",
      "Epoch : 1628/2000 data_batch_3,  Train_loss : 4900.0771  Test_loss : 4831.9121, Time/batch_file : 2.2772, Training time: 18869.7402\n",
      "Epoch : 1628/2000 data_batch_4,  Train_loss : 4995.2070  Test_loss : 4661.4238, Time/batch_file : 2.2772, Training time: 18872.0176\n",
      "Epoch : 1628/2000 data_batch_5,  Train_loss : 4914.2969  Test_loss : 4883.0605, Time/batch_file : 2.2966, Training time: 18874.3144\n",
      "Epoch : 1629/2000 data_batch_1,  Train_loss : 4843.4316  Test_loss : 4448.1582, Time/batch_file : 2.2654, Training time: 18876.5800\n",
      "Epoch : 1629/2000 data_batch_2,  Train_loss : 4738.4810  Test_loss : 4591.2520, Time/batch_file : 2.2680, Training time: 18878.8482\n",
      "Epoch : 1629/2000 data_batch_3,  Train_loss : 4880.2568  Test_loss : 4386.1880, Time/batch_file : 2.2687, Training time: 18881.1171\n",
      "Epoch : 1629/2000 data_batch_4,  Train_loss : 4675.3320  Test_loss : 4677.5156, Time/batch_file : 2.2702, Training time: 18883.3875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1629/2000 data_batch_5,  Train_loss : 4942.0410  Test_loss : 4862.9697, Time/batch_file : 2.2707, Training time: 18885.6584\n",
      "Epoch : 1630/2000 data_batch_1,  Train_loss : 4459.9897  Test_loss : 4788.8618, Time/batch_file : 2.2811, Training time: 18887.9397\n",
      "Epoch : 1630/2000 data_batch_2,  Train_loss : 4619.6133  Test_loss : 4758.5000, Time/batch_file : 2.2734, Training time: 18890.2133\n",
      "Epoch : 1630/2000 data_batch_3,  Train_loss : 4574.4336  Test_loss : 4663.4565, Time/batch_file : 2.3008, Training time: 18892.5143\n",
      "Epoch : 1630/2000 data_batch_4,  Train_loss : 4690.4780  Test_loss : 5169.3999, Time/batch_file : 2.2738, Training time: 18894.7883\n",
      "Epoch : 1630/2000 data_batch_5,  Train_loss : 4683.5786  Test_loss : 4883.9722, Time/batch_file : 2.2861, Training time: 18897.0746\n",
      "[./nets/net-1630.ckpt] SAVED\n",
      "Epoch : 1631/2000 data_batch_1,  Train_loss : 4159.0269  Test_loss : 5254.6987, Time/batch_file : 2.3011, Training time: 18900.7214\n",
      "Epoch : 1631/2000 data_batch_2,  Train_loss : 4533.1367  Test_loss : 5208.9131, Time/batch_file : 2.2839, Training time: 18903.0055\n",
      "Epoch : 1631/2000 data_batch_3,  Train_loss : 4310.1201  Test_loss : 5410.1992, Time/batch_file : 2.2798, Training time: 18905.2854\n",
      "Epoch : 1631/2000 data_batch_4,  Train_loss : 4234.2861  Test_loss : 5207.5381, Time/batch_file : 2.2909, Training time: 18907.5766\n",
      "Epoch : 1631/2000 data_batch_5,  Train_loss : 4339.0459  Test_loss : 5068.9199, Time/batch_file : 2.2942, Training time: 18909.8709\n",
      "Epoch : 1632/2000 data_batch_1,  Train_loss : 5187.8223  Test_loss : 4490.4341, Time/batch_file : 2.2699, Training time: 18912.1410\n",
      "Epoch : 1632/2000 data_batch_2,  Train_loss : 5446.6846  Test_loss : 4824.8462, Time/batch_file : 2.2945, Training time: 18914.4358\n",
      "Epoch : 1632/2000 data_batch_3,  Train_loss : 5175.2461  Test_loss : 4599.9932, Time/batch_file : 2.2735, Training time: 18916.7094\n",
      "Epoch : 1632/2000 data_batch_4,  Train_loss : 5192.8315  Test_loss : 4436.8638, Time/batch_file : 2.2887, Training time: 18918.9982\n",
      "Epoch : 1632/2000 data_batch_5,  Train_loss : 5301.0156  Test_loss : 4816.2656, Time/batch_file : 2.3071, Training time: 18921.3055\n",
      "Epoch : 1633/2000 data_batch_1,  Train_loss : 4886.7559  Test_loss : 4473.7349, Time/batch_file : 2.2940, Training time: 18923.5997\n",
      "Epoch : 1633/2000 data_batch_2,  Train_loss : 4822.6934  Test_loss : 4684.4062, Time/batch_file : 2.2752, Training time: 18925.8751\n",
      "Epoch : 1633/2000 data_batch_3,  Train_loss : 4804.5571  Test_loss : 4731.8809, Time/batch_file : 2.3124, Training time: 18928.1877\n",
      "Epoch : 1633/2000 data_batch_4,  Train_loss : 5078.2832  Test_loss : 4805.9868, Time/batch_file : 2.2918, Training time: 18930.4797\n",
      "Epoch : 1633/2000 data_batch_5,  Train_loss : 4776.8853  Test_loss : 4657.7773, Time/batch_file : 2.2933, Training time: 18932.7732\n",
      "Epoch : 1634/2000 data_batch_1,  Train_loss : 5025.9336  Test_loss : 5130.3032, Time/batch_file : 2.3042, Training time: 18935.0776\n",
      "Epoch : 1634/2000 data_batch_2,  Train_loss : 4865.8350  Test_loss : 5127.5747, Time/batch_file : 2.2939, Training time: 18937.3717\n",
      "Epoch : 1634/2000 data_batch_3,  Train_loss : 4931.9863  Test_loss : 4980.2207, Time/batch_file : 2.2899, Training time: 18939.6618\n",
      "Epoch : 1634/2000 data_batch_4,  Train_loss : 5043.0923  Test_loss : 5128.9116, Time/batch_file : 2.2936, Training time: 18941.9556\n",
      "Epoch : 1634/2000 data_batch_5,  Train_loss : 5032.7104  Test_loss : 4936.0586, Time/batch_file : 2.2951, Training time: 18944.2509\n",
      "Epoch : 1635/2000 data_batch_1,  Train_loss : 4376.5771  Test_loss : 5275.0181, Time/batch_file : 2.2815, Training time: 18946.5326\n",
      "Epoch : 1635/2000 data_batch_2,  Train_loss : 4529.7773  Test_loss : 5154.8530, Time/batch_file : 2.2794, Training time: 18948.8122\n",
      "Epoch : 1635/2000 data_batch_3,  Train_loss : 4448.5410  Test_loss : 5242.4326, Time/batch_file : 2.2740, Training time: 18951.0865\n",
      "Epoch : 1635/2000 data_batch_4,  Train_loss : 4307.2002  Test_loss : 5170.3281, Time/batch_file : 2.2688, Training time: 18953.3554\n",
      "Epoch : 1635/2000 data_batch_5,  Train_loss : 4459.9272  Test_loss : 5376.1025, Time/batch_file : 2.2765, Training time: 18955.6321\n",
      "Epoch : 1636/2000 data_batch_1,  Train_loss : 4413.9307  Test_loss : 4747.8486, Time/batch_file : 2.2623, Training time: 18957.8946\n",
      "Epoch : 1636/2000 data_batch_2,  Train_loss : 4337.8398  Test_loss : 4835.3760, Time/batch_file : 2.2803, Training time: 18960.1751\n",
      "Epoch : 1636/2000 data_batch_3,  Train_loss : 4732.3804  Test_loss : 4802.3877, Time/batch_file : 2.2738, Training time: 18962.4492\n",
      "Epoch : 1636/2000 data_batch_4,  Train_loss : 4656.6479  Test_loss : 4738.1113, Time/batch_file : 2.2884, Training time: 18964.7377\n",
      "Epoch : 1636/2000 data_batch_5,  Train_loss : 4636.9609  Test_loss : 5000.9424, Time/batch_file : 2.3001, Training time: 18967.0380\n",
      "Epoch : 1637/2000 data_batch_1,  Train_loss : 4995.5215  Test_loss : 4867.8789, Time/batch_file : 2.2827, Training time: 18969.3209\n",
      "Epoch : 1637/2000 data_batch_2,  Train_loss : 4981.4688  Test_loss : 5096.6992, Time/batch_file : 2.3013, Training time: 18971.6224\n",
      "Epoch : 1637/2000 data_batch_3,  Train_loss : 4886.1680  Test_loss : 5093.4307, Time/batch_file : 2.3054, Training time: 18973.9280\n",
      "Epoch : 1637/2000 data_batch_4,  Train_loss : 4919.1177  Test_loss : 4898.7852, Time/batch_file : 2.3105, Training time: 18976.2388\n",
      "Epoch : 1637/2000 data_batch_5,  Train_loss : 5030.2773  Test_loss : 5101.1777, Time/batch_file : 2.2831, Training time: 18978.5220\n",
      "Epoch : 1638/2000 data_batch_1,  Train_loss : 4816.1304  Test_loss : 4276.9028, Time/batch_file : 2.3072, Training time: 18980.8294\n",
      "Epoch : 1638/2000 data_batch_2,  Train_loss : 5399.0190  Test_loss : 4194.9287, Time/batch_file : 2.2850, Training time: 18983.1145\n",
      "Epoch : 1638/2000 data_batch_3,  Train_loss : 5159.3306  Test_loss : 4500.5381, Time/batch_file : 2.2861, Training time: 18985.4009\n",
      "Epoch : 1638/2000 data_batch_4,  Train_loss : 5216.7515  Test_loss : 4204.1943, Time/batch_file : 2.2732, Training time: 18987.6743\n",
      "Epoch : 1638/2000 data_batch_5,  Train_loss : 4776.5391  Test_loss : 4408.3096, Time/batch_file : 2.2662, Training time: 18989.9406\n",
      "Epoch : 1639/2000 data_batch_1,  Train_loss : 4500.0942  Test_loss : 4847.0479, Time/batch_file : 2.3113, Training time: 18992.2521\n",
      "Epoch : 1639/2000 data_batch_2,  Train_loss : 4784.8232  Test_loss : 5033.4233, Time/batch_file : 2.2744, Training time: 18994.5266\n",
      "Epoch : 1639/2000 data_batch_3,  Train_loss : 4545.7021  Test_loss : 5144.2617, Time/batch_file : 2.2891, Training time: 18996.8159\n",
      "Epoch : 1639/2000 data_batch_4,  Train_loss : 4811.4287  Test_loss : 5044.7305, Time/batch_file : 2.2722, Training time: 18999.0882\n",
      "Epoch : 1639/2000 data_batch_5,  Train_loss : 4749.4619  Test_loss : 4865.7119, Time/batch_file : 2.2823, Training time: 19001.3707\n",
      "Epoch : 1640/2000 data_batch_1,  Train_loss : 4368.2368  Test_loss : 4594.0806, Time/batch_file : 2.2976, Training time: 19003.6687\n",
      "Epoch : 1640/2000 data_batch_2,  Train_loss : 4621.3647  Test_loss : 4778.6860, Time/batch_file : 2.2834, Training time: 19005.9522\n",
      "Epoch : 1640/2000 data_batch_3,  Train_loss : 4774.0103  Test_loss : 4631.2446, Time/batch_file : 2.2973, Training time: 19008.2497\n",
      "Epoch : 1640/2000 data_batch_4,  Train_loss : 4701.0898  Test_loss : 4604.8633, Time/batch_file : 2.2845, Training time: 19010.5344\n",
      "Epoch : 1640/2000 data_batch_5,  Train_loss : 4619.0645  Test_loss : 4530.3252, Time/batch_file : 2.2854, Training time: 19012.8199\n",
      "[./nets/net-1640.ckpt] SAVED\n",
      "Epoch : 1641/2000 data_batch_1,  Train_loss : 4771.9268  Test_loss : 5166.7646, Time/batch_file : 2.4461, Training time: 19016.6005\n",
      "Epoch : 1641/2000 data_batch_2,  Train_loss : 4772.3945  Test_loss : 5381.5249, Time/batch_file : 2.2898, Training time: 19018.8905\n",
      "Epoch : 1641/2000 data_batch_3,  Train_loss : 4662.8311  Test_loss : 5345.0933, Time/batch_file : 2.2628, Training time: 19021.1535\n",
      "Epoch : 1641/2000 data_batch_4,  Train_loss : 4660.9209  Test_loss : 5198.2461, Time/batch_file : 2.2462, Training time: 19023.3999\n",
      "Epoch : 1641/2000 data_batch_5,  Train_loss : 4904.7876  Test_loss : 5190.7305, Time/batch_file : 2.2678, Training time: 19025.6679\n",
      "Epoch : 1642/2000 data_batch_1,  Train_loss : 4533.1660  Test_loss : 4528.8862, Time/batch_file : 2.2797, Training time: 19027.9478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1642/2000 data_batch_2,  Train_loss : 4420.8604  Test_loss : 4540.6611, Time/batch_file : 2.2979, Training time: 19030.2459\n",
      "Epoch : 1642/2000 data_batch_3,  Train_loss : 4514.7734  Test_loss : 4531.9800, Time/batch_file : 2.2779, Training time: 19032.5240\n",
      "Epoch : 1642/2000 data_batch_4,  Train_loss : 4650.9854  Test_loss : 4726.5449, Time/batch_file : 2.2724, Training time: 19034.7966\n",
      "Epoch : 1642/2000 data_batch_5,  Train_loss : 4339.4072  Test_loss : 4671.6411, Time/batch_file : 2.2678, Training time: 19037.0646\n",
      "Epoch : 1643/2000 data_batch_1,  Train_loss : 4252.1675  Test_loss : 4627.4375, Time/batch_file : 2.2900, Training time: 19039.3547\n",
      "Epoch : 1643/2000 data_batch_2,  Train_loss : 4493.2378  Test_loss : 4719.4814, Time/batch_file : 2.2615, Training time: 19041.6165\n",
      "Epoch : 1643/2000 data_batch_3,  Train_loss : 4243.5083  Test_loss : 4796.0117, Time/batch_file : 2.2592, Training time: 19043.8760\n",
      "Epoch : 1643/2000 data_batch_4,  Train_loss : 4247.5889  Test_loss : 4743.4629, Time/batch_file : 2.2592, Training time: 19046.1354\n",
      "Epoch : 1643/2000 data_batch_5,  Train_loss : 4170.5957  Test_loss : 4786.1318, Time/batch_file : 2.2601, Training time: 19048.3957\n",
      "Epoch : 1644/2000 data_batch_1,  Train_loss : 4645.1846  Test_loss : 4968.5693, Time/batch_file : 2.2696, Training time: 19050.6654\n",
      "Epoch : 1644/2000 data_batch_2,  Train_loss : 4633.1802  Test_loss : 4850.6714, Time/batch_file : 2.2700, Training time: 19052.9357\n",
      "Epoch : 1644/2000 data_batch_3,  Train_loss : 4484.0913  Test_loss : 5087.1455, Time/batch_file : 2.2676, Training time: 19055.2036\n",
      "Epoch : 1644/2000 data_batch_4,  Train_loss : 4557.1504  Test_loss : 5173.0977, Time/batch_file : 2.2661, Training time: 19057.4699\n",
      "Epoch : 1644/2000 data_batch_5,  Train_loss : 4439.2520  Test_loss : 4819.2295, Time/batch_file : 2.2716, Training time: 19059.7416\n",
      "Epoch : 1645/2000 data_batch_1,  Train_loss : 4697.3320  Test_loss : 4468.4004, Time/batch_file : 2.2590, Training time: 19062.0008\n",
      "Epoch : 1645/2000 data_batch_2,  Train_loss : 4515.7573  Test_loss : 4430.6226, Time/batch_file : 2.2790, Training time: 19064.2800\n",
      "Epoch : 1645/2000 data_batch_3,  Train_loss : 4581.6562  Test_loss : 4586.9849, Time/batch_file : 2.2665, Training time: 19066.5466\n",
      "Epoch : 1645/2000 data_batch_4,  Train_loss : 4483.6372  Test_loss : 4066.4941, Time/batch_file : 2.2783, Training time: 19068.8251\n",
      "Epoch : 1645/2000 data_batch_5,  Train_loss : 4466.4189  Test_loss : 4456.9858, Time/batch_file : 2.2784, Training time: 19071.1037\n",
      "Epoch : 1646/2000 data_batch_1,  Train_loss : 4155.9023  Test_loss : 4498.7568, Time/batch_file : 2.2703, Training time: 19073.3741\n",
      "Epoch : 1646/2000 data_batch_2,  Train_loss : 4010.0811  Test_loss : 4494.2490, Time/batch_file : 2.2698, Training time: 19075.6441\n",
      "Epoch : 1646/2000 data_batch_3,  Train_loss : 4250.8394  Test_loss : 4557.3149, Time/batch_file : 2.2685, Training time: 19077.9128\n",
      "Epoch : 1646/2000 data_batch_4,  Train_loss : 4146.7354  Test_loss : 4462.7886, Time/batch_file : 2.2748, Training time: 19080.1877\n",
      "Epoch : 1646/2000 data_batch_5,  Train_loss : 4151.1050  Test_loss : 4472.7197, Time/batch_file : 2.2617, Training time: 19082.4495\n",
      "Epoch : 1647/2000 data_batch_1,  Train_loss : 4608.5654  Test_loss : 4828.6865, Time/batch_file : 2.3012, Training time: 19084.7510\n",
      "Epoch : 1647/2000 data_batch_2,  Train_loss : 5040.0781  Test_loss : 4790.6514, Time/batch_file : 2.2803, Training time: 19087.0314\n",
      "Epoch : 1647/2000 data_batch_3,  Train_loss : 4984.2070  Test_loss : 4886.7314, Time/batch_file : 2.2802, Training time: 19089.3119\n",
      "Epoch : 1647/2000 data_batch_4,  Train_loss : 4587.8223  Test_loss : 4945.4712, Time/batch_file : 2.2718, Training time: 19091.5839\n",
      "Epoch : 1647/2000 data_batch_5,  Train_loss : 4717.8833  Test_loss : 4931.2876, Time/batch_file : 2.2811, Training time: 19093.8652\n",
      "Epoch : 1648/2000 data_batch_1,  Train_loss : 4526.2583  Test_loss : 4536.7573, Time/batch_file : 2.2795, Training time: 19096.1449\n",
      "Epoch : 1648/2000 data_batch_2,  Train_loss : 4833.6162  Test_loss : 4836.8965, Time/batch_file : 2.2785, Training time: 19098.4236\n",
      "Epoch : 1648/2000 data_batch_3,  Train_loss : 4744.9302  Test_loss : 4513.8047, Time/batch_file : 2.2861, Training time: 19100.7100\n",
      "Epoch : 1648/2000 data_batch_4,  Train_loss : 4874.4717  Test_loss : 4691.7471, Time/batch_file : 2.2568, Training time: 19102.9671\n",
      "Epoch : 1648/2000 data_batch_5,  Train_loss : 4897.8867  Test_loss : 4546.1562, Time/batch_file : 2.2623, Training time: 19105.2295\n",
      "Epoch : 1649/2000 data_batch_1,  Train_loss : 5141.5483  Test_loss : 4965.5269, Time/batch_file : 2.2751, Training time: 19107.5048\n",
      "Epoch : 1649/2000 data_batch_2,  Train_loss : 5328.5942  Test_loss : 4986.9941, Time/batch_file : 2.2604, Training time: 19109.7654\n",
      "Epoch : 1649/2000 data_batch_3,  Train_loss : 5300.4575  Test_loss : 4779.5928, Time/batch_file : 2.2725, Training time: 19112.0381\n",
      "Epoch : 1649/2000 data_batch_4,  Train_loss : 5075.6870  Test_loss : 5038.1245, Time/batch_file : 2.2869, Training time: 19114.3251\n",
      "Epoch : 1649/2000 data_batch_5,  Train_loss : 5236.6162  Test_loss : 5071.1582, Time/batch_file : 2.2536, Training time: 19116.5789\n",
      "Epoch : 1650/2000 data_batch_1,  Train_loss : 4825.9658  Test_loss : 5073.1250, Time/batch_file : 2.2756, Training time: 19118.8547\n",
      "Epoch : 1650/2000 data_batch_2,  Train_loss : 4681.6582  Test_loss : 5026.0361, Time/batch_file : 2.2923, Training time: 19121.1472\n",
      "Epoch : 1650/2000 data_batch_3,  Train_loss : 4850.8159  Test_loss : 4901.8164, Time/batch_file : 2.2838, Training time: 19123.4311\n",
      "Epoch : 1650/2000 data_batch_4,  Train_loss : 4690.4121  Test_loss : 5174.3140, Time/batch_file : 2.2713, Training time: 19125.7027\n",
      "Epoch : 1650/2000 data_batch_5,  Train_loss : 4521.2427  Test_loss : 5278.6865, Time/batch_file : 2.2891, Training time: 19127.9920\n",
      "[./nets/net-1650.ckpt] SAVED\n",
      "Epoch : 1651/2000 data_batch_1,  Train_loss : 4514.8242  Test_loss : 4350.8013, Time/batch_file : 2.2994, Training time: 19131.5634\n",
      "Epoch : 1651/2000 data_batch_2,  Train_loss : 4243.9106  Test_loss : 4241.1313, Time/batch_file : 2.2692, Training time: 19133.8328\n",
      "Epoch : 1651/2000 data_batch_3,  Train_loss : 4427.1646  Test_loss : 4443.6577, Time/batch_file : 2.2911, Training time: 19136.1241\n",
      "Epoch : 1651/2000 data_batch_4,  Train_loss : 4098.5859  Test_loss : 4279.2422, Time/batch_file : 2.2982, Training time: 19138.4225\n",
      "Epoch : 1651/2000 data_batch_5,  Train_loss : 4191.6445  Test_loss : 4529.5322, Time/batch_file : 2.2780, Training time: 19140.7007\n",
      "Epoch : 1652/2000 data_batch_1,  Train_loss : 4930.2402  Test_loss : 4878.7568, Time/batch_file : 2.2877, Training time: 19142.9886\n",
      "Epoch : 1652/2000 data_batch_2,  Train_loss : 5332.8975  Test_loss : 5051.5898, Time/batch_file : 2.2906, Training time: 19145.2795\n",
      "Epoch : 1652/2000 data_batch_3,  Train_loss : 4997.7163  Test_loss : 4680.8408, Time/batch_file : 2.2876, Training time: 19147.5673\n",
      "Epoch : 1652/2000 data_batch_4,  Train_loss : 4994.8560  Test_loss : 4821.6289, Time/batch_file : 2.2765, Training time: 19149.8440\n",
      "Epoch : 1652/2000 data_batch_5,  Train_loss : 5183.6294  Test_loss : 4883.1650, Time/batch_file : 2.2859, Training time: 19152.1300\n",
      "Epoch : 1653/2000 data_batch_1,  Train_loss : 4551.4985  Test_loss : 4909.5425, Time/batch_file : 2.2748, Training time: 19154.4051\n",
      "Epoch : 1653/2000 data_batch_2,  Train_loss : 4412.2544  Test_loss : 4913.0479, Time/batch_file : 2.2828, Training time: 19156.6881\n",
      "Epoch : 1653/2000 data_batch_3,  Train_loss : 4507.6855  Test_loss : 4971.6768, Time/batch_file : 2.2693, Training time: 19158.9576\n",
      "Epoch : 1653/2000 data_batch_4,  Train_loss : 4354.1294  Test_loss : 4723.5967, Time/batch_file : 2.2834, Training time: 19161.2411\n",
      "Epoch : 1653/2000 data_batch_5,  Train_loss : 4325.9375  Test_loss : 4874.5288, Time/batch_file : 2.2825, Training time: 19163.5238\n",
      "Epoch : 1654/2000 data_batch_1,  Train_loss : 4845.2520  Test_loss : 4342.5801, Time/batch_file : 2.2842, Training time: 19165.8082\n",
      "Epoch : 1654/2000 data_batch_2,  Train_loss : 4658.4360  Test_loss : 4554.1704, Time/batch_file : 2.2857, Training time: 19168.0943\n",
      "Epoch : 1654/2000 data_batch_3,  Train_loss : 4545.0098  Test_loss : 4521.8618, Time/batch_file : 2.2902, Training time: 19170.3848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1654/2000 data_batch_4,  Train_loss : 4791.4775  Test_loss : 4758.4180, Time/batch_file : 2.2797, Training time: 19172.6646\n",
      "Epoch : 1654/2000 data_batch_5,  Train_loss : 4529.0068  Test_loss : 4557.5420, Time/batch_file : 2.2888, Training time: 19174.9536\n",
      "Epoch : 1655/2000 data_batch_1,  Train_loss : 4625.8330  Test_loss : 4290.2080, Time/batch_file : 2.2749, Training time: 19177.2287\n",
      "Epoch : 1655/2000 data_batch_2,  Train_loss : 4491.8223  Test_loss : 4456.2012, Time/batch_file : 2.2911, Training time: 19179.5199\n",
      "Epoch : 1655/2000 data_batch_3,  Train_loss : 4723.5688  Test_loss : 4353.8779, Time/batch_file : 2.2776, Training time: 19181.7977\n",
      "Epoch : 1655/2000 data_batch_4,  Train_loss : 4792.0269  Test_loss : 4398.4512, Time/batch_file : 2.2908, Training time: 19184.0887\n",
      "Epoch : 1655/2000 data_batch_5,  Train_loss : 4543.7476  Test_loss : 4392.9023, Time/batch_file : 2.2795, Training time: 19186.3683\n",
      "Epoch : 1656/2000 data_batch_1,  Train_loss : 4394.5557  Test_loss : 4746.5806, Time/batch_file : 2.2709, Training time: 19188.6394\n",
      "Epoch : 1656/2000 data_batch_2,  Train_loss : 4589.0732  Test_loss : 4626.7075, Time/batch_file : 2.2745, Training time: 19190.9141\n",
      "Epoch : 1656/2000 data_batch_3,  Train_loss : 4590.3242  Test_loss : 4504.4487, Time/batch_file : 2.2823, Training time: 19193.1967\n",
      "Epoch : 1656/2000 data_batch_4,  Train_loss : 4900.7285  Test_loss : 4716.2256, Time/batch_file : 2.2712, Training time: 19195.4681\n",
      "Epoch : 1656/2000 data_batch_5,  Train_loss : 4440.4868  Test_loss : 4791.3643, Time/batch_file : 2.2761, Training time: 19197.7444\n",
      "Epoch : 1657/2000 data_batch_1,  Train_loss : 4668.2559  Test_loss : 4761.6426, Time/batch_file : 2.2857, Training time: 19200.0303\n",
      "Epoch : 1657/2000 data_batch_2,  Train_loss : 4914.6191  Test_loss : 4837.0859, Time/batch_file : 2.2860, Training time: 19202.3165\n",
      "Epoch : 1657/2000 data_batch_3,  Train_loss : 4740.2979  Test_loss : 5010.2988, Time/batch_file : 2.2866, Training time: 19204.6034\n",
      "Epoch : 1657/2000 data_batch_4,  Train_loss : 4913.5054  Test_loss : 4672.6499, Time/batch_file : 2.2876, Training time: 19206.8912\n",
      "Epoch : 1657/2000 data_batch_5,  Train_loss : 4898.4736  Test_loss : 4764.1538, Time/batch_file : 2.2771, Training time: 19209.1686\n",
      "Epoch : 1658/2000 data_batch_1,  Train_loss : 4396.1445  Test_loss : 4746.4033, Time/batch_file : 2.2745, Training time: 19211.4433\n",
      "Epoch : 1658/2000 data_batch_2,  Train_loss : 4404.7061  Test_loss : 4758.5117, Time/batch_file : 2.2783, Training time: 19213.7217\n",
      "Epoch : 1658/2000 data_batch_3,  Train_loss : 4463.1055  Test_loss : 4636.5723, Time/batch_file : 2.2758, Training time: 19215.9977\n",
      "Epoch : 1658/2000 data_batch_4,  Train_loss : 4612.7603  Test_loss : 4897.2847, Time/batch_file : 2.2630, Training time: 19218.2609\n",
      "Epoch : 1658/2000 data_batch_5,  Train_loss : 4493.0176  Test_loss : 5058.8882, Time/batch_file : 2.2938, Training time: 19220.5548\n",
      "Epoch : 1659/2000 data_batch_1,  Train_loss : 4315.0137  Test_loss : 5022.1758, Time/batch_file : 2.2823, Training time: 19222.8373\n",
      "Epoch : 1659/2000 data_batch_2,  Train_loss : 4312.9795  Test_loss : 4889.2109, Time/batch_file : 2.2733, Training time: 19225.1109\n",
      "Epoch : 1659/2000 data_batch_3,  Train_loss : 4299.5811  Test_loss : 4899.5664, Time/batch_file : 2.2605, Training time: 19227.3717\n",
      "Epoch : 1659/2000 data_batch_4,  Train_loss : 4280.1011  Test_loss : 4865.3647, Time/batch_file : 2.2675, Training time: 19229.6394\n",
      "Epoch : 1659/2000 data_batch_5,  Train_loss : 4113.2568  Test_loss : 5135.4448, Time/batch_file : 2.2663, Training time: 19231.9058\n",
      "Epoch : 1660/2000 data_batch_1,  Train_loss : 4310.8545  Test_loss : 4505.1929, Time/batch_file : 2.2906, Training time: 19234.1966\n",
      "Epoch : 1660/2000 data_batch_2,  Train_loss : 4527.5801  Test_loss : 4678.5034, Time/batch_file : 2.2805, Training time: 19236.4773\n",
      "Epoch : 1660/2000 data_batch_3,  Train_loss : 4456.1875  Test_loss : 4650.3408, Time/batch_file : 2.2861, Training time: 19238.7636\n",
      "Epoch : 1660/2000 data_batch_4,  Train_loss : 4486.9238  Test_loss : 4694.1592, Time/batch_file : 2.2822, Training time: 19241.0459\n",
      "Epoch : 1660/2000 data_batch_5,  Train_loss : 4469.7290  Test_loss : 4494.5269, Time/batch_file : 2.2875, Training time: 19243.3335\n",
      "[./nets/net-1660.ckpt] SAVED\n",
      "Epoch : 1661/2000 data_batch_1,  Train_loss : 4770.4922  Test_loss : 5119.7754, Time/batch_file : 2.3010, Training time: 19246.9052\n",
      "Epoch : 1661/2000 data_batch_2,  Train_loss : 4878.7749  Test_loss : 5076.5742, Time/batch_file : 2.2821, Training time: 19249.1876\n",
      "Epoch : 1661/2000 data_batch_3,  Train_loss : 4813.1665  Test_loss : 4894.0825, Time/batch_file : 2.2661, Training time: 19251.4539\n",
      "Epoch : 1661/2000 data_batch_4,  Train_loss : 4852.5596  Test_loss : 5110.2017, Time/batch_file : 2.2773, Training time: 19253.7314\n",
      "Epoch : 1661/2000 data_batch_5,  Train_loss : 4964.2969  Test_loss : 5084.1826, Time/batch_file : 2.2947, Training time: 19256.0264\n",
      "Epoch : 1662/2000 data_batch_1,  Train_loss : 4580.5444  Test_loss : 5173.4595, Time/batch_file : 2.3259, Training time: 19258.3525\n",
      "Epoch : 1662/2000 data_batch_2,  Train_loss : 4784.9043  Test_loss : 5132.7510, Time/batch_file : 2.2783, Training time: 19260.6311\n",
      "Epoch : 1662/2000 data_batch_3,  Train_loss : 4829.0273  Test_loss : 4628.0542, Time/batch_file : 2.2707, Training time: 19262.9021\n",
      "Epoch : 1662/2000 data_batch_4,  Train_loss : 4820.0088  Test_loss : 5055.5664, Time/batch_file : 2.2856, Training time: 19265.1880\n",
      "Epoch : 1662/2000 data_batch_5,  Train_loss : 4818.0859  Test_loss : 4853.6499, Time/batch_file : 2.2887, Training time: 19267.4769\n",
      "Epoch : 1663/2000 data_batch_1,  Train_loss : 4652.8955  Test_loss : 4415.7324, Time/batch_file : 2.2842, Training time: 19269.7613\n",
      "Epoch : 1663/2000 data_batch_2,  Train_loss : 4598.3633  Test_loss : 4231.2031, Time/batch_file : 2.2911, Training time: 19272.0526\n",
      "Epoch : 1663/2000 data_batch_3,  Train_loss : 4274.5093  Test_loss : 4217.3989, Time/batch_file : 2.3014, Training time: 19274.3542\n",
      "Epoch : 1663/2000 data_batch_4,  Train_loss : 4392.0205  Test_loss : 4566.7085, Time/batch_file : 2.2947, Training time: 19276.6491\n",
      "Epoch : 1663/2000 data_batch_5,  Train_loss : 4356.1719  Test_loss : 4490.0098, Time/batch_file : 2.2838, Training time: 19278.9331\n",
      "Epoch : 1664/2000 data_batch_1,  Train_loss : 4207.2456  Test_loss : 4872.9482, Time/batch_file : 2.2799, Training time: 19281.2132\n",
      "Epoch : 1664/2000 data_batch_2,  Train_loss : 4094.4878  Test_loss : 4842.2827, Time/batch_file : 2.2568, Training time: 19283.4701\n",
      "Epoch : 1664/2000 data_batch_3,  Train_loss : 4192.8828  Test_loss : 4901.0806, Time/batch_file : 2.2686, Training time: 19285.7389\n",
      "Epoch : 1664/2000 data_batch_4,  Train_loss : 4072.8511  Test_loss : 4764.4795, Time/batch_file : 2.2625, Training time: 19288.0016\n",
      "Epoch : 1664/2000 data_batch_5,  Train_loss : 4282.2241  Test_loss : 5187.7979, Time/batch_file : 2.2658, Training time: 19290.2676\n",
      "Epoch : 1665/2000 data_batch_1,  Train_loss : 4571.4541  Test_loss : 4886.6699, Time/batch_file : 2.2731, Training time: 19292.5410\n",
      "Epoch : 1665/2000 data_batch_2,  Train_loss : 4299.8477  Test_loss : 4767.2754, Time/batch_file : 2.2782, Training time: 19294.8193\n",
      "Epoch : 1665/2000 data_batch_3,  Train_loss : 4422.1987  Test_loss : 4890.5195, Time/batch_file : 2.2806, Training time: 19297.1001\n",
      "Epoch : 1665/2000 data_batch_4,  Train_loss : 4231.4404  Test_loss : 4926.2842, Time/batch_file : 2.2746, Training time: 19299.3750\n",
      "Epoch : 1665/2000 data_batch_5,  Train_loss : 4050.9863  Test_loss : 4805.5410, Time/batch_file : 2.2618, Training time: 19301.6371\n",
      "Epoch : 1666/2000 data_batch_1,  Train_loss : 4740.0244  Test_loss : 5147.1582, Time/batch_file : 2.2738, Training time: 19303.9111\n",
      "Epoch : 1666/2000 data_batch_2,  Train_loss : 4661.8936  Test_loss : 5455.0645, Time/batch_file : 2.2924, Training time: 19306.2037\n",
      "Epoch : 1666/2000 data_batch_3,  Train_loss : 4791.6675  Test_loss : 5239.0967, Time/batch_file : 2.2752, Training time: 19308.4792\n",
      "Epoch : 1666/2000 data_batch_4,  Train_loss : 4653.3555  Test_loss : 5285.5547, Time/batch_file : 2.2876, Training time: 19310.7669\n",
      "Epoch : 1666/2000 data_batch_5,  Train_loss : 4456.8491  Test_loss : 5055.0166, Time/batch_file : 2.2786, Training time: 19313.0457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1667/2000 data_batch_1,  Train_loss : 4678.8081  Test_loss : 5210.4746, Time/batch_file : 2.2932, Training time: 19315.3391\n",
      "Epoch : 1667/2000 data_batch_2,  Train_loss : 4529.9492  Test_loss : 5021.2114, Time/batch_file : 2.2778, Training time: 19317.6171\n",
      "Epoch : 1667/2000 data_batch_3,  Train_loss : 4528.9844  Test_loss : 5448.8096, Time/batch_file : 2.2871, Training time: 19319.9044\n",
      "Epoch : 1667/2000 data_batch_4,  Train_loss : 4635.3086  Test_loss : 5570.7173, Time/batch_file : 2.2826, Training time: 19322.1873\n",
      "Epoch : 1667/2000 data_batch_5,  Train_loss : 4729.7588  Test_loss : 5513.8906, Time/batch_file : 2.3023, Training time: 19324.4897\n",
      "Epoch : 1668/2000 data_batch_1,  Train_loss : 4521.7280  Test_loss : 5172.8398, Time/batch_file : 2.2858, Training time: 19326.7758\n",
      "Epoch : 1668/2000 data_batch_2,  Train_loss : 4135.2031  Test_loss : 5078.8916, Time/batch_file : 2.3019, Training time: 19329.0778\n",
      "Epoch : 1668/2000 data_batch_3,  Train_loss : 4422.8662  Test_loss : 5167.8735, Time/batch_file : 2.3068, Training time: 19331.3848\n",
      "Epoch : 1668/2000 data_batch_4,  Train_loss : 4407.0796  Test_loss : 4948.3027, Time/batch_file : 2.3032, Training time: 19333.6882\n",
      "Epoch : 1668/2000 data_batch_5,  Train_loss : 4313.2939  Test_loss : 5072.9072, Time/batch_file : 2.3091, Training time: 19335.9974\n",
      "Epoch : 1669/2000 data_batch_1,  Train_loss : 4592.7168  Test_loss : 4418.5859, Time/batch_file : 2.2746, Training time: 19338.2723\n",
      "Epoch : 1669/2000 data_batch_2,  Train_loss : 4585.7002  Test_loss : 4675.4038, Time/batch_file : 2.2748, Training time: 19340.5472\n",
      "Epoch : 1669/2000 data_batch_3,  Train_loss : 4632.5674  Test_loss : 4650.0659, Time/batch_file : 2.2881, Training time: 19342.8356\n",
      "Epoch : 1669/2000 data_batch_4,  Train_loss : 4742.3223  Test_loss : 4832.0459, Time/batch_file : 2.2678, Training time: 19345.1036\n",
      "Epoch : 1669/2000 data_batch_5,  Train_loss : 4651.0713  Test_loss : 4571.1411, Time/batch_file : 2.2950, Training time: 19347.3988\n",
      "Epoch : 1670/2000 data_batch_1,  Train_loss : 4237.1050  Test_loss : 4872.1812, Time/batch_file : 2.3011, Training time: 19349.7001\n",
      "Epoch : 1670/2000 data_batch_2,  Train_loss : 4389.5444  Test_loss : 4723.6621, Time/batch_file : 2.2876, Training time: 19351.9879\n",
      "Epoch : 1670/2000 data_batch_3,  Train_loss : 4607.7593  Test_loss : 5029.9629, Time/batch_file : 2.2870, Training time: 19354.2752\n",
      "Epoch : 1670/2000 data_batch_4,  Train_loss : 4255.3018  Test_loss : 4819.2051, Time/batch_file : 2.2930, Training time: 19356.5685\n",
      "Epoch : 1670/2000 data_batch_5,  Train_loss : 4264.5767  Test_loss : 5044.7588, Time/batch_file : 2.2961, Training time: 19358.8648\n",
      "[./nets/net-1670.ckpt] SAVED\n",
      "Epoch : 1671/2000 data_batch_1,  Train_loss : 4325.5078  Test_loss : 5534.4893, Time/batch_file : 2.3832, Training time: 19367.8732\n",
      "Epoch : 1671/2000 data_batch_2,  Train_loss : 4352.7578  Test_loss : 4768.3799, Time/batch_file : 2.2938, Training time: 19370.1673\n",
      "Epoch : 1671/2000 data_batch_3,  Train_loss : 4385.4771  Test_loss : 5135.3477, Time/batch_file : 2.3126, Training time: 19372.4801\n",
      "Epoch : 1671/2000 data_batch_4,  Train_loss : 4429.1177  Test_loss : 5316.2305, Time/batch_file : 2.3008, Training time: 19374.7811\n",
      "Epoch : 1671/2000 data_batch_5,  Train_loss : 4761.9482  Test_loss : 5114.8354, Time/batch_file : 2.2746, Training time: 19377.0559\n",
      "Epoch : 1672/2000 data_batch_1,  Train_loss : 4578.7627  Test_loss : 4530.1367, Time/batch_file : 2.3371, Training time: 19379.3931\n",
      "Epoch : 1672/2000 data_batch_2,  Train_loss : 4581.1670  Test_loss : 4579.2192, Time/batch_file : 2.2802, Training time: 19381.6735\n",
      "Epoch : 1672/2000 data_batch_3,  Train_loss : 4627.5928  Test_loss : 4577.3906, Time/batch_file : 2.2899, Training time: 19383.9635\n",
      "Epoch : 1672/2000 data_batch_4,  Train_loss : 4729.8164  Test_loss : 4510.1680, Time/batch_file : 2.3188, Training time: 19386.2825\n",
      "Epoch : 1672/2000 data_batch_5,  Train_loss : 4646.8052  Test_loss : 4518.2183, Time/batch_file : 2.2843, Training time: 19388.5670\n",
      "Epoch : 1673/2000 data_batch_1,  Train_loss : 4201.2109  Test_loss : 5191.3921, Time/batch_file : 2.2811, Training time: 19390.8483\n",
      "Epoch : 1673/2000 data_batch_2,  Train_loss : 4364.5483  Test_loss : 5208.6260, Time/batch_file : 2.2829, Training time: 19393.1314\n",
      "Epoch : 1673/2000 data_batch_3,  Train_loss : 4492.7598  Test_loss : 5362.6074, Time/batch_file : 2.2832, Training time: 19395.4149\n",
      "Epoch : 1673/2000 data_batch_4,  Train_loss : 4158.5615  Test_loss : 5007.8203, Time/batch_file : 2.2905, Training time: 19397.7056\n",
      "Epoch : 1673/2000 data_batch_5,  Train_loss : 4380.6357  Test_loss : 5043.6011, Time/batch_file : 2.3072, Training time: 19400.0130\n",
      "Epoch : 1674/2000 data_batch_1,  Train_loss : 4820.6826  Test_loss : 4822.5244, Time/batch_file : 2.3043, Training time: 19402.3174\n",
      "Epoch : 1674/2000 data_batch_2,  Train_loss : 4458.7861  Test_loss : 4792.8345, Time/batch_file : 2.2919, Training time: 19404.6095\n",
      "Epoch : 1674/2000 data_batch_3,  Train_loss : 4745.9868  Test_loss : 4916.5723, Time/batch_file : 2.2952, Training time: 19406.9049\n",
      "Epoch : 1674/2000 data_batch_4,  Train_loss : 4703.1919  Test_loss : 4780.6172, Time/batch_file : 2.3018, Training time: 19409.2069\n",
      "Epoch : 1674/2000 data_batch_5,  Train_loss : 4685.8467  Test_loss : 4861.0244, Time/batch_file : 2.2955, Training time: 19411.5025\n",
      "Epoch : 1675/2000 data_batch_1,  Train_loss : 4490.2114  Test_loss : 4394.7178, Time/batch_file : 2.3096, Training time: 19413.8123\n",
      "Epoch : 1675/2000 data_batch_2,  Train_loss : 4664.0991  Test_loss : 4750.0781, Time/batch_file : 2.2978, Training time: 19416.1104\n",
      "Epoch : 1675/2000 data_batch_3,  Train_loss : 4883.4023  Test_loss : 4468.8086, Time/batch_file : 2.2949, Training time: 19418.4055\n",
      "Epoch : 1675/2000 data_batch_4,  Train_loss : 4579.4917  Test_loss : 4622.8867, Time/batch_file : 2.3020, Training time: 19420.7077\n",
      "Epoch : 1675/2000 data_batch_5,  Train_loss : 4763.9141  Test_loss : 4515.8188, Time/batch_file : 2.3052, Training time: 19423.0132\n",
      "Epoch : 1676/2000 data_batch_1,  Train_loss : 4652.8940  Test_loss : 4784.2729, Time/batch_file : 2.3006, Training time: 19425.3139\n",
      "Epoch : 1676/2000 data_batch_2,  Train_loss : 4813.2998  Test_loss : 4806.2183, Time/batch_file : 2.3053, Training time: 19427.6194\n",
      "Epoch : 1676/2000 data_batch_3,  Train_loss : 4687.6230  Test_loss : 4876.2090, Time/batch_file : 2.3135, Training time: 19429.9331\n",
      "Epoch : 1676/2000 data_batch_4,  Train_loss : 4706.0596  Test_loss : 5028.2598, Time/batch_file : 2.2896, Training time: 19432.2229\n",
      "Epoch : 1676/2000 data_batch_5,  Train_loss : 4751.1689  Test_loss : 4881.6558, Time/batch_file : 2.2997, Training time: 19434.5229\n",
      "Epoch : 1677/2000 data_batch_1,  Train_loss : 4398.3994  Test_loss : 4824.2368, Time/batch_file : 2.2720, Training time: 19436.7951\n",
      "Epoch : 1677/2000 data_batch_2,  Train_loss : 4383.1079  Test_loss : 4861.0713, Time/batch_file : 2.2615, Training time: 19439.0568\n",
      "Epoch : 1677/2000 data_batch_3,  Train_loss : 4321.7310  Test_loss : 4766.3960, Time/batch_file : 2.2942, Training time: 19441.3513\n",
      "Epoch : 1677/2000 data_batch_4,  Train_loss : 4181.2676  Test_loss : 4449.6260, Time/batch_file : 2.2733, Training time: 19443.6248\n",
      "Epoch : 1677/2000 data_batch_5,  Train_loss : 4011.2822  Test_loss : 4543.3149, Time/batch_file : 2.2658, Training time: 19445.8908\n",
      "Epoch : 1678/2000 data_batch_1,  Train_loss : 4404.5811  Test_loss : 4657.3887, Time/batch_file : 2.2859, Training time: 19448.1768\n",
      "Epoch : 1678/2000 data_batch_2,  Train_loss : 4440.0303  Test_loss : 5227.3242, Time/batch_file : 2.2808, Training time: 19450.4579\n",
      "Epoch : 1678/2000 data_batch_3,  Train_loss : 4413.0991  Test_loss : 5155.1826, Time/batch_file : 2.2762, Training time: 19452.7343\n",
      "Epoch : 1678/2000 data_batch_4,  Train_loss : 4423.7866  Test_loss : 5119.5786, Time/batch_file : 2.2956, Training time: 19455.0300\n",
      "Epoch : 1678/2000 data_batch_5,  Train_loss : 4323.6284  Test_loss : 4920.0449, Time/batch_file : 2.2883, Training time: 19457.3185\n",
      "Epoch : 1679/2000 data_batch_1,  Train_loss : 4473.9141  Test_loss : 5117.9648, Time/batch_file : 2.2921, Training time: 19459.6109\n",
      "Epoch : 1679/2000 data_batch_2,  Train_loss : 4070.7495  Test_loss : 5536.3340, Time/batch_file : 2.2983, Training time: 19461.9094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1679/2000 data_batch_3,  Train_loss : 4360.2480  Test_loss : 5540.1426, Time/batch_file : 2.2946, Training time: 19464.2042\n",
      "Epoch : 1679/2000 data_batch_4,  Train_loss : 4472.6465  Test_loss : 4954.7847, Time/batch_file : 2.2970, Training time: 19466.5014\n",
      "Epoch : 1679/2000 data_batch_5,  Train_loss : 4278.2310  Test_loss : 5240.6353, Time/batch_file : 2.3253, Training time: 19468.8269\n",
      "Epoch : 1680/2000 data_batch_1,  Train_loss : 4603.5508  Test_loss : 5018.4434, Time/batch_file : 2.2921, Training time: 19471.1192\n",
      "Epoch : 1680/2000 data_batch_2,  Train_loss : 4401.6235  Test_loss : 4786.4248, Time/batch_file : 2.2939, Training time: 19473.4134\n",
      "Epoch : 1680/2000 data_batch_3,  Train_loss : 4607.8867  Test_loss : 4799.0112, Time/batch_file : 2.2801, Training time: 19475.6937\n",
      "Epoch : 1680/2000 data_batch_4,  Train_loss : 4238.8950  Test_loss : 4937.0732, Time/batch_file : 2.2816, Training time: 19477.9755\n",
      "Epoch : 1680/2000 data_batch_5,  Train_loss : 4494.8428  Test_loss : 4779.7124, Time/batch_file : 2.2983, Training time: 19480.2740\n",
      "[./nets/net-1680.ckpt] SAVED\n",
      "Epoch : 1681/2000 data_batch_1,  Train_loss : 5089.9160  Test_loss : 4950.8237, Time/batch_file : 2.3345, Training time: 19483.9144\n",
      "Epoch : 1681/2000 data_batch_2,  Train_loss : 4873.2310  Test_loss : 5264.7939, Time/batch_file : 2.3052, Training time: 19486.2198\n",
      "Epoch : 1681/2000 data_batch_3,  Train_loss : 4760.4883  Test_loss : 4589.2368, Time/batch_file : 2.2958, Training time: 19488.5159\n",
      "Epoch : 1681/2000 data_batch_4,  Train_loss : 5036.9053  Test_loss : 5052.0918, Time/batch_file : 2.3070, Training time: 19490.8231\n",
      "Epoch : 1681/2000 data_batch_5,  Train_loss : 4975.2266  Test_loss : 5385.3911, Time/batch_file : 2.2675, Training time: 19493.0908\n",
      "Epoch : 1682/2000 data_batch_1,  Train_loss : 4775.6265  Test_loss : 4615.9692, Time/batch_file : 2.3286, Training time: 19495.4195\n",
      "Epoch : 1682/2000 data_batch_2,  Train_loss : 4800.4053  Test_loss : 4792.5015, Time/batch_file : 2.3154, Training time: 19497.7352\n",
      "Epoch : 1682/2000 data_batch_3,  Train_loss : 4856.7954  Test_loss : 4666.3364, Time/batch_file : 2.3140, Training time: 19500.0495\n",
      "Epoch : 1682/2000 data_batch_4,  Train_loss : 4857.6763  Test_loss : 4606.4199, Time/batch_file : 2.2864, Training time: 19502.3360\n",
      "Epoch : 1682/2000 data_batch_5,  Train_loss : 5067.0166  Test_loss : 4815.8770, Time/batch_file : 2.3010, Training time: 19504.6373\n",
      "Epoch : 1683/2000 data_batch_1,  Train_loss : 4470.2715  Test_loss : 5084.9229, Time/batch_file : 2.3019, Training time: 19506.9394\n",
      "Epoch : 1683/2000 data_batch_2,  Train_loss : 4515.6450  Test_loss : 5234.9458, Time/batch_file : 2.2591, Training time: 19509.1987\n",
      "Epoch : 1683/2000 data_batch_3,  Train_loss : 4614.2285  Test_loss : 5094.5234, Time/batch_file : 2.2739, Training time: 19511.4727\n",
      "Epoch : 1683/2000 data_batch_4,  Train_loss : 4543.6372  Test_loss : 5115.6582, Time/batch_file : 2.2955, Training time: 19513.7683\n",
      "Epoch : 1683/2000 data_batch_5,  Train_loss : 4106.4072  Test_loss : 5272.8584, Time/batch_file : 2.2724, Training time: 19516.0409\n",
      "Epoch : 1684/2000 data_batch_1,  Train_loss : 4774.0381  Test_loss : 5109.1011, Time/batch_file : 2.2785, Training time: 19518.3195\n",
      "Epoch : 1684/2000 data_batch_2,  Train_loss : 4766.5410  Test_loss : 4892.9502, Time/batch_file : 2.3122, Training time: 19520.6320\n",
      "Epoch : 1684/2000 data_batch_3,  Train_loss : 4476.6025  Test_loss : 4838.2026, Time/batch_file : 2.2606, Training time: 19522.8928\n",
      "Epoch : 1684/2000 data_batch_4,  Train_loss : 4899.7207  Test_loss : 5052.6304, Time/batch_file : 2.2760, Training time: 19525.1691\n",
      "Epoch : 1684/2000 data_batch_5,  Train_loss : 4677.6367  Test_loss : 4713.6152, Time/batch_file : 2.2818, Training time: 19527.4511\n",
      "Epoch : 1685/2000 data_batch_1,  Train_loss : 4247.6333  Test_loss : 4297.3853, Time/batch_file : 2.2642, Training time: 19529.7155\n",
      "Epoch : 1685/2000 data_batch_2,  Train_loss : 4512.2451  Test_loss : 4395.5674, Time/batch_file : 2.2820, Training time: 19531.9978\n",
      "Epoch : 1685/2000 data_batch_3,  Train_loss : 4531.0322  Test_loss : 4641.0879, Time/batch_file : 2.2919, Training time: 19534.2898\n",
      "Epoch : 1685/2000 data_batch_4,  Train_loss : 4217.2524  Test_loss : 4576.7769, Time/batch_file : 2.2660, Training time: 19536.5561\n",
      "Epoch : 1685/2000 data_batch_5,  Train_loss : 4314.2061  Test_loss : 4540.0298, Time/batch_file : 2.2899, Training time: 19538.8462\n",
      "Epoch : 1686/2000 data_batch_1,  Train_loss : 4960.9688  Test_loss : 4900.2139, Time/batch_file : 2.2869, Training time: 19541.1332\n",
      "Epoch : 1686/2000 data_batch_2,  Train_loss : 5187.6572  Test_loss : 4859.7202, Time/batch_file : 2.2546, Training time: 19543.3880\n",
      "Epoch : 1686/2000 data_batch_3,  Train_loss : 4962.5303  Test_loss : 4904.7266, Time/batch_file : 2.2758, Training time: 19545.6640\n",
      "Epoch : 1686/2000 data_batch_4,  Train_loss : 5057.8813  Test_loss : 4461.3223, Time/batch_file : 2.2863, Training time: 19547.9506\n",
      "Epoch : 1686/2000 data_batch_5,  Train_loss : 5088.1553  Test_loss : 4876.0532, Time/batch_file : 2.2598, Training time: 19550.2105\n",
      "Epoch : 1687/2000 data_batch_1,  Train_loss : 4518.6455  Test_loss : 4707.3115, Time/batch_file : 2.2714, Training time: 19552.4822\n",
      "Epoch : 1687/2000 data_batch_2,  Train_loss : 4726.7026  Test_loss : 4604.4536, Time/batch_file : 2.2837, Training time: 19554.7662\n",
      "Epoch : 1687/2000 data_batch_3,  Train_loss : 4408.0938  Test_loss : 4627.8208, Time/batch_file : 2.2703, Training time: 19557.0367\n",
      "Epoch : 1687/2000 data_batch_4,  Train_loss : 4542.9736  Test_loss : 4630.2129, Time/batch_file : 2.2706, Training time: 19559.3075\n",
      "Epoch : 1687/2000 data_batch_5,  Train_loss : 4590.2437  Test_loss : 4573.3447, Time/batch_file : 2.2855, Training time: 19561.5933\n",
      "Epoch : 1688/2000 data_batch_1,  Train_loss : 4697.6504  Test_loss : 5533.1606, Time/batch_file : 2.2839, Training time: 19563.8774\n",
      "Epoch : 1688/2000 data_batch_2,  Train_loss : 4863.9263  Test_loss : 5144.1860, Time/batch_file : 2.2993, Training time: 19566.1769\n",
      "Epoch : 1688/2000 data_batch_3,  Train_loss : 4916.1841  Test_loss : 5265.1973, Time/batch_file : 2.2976, Training time: 19568.4747\n",
      "Epoch : 1688/2000 data_batch_4,  Train_loss : 4815.9233  Test_loss : 5164.7510, Time/batch_file : 2.2747, Training time: 19570.7496\n",
      "Epoch : 1688/2000 data_batch_5,  Train_loss : 4749.4873  Test_loss : 5380.0469, Time/batch_file : 2.2789, Training time: 19573.0286\n",
      "Epoch : 1689/2000 data_batch_1,  Train_loss : 4169.3154  Test_loss : 5051.0830, Time/batch_file : 2.3025, Training time: 19575.3313\n",
      "Epoch : 1689/2000 data_batch_2,  Train_loss : 4202.6172  Test_loss : 5310.1934, Time/batch_file : 2.2726, Training time: 19577.6041\n",
      "Epoch : 1689/2000 data_batch_3,  Train_loss : 4271.3496  Test_loss : 5082.0029, Time/batch_file : 2.2968, Training time: 19579.9012\n",
      "Epoch : 1689/2000 data_batch_4,  Train_loss : 4253.8926  Test_loss : 5212.2954, Time/batch_file : 2.2915, Training time: 19582.1930\n",
      "Epoch : 1689/2000 data_batch_5,  Train_loss : 4313.4204  Test_loss : 4896.8081, Time/batch_file : 2.2910, Training time: 19584.4841\n",
      "Epoch : 1690/2000 data_batch_1,  Train_loss : 4309.0840  Test_loss : 5074.7720, Time/batch_file : 2.2991, Training time: 19586.7834\n",
      "Epoch : 1690/2000 data_batch_2,  Train_loss : 4204.1060  Test_loss : 5195.8770, Time/batch_file : 2.2990, Training time: 19589.0827\n",
      "Epoch : 1690/2000 data_batch_3,  Train_loss : 4106.2070  Test_loss : 5429.3164, Time/batch_file : 2.2781, Training time: 19591.3610\n",
      "Epoch : 1690/2000 data_batch_4,  Train_loss : 4263.1846  Test_loss : 5176.4854, Time/batch_file : 2.2968, Training time: 19593.6581\n",
      "Epoch : 1690/2000 data_batch_5,  Train_loss : 4051.0762  Test_loss : 5240.4658, Time/batch_file : 2.3022, Training time: 19595.9605\n",
      "[./nets/net-1690.ckpt] SAVED\n",
      "Epoch : 1691/2000 data_batch_1,  Train_loss : 5002.9502  Test_loss : 4945.2544, Time/batch_file : 2.3529, Training time: 19599.6097\n",
      "Epoch : 1691/2000 data_batch_2,  Train_loss : 5108.7319  Test_loss : 4873.8413, Time/batch_file : 2.2643, Training time: 19601.8742\n",
      "Epoch : 1691/2000 data_batch_3,  Train_loss : 4935.9194  Test_loss : 4745.8931, Time/batch_file : 2.2618, Training time: 19604.1362\n",
      "Epoch : 1691/2000 data_batch_4,  Train_loss : 4987.5107  Test_loss : 5014.8550, Time/batch_file : 2.2828, Training time: 19606.4192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1691/2000 data_batch_5,  Train_loss : 5210.5562  Test_loss : 4652.6641, Time/batch_file : 2.2632, Training time: 19608.6826\n",
      "Epoch : 1692/2000 data_batch_1,  Train_loss : 4386.4277  Test_loss : 4685.5254, Time/batch_file : 2.2944, Training time: 19610.9771\n",
      "Epoch : 1692/2000 data_batch_2,  Train_loss : 4323.8213  Test_loss : 4638.4570, Time/batch_file : 2.2498, Training time: 19613.2271\n",
      "Epoch : 1692/2000 data_batch_3,  Train_loss : 4700.2993  Test_loss : 4767.0151, Time/batch_file : 2.2904, Training time: 19615.5177\n",
      "Epoch : 1692/2000 data_batch_4,  Train_loss : 4339.5962  Test_loss : 4740.1401, Time/batch_file : 2.2794, Training time: 19617.7975\n",
      "Epoch : 1692/2000 data_batch_5,  Train_loss : 4346.1011  Test_loss : 4597.0259, Time/batch_file : 2.2964, Training time: 19620.0942\n",
      "Epoch : 1693/2000 data_batch_1,  Train_loss : 4375.3237  Test_loss : 4713.0308, Time/batch_file : 2.3090, Training time: 19622.4033\n",
      "Epoch : 1693/2000 data_batch_2,  Train_loss : 4442.9307  Test_loss : 4593.0195, Time/batch_file : 2.3058, Training time: 19624.7093\n",
      "Epoch : 1693/2000 data_batch_3,  Train_loss : 4544.2158  Test_loss : 4662.1182, Time/batch_file : 2.2960, Training time: 19627.0055\n",
      "Epoch : 1693/2000 data_batch_4,  Train_loss : 4754.6348  Test_loss : 4605.7334, Time/batch_file : 2.2883, Training time: 19629.2940\n",
      "Epoch : 1693/2000 data_batch_5,  Train_loss : 4840.1758  Test_loss : 4803.1719, Time/batch_file : 2.2786, Training time: 19631.5728\n",
      "Epoch : 1694/2000 data_batch_1,  Train_loss : 4342.6953  Test_loss : 4751.0449, Time/batch_file : 2.2722, Training time: 19633.8451\n",
      "Epoch : 1694/2000 data_batch_2,  Train_loss : 4503.4639  Test_loss : 4705.2969, Time/batch_file : 2.2836, Training time: 19636.1288\n",
      "Epoch : 1694/2000 data_batch_3,  Train_loss : 4496.7520  Test_loss : 4733.6792, Time/batch_file : 2.2822, Training time: 19638.4113\n",
      "Epoch : 1694/2000 data_batch_4,  Train_loss : 4474.9756  Test_loss : 4728.8301, Time/batch_file : 2.2659, Training time: 19640.6775\n",
      "Epoch : 1694/2000 data_batch_5,  Train_loss : 4545.3882  Test_loss : 5054.1611, Time/batch_file : 2.2754, Training time: 19642.9531\n",
      "Epoch : 1695/2000 data_batch_1,  Train_loss : 4752.6777  Test_loss : 4836.4604, Time/batch_file : 2.2756, Training time: 19645.2289\n",
      "Epoch : 1695/2000 data_batch_2,  Train_loss : 4760.1372  Test_loss : 4899.6069, Time/batch_file : 2.2766, Training time: 19647.5058\n",
      "Epoch : 1695/2000 data_batch_3,  Train_loss : 4909.0947  Test_loss : 4422.0640, Time/batch_file : 2.2913, Training time: 19649.7974\n",
      "Epoch : 1695/2000 data_batch_4,  Train_loss : 4609.3994  Test_loss : 4427.9868, Time/batch_file : 2.2782, Training time: 19652.0757\n",
      "Epoch : 1695/2000 data_batch_5,  Train_loss : 4708.0229  Test_loss : 5085.1084, Time/batch_file : 2.3000, Training time: 19654.3760\n",
      "Epoch : 1696/2000 data_batch_1,  Train_loss : 4337.4702  Test_loss : 4461.1514, Time/batch_file : 2.2878, Training time: 19656.6639\n",
      "Epoch : 1696/2000 data_batch_2,  Train_loss : 4522.4795  Test_loss : 4149.0664, Time/batch_file : 2.3118, Training time: 19658.9758\n",
      "Epoch : 1696/2000 data_batch_3,  Train_loss : 4237.7178  Test_loss : 4103.4102, Time/batch_file : 2.2778, Training time: 19661.2538\n",
      "Epoch : 1696/2000 data_batch_4,  Train_loss : 4477.1123  Test_loss : 4234.6392, Time/batch_file : 2.3098, Training time: 19663.5639\n",
      "Epoch : 1696/2000 data_batch_5,  Train_loss : 4672.4766  Test_loss : 3971.6021, Time/batch_file : 2.2783, Training time: 19665.8424\n",
      "Epoch : 1697/2000 data_batch_1,  Train_loss : 4864.0088  Test_loss : 4733.3989, Time/batch_file : 2.2934, Training time: 19668.1359\n",
      "Epoch : 1697/2000 data_batch_2,  Train_loss : 4936.0044  Test_loss : 4852.3521, Time/batch_file : 2.2696, Training time: 19670.4058\n",
      "Epoch : 1697/2000 data_batch_3,  Train_loss : 4923.1299  Test_loss : 4913.6880, Time/batch_file : 2.2868, Training time: 19672.6928\n",
      "Epoch : 1697/2000 data_batch_4,  Train_loss : 4788.0820  Test_loss : 4757.6958, Time/batch_file : 2.2887, Training time: 19674.9817\n",
      "Epoch : 1697/2000 data_batch_5,  Train_loss : 4479.7319  Test_loss : 4837.5596, Time/batch_file : 2.2914, Training time: 19677.2733\n",
      "Epoch : 1698/2000 data_batch_1,  Train_loss : 4828.3120  Test_loss : 4636.1899, Time/batch_file : 2.2767, Training time: 19679.5501\n",
      "Epoch : 1698/2000 data_batch_2,  Train_loss : 4754.1299  Test_loss : 4890.4482, Time/batch_file : 2.3022, Training time: 19681.8526\n",
      "Epoch : 1698/2000 data_batch_3,  Train_loss : 4956.4424  Test_loss : 4730.2266, Time/batch_file : 2.2886, Training time: 19684.1413\n",
      "Epoch : 1698/2000 data_batch_4,  Train_loss : 4444.7793  Test_loss : 4792.8643, Time/batch_file : 2.3036, Training time: 19686.4451\n",
      "Epoch : 1698/2000 data_batch_5,  Train_loss : 4769.6191  Test_loss : 4983.8916, Time/batch_file : 2.2719, Training time: 19688.7171\n",
      "Epoch : 1699/2000 data_batch_1,  Train_loss : 4845.3662  Test_loss : 5213.2334, Time/batch_file : 2.3140, Training time: 19691.0313\n",
      "Epoch : 1699/2000 data_batch_2,  Train_loss : 4828.7598  Test_loss : 5493.9258, Time/batch_file : 2.2730, Training time: 19693.3045\n",
      "Epoch : 1699/2000 data_batch_3,  Train_loss : 4798.3525  Test_loss : 5188.9043, Time/batch_file : 2.3050, Training time: 19695.6097\n",
      "Epoch : 1699/2000 data_batch_4,  Train_loss : 4654.8779  Test_loss : 5217.9927, Time/batch_file : 2.2750, Training time: 19697.8849\n",
      "Epoch : 1699/2000 data_batch_5,  Train_loss : 5037.7534  Test_loss : 5308.7158, Time/batch_file : 2.2999, Training time: 19700.1852\n",
      "Epoch : 1700/2000 data_batch_1,  Train_loss : 5102.4443  Test_loss : 4875.5840, Time/batch_file : 2.2864, Training time: 19702.4718\n",
      "Epoch : 1700/2000 data_batch_2,  Train_loss : 4791.0752  Test_loss : 5032.8496, Time/batch_file : 2.2928, Training time: 19704.7648\n",
      "Epoch : 1700/2000 data_batch_3,  Train_loss : 4992.6099  Test_loss : 5215.9863, Time/batch_file : 2.2749, Training time: 19707.0400\n",
      "Epoch : 1700/2000 data_batch_4,  Train_loss : 5029.2251  Test_loss : 4845.0205, Time/batch_file : 2.3119, Training time: 19709.3522\n",
      "Epoch : 1700/2000 data_batch_5,  Train_loss : 4831.3896  Test_loss : 5105.6494, Time/batch_file : 2.2839, Training time: 19711.6363\n",
      "[./nets/net-1700.ckpt] SAVED\n",
      "Epoch : 1701/2000 data_batch_1,  Train_loss : 4170.5947  Test_loss : 4469.6353, Time/batch_file : 2.4835, Training time: 19715.4019\n",
      "Epoch : 1701/2000 data_batch_2,  Train_loss : 4385.6816  Test_loss : 4602.7944, Time/batch_file : 2.2761, Training time: 19717.6782\n",
      "Epoch : 1701/2000 data_batch_3,  Train_loss : 4439.4219  Test_loss : 4429.2339, Time/batch_file : 2.3046, Training time: 19719.9830\n",
      "Epoch : 1701/2000 data_batch_4,  Train_loss : 4446.7144  Test_loss : 4471.6309, Time/batch_file : 2.2917, Training time: 19722.2748\n",
      "Epoch : 1701/2000 data_batch_5,  Train_loss : 4368.4980  Test_loss : 4414.0576, Time/batch_file : 2.3079, Training time: 19724.5829\n",
      "Epoch : 1702/2000 data_batch_1,  Train_loss : 4694.9834  Test_loss : 4765.7305, Time/batch_file : 2.2751, Training time: 19726.8581\n",
      "Epoch : 1702/2000 data_batch_2,  Train_loss : 4481.9009  Test_loss : 4846.2520, Time/batch_file : 2.2842, Training time: 19729.1425\n",
      "Epoch : 1702/2000 data_batch_3,  Train_loss : 4357.3696  Test_loss : 4743.1055, Time/batch_file : 2.2671, Training time: 19731.4098\n",
      "Epoch : 1702/2000 data_batch_4,  Train_loss : 4438.9121  Test_loss : 4726.3853, Time/batch_file : 2.2659, Training time: 19733.6760\n",
      "Epoch : 1702/2000 data_batch_5,  Train_loss : 4352.9189  Test_loss : 4642.8745, Time/batch_file : 2.2623, Training time: 19735.9385\n",
      "Epoch : 1703/2000 data_batch_1,  Train_loss : 4749.7915  Test_loss : 4696.8169, Time/batch_file : 2.3293, Training time: 19738.2681\n",
      "Epoch : 1703/2000 data_batch_2,  Train_loss : 4763.4116  Test_loss : 4789.7266, Time/batch_file : 2.2972, Training time: 19740.5655\n",
      "Epoch : 1703/2000 data_batch_3,  Train_loss : 4886.9912  Test_loss : 4412.7983, Time/batch_file : 2.2921, Training time: 19742.8578\n",
      "Epoch : 1703/2000 data_batch_4,  Train_loss : 4612.5996  Test_loss : 4797.4512, Time/batch_file : 2.2734, Training time: 19745.1315\n",
      "Epoch : 1703/2000 data_batch_5,  Train_loss : 4568.7021  Test_loss : 4014.5693, Time/batch_file : 2.2897, Training time: 19747.4214\n",
      "Epoch : 1704/2000 data_batch_1,  Train_loss : 5112.4795  Test_loss : 4965.7607, Time/batch_file : 2.2594, Training time: 19749.6811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1704/2000 data_batch_2,  Train_loss : 5138.2690  Test_loss : 4898.9331, Time/batch_file : 2.2531, Training time: 19751.9344\n",
      "Epoch : 1704/2000 data_batch_3,  Train_loss : 4940.2793  Test_loss : 5045.0254, Time/batch_file : 2.2725, Training time: 19754.2071\n",
      "Epoch : 1704/2000 data_batch_4,  Train_loss : 5090.1348  Test_loss : 5123.2905, Time/batch_file : 2.2568, Training time: 19756.4641\n",
      "Epoch : 1704/2000 data_batch_5,  Train_loss : 4792.6895  Test_loss : 4966.4009, Time/batch_file : 2.2588, Training time: 19758.7231\n",
      "Epoch : 1705/2000 data_batch_1,  Train_loss : 4696.3267  Test_loss : 4763.0508, Time/batch_file : 2.2804, Training time: 19761.0037\n",
      "Epoch : 1705/2000 data_batch_2,  Train_loss : 4516.4854  Test_loss : 5050.8843, Time/batch_file : 2.2702, Training time: 19763.2741\n",
      "Epoch : 1705/2000 data_batch_3,  Train_loss : 4631.3682  Test_loss : 4980.9414, Time/batch_file : 2.2807, Training time: 19765.5549\n",
      "Epoch : 1705/2000 data_batch_4,  Train_loss : 4618.2271  Test_loss : 4880.3647, Time/batch_file : 2.2815, Training time: 19767.8366\n",
      "Epoch : 1705/2000 data_batch_5,  Train_loss : 4605.6680  Test_loss : 4982.3867, Time/batch_file : 2.2850, Training time: 19770.1218\n",
      "Epoch : 1706/2000 data_batch_1,  Train_loss : 5079.3672  Test_loss : 5037.2261, Time/batch_file : 2.2520, Training time: 19772.3740\n",
      "Epoch : 1706/2000 data_batch_2,  Train_loss : 4736.3867  Test_loss : 5086.3804, Time/batch_file : 2.2756, Training time: 19774.6498\n",
      "Epoch : 1706/2000 data_batch_3,  Train_loss : 4709.2280  Test_loss : 5057.2056, Time/batch_file : 2.2636, Training time: 19776.9136\n",
      "Epoch : 1706/2000 data_batch_4,  Train_loss : 4748.7666  Test_loss : 5023.4541, Time/batch_file : 2.2650, Training time: 19779.1788\n",
      "Epoch : 1706/2000 data_batch_5,  Train_loss : 4993.6406  Test_loss : 4989.4097, Time/batch_file : 2.2828, Training time: 19781.4617\n",
      "Epoch : 1707/2000 data_batch_1,  Train_loss : 4749.4927  Test_loss : 4717.5220, Time/batch_file : 2.2908, Training time: 19783.7527\n",
      "Epoch : 1707/2000 data_batch_2,  Train_loss : 4525.3223  Test_loss : 4907.2598, Time/batch_file : 2.2665, Training time: 19786.0194\n",
      "Epoch : 1707/2000 data_batch_3,  Train_loss : 4802.8359  Test_loss : 4914.1494, Time/batch_file : 2.2888, Training time: 19788.3085\n",
      "Epoch : 1707/2000 data_batch_4,  Train_loss : 5004.1201  Test_loss : 5040.5073, Time/batch_file : 2.2744, Training time: 19790.5831\n",
      "Epoch : 1707/2000 data_batch_5,  Train_loss : 4539.1328  Test_loss : 4800.6875, Time/batch_file : 2.2733, Training time: 19792.8566\n",
      "Epoch : 1708/2000 data_batch_1,  Train_loss : 4894.0317  Test_loss : 4631.5850, Time/batch_file : 2.2674, Training time: 19795.1242\n",
      "Epoch : 1708/2000 data_batch_2,  Train_loss : 4975.7769  Test_loss : 4781.4370, Time/batch_file : 2.2806, Training time: 19797.4050\n",
      "Epoch : 1708/2000 data_batch_3,  Train_loss : 5072.1436  Test_loss : 4368.9629, Time/batch_file : 2.2627, Training time: 19799.6679\n",
      "Epoch : 1708/2000 data_batch_4,  Train_loss : 4814.8828  Test_loss : 4419.3574, Time/batch_file : 2.2685, Training time: 19801.9367\n",
      "Epoch : 1708/2000 data_batch_5,  Train_loss : 5098.6553  Test_loss : 4554.8530, Time/batch_file : 2.2609, Training time: 19804.1978\n",
      "Epoch : 1709/2000 data_batch_1,  Train_loss : 4831.1201  Test_loss : 4835.8779, Time/batch_file : 2.3075, Training time: 19806.5056\n",
      "Epoch : 1709/2000 data_batch_2,  Train_loss : 4726.1313  Test_loss : 4712.3438, Time/batch_file : 2.2758, Training time: 19808.7817\n",
      "Epoch : 1709/2000 data_batch_3,  Train_loss : 4738.4434  Test_loss : 4827.3687, Time/batch_file : 2.3054, Training time: 19811.0874\n",
      "Epoch : 1709/2000 data_batch_4,  Train_loss : 4632.1523  Test_loss : 5093.0020, Time/batch_file : 2.2807, Training time: 19813.3684\n",
      "Epoch : 1709/2000 data_batch_5,  Train_loss : 4810.7158  Test_loss : 5160.9966, Time/batch_file : 2.2778, Training time: 19815.6464\n",
      "Epoch : 1710/2000 data_batch_1,  Train_loss : 4651.2925  Test_loss : 4828.7290, Time/batch_file : 2.2895, Training time: 19817.9361\n",
      "Epoch : 1710/2000 data_batch_2,  Train_loss : 4803.6074  Test_loss : 4459.6836, Time/batch_file : 2.2895, Training time: 19820.2259\n",
      "Epoch : 1710/2000 data_batch_3,  Train_loss : 4762.1973  Test_loss : 4831.7412, Time/batch_file : 2.2869, Training time: 19822.5130\n",
      "Epoch : 1710/2000 data_batch_4,  Train_loss : 4886.9458  Test_loss : 4765.2080, Time/batch_file : 2.2570, Training time: 19824.7703\n",
      "Epoch : 1710/2000 data_batch_5,  Train_loss : 5149.8179  Test_loss : 4970.5439, Time/batch_file : 2.2617, Training time: 19827.0322\n",
      "[./nets/net-1710.ckpt] SAVED\n",
      "Epoch : 1711/2000 data_batch_1,  Train_loss : 5060.6953  Test_loss : 5374.6006, Time/batch_file : 2.3374, Training time: 19830.6465\n",
      "Epoch : 1711/2000 data_batch_2,  Train_loss : 4990.5044  Test_loss : 4925.2197, Time/batch_file : 2.3017, Training time: 19832.9482\n",
      "Epoch : 1711/2000 data_batch_3,  Train_loss : 5068.4048  Test_loss : 5076.4531, Time/batch_file : 2.3700, Training time: 19835.3184\n",
      "Epoch : 1711/2000 data_batch_4,  Train_loss : 4938.7417  Test_loss : 5094.4854, Time/batch_file : 2.3036, Training time: 19837.6222\n",
      "Epoch : 1711/2000 data_batch_5,  Train_loss : 4958.7734  Test_loss : 4901.4028, Time/batch_file : 2.3076, Training time: 19839.9300\n",
      "Epoch : 1712/2000 data_batch_1,  Train_loss : 4479.3262  Test_loss : 5061.6475, Time/batch_file : 2.2909, Training time: 19842.2211\n",
      "Epoch : 1712/2000 data_batch_2,  Train_loss : 4929.5210  Test_loss : 5136.7632, Time/batch_file : 2.3064, Training time: 19844.5277\n",
      "Epoch : 1712/2000 data_batch_3,  Train_loss : 4775.0986  Test_loss : 5052.7075, Time/batch_file : 2.2794, Training time: 19846.8073\n",
      "Epoch : 1712/2000 data_batch_4,  Train_loss : 4706.3848  Test_loss : 5060.7012, Time/batch_file : 2.2782, Training time: 19849.0856\n",
      "Epoch : 1712/2000 data_batch_5,  Train_loss : 4892.2935  Test_loss : 5173.1626, Time/batch_file : 2.2814, Training time: 19851.3673\n",
      "Epoch : 1713/2000 data_batch_1,  Train_loss : 4764.9795  Test_loss : 5123.8130, Time/batch_file : 2.3008, Training time: 19853.6683\n",
      "Epoch : 1713/2000 data_batch_2,  Train_loss : 4381.0713  Test_loss : 4726.7842, Time/batch_file : 2.2981, Training time: 19855.9666\n",
      "Epoch : 1713/2000 data_batch_3,  Train_loss : 4606.9844  Test_loss : 4792.4219, Time/batch_file : 2.3116, Training time: 19858.2784\n",
      "Epoch : 1713/2000 data_batch_4,  Train_loss : 4693.8833  Test_loss : 4527.9873, Time/batch_file : 2.3101, Training time: 19860.5887\n",
      "Epoch : 1713/2000 data_batch_5,  Train_loss : 4554.6401  Test_loss : 5044.5088, Time/batch_file : 2.3030, Training time: 19862.8920\n",
      "Epoch : 1714/2000 data_batch_1,  Train_loss : 4543.3550  Test_loss : 4707.6030, Time/batch_file : 2.2832, Training time: 19865.1754\n",
      "Epoch : 1714/2000 data_batch_2,  Train_loss : 4296.5254  Test_loss : 4604.8169, Time/batch_file : 2.2838, Training time: 19867.4593\n",
      "Epoch : 1714/2000 data_batch_3,  Train_loss : 4499.5874  Test_loss : 4710.7031, Time/batch_file : 2.2950, Training time: 19869.7545\n",
      "Epoch : 1714/2000 data_batch_4,  Train_loss : 4494.3706  Test_loss : 4790.2227, Time/batch_file : 2.2998, Training time: 19872.0546\n",
      "Epoch : 1714/2000 data_batch_5,  Train_loss : 4266.5181  Test_loss : 4781.7871, Time/batch_file : 2.2835, Training time: 19874.3383\n",
      "Epoch : 1715/2000 data_batch_1,  Train_loss : 4546.7397  Test_loss : 4733.1807, Time/batch_file : 2.3056, Training time: 19876.6441\n",
      "Epoch : 1715/2000 data_batch_2,  Train_loss : 4648.9673  Test_loss : 4603.9746, Time/batch_file : 2.2733, Training time: 19878.9176\n",
      "Epoch : 1715/2000 data_batch_3,  Train_loss : 4869.4297  Test_loss : 4777.4482, Time/batch_file : 2.2874, Training time: 19881.2053\n",
      "Epoch : 1715/2000 data_batch_4,  Train_loss : 4680.5547  Test_loss : 5134.6504, Time/batch_file : 2.2857, Training time: 19883.4912\n",
      "Epoch : 1715/2000 data_batch_5,  Train_loss : 4679.9902  Test_loss : 4803.7607, Time/batch_file : 2.2976, Training time: 19885.7891\n",
      "Epoch : 1716/2000 data_batch_1,  Train_loss : 4458.2764  Test_loss : 4867.8604, Time/batch_file : 2.2907, Training time: 19888.0800\n",
      "Epoch : 1716/2000 data_batch_2,  Train_loss : 4181.3843  Test_loss : 4784.0444, Time/batch_file : 2.2904, Training time: 19890.3706\n",
      "Epoch : 1716/2000 data_batch_3,  Train_loss : 4414.9590  Test_loss : 4935.0474, Time/batch_file : 2.2821, Training time: 19892.6529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1716/2000 data_batch_4,  Train_loss : 4590.2524  Test_loss : 4694.7524, Time/batch_file : 2.2785, Training time: 19894.9316\n",
      "Epoch : 1716/2000 data_batch_5,  Train_loss : 4390.3018  Test_loss : 4832.8960, Time/batch_file : 2.2714, Training time: 19897.2034\n",
      "Epoch : 1717/2000 data_batch_1,  Train_loss : 4211.5840  Test_loss : 4820.0581, Time/batch_file : 2.2966, Training time: 19899.5002\n",
      "Epoch : 1717/2000 data_batch_2,  Train_loss : 4322.0229  Test_loss : 4813.2173, Time/batch_file : 2.2786, Training time: 19901.7790\n",
      "Epoch : 1717/2000 data_batch_3,  Train_loss : 4048.6150  Test_loss : 4659.6182, Time/batch_file : 2.2989, Training time: 19904.0782\n",
      "Epoch : 1717/2000 data_batch_4,  Train_loss : 4179.6157  Test_loss : 4703.9229, Time/batch_file : 2.2854, Training time: 19906.3638\n",
      "Epoch : 1717/2000 data_batch_5,  Train_loss : 4303.8828  Test_loss : 4456.8950, Time/batch_file : 2.2815, Training time: 19908.6455\n",
      "Epoch : 1718/2000 data_batch_1,  Train_loss : 4841.3096  Test_loss : 5168.4053, Time/batch_file : 2.2803, Training time: 19910.9260\n",
      "Epoch : 1718/2000 data_batch_2,  Train_loss : 4920.6753  Test_loss : 4976.2852, Time/batch_file : 2.2916, Training time: 19913.2178\n",
      "Epoch : 1718/2000 data_batch_3,  Train_loss : 4838.6343  Test_loss : 4631.1631, Time/batch_file : 2.2965, Training time: 19915.5146\n",
      "Epoch : 1718/2000 data_batch_4,  Train_loss : 4521.5674  Test_loss : 5024.5635, Time/batch_file : 2.3056, Training time: 19917.8204\n",
      "Epoch : 1718/2000 data_batch_5,  Train_loss : 4615.0889  Test_loss : 4766.1021, Time/batch_file : 2.2801, Training time: 19920.1007\n",
      "Epoch : 1719/2000 data_batch_1,  Train_loss : 4515.3506  Test_loss : 4651.8037, Time/batch_file : 2.2844, Training time: 19922.3853\n",
      "Epoch : 1719/2000 data_batch_2,  Train_loss : 4610.0015  Test_loss : 4502.1084, Time/batch_file : 2.2683, Training time: 19924.6538\n",
      "Epoch : 1719/2000 data_batch_3,  Train_loss : 4534.7295  Test_loss : 4479.1787, Time/batch_file : 2.2899, Training time: 19926.9439\n",
      "Epoch : 1719/2000 data_batch_4,  Train_loss : 4591.9995  Test_loss : 4819.4502, Time/batch_file : 2.2855, Training time: 19929.2295\n",
      "Epoch : 1719/2000 data_batch_5,  Train_loss : 4754.8467  Test_loss : 4628.1411, Time/batch_file : 2.3184, Training time: 19931.5481\n",
      "Epoch : 1720/2000 data_batch_1,  Train_loss : 4551.6582  Test_loss : 5137.8486, Time/batch_file : 2.2937, Training time: 19933.8420\n",
      "Epoch : 1720/2000 data_batch_2,  Train_loss : 4505.7856  Test_loss : 4961.6680, Time/batch_file : 2.3046, Training time: 19936.1469\n",
      "Epoch : 1720/2000 data_batch_3,  Train_loss : 4543.5732  Test_loss : 4969.6836, Time/batch_file : 2.2880, Training time: 19938.4350\n",
      "Epoch : 1720/2000 data_batch_4,  Train_loss : 4550.4492  Test_loss : 4964.5239, Time/batch_file : 2.2807, Training time: 19940.7159\n",
      "Epoch : 1720/2000 data_batch_5,  Train_loss : 4287.2471  Test_loss : 5024.9551, Time/batch_file : 2.2713, Training time: 19942.9874\n",
      "[./nets/net-1720.ckpt] SAVED\n",
      "Epoch : 1721/2000 data_batch_1,  Train_loss : 4762.1816  Test_loss : 4818.5010, Time/batch_file : 2.3247, Training time: 19946.6116\n",
      "Epoch : 1721/2000 data_batch_2,  Train_loss : 4385.7012  Test_loss : 4829.9199, Time/batch_file : 2.2917, Training time: 19948.9035\n",
      "Epoch : 1721/2000 data_batch_3,  Train_loss : 4692.4927  Test_loss : 5082.9937, Time/batch_file : 2.3211, Training time: 19951.2249\n",
      "Epoch : 1721/2000 data_batch_4,  Train_loss : 4575.6899  Test_loss : 4736.8584, Time/batch_file : 2.3014, Training time: 19953.5266\n",
      "Epoch : 1721/2000 data_batch_5,  Train_loss : 4647.6201  Test_loss : 4900.0537, Time/batch_file : 2.3370, Training time: 19955.8638\n",
      "Epoch : 1722/2000 data_batch_1,  Train_loss : 4297.6582  Test_loss : 4681.7305, Time/batch_file : 2.2900, Training time: 19958.1540\n",
      "Epoch : 1722/2000 data_batch_2,  Train_loss : 4294.9639  Test_loss : 4616.7686, Time/batch_file : 2.3102, Training time: 19960.4644\n",
      "Epoch : 1722/2000 data_batch_3,  Train_loss : 4033.5356  Test_loss : 5082.8296, Time/batch_file : 2.2880, Training time: 19962.7525\n",
      "Epoch : 1722/2000 data_batch_4,  Train_loss : 3848.7278  Test_loss : 4636.3296, Time/batch_file : 2.3148, Training time: 19965.0675\n",
      "Epoch : 1722/2000 data_batch_5,  Train_loss : 4378.3428  Test_loss : 4801.1172, Time/batch_file : 2.2826, Training time: 19967.3503\n",
      "Epoch : 1723/2000 data_batch_1,  Train_loss : 4662.6460  Test_loss : 5461.6772, Time/batch_file : 2.3201, Training time: 19969.6707\n",
      "Epoch : 1723/2000 data_batch_2,  Train_loss : 4721.2119  Test_loss : 5142.8857, Time/batch_file : 2.2694, Training time: 19971.9403\n",
      "Epoch : 1723/2000 data_batch_3,  Train_loss : 4648.4531  Test_loss : 5291.0015, Time/batch_file : 2.3072, Training time: 19974.2479\n",
      "Epoch : 1723/2000 data_batch_4,  Train_loss : 4531.9170  Test_loss : 5249.9526, Time/batch_file : 2.2730, Training time: 19976.5211\n",
      "Epoch : 1723/2000 data_batch_5,  Train_loss : 4363.9033  Test_loss : 5292.4863, Time/batch_file : 2.3077, Training time: 19978.8290\n",
      "Epoch : 1724/2000 data_batch_1,  Train_loss : 4657.9014  Test_loss : 4975.4482, Time/batch_file : 2.2790, Training time: 19981.1083\n",
      "Epoch : 1724/2000 data_batch_2,  Train_loss : 4833.8228  Test_loss : 4844.2847, Time/batch_file : 2.2822, Training time: 19983.3907\n",
      "Epoch : 1724/2000 data_batch_3,  Train_loss : 4636.0312  Test_loss : 4867.0337, Time/batch_file : 2.2793, Training time: 19985.6702\n",
      "Epoch : 1724/2000 data_batch_4,  Train_loss : 4415.3481  Test_loss : 4748.7612, Time/batch_file : 2.2926, Training time: 19987.9631\n",
      "Epoch : 1724/2000 data_batch_5,  Train_loss : 4435.2588  Test_loss : 4694.3979, Time/batch_file : 2.2768, Training time: 19990.2401\n",
      "Epoch : 1725/2000 data_batch_1,  Train_loss : 4202.4023  Test_loss : 4921.8169, Time/batch_file : 2.2877, Training time: 19992.5283\n",
      "Epoch : 1725/2000 data_batch_2,  Train_loss : 4101.0503  Test_loss : 4613.8926, Time/batch_file : 2.2822, Training time: 19994.8107\n",
      "Epoch : 1725/2000 data_batch_3,  Train_loss : 4091.6567  Test_loss : 4760.1206, Time/batch_file : 2.2841, Training time: 19997.0950\n",
      "Epoch : 1725/2000 data_batch_4,  Train_loss : 4137.5547  Test_loss : 4895.0552, Time/batch_file : 2.2890, Training time: 19999.3843\n",
      "Epoch : 1725/2000 data_batch_5,  Train_loss : 3935.3899  Test_loss : 5083.0098, Time/batch_file : 2.2928, Training time: 20001.6772\n",
      "Epoch : 1726/2000 data_batch_1,  Train_loss : 4696.7163  Test_loss : 4351.1689, Time/batch_file : 2.2973, Training time: 20003.9747\n",
      "Epoch : 1726/2000 data_batch_2,  Train_loss : 4851.3594  Test_loss : 4557.4219, Time/batch_file : 2.3101, Training time: 20006.2849\n",
      "Epoch : 1726/2000 data_batch_3,  Train_loss : 4957.3389  Test_loss : 4870.8057, Time/batch_file : 2.2873, Training time: 20008.5725\n",
      "Epoch : 1726/2000 data_batch_4,  Train_loss : 4735.2925  Test_loss : 4617.2734, Time/batch_file : 2.3073, Training time: 20010.8800\n",
      "Epoch : 1726/2000 data_batch_5,  Train_loss : 4823.3760  Test_loss : 4599.0835, Time/batch_file : 2.2891, Training time: 20013.1693\n",
      "Epoch : 1727/2000 data_batch_1,  Train_loss : 4992.7505  Test_loss : 4916.7935, Time/batch_file : 2.2848, Training time: 20015.4542\n",
      "Epoch : 1727/2000 data_batch_2,  Train_loss : 4717.1255  Test_loss : 4707.2339, Time/batch_file : 2.2764, Training time: 20017.7309\n",
      "Epoch : 1727/2000 data_batch_3,  Train_loss : 4814.9224  Test_loss : 5001.1465, Time/batch_file : 2.2935, Training time: 20020.0247\n",
      "Epoch : 1727/2000 data_batch_4,  Train_loss : 4939.0420  Test_loss : 5218.5898, Time/batch_file : 2.2686, Training time: 20022.2935\n",
      "Epoch : 1727/2000 data_batch_5,  Train_loss : 4816.1548  Test_loss : 4912.8506, Time/batch_file : 2.2823, Training time: 20024.5761\n",
      "Epoch : 1728/2000 data_batch_1,  Train_loss : 4823.7954  Test_loss : 5095.4170, Time/batch_file : 2.2911, Training time: 20026.8674\n",
      "Epoch : 1728/2000 data_batch_2,  Train_loss : 4652.3286  Test_loss : 5126.1494, Time/batch_file : 2.3107, Training time: 20029.1783\n",
      "Epoch : 1728/2000 data_batch_3,  Train_loss : 4682.8926  Test_loss : 5142.7817, Time/batch_file : 2.3011, Training time: 20031.4797\n",
      "Epoch : 1728/2000 data_batch_4,  Train_loss : 4719.3999  Test_loss : 5091.8057, Time/batch_file : 2.3023, Training time: 20033.7822\n",
      "Epoch : 1728/2000 data_batch_5,  Train_loss : 4670.8711  Test_loss : 5194.7495, Time/batch_file : 2.2934, Training time: 20036.0757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1729/2000 data_batch_1,  Train_loss : 4840.9521  Test_loss : 5239.7822, Time/batch_file : 2.2997, Training time: 20038.3755\n",
      "Epoch : 1729/2000 data_batch_2,  Train_loss : 4772.7324  Test_loss : 5793.6309, Time/batch_file : 2.2939, Training time: 20040.6696\n",
      "Epoch : 1729/2000 data_batch_3,  Train_loss : 4788.6079  Test_loss : 5207.9702, Time/batch_file : 2.3027, Training time: 20042.9725\n",
      "Epoch : 1729/2000 data_batch_4,  Train_loss : 5069.2896  Test_loss : 5354.0205, Time/batch_file : 2.2873, Training time: 20045.2601\n",
      "Epoch : 1729/2000 data_batch_5,  Train_loss : 5055.7305  Test_loss : 5252.9854, Time/batch_file : 2.2984, Training time: 20047.5587\n",
      "Epoch : 1730/2000 data_batch_1,  Train_loss : 4654.8799  Test_loss : 4265.5898, Time/batch_file : 2.2719, Training time: 20049.8307\n",
      "Epoch : 1730/2000 data_batch_2,  Train_loss : 4955.6943  Test_loss : 4222.7334, Time/batch_file : 2.2791, Training time: 20052.1101\n",
      "Epoch : 1730/2000 data_batch_3,  Train_loss : 4966.4399  Test_loss : 4794.2612, Time/batch_file : 2.2820, Training time: 20054.3922\n",
      "Epoch : 1730/2000 data_batch_4,  Train_loss : 5052.2295  Test_loss : 4435.9150, Time/batch_file : 2.2879, Training time: 20056.6803\n",
      "Epoch : 1730/2000 data_batch_5,  Train_loss : 4921.0166  Test_loss : 4673.4487, Time/batch_file : 2.2814, Training time: 20058.9617\n",
      "[./nets/net-1730.ckpt] SAVED\n",
      "Epoch : 1731/2000 data_batch_1,  Train_loss : 4370.5679  Test_loss : 4777.5303, Time/batch_file : 2.5577, Training time: 20062.7956\n",
      "Epoch : 1731/2000 data_batch_2,  Train_loss : 4685.4800  Test_loss : 4659.8096, Time/batch_file : 2.3091, Training time: 20065.1050\n",
      "Epoch : 1731/2000 data_batch_3,  Train_loss : 4443.7417  Test_loss : 4896.3813, Time/batch_file : 2.3092, Training time: 20067.4145\n",
      "Epoch : 1731/2000 data_batch_4,  Train_loss : 4266.8945  Test_loss : 4939.6221, Time/batch_file : 2.2858, Training time: 20069.7006\n",
      "Epoch : 1731/2000 data_batch_5,  Train_loss : 4517.6318  Test_loss : 4953.4009, Time/batch_file : 2.2866, Training time: 20071.9874\n",
      "Epoch : 1732/2000 data_batch_1,  Train_loss : 4836.6587  Test_loss : 4272.1626, Time/batch_file : 2.2742, Training time: 20074.2618\n",
      "Epoch : 1732/2000 data_batch_2,  Train_loss : 4604.1533  Test_loss : 4436.8916, Time/batch_file : 2.2760, Training time: 20076.5379\n",
      "Epoch : 1732/2000 data_batch_3,  Train_loss : 4893.1348  Test_loss : 4243.1631, Time/batch_file : 2.2714, Training time: 20078.8095\n",
      "Epoch : 1732/2000 data_batch_4,  Train_loss : 4778.8564  Test_loss : 4305.6094, Time/batch_file : 2.2641, Training time: 20081.0739\n",
      "Epoch : 1732/2000 data_batch_5,  Train_loss : 4596.4087  Test_loss : 4263.5879, Time/batch_file : 2.2848, Training time: 20083.3589\n",
      "Epoch : 1733/2000 data_batch_1,  Train_loss : 4819.3506  Test_loss : 5007.6963, Time/batch_file : 2.2687, Training time: 20085.6278\n",
      "Epoch : 1733/2000 data_batch_2,  Train_loss : 4977.3545  Test_loss : 5034.7212, Time/batch_file : 2.2731, Training time: 20087.9010\n",
      "Epoch : 1733/2000 data_batch_3,  Train_loss : 5083.5161  Test_loss : 4872.4463, Time/batch_file : 2.2716, Training time: 20090.1728\n",
      "Epoch : 1733/2000 data_batch_4,  Train_loss : 5182.4854  Test_loss : 5026.1562, Time/batch_file : 2.2877, Training time: 20092.4607\n",
      "Epoch : 1733/2000 data_batch_5,  Train_loss : 5088.1494  Test_loss : 5466.8604, Time/batch_file : 2.2682, Training time: 20094.7290\n",
      "Epoch : 1734/2000 data_batch_1,  Train_loss : 4597.7891  Test_loss : 4687.5195, Time/batch_file : 2.2675, Training time: 20096.9968\n",
      "Epoch : 1734/2000 data_batch_2,  Train_loss : 4733.3843  Test_loss : 4990.5908, Time/batch_file : 2.3242, Training time: 20099.3211\n",
      "Epoch : 1734/2000 data_batch_3,  Train_loss : 4773.9258  Test_loss : 4874.4980, Time/batch_file : 2.2676, Training time: 20101.5890\n",
      "Epoch : 1734/2000 data_batch_4,  Train_loss : 4529.6831  Test_loss : 4938.6909, Time/batch_file : 2.2749, Training time: 20103.8641\n",
      "Epoch : 1734/2000 data_batch_5,  Train_loss : 4970.4648  Test_loss : 4972.8379, Time/batch_file : 2.2709, Training time: 20106.1352\n",
      "Epoch : 1735/2000 data_batch_1,  Train_loss : 5312.3540  Test_loss : 4755.4961, Time/batch_file : 2.2893, Training time: 20108.4247\n",
      "Epoch : 1735/2000 data_batch_2,  Train_loss : 5000.0747  Test_loss : 5034.7471, Time/batch_file : 2.2804, Training time: 20110.7053\n",
      "Epoch : 1735/2000 data_batch_3,  Train_loss : 4843.3438  Test_loss : 4905.9727, Time/batch_file : 2.2869, Training time: 20112.9924\n",
      "Epoch : 1735/2000 data_batch_4,  Train_loss : 4926.0283  Test_loss : 4607.8276, Time/batch_file : 2.2867, Training time: 20115.2794\n",
      "Epoch : 1735/2000 data_batch_5,  Train_loss : 4960.9272  Test_loss : 4958.7227, Time/batch_file : 2.3029, Training time: 20117.5825\n",
      "Epoch : 1736/2000 data_batch_1,  Train_loss : 4327.0469  Test_loss : 4798.5200, Time/batch_file : 2.2778, Training time: 20119.8605\n",
      "Epoch : 1736/2000 data_batch_2,  Train_loss : 4289.5986  Test_loss : 5042.9771, Time/batch_file : 2.3050, Training time: 20122.1657\n",
      "Epoch : 1736/2000 data_batch_3,  Train_loss : 4304.7427  Test_loss : 5127.4316, Time/batch_file : 2.2745, Training time: 20124.4405\n",
      "Epoch : 1736/2000 data_batch_4,  Train_loss : 4415.5791  Test_loss : 4897.5972, Time/batch_file : 2.2779, Training time: 20126.7185\n",
      "Epoch : 1736/2000 data_batch_5,  Train_loss : 4536.6104  Test_loss : 4758.2485, Time/batch_file : 2.2763, Training time: 20128.9950\n",
      "Epoch : 1737/2000 data_batch_1,  Train_loss : 4467.7764  Test_loss : 4889.7744, Time/batch_file : 2.2577, Training time: 20131.2530\n",
      "Epoch : 1737/2000 data_batch_2,  Train_loss : 4408.4253  Test_loss : 4942.4106, Time/batch_file : 2.2780, Training time: 20133.5312\n",
      "Epoch : 1737/2000 data_batch_3,  Train_loss : 4463.5493  Test_loss : 4900.7949, Time/batch_file : 2.2597, Training time: 20135.7911\n",
      "Epoch : 1737/2000 data_batch_4,  Train_loss : 4628.3604  Test_loss : 4779.4688, Time/batch_file : 2.2808, Training time: 20138.0721\n",
      "Epoch : 1737/2000 data_batch_5,  Train_loss : 4404.1084  Test_loss : 4921.0518, Time/batch_file : 2.2715, Training time: 20140.3437\n",
      "Epoch : 1738/2000 data_batch_1,  Train_loss : 4701.2646  Test_loss : 5449.1094, Time/batch_file : 2.2592, Training time: 20142.6031\n",
      "Epoch : 1738/2000 data_batch_2,  Train_loss : 4619.9062  Test_loss : 5430.7803, Time/batch_file : 2.2700, Training time: 20144.8734\n",
      "Epoch : 1738/2000 data_batch_3,  Train_loss : 4545.7373  Test_loss : 5248.9492, Time/batch_file : 2.2686, Training time: 20147.1422\n",
      "Epoch : 1738/2000 data_batch_4,  Train_loss : 4510.3228  Test_loss : 5412.4482, Time/batch_file : 2.2606, Training time: 20149.4031\n",
      "Epoch : 1738/2000 data_batch_5,  Train_loss : 4707.4434  Test_loss : 5381.6729, Time/batch_file : 2.2857, Training time: 20151.6890\n",
      "Epoch : 1739/2000 data_batch_1,  Train_loss : 4394.5508  Test_loss : 5176.6152, Time/batch_file : 2.2703, Training time: 20153.9596\n",
      "Epoch : 1739/2000 data_batch_2,  Train_loss : 4578.1455  Test_loss : 5333.4893, Time/batch_file : 2.2751, Training time: 20156.2350\n",
      "Epoch : 1739/2000 data_batch_3,  Train_loss : 4511.1016  Test_loss : 5139.1230, Time/batch_file : 2.2730, Training time: 20158.5083\n",
      "Epoch : 1739/2000 data_batch_4,  Train_loss : 4275.5566  Test_loss : 5351.4985, Time/batch_file : 2.2886, Training time: 20160.7971\n",
      "Epoch : 1739/2000 data_batch_5,  Train_loss : 4449.0908  Test_loss : 5409.3545, Time/batch_file : 2.2761, Training time: 20163.0733\n",
      "Epoch : 1740/2000 data_batch_1,  Train_loss : 4447.6094  Test_loss : 4630.6587, Time/batch_file : 2.2637, Training time: 20165.3372\n",
      "Epoch : 1740/2000 data_batch_2,  Train_loss : 4170.2734  Test_loss : 4727.2471, Time/batch_file : 2.2942, Training time: 20167.6317\n",
      "Epoch : 1740/2000 data_batch_3,  Train_loss : 4545.7114  Test_loss : 4719.1841, Time/batch_file : 2.2698, Training time: 20169.9017\n",
      "Epoch : 1740/2000 data_batch_4,  Train_loss : 4500.7046  Test_loss : 4448.6899, Time/batch_file : 2.2751, Training time: 20172.1770\n",
      "Epoch : 1740/2000 data_batch_5,  Train_loss : 4477.0269  Test_loss : 4554.6772, Time/batch_file : 2.2764, Training time: 20174.4535\n",
      "[./nets/net-1740.ckpt] SAVED\n",
      "Epoch : 1741/2000 data_batch_1,  Train_loss : 4441.3169  Test_loss : 4514.8877, Time/batch_file : 2.2968, Training time: 20178.0541\n",
      "Epoch : 1741/2000 data_batch_2,  Train_loss : 4254.7993  Test_loss : 4467.0762, Time/batch_file : 2.2999, Training time: 20180.3543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1741/2000 data_batch_3,  Train_loss : 4276.2607  Test_loss : 4286.0361, Time/batch_file : 2.2798, Training time: 20182.6342\n",
      "Epoch : 1741/2000 data_batch_4,  Train_loss : 4708.2549  Test_loss : 4750.4639, Time/batch_file : 2.3115, Training time: 20184.9460\n",
      "Epoch : 1741/2000 data_batch_5,  Train_loss : 4059.8193  Test_loss : 4562.6313, Time/batch_file : 2.3004, Training time: 20187.2465\n",
      "Epoch : 1742/2000 data_batch_1,  Train_loss : 4207.3540  Test_loss : 4719.0205, Time/batch_file : 2.3085, Training time: 20189.5552\n",
      "Epoch : 1742/2000 data_batch_2,  Train_loss : 4348.7783  Test_loss : 4744.5186, Time/batch_file : 2.2889, Training time: 20191.8444\n",
      "Epoch : 1742/2000 data_batch_3,  Train_loss : 3881.5303  Test_loss : 4417.6230, Time/batch_file : 2.3063, Training time: 20194.1508\n",
      "Epoch : 1742/2000 data_batch_4,  Train_loss : 4111.1094  Test_loss : 4750.0933, Time/batch_file : 2.2833, Training time: 20196.4343\n",
      "Epoch : 1742/2000 data_batch_5,  Train_loss : 4105.6426  Test_loss : 4819.0625, Time/batch_file : 2.3018, Training time: 20198.7363\n",
      "Epoch : 1743/2000 data_batch_1,  Train_loss : 4687.2866  Test_loss : 4746.2681, Time/batch_file : 2.2735, Training time: 20201.0099\n",
      "Epoch : 1743/2000 data_batch_2,  Train_loss : 4993.9238  Test_loss : 4480.5723, Time/batch_file : 2.2982, Training time: 20203.3083\n",
      "Epoch : 1743/2000 data_batch_3,  Train_loss : 4741.8203  Test_loss : 4319.3408, Time/batch_file : 2.2844, Training time: 20205.5929\n",
      "Epoch : 1743/2000 data_batch_4,  Train_loss : 4813.1523  Test_loss : 4714.5342, Time/batch_file : 2.3012, Training time: 20207.8943\n",
      "Epoch : 1743/2000 data_batch_5,  Train_loss : 5047.7451  Test_loss : 4588.7227, Time/batch_file : 2.3115, Training time: 20210.2061\n",
      "Epoch : 1744/2000 data_batch_1,  Train_loss : 4363.3096  Test_loss : 4762.9614, Time/batch_file : 2.3116, Training time: 20212.5180\n",
      "Epoch : 1744/2000 data_batch_2,  Train_loss : 4370.9966  Test_loss : 4944.4902, Time/batch_file : 2.2969, Training time: 20214.8151\n",
      "Epoch : 1744/2000 data_batch_3,  Train_loss : 4231.7314  Test_loss : 4586.3911, Time/batch_file : 2.3131, Training time: 20217.1284\n",
      "Epoch : 1744/2000 data_batch_4,  Train_loss : 4116.2119  Test_loss : 4872.5459, Time/batch_file : 2.3249, Training time: 20219.4535\n",
      "Epoch : 1744/2000 data_batch_5,  Train_loss : 4012.1401  Test_loss : 4858.8672, Time/batch_file : 2.3092, Training time: 20221.7629\n",
      "Epoch : 1745/2000 data_batch_1,  Train_loss : 4266.8911  Test_loss : 4476.1699, Time/batch_file : 2.2663, Training time: 20224.0295\n",
      "Epoch : 1745/2000 data_batch_2,  Train_loss : 4198.3613  Test_loss : 4136.2617, Time/batch_file : 2.2938, Training time: 20226.3235\n",
      "Epoch : 1745/2000 data_batch_3,  Train_loss : 4200.3271  Test_loss : 4424.8027, Time/batch_file : 2.2713, Training time: 20228.5949\n",
      "Epoch : 1745/2000 data_batch_4,  Train_loss : 4318.8770  Test_loss : 4302.2100, Time/batch_file : 2.2983, Training time: 20230.8933\n",
      "Epoch : 1745/2000 data_batch_5,  Train_loss : 4322.9150  Test_loss : 4649.0864, Time/batch_file : 2.2895, Training time: 20233.1830\n",
      "Epoch : 1746/2000 data_batch_1,  Train_loss : 4747.8955  Test_loss : 5050.3789, Time/batch_file : 2.3162, Training time: 20235.4994\n",
      "Epoch : 1746/2000 data_batch_2,  Train_loss : 4935.8550  Test_loss : 4987.6406, Time/batch_file : 2.2951, Training time: 20237.7947\n",
      "Epoch : 1746/2000 data_batch_3,  Train_loss : 5029.5645  Test_loss : 5098.3018, Time/batch_file : 2.3074, Training time: 20240.1024\n",
      "Epoch : 1746/2000 data_batch_4,  Train_loss : 4860.2446  Test_loss : 5051.0449, Time/batch_file : 2.3039, Training time: 20242.4065\n",
      "Epoch : 1746/2000 data_batch_5,  Train_loss : 4748.2686  Test_loss : 4851.1011, Time/batch_file : 2.3129, Training time: 20244.7195\n",
      "Epoch : 1747/2000 data_batch_1,  Train_loss : 4712.7603  Test_loss : 4899.7202, Time/batch_file : 2.2804, Training time: 20247.0002\n",
      "Epoch : 1747/2000 data_batch_2,  Train_loss : 4722.2905  Test_loss : 4827.4009, Time/batch_file : 2.3027, Training time: 20249.3030\n",
      "Epoch : 1747/2000 data_batch_3,  Train_loss : 4617.7490  Test_loss : 4666.1812, Time/batch_file : 2.2722, Training time: 20251.5753\n",
      "Epoch : 1747/2000 data_batch_4,  Train_loss : 4658.7539  Test_loss : 4838.7124, Time/batch_file : 2.2966, Training time: 20253.8721\n",
      "Epoch : 1747/2000 data_batch_5,  Train_loss : 4741.9297  Test_loss : 4972.1621, Time/batch_file : 2.2898, Training time: 20256.1620\n",
      "Epoch : 1748/2000 data_batch_1,  Train_loss : 4943.1118  Test_loss : 4736.1172, Time/batch_file : 2.2977, Training time: 20258.4599\n",
      "Epoch : 1748/2000 data_batch_2,  Train_loss : 4913.2383  Test_loss : 5038.8169, Time/batch_file : 2.2883, Training time: 20260.7484\n",
      "Epoch : 1748/2000 data_batch_3,  Train_loss : 4893.8735  Test_loss : 4917.9053, Time/batch_file : 2.2994, Training time: 20263.0480\n",
      "Epoch : 1748/2000 data_batch_4,  Train_loss : 4746.2656  Test_loss : 4736.8413, Time/batch_file : 2.2766, Training time: 20265.3249\n",
      "Epoch : 1748/2000 data_batch_5,  Train_loss : 4861.3252  Test_loss : 5132.4922, Time/batch_file : 2.2982, Training time: 20267.6232\n",
      "Epoch : 1749/2000 data_batch_1,  Train_loss : 4464.4272  Test_loss : 4886.3369, Time/batch_file : 2.2836, Training time: 20269.9071\n",
      "Epoch : 1749/2000 data_batch_2,  Train_loss : 4609.3911  Test_loss : 5005.5000, Time/batch_file : 2.3055, Training time: 20272.2128\n",
      "Epoch : 1749/2000 data_batch_3,  Train_loss : 4913.4883  Test_loss : 4628.4116, Time/batch_file : 2.2834, Training time: 20274.4964\n",
      "Epoch : 1749/2000 data_batch_4,  Train_loss : 4803.6177  Test_loss : 4764.0020, Time/batch_file : 2.3149, Training time: 20276.8115\n",
      "Epoch : 1749/2000 data_batch_5,  Train_loss : 4585.3218  Test_loss : 4740.5498, Time/batch_file : 2.3096, Training time: 20279.1213\n",
      "Epoch : 1750/2000 data_batch_1,  Train_loss : 4494.5029  Test_loss : 4402.6768, Time/batch_file : 2.3107, Training time: 20281.4323\n",
      "Epoch : 1750/2000 data_batch_2,  Train_loss : 4604.9204  Test_loss : 4613.1982, Time/batch_file : 2.2959, Training time: 20283.7283\n",
      "Epoch : 1750/2000 data_batch_3,  Train_loss : 4936.9878  Test_loss : 4504.8828, Time/batch_file : 2.3086, Training time: 20286.0371\n",
      "Epoch : 1750/2000 data_batch_4,  Train_loss : 4355.1772  Test_loss : 4331.2344, Time/batch_file : 2.3008, Training time: 20288.3381\n",
      "Epoch : 1750/2000 data_batch_5,  Train_loss : 4606.9688  Test_loss : 4647.5601, Time/batch_file : 2.3094, Training time: 20290.6477\n",
      "[./nets/net-1750.ckpt] SAVED\n",
      "Epoch : 1751/2000 data_batch_1,  Train_loss : 4509.5430  Test_loss : 4843.1147, Time/batch_file : 2.4438, Training time: 20294.3997\n",
      "Epoch : 1751/2000 data_batch_2,  Train_loss : 4415.9814  Test_loss : 4723.6699, Time/batch_file : 2.3106, Training time: 20296.7106\n",
      "Epoch : 1751/2000 data_batch_3,  Train_loss : 4915.1973  Test_loss : 4864.6919, Time/batch_file : 2.3091, Training time: 20299.0199\n",
      "Epoch : 1751/2000 data_batch_4,  Train_loss : 4374.6064  Test_loss : 4776.3394, Time/batch_file : 2.3148, Training time: 20301.3349\n",
      "Epoch : 1751/2000 data_batch_5,  Train_loss : 4259.3623  Test_loss : 4806.7236, Time/batch_file : 2.2729, Training time: 20303.6080\n",
      "Epoch : 1752/2000 data_batch_1,  Train_loss : 4853.1709  Test_loss : 4803.0244, Time/batch_file : 2.3023, Training time: 20305.9105\n",
      "Epoch : 1752/2000 data_batch_2,  Train_loss : 4981.1914  Test_loss : 4665.2236, Time/batch_file : 2.3108, Training time: 20308.2215\n",
      "Epoch : 1752/2000 data_batch_3,  Train_loss : 4990.6758  Test_loss : 4505.6514, Time/batch_file : 2.2861, Training time: 20310.5078\n",
      "Epoch : 1752/2000 data_batch_4,  Train_loss : 4765.3291  Test_loss : 4636.9233, Time/batch_file : 2.2985, Training time: 20312.8065\n",
      "Epoch : 1752/2000 data_batch_5,  Train_loss : 4847.4834  Test_loss : 4576.3716, Time/batch_file : 2.3274, Training time: 20315.1340\n",
      "Epoch : 1753/2000 data_batch_1,  Train_loss : 4681.7979  Test_loss : 4659.4736, Time/batch_file : 2.2859, Training time: 20317.4201\n",
      "Epoch : 1753/2000 data_batch_2,  Train_loss : 4676.3760  Test_loss : 4994.0703, Time/batch_file : 2.3022, Training time: 20319.7225\n",
      "Epoch : 1753/2000 data_batch_3,  Train_loss : 4537.4961  Test_loss : 4843.3877, Time/batch_file : 2.3119, Training time: 20322.0347\n",
      "Epoch : 1753/2000 data_batch_4,  Train_loss : 4620.2451  Test_loss : 4612.8247, Time/batch_file : 2.2994, Training time: 20324.3343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1753/2000 data_batch_5,  Train_loss : 4805.4307  Test_loss : 4825.3140, Time/batch_file : 2.2887, Training time: 20326.6232\n",
      "Epoch : 1754/2000 data_batch_1,  Train_loss : 4511.8037  Test_loss : 4681.7251, Time/batch_file : 2.2891, Training time: 20328.9126\n",
      "Epoch : 1754/2000 data_batch_2,  Train_loss : 4678.1094  Test_loss : 4797.2788, Time/batch_file : 2.2875, Training time: 20331.2004\n",
      "Epoch : 1754/2000 data_batch_3,  Train_loss : 4648.0337  Test_loss : 4724.9102, Time/batch_file : 2.3075, Training time: 20333.5081\n",
      "Epoch : 1754/2000 data_batch_4,  Train_loss : 4331.1929  Test_loss : 4597.7715, Time/batch_file : 2.2840, Training time: 20335.7923\n",
      "Epoch : 1754/2000 data_batch_5,  Train_loss : 4594.9165  Test_loss : 4808.3555, Time/batch_file : 2.3001, Training time: 20338.0926\n",
      "Epoch : 1755/2000 data_batch_1,  Train_loss : 4042.0029  Test_loss : 5235.2798, Time/batch_file : 2.3091, Training time: 20340.4020\n",
      "Epoch : 1755/2000 data_batch_2,  Train_loss : 4256.5889  Test_loss : 5040.6855, Time/batch_file : 2.2955, Training time: 20342.6976\n",
      "Epoch : 1755/2000 data_batch_3,  Train_loss : 4113.3252  Test_loss : 5150.3916, Time/batch_file : 2.2816, Training time: 20344.9795\n",
      "Epoch : 1755/2000 data_batch_4,  Train_loss : 4033.2239  Test_loss : 5259.8628, Time/batch_file : 2.2882, Training time: 20347.2679\n",
      "Epoch : 1755/2000 data_batch_5,  Train_loss : 3856.4937  Test_loss : 5145.0459, Time/batch_file : 2.3023, Training time: 20349.5705\n",
      "Epoch : 1756/2000 data_batch_1,  Train_loss : 4608.5781  Test_loss : 4352.0322, Time/batch_file : 2.2828, Training time: 20351.8534\n",
      "Epoch : 1756/2000 data_batch_2,  Train_loss : 4706.7695  Test_loss : 4330.4844, Time/batch_file : 2.2692, Training time: 20354.1228\n",
      "Epoch : 1756/2000 data_batch_3,  Train_loss : 4766.8428  Test_loss : 4625.2783, Time/batch_file : 2.2848, Training time: 20356.4078\n",
      "Epoch : 1756/2000 data_batch_4,  Train_loss : 4834.8555  Test_loss : 4382.4932, Time/batch_file : 2.2866, Training time: 20358.6946\n",
      "Epoch : 1756/2000 data_batch_5,  Train_loss : 4621.1626  Test_loss : 4253.7100, Time/batch_file : 2.3006, Training time: 20360.9953\n",
      "Epoch : 1757/2000 data_batch_1,  Train_loss : 4483.6484  Test_loss : 4804.1807, Time/batch_file : 2.2719, Training time: 20363.2674\n",
      "Epoch : 1757/2000 data_batch_2,  Train_loss : 4399.7305  Test_loss : 4328.1660, Time/batch_file : 2.2868, Training time: 20365.5545\n",
      "Epoch : 1757/2000 data_batch_3,  Train_loss : 4398.9971  Test_loss : 4302.2114, Time/batch_file : 2.3055, Training time: 20367.8602\n",
      "Epoch : 1757/2000 data_batch_4,  Train_loss : 4662.0679  Test_loss : 4772.5024, Time/batch_file : 2.2945, Training time: 20370.1550\n",
      "Epoch : 1757/2000 data_batch_5,  Train_loss : 4459.0015  Test_loss : 4512.3774, Time/batch_file : 2.2725, Training time: 20372.4277\n",
      "Epoch : 1758/2000 data_batch_1,  Train_loss : 4512.4341  Test_loss : 4473.9087, Time/batch_file : 2.2901, Training time: 20374.7181\n",
      "Epoch : 1758/2000 data_batch_2,  Train_loss : 4628.1196  Test_loss : 4569.2803, Time/batch_file : 2.3062, Training time: 20377.0245\n",
      "Epoch : 1758/2000 data_batch_3,  Train_loss : 4680.7422  Test_loss : 4578.2168, Time/batch_file : 2.2950, Training time: 20379.3197\n",
      "Epoch : 1758/2000 data_batch_4,  Train_loss : 4457.5635  Test_loss : 4817.2295, Time/batch_file : 2.2842, Training time: 20381.6041\n",
      "Epoch : 1758/2000 data_batch_5,  Train_loss : 4577.3105  Test_loss : 4547.3135, Time/batch_file : 2.2909, Training time: 20383.8953\n",
      "Epoch : 1759/2000 data_batch_1,  Train_loss : 4573.7080  Test_loss : 4667.3413, Time/batch_file : 2.2988, Training time: 20386.1942\n",
      "Epoch : 1759/2000 data_batch_2,  Train_loss : 4594.6963  Test_loss : 4705.5854, Time/batch_file : 2.3070, Training time: 20388.5014\n",
      "Epoch : 1759/2000 data_batch_3,  Train_loss : 4432.3037  Test_loss : 4730.5312, Time/batch_file : 2.2818, Training time: 20390.7834\n",
      "Epoch : 1759/2000 data_batch_4,  Train_loss : 4456.5933  Test_loss : 4457.0151, Time/batch_file : 2.2793, Training time: 20393.0630\n",
      "Epoch : 1759/2000 data_batch_5,  Train_loss : 4470.5293  Test_loss : 4887.3135, Time/batch_file : 2.2998, Training time: 20395.3629\n",
      "Epoch : 1760/2000 data_batch_1,  Train_loss : 4309.7207  Test_loss : 5159.8901, Time/batch_file : 2.3017, Training time: 20397.6649\n",
      "Epoch : 1760/2000 data_batch_2,  Train_loss : 4496.3145  Test_loss : 5651.8628, Time/batch_file : 2.2894, Training time: 20399.9544\n",
      "Epoch : 1760/2000 data_batch_3,  Train_loss : 4318.2144  Test_loss : 5334.9937, Time/batch_file : 2.3056, Training time: 20402.2603\n",
      "Epoch : 1760/2000 data_batch_4,  Train_loss : 4408.7686  Test_loss : 5249.1128, Time/batch_file : 2.3061, Training time: 20404.5666\n",
      "Epoch : 1760/2000 data_batch_5,  Train_loss : 4372.1548  Test_loss : 5249.8726, Time/batch_file : 2.3046, Training time: 20406.8714\n",
      "[./nets/net-1760.ckpt] SAVED\n",
      "Epoch : 1761/2000 data_batch_1,  Train_loss : 4946.3457  Test_loss : 4556.0283, Time/batch_file : 2.2898, Training time: 20410.4478\n",
      "Epoch : 1761/2000 data_batch_2,  Train_loss : 5351.0889  Test_loss : 4645.1094, Time/batch_file : 2.2823, Training time: 20412.7302\n",
      "Epoch : 1761/2000 data_batch_3,  Train_loss : 5135.8516  Test_loss : 4669.8911, Time/batch_file : 2.2635, Training time: 20414.9939\n",
      "Epoch : 1761/2000 data_batch_4,  Train_loss : 5231.7471  Test_loss : 4667.9189, Time/batch_file : 2.2701, Training time: 20417.2642\n",
      "Epoch : 1761/2000 data_batch_5,  Train_loss : 5232.3584  Test_loss : 4559.0244, Time/batch_file : 2.2672, Training time: 20419.5316\n",
      "Epoch : 1762/2000 data_batch_1,  Train_loss : 4353.5107  Test_loss : 4989.5405, Time/batch_file : 2.2881, Training time: 20421.8199\n",
      "Epoch : 1762/2000 data_batch_2,  Train_loss : 4510.0601  Test_loss : 4771.3486, Time/batch_file : 2.2680, Training time: 20424.0880\n",
      "Epoch : 1762/2000 data_batch_3,  Train_loss : 4615.0688  Test_loss : 4723.4546, Time/batch_file : 2.2503, Training time: 20426.3387\n",
      "Epoch : 1762/2000 data_batch_4,  Train_loss : 4234.1846  Test_loss : 5140.2954, Time/batch_file : 2.2802, Training time: 20428.6191\n",
      "Epoch : 1762/2000 data_batch_5,  Train_loss : 4364.5781  Test_loss : 4711.2852, Time/batch_file : 2.2679, Training time: 20430.8872\n",
      "Epoch : 1763/2000 data_batch_1,  Train_loss : 4586.2266  Test_loss : 5051.4097, Time/batch_file : 2.3056, Training time: 20433.1929\n",
      "Epoch : 1763/2000 data_batch_2,  Train_loss : 4711.3477  Test_loss : 4801.6255, Time/batch_file : 2.2918, Training time: 20435.4849\n",
      "Epoch : 1763/2000 data_batch_3,  Train_loss : 4675.3018  Test_loss : 4727.8022, Time/batch_file : 2.2751, Training time: 20437.7602\n",
      "Epoch : 1763/2000 data_batch_4,  Train_loss : 4556.8145  Test_loss : 4703.5527, Time/batch_file : 2.2634, Training time: 20440.0237\n",
      "Epoch : 1763/2000 data_batch_5,  Train_loss : 4783.1357  Test_loss : 4483.3164, Time/batch_file : 2.2646, Training time: 20442.2886\n",
      "Epoch : 1764/2000 data_batch_1,  Train_loss : 4539.8926  Test_loss : 5039.2305, Time/batch_file : 2.2581, Training time: 20444.5469\n",
      "Epoch : 1764/2000 data_batch_2,  Train_loss : 4461.4502  Test_loss : 4863.9326, Time/batch_file : 2.2491, Training time: 20446.7961\n",
      "Epoch : 1764/2000 data_batch_3,  Train_loss : 4792.4048  Test_loss : 5110.8140, Time/batch_file : 2.2597, Training time: 20449.0560\n",
      "Epoch : 1764/2000 data_batch_4,  Train_loss : 4535.6562  Test_loss : 4939.9653, Time/batch_file : 2.2637, Training time: 20451.3198\n",
      "Epoch : 1764/2000 data_batch_5,  Train_loss : 4542.4951  Test_loss : 5029.6821, Time/batch_file : 2.2601, Training time: 20453.5801\n",
      "Epoch : 1765/2000 data_batch_1,  Train_loss : 4722.8364  Test_loss : 5437.1504, Time/batch_file : 2.2689, Training time: 20455.8493\n",
      "Epoch : 1765/2000 data_batch_2,  Train_loss : 4855.7310  Test_loss : 5040.0581, Time/batch_file : 2.2758, Training time: 20458.1253\n",
      "Epoch : 1765/2000 data_batch_3,  Train_loss : 4832.9097  Test_loss : 4968.6992, Time/batch_file : 2.2618, Training time: 20460.3872\n",
      "Epoch : 1765/2000 data_batch_4,  Train_loss : 4897.7217  Test_loss : 5114.1504, Time/batch_file : 2.2590, Training time: 20462.6464\n",
      "Epoch : 1765/2000 data_batch_5,  Train_loss : 4865.2012  Test_loss : 5237.9629, Time/batch_file : 2.2694, Training time: 20464.9160\n",
      "Epoch : 1766/2000 data_batch_1,  Train_loss : 4891.4287  Test_loss : 4843.7139, Time/batch_file : 2.2648, Training time: 20467.1811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1766/2000 data_batch_2,  Train_loss : 4851.6831  Test_loss : 5227.5693, Time/batch_file : 2.2601, Training time: 20469.4415\n",
      "Epoch : 1766/2000 data_batch_3,  Train_loss : 5119.3013  Test_loss : 5238.0654, Time/batch_file : 2.2742, Training time: 20471.7159\n",
      "Epoch : 1766/2000 data_batch_4,  Train_loss : 4957.0391  Test_loss : 5230.2070, Time/batch_file : 2.2718, Training time: 20473.9879\n",
      "Epoch : 1766/2000 data_batch_5,  Train_loss : 4898.2168  Test_loss : 4963.3027, Time/batch_file : 2.2674, Training time: 20476.2556\n",
      "Epoch : 1767/2000 data_batch_1,  Train_loss : 4624.2856  Test_loss : 5057.4082, Time/batch_file : 2.2596, Training time: 20478.5154\n",
      "Epoch : 1767/2000 data_batch_2,  Train_loss : 4594.5532  Test_loss : 4946.8574, Time/batch_file : 2.2529, Training time: 20480.7685\n",
      "Epoch : 1767/2000 data_batch_3,  Train_loss : 4586.3765  Test_loss : 4944.8438, Time/batch_file : 2.2571, Training time: 20483.0258\n",
      "Epoch : 1767/2000 data_batch_4,  Train_loss : 4799.1172  Test_loss : 4691.9561, Time/batch_file : 2.2624, Training time: 20485.2883\n",
      "Epoch : 1767/2000 data_batch_5,  Train_loss : 4717.8667  Test_loss : 4509.3281, Time/batch_file : 2.2507, Training time: 20487.5392\n",
      "Epoch : 1768/2000 data_batch_1,  Train_loss : 4239.1562  Test_loss : 4136.0288, Time/batch_file : 2.2651, Training time: 20489.8045\n",
      "Epoch : 1768/2000 data_batch_2,  Train_loss : 4310.0498  Test_loss : 4439.6318, Time/batch_file : 2.2712, Training time: 20492.0759\n",
      "Epoch : 1768/2000 data_batch_3,  Train_loss : 4432.3794  Test_loss : 4429.6377, Time/batch_file : 2.2539, Training time: 20494.3300\n",
      "Epoch : 1768/2000 data_batch_4,  Train_loss : 4228.5088  Test_loss : 4596.8701, Time/batch_file : 2.2787, Training time: 20496.6089\n",
      "Epoch : 1768/2000 data_batch_5,  Train_loss : 4582.9321  Test_loss : 4408.4102, Time/batch_file : 2.2790, Training time: 20498.8882\n",
      "Epoch : 1769/2000 data_batch_1,  Train_loss : 4357.5400  Test_loss : 4894.5723, Time/batch_file : 2.2760, Training time: 20501.1644\n",
      "Epoch : 1769/2000 data_batch_2,  Train_loss : 4696.4697  Test_loss : 4841.9590, Time/batch_file : 2.2711, Training time: 20503.4357\n",
      "Epoch : 1769/2000 data_batch_3,  Train_loss : 4672.0425  Test_loss : 4878.9561, Time/batch_file : 2.2807, Training time: 20505.7166\n",
      "Epoch : 1769/2000 data_batch_4,  Train_loss : 4809.3623  Test_loss : 4707.4697, Time/batch_file : 2.2816, Training time: 20507.9983\n",
      "Epoch : 1769/2000 data_batch_5,  Train_loss : 4261.0527  Test_loss : 4815.9521, Time/batch_file : 2.2709, Training time: 20510.2695\n",
      "Epoch : 1770/2000 data_batch_1,  Train_loss : 4667.4756  Test_loss : 4651.1436, Time/batch_file : 2.2506, Training time: 20512.5203\n",
      "Epoch : 1770/2000 data_batch_2,  Train_loss : 4715.8242  Test_loss : 4765.5986, Time/batch_file : 2.2552, Training time: 20514.7757\n",
      "Epoch : 1770/2000 data_batch_3,  Train_loss : 4638.4893  Test_loss : 4859.8066, Time/batch_file : 2.2534, Training time: 20517.0293\n",
      "Epoch : 1770/2000 data_batch_4,  Train_loss : 4732.9580  Test_loss : 4726.1196, Time/batch_file : 2.2596, Training time: 20519.2892\n",
      "Epoch : 1770/2000 data_batch_5,  Train_loss : 4573.0098  Test_loss : 4861.8330, Time/batch_file : 2.2532, Training time: 20521.5425\n",
      "[./nets/net-1770.ckpt] SAVED\n",
      "Epoch : 1771/2000 data_batch_1,  Train_loss : 4712.2197  Test_loss : 4566.9111, Time/batch_file : 2.3230, Training time: 20525.1414\n",
      "Epoch : 1771/2000 data_batch_2,  Train_loss : 4636.5576  Test_loss : 4556.5293, Time/batch_file : 2.2964, Training time: 20527.4381\n",
      "Epoch : 1771/2000 data_batch_3,  Train_loss : 4768.3452  Test_loss : 4205.0728, Time/batch_file : 2.3031, Training time: 20529.7414\n",
      "Epoch : 1771/2000 data_batch_4,  Train_loss : 4787.5664  Test_loss : 4285.8008, Time/batch_file : 2.2980, Training time: 20532.0396\n",
      "Epoch : 1771/2000 data_batch_5,  Train_loss : 4764.8838  Test_loss : 4281.1699, Time/batch_file : 2.3112, Training time: 20534.3510\n",
      "Epoch : 1772/2000 data_batch_1,  Train_loss : 4578.3369  Test_loss : 4891.3672, Time/batch_file : 2.2997, Training time: 20536.6509\n",
      "Epoch : 1772/2000 data_batch_2,  Train_loss : 4548.9297  Test_loss : 4856.4858, Time/batch_file : 2.2691, Training time: 20538.9202\n",
      "Epoch : 1772/2000 data_batch_3,  Train_loss : 4594.4868  Test_loss : 4886.4326, Time/batch_file : 2.2814, Training time: 20541.2017\n",
      "Epoch : 1772/2000 data_batch_4,  Train_loss : 4546.2402  Test_loss : 4855.8833, Time/batch_file : 2.2738, Training time: 20543.4757\n",
      "Epoch : 1772/2000 data_batch_5,  Train_loss : 4658.8970  Test_loss : 4939.1641, Time/batch_file : 2.2830, Training time: 20545.7589\n",
      "Epoch : 1773/2000 data_batch_1,  Train_loss : 4404.7139  Test_loss : 4636.4463, Time/batch_file : 2.2701, Training time: 20548.0292\n",
      "Epoch : 1773/2000 data_batch_2,  Train_loss : 4544.2891  Test_loss : 4735.6602, Time/batch_file : 2.3098, Training time: 20550.3392\n",
      "Epoch : 1773/2000 data_batch_3,  Train_loss : 4484.3770  Test_loss : 5010.4009, Time/batch_file : 2.2695, Training time: 20552.6090\n",
      "Epoch : 1773/2000 data_batch_4,  Train_loss : 4496.2534  Test_loss : 4775.4570, Time/batch_file : 2.2866, Training time: 20554.8957\n",
      "Epoch : 1773/2000 data_batch_5,  Train_loss : 4225.4795  Test_loss : 4771.9604, Time/batch_file : 2.3193, Training time: 20557.2153\n",
      "Epoch : 1774/2000 data_batch_1,  Train_loss : 4424.7041  Test_loss : 5641.6533, Time/batch_file : 2.2945, Training time: 20559.5100\n",
      "Epoch : 1774/2000 data_batch_2,  Train_loss : 4437.7437  Test_loss : 5261.8135, Time/batch_file : 2.3113, Training time: 20561.8216\n",
      "Epoch : 1774/2000 data_batch_3,  Train_loss : 4192.5342  Test_loss : 5753.3467, Time/batch_file : 2.2874, Training time: 20564.1091\n",
      "Epoch : 1774/2000 data_batch_4,  Train_loss : 4045.2393  Test_loss : 5325.8989, Time/batch_file : 2.2757, Training time: 20566.3850\n",
      "Epoch : 1774/2000 data_batch_5,  Train_loss : 4251.9893  Test_loss : 5267.5737, Time/batch_file : 2.2775, Training time: 20568.6627\n",
      "Epoch : 1775/2000 data_batch_1,  Train_loss : 4497.0981  Test_loss : 5029.5791, Time/batch_file : 2.2877, Training time: 20570.9506\n",
      "Epoch : 1775/2000 data_batch_2,  Train_loss : 4448.7217  Test_loss : 5106.3896, Time/batch_file : 2.2813, Training time: 20573.2322\n",
      "Epoch : 1775/2000 data_batch_3,  Train_loss : 4539.0474  Test_loss : 5061.0146, Time/batch_file : 2.2771, Training time: 20575.5094\n",
      "Epoch : 1775/2000 data_batch_4,  Train_loss : 4068.4097  Test_loss : 5020.7300, Time/batch_file : 2.2911, Training time: 20577.8007\n",
      "Epoch : 1775/2000 data_batch_5,  Train_loss : 4291.7490  Test_loss : 5178.5898, Time/batch_file : 2.3024, Training time: 20580.1035\n",
      "Epoch : 1776/2000 data_batch_1,  Train_loss : 4657.9336  Test_loss : 4819.8130, Time/batch_file : 2.2802, Training time: 20582.3839\n",
      "Epoch : 1776/2000 data_batch_2,  Train_loss : 4750.7681  Test_loss : 4354.8896, Time/batch_file : 2.2971, Training time: 20584.6811\n",
      "Epoch : 1776/2000 data_batch_3,  Train_loss : 4707.2476  Test_loss : 4455.5752, Time/batch_file : 2.3113, Training time: 20586.9926\n",
      "Epoch : 1776/2000 data_batch_4,  Train_loss : 4723.0498  Test_loss : 4557.2783, Time/batch_file : 2.3088, Training time: 20589.3015\n",
      "Epoch : 1776/2000 data_batch_5,  Train_loss : 4925.5854  Test_loss : 4424.2871, Time/batch_file : 2.2931, Training time: 20591.5948\n",
      "Epoch : 1777/2000 data_batch_1,  Train_loss : 4827.3364  Test_loss : 5348.8477, Time/batch_file : 2.2826, Training time: 20593.8777\n",
      "Epoch : 1777/2000 data_batch_2,  Train_loss : 4749.4131  Test_loss : 5084.3755, Time/batch_file : 2.2846, Training time: 20596.1625\n",
      "Epoch : 1777/2000 data_batch_3,  Train_loss : 4865.8887  Test_loss : 5372.4043, Time/batch_file : 2.2991, Training time: 20598.4618\n",
      "Epoch : 1777/2000 data_batch_4,  Train_loss : 4713.8770  Test_loss : 5403.3140, Time/batch_file : 2.2987, Training time: 20600.7606\n",
      "Epoch : 1777/2000 data_batch_5,  Train_loss : 4781.4395  Test_loss : 5270.0850, Time/batch_file : 2.2881, Training time: 20603.0489\n",
      "Epoch : 1778/2000 data_batch_1,  Train_loss : 3955.1113  Test_loss : 4940.4463, Time/batch_file : 2.2940, Training time: 20605.3432\n",
      "Epoch : 1778/2000 data_batch_2,  Train_loss : 4178.7090  Test_loss : 4793.8701, Time/batch_file : 2.2684, Training time: 20607.6118\n",
      "Epoch : 1778/2000 data_batch_3,  Train_loss : 4187.4287  Test_loss : 4932.2002, Time/batch_file : 2.2933, Training time: 20609.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1778/2000 data_batch_4,  Train_loss : 4165.4253  Test_loss : 4612.2603, Time/batch_file : 2.2830, Training time: 20612.1885\n",
      "Epoch : 1778/2000 data_batch_5,  Train_loss : 4190.0669  Test_loss : 5054.3906, Time/batch_file : 2.2815, Training time: 20614.4702\n",
      "Epoch : 1779/2000 data_batch_1,  Train_loss : 4813.7046  Test_loss : 4844.7739, Time/batch_file : 2.3131, Training time: 20616.7836\n",
      "Epoch : 1779/2000 data_batch_2,  Train_loss : 4552.4766  Test_loss : 5014.6743, Time/batch_file : 2.3011, Training time: 20619.0848\n",
      "Epoch : 1779/2000 data_batch_3,  Train_loss : 4454.2490  Test_loss : 5030.6548, Time/batch_file : 2.2896, Training time: 20621.3746\n",
      "Epoch : 1779/2000 data_batch_4,  Train_loss : 4444.9473  Test_loss : 5031.8335, Time/batch_file : 2.2878, Training time: 20623.6626\n",
      "Epoch : 1779/2000 data_batch_5,  Train_loss : 4425.5708  Test_loss : 4633.6489, Time/batch_file : 2.2881, Training time: 20625.9509\n",
      "Epoch : 1780/2000 data_batch_1,  Train_loss : 4513.8232  Test_loss : 4845.1172, Time/batch_file : 2.2971, Training time: 20628.2483\n",
      "Epoch : 1780/2000 data_batch_2,  Train_loss : 4758.2217  Test_loss : 4617.1631, Time/batch_file : 2.2823, Training time: 20630.5308\n",
      "Epoch : 1780/2000 data_batch_3,  Train_loss : 4358.8828  Test_loss : 4829.9497, Time/batch_file : 2.2856, Training time: 20632.8166\n",
      "Epoch : 1780/2000 data_batch_4,  Train_loss : 4271.1455  Test_loss : 4724.1182, Time/batch_file : 2.2854, Training time: 20635.1022\n",
      "Epoch : 1780/2000 data_batch_5,  Train_loss : 4181.5356  Test_loss : 4500.8076, Time/batch_file : 2.2834, Training time: 20637.3858\n",
      "[./nets/net-1780.ckpt] SAVED\n",
      "Epoch : 1781/2000 data_batch_1,  Train_loss : 4161.3169  Test_loss : 4981.1606, Time/batch_file : 2.4051, Training time: 20641.0819\n",
      "Epoch : 1781/2000 data_batch_2,  Train_loss : 4193.5088  Test_loss : 5136.2690, Time/batch_file : 2.2730, Training time: 20643.3551\n",
      "Epoch : 1781/2000 data_batch_3,  Train_loss : 4256.8213  Test_loss : 5206.0820, Time/batch_file : 2.2546, Training time: 20645.6100\n",
      "Epoch : 1781/2000 data_batch_4,  Train_loss : 4210.9844  Test_loss : 5176.6274, Time/batch_file : 2.2820, Training time: 20647.8921\n",
      "Epoch : 1781/2000 data_batch_5,  Train_loss : 4430.7490  Test_loss : 5060.7720, Time/batch_file : 2.2554, Training time: 20650.1477\n",
      "Epoch : 1782/2000 data_batch_1,  Train_loss : 4620.6582  Test_loss : 5019.5776, Time/batch_file : 2.2970, Training time: 20652.4450\n",
      "Epoch : 1782/2000 data_batch_2,  Train_loss : 4518.0898  Test_loss : 4965.2783, Time/batch_file : 2.2678, Training time: 20654.7130\n",
      "Epoch : 1782/2000 data_batch_3,  Train_loss : 4441.9097  Test_loss : 5096.3784, Time/batch_file : 2.2862, Training time: 20656.9994\n",
      "Epoch : 1782/2000 data_batch_4,  Train_loss : 4330.7412  Test_loss : 4921.1812, Time/batch_file : 2.2738, Training time: 20659.2733\n",
      "Epoch : 1782/2000 data_batch_5,  Train_loss : 4600.4824  Test_loss : 5018.7983, Time/batch_file : 2.2751, Training time: 20661.5487\n",
      "Epoch : 1783/2000 data_batch_1,  Train_loss : 4709.2275  Test_loss : 5076.6538, Time/batch_file : 2.2528, Training time: 20663.8016\n",
      "Epoch : 1783/2000 data_batch_2,  Train_loss : 4819.4111  Test_loss : 4828.6035, Time/batch_file : 2.2685, Training time: 20666.0704\n",
      "Epoch : 1783/2000 data_batch_3,  Train_loss : 4712.7700  Test_loss : 5056.1616, Time/batch_file : 2.2723, Training time: 20668.3429\n",
      "Epoch : 1783/2000 data_batch_4,  Train_loss : 4753.3955  Test_loss : 4864.3643, Time/batch_file : 2.2703, Training time: 20670.6135\n",
      "Epoch : 1783/2000 data_batch_5,  Train_loss : 4362.6851  Test_loss : 5139.0786, Time/batch_file : 2.2919, Training time: 20672.9056\n",
      "Epoch : 1784/2000 data_batch_1,  Train_loss : 5116.3232  Test_loss : 4856.9404, Time/batch_file : 2.2668, Training time: 20675.1727\n",
      "Epoch : 1784/2000 data_batch_2,  Train_loss : 4786.9980  Test_loss : 5056.8345, Time/batch_file : 2.2782, Training time: 20677.4512\n",
      "Epoch : 1784/2000 data_batch_3,  Train_loss : 5032.1299  Test_loss : 4960.8130, Time/batch_file : 2.2779, Training time: 20679.7292\n",
      "Epoch : 1784/2000 data_batch_4,  Train_loss : 5024.6953  Test_loss : 4957.7617, Time/batch_file : 2.2691, Training time: 20681.9983\n",
      "Epoch : 1784/2000 data_batch_5,  Train_loss : 5173.4004  Test_loss : 4988.8916, Time/batch_file : 2.2670, Training time: 20684.2656\n",
      "Epoch : 1785/2000 data_batch_1,  Train_loss : 4350.6328  Test_loss : 4794.4326, Time/batch_file : 2.2821, Training time: 20686.5478\n",
      "Epoch : 1785/2000 data_batch_2,  Train_loss : 4208.0020  Test_loss : 4891.4082, Time/batch_file : 2.2744, Training time: 20688.8224\n",
      "Epoch : 1785/2000 data_batch_3,  Train_loss : 4306.7217  Test_loss : 4654.8330, Time/batch_file : 2.3065, Training time: 20691.1291\n",
      "Epoch : 1785/2000 data_batch_4,  Train_loss : 4185.3828  Test_loss : 4888.8535, Time/batch_file : 2.2667, Training time: 20693.3961\n",
      "Epoch : 1785/2000 data_batch_5,  Train_loss : 4089.7156  Test_loss : 4804.7896, Time/batch_file : 2.2864, Training time: 20695.6828\n",
      "Epoch : 1786/2000 data_batch_1,  Train_loss : 4397.8696  Test_loss : 4770.8047, Time/batch_file : 2.2839, Training time: 20697.9668\n",
      "Epoch : 1786/2000 data_batch_2,  Train_loss : 4665.0303  Test_loss : 4785.2432, Time/batch_file : 2.2674, Training time: 20700.2345\n",
      "Epoch : 1786/2000 data_batch_3,  Train_loss : 4588.8706  Test_loss : 4659.3271, Time/batch_file : 2.2598, Training time: 20702.4944\n",
      "Epoch : 1786/2000 data_batch_4,  Train_loss : 4737.4585  Test_loss : 4714.1094, Time/batch_file : 2.2644, Training time: 20704.7591\n",
      "Epoch : 1786/2000 data_batch_5,  Train_loss : 4876.7500  Test_loss : 4837.0596, Time/batch_file : 2.2670, Training time: 20707.0262\n",
      "Epoch : 1787/2000 data_batch_1,  Train_loss : 4946.2910  Test_loss : 5368.8799, Time/batch_file : 2.2874, Training time: 20709.3138\n",
      "Epoch : 1787/2000 data_batch_2,  Train_loss : 5251.9409  Test_loss : 5211.4531, Time/batch_file : 2.2768, Training time: 20711.5907\n",
      "Epoch : 1787/2000 data_batch_3,  Train_loss : 5212.4785  Test_loss : 5053.4209, Time/batch_file : 2.2944, Training time: 20713.8854\n",
      "Epoch : 1787/2000 data_batch_4,  Train_loss : 4993.6055  Test_loss : 4907.3462, Time/batch_file : 2.2668, Training time: 20716.1524\n",
      "Epoch : 1787/2000 data_batch_5,  Train_loss : 4846.8525  Test_loss : 4894.4170, Time/batch_file : 2.2981, Training time: 20718.4507\n",
      "Epoch : 1788/2000 data_batch_1,  Train_loss : 4755.9121  Test_loss : 4630.1191, Time/batch_file : 2.3089, Training time: 20720.7597\n",
      "Epoch : 1788/2000 data_batch_2,  Train_loss : 4782.2974  Test_loss : 4600.4844, Time/batch_file : 2.2810, Training time: 20723.0410\n",
      "Epoch : 1788/2000 data_batch_3,  Train_loss : 4806.8506  Test_loss : 4585.5835, Time/batch_file : 2.2775, Training time: 20725.3187\n",
      "Epoch : 1788/2000 data_batch_4,  Train_loss : 4841.9893  Test_loss : 4430.9351, Time/batch_file : 2.2650, Training time: 20727.5838\n",
      "Epoch : 1788/2000 data_batch_5,  Train_loss : 4495.5679  Test_loss : 4654.1294, Time/batch_file : 2.3006, Training time: 20729.8846\n",
      "Epoch : 1789/2000 data_batch_1,  Train_loss : 5030.4824  Test_loss : 4780.8530, Time/batch_file : 2.2649, Training time: 20732.1497\n",
      "Epoch : 1789/2000 data_batch_2,  Train_loss : 4595.5742  Test_loss : 4627.3223, Time/batch_file : 2.2751, Training time: 20734.4250\n",
      "Epoch : 1789/2000 data_batch_3,  Train_loss : 4492.6162  Test_loss : 4811.6045, Time/batch_file : 2.2718, Training time: 20736.6969\n",
      "Epoch : 1789/2000 data_batch_4,  Train_loss : 4905.8291  Test_loss : 4998.7788, Time/batch_file : 2.2749, Training time: 20738.9720\n",
      "Epoch : 1789/2000 data_batch_5,  Train_loss : 4509.5122  Test_loss : 4581.3779, Time/batch_file : 2.2662, Training time: 20741.2383\n",
      "Epoch : 1790/2000 data_batch_1,  Train_loss : 4496.8467  Test_loss : 4628.6245, Time/batch_file : 2.2640, Training time: 20743.5025\n",
      "Epoch : 1790/2000 data_batch_2,  Train_loss : 4399.7314  Test_loss : 4626.7544, Time/batch_file : 2.2673, Training time: 20745.7700\n",
      "Epoch : 1790/2000 data_batch_3,  Train_loss : 4429.7529  Test_loss : 4467.4438, Time/batch_file : 2.2646, Training time: 20748.0348\n",
      "Epoch : 1790/2000 data_batch_4,  Train_loss : 4572.7349  Test_loss : 4399.6104, Time/batch_file : 2.2624, Training time: 20750.2974\n",
      "Epoch : 1790/2000 data_batch_5,  Train_loss : 4456.6719  Test_loss : 4405.2148, Time/batch_file : 2.2598, Training time: 20752.5575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[./nets/net-1790.ckpt] SAVED\n",
      "Epoch : 1791/2000 data_batch_1,  Train_loss : 4468.4561  Test_loss : 4510.6411, Time/batch_file : 2.3021, Training time: 20756.1558\n",
      "Epoch : 1791/2000 data_batch_2,  Train_loss : 4592.4375  Test_loss : 4659.1514, Time/batch_file : 2.2346, Training time: 20758.3906\n",
      "Epoch : 1791/2000 data_batch_3,  Train_loss : 4580.5498  Test_loss : 4706.3145, Time/batch_file : 2.2445, Training time: 20760.6354\n",
      "Epoch : 1791/2000 data_batch_4,  Train_loss : 4553.3638  Test_loss : 4700.4580, Time/batch_file : 2.2477, Training time: 20762.8834\n",
      "Epoch : 1791/2000 data_batch_5,  Train_loss : 4628.1216  Test_loss : 4702.1826, Time/batch_file : 2.2601, Training time: 20765.1438\n",
      "Epoch : 1792/2000 data_batch_1,  Train_loss : 4846.7012  Test_loss : 4671.3237, Time/batch_file : 2.2709, Training time: 20767.4149\n",
      "Epoch : 1792/2000 data_batch_2,  Train_loss : 4761.3096  Test_loss : 4763.2412, Time/batch_file : 2.2714, Training time: 20769.6865\n",
      "Epoch : 1792/2000 data_batch_3,  Train_loss : 4860.4653  Test_loss : 4619.6235, Time/batch_file : 2.2725, Training time: 20771.9592\n",
      "Epoch : 1792/2000 data_batch_4,  Train_loss : 4907.7842  Test_loss : 4687.6279, Time/batch_file : 2.2739, Training time: 20774.2334\n",
      "Epoch : 1792/2000 data_batch_5,  Train_loss : 4768.9414  Test_loss : 4759.1201, Time/batch_file : 2.2733, Training time: 20776.5069\n",
      "Epoch : 1793/2000 data_batch_1,  Train_loss : 4524.3472  Test_loss : 5304.8257, Time/batch_file : 2.2902, Training time: 20778.7972\n",
      "Epoch : 1793/2000 data_batch_2,  Train_loss : 4675.3213  Test_loss : 5407.7534, Time/batch_file : 2.2899, Training time: 20781.0872\n",
      "Epoch : 1793/2000 data_batch_3,  Train_loss : 4658.2603  Test_loss : 5806.6953, Time/batch_file : 2.2864, Training time: 20783.3739\n",
      "Epoch : 1793/2000 data_batch_4,  Train_loss : 4443.3623  Test_loss : 5559.8838, Time/batch_file : 2.2872, Training time: 20785.6613\n",
      "Epoch : 1793/2000 data_batch_5,  Train_loss : 4566.1001  Test_loss : 5394.5312, Time/batch_file : 2.2857, Training time: 20787.9473\n",
      "Epoch : 1794/2000 data_batch_1,  Train_loss : 4608.3101  Test_loss : 4903.0903, Time/batch_file : 2.2596, Training time: 20790.2071\n",
      "Epoch : 1794/2000 data_batch_2,  Train_loss : 4631.7090  Test_loss : 4841.9448, Time/batch_file : 2.2544, Training time: 20792.4617\n",
      "Epoch : 1794/2000 data_batch_3,  Train_loss : 4412.2754  Test_loss : 4919.8677, Time/batch_file : 2.2578, Training time: 20794.7198\n",
      "Epoch : 1794/2000 data_batch_4,  Train_loss : 4220.5273  Test_loss : 4820.9155, Time/batch_file : 2.2519, Training time: 20796.9720\n",
      "Epoch : 1794/2000 data_batch_5,  Train_loss : 4414.4189  Test_loss : 4629.9473, Time/batch_file : 2.2643, Training time: 20799.2365\n",
      "Epoch : 1795/2000 data_batch_1,  Train_loss : 4643.8110  Test_loss : 4656.6768, Time/batch_file : 2.2536, Training time: 20801.4903\n",
      "Epoch : 1795/2000 data_batch_2,  Train_loss : 4529.4448  Test_loss : 4764.8999, Time/batch_file : 2.2577, Training time: 20803.7481\n",
      "Epoch : 1795/2000 data_batch_3,  Train_loss : 4624.2227  Test_loss : 4745.7026, Time/batch_file : 2.2625, Training time: 20806.0108\n",
      "Epoch : 1795/2000 data_batch_4,  Train_loss : 4575.9160  Test_loss : 4993.7397, Time/batch_file : 2.2577, Training time: 20808.2686\n",
      "Epoch : 1795/2000 data_batch_5,  Train_loss : 4408.0215  Test_loss : 5096.4873, Time/batch_file : 2.2647, Training time: 20810.5335\n",
      "Epoch : 1796/2000 data_batch_1,  Train_loss : 4383.6416  Test_loss : 5354.9478, Time/batch_file : 2.2655, Training time: 20812.7992\n",
      "Epoch : 1796/2000 data_batch_2,  Train_loss : 4122.2344  Test_loss : 5155.8008, Time/batch_file : 2.2602, Training time: 20815.0596\n",
      "Epoch : 1796/2000 data_batch_3,  Train_loss : 4112.3770  Test_loss : 5248.3779, Time/batch_file : 2.2519, Training time: 20817.3116\n",
      "Epoch : 1796/2000 data_batch_4,  Train_loss : 4279.2168  Test_loss : 5523.4487, Time/batch_file : 2.2854, Training time: 20819.5971\n",
      "Epoch : 1796/2000 data_batch_5,  Train_loss : 4153.3052  Test_loss : 5436.5635, Time/batch_file : 2.2522, Training time: 20821.8495\n",
      "Epoch : 1797/2000 data_batch_1,  Train_loss : 4435.3564  Test_loss : 4705.8892, Time/batch_file : 2.2673, Training time: 20824.1170\n",
      "Epoch : 1797/2000 data_batch_2,  Train_loss : 4185.8105  Test_loss : 4384.7358, Time/batch_file : 2.2655, Training time: 20826.3826\n",
      "Epoch : 1797/2000 data_batch_3,  Train_loss : 4485.4961  Test_loss : 4688.8389, Time/batch_file : 2.2634, Training time: 20828.6462\n",
      "Epoch : 1797/2000 data_batch_4,  Train_loss : 4399.8271  Test_loss : 4210.8745, Time/batch_file : 2.2688, Training time: 20830.9153\n",
      "Epoch : 1797/2000 data_batch_5,  Train_loss : 4116.2354  Test_loss : 4769.7676, Time/batch_file : 2.2622, Training time: 20833.1777\n",
      "Epoch : 1798/2000 data_batch_1,  Train_loss : 5053.4785  Test_loss : 5258.4424, Time/batch_file : 2.2616, Training time: 20835.4395\n",
      "Epoch : 1798/2000 data_batch_2,  Train_loss : 4879.8955  Test_loss : 5403.4131, Time/batch_file : 2.2848, Training time: 20837.7245\n",
      "Epoch : 1798/2000 data_batch_3,  Train_loss : 4821.6611  Test_loss : 5209.8125, Time/batch_file : 2.2726, Training time: 20839.9973\n",
      "Epoch : 1798/2000 data_batch_4,  Train_loss : 4940.3262  Test_loss : 5215.8252, Time/batch_file : 2.2653, Training time: 20842.2629\n",
      "Epoch : 1798/2000 data_batch_5,  Train_loss : 4963.8281  Test_loss : 5362.6895, Time/batch_file : 2.2703, Training time: 20844.5334\n",
      "Epoch : 1799/2000 data_batch_1,  Train_loss : 4852.3906  Test_loss : 4970.1367, Time/batch_file : 2.2661, Training time: 20846.7996\n",
      "Epoch : 1799/2000 data_batch_2,  Train_loss : 4599.8291  Test_loss : 4868.4355, Time/batch_file : 2.2629, Training time: 20849.0628\n",
      "Epoch : 1799/2000 data_batch_3,  Train_loss : 4902.5005  Test_loss : 5114.4697, Time/batch_file : 2.2621, Training time: 20851.3250\n",
      "Epoch : 1799/2000 data_batch_4,  Train_loss : 4699.4888  Test_loss : 4912.7563, Time/batch_file : 2.2699, Training time: 20853.5951\n",
      "Epoch : 1799/2000 data_batch_5,  Train_loss : 4711.3555  Test_loss : 4788.5908, Time/batch_file : 2.2691, Training time: 20855.8644\n",
      "Epoch : 1800/2000 data_batch_1,  Train_loss : 4368.5347  Test_loss : 4512.9170, Time/batch_file : 2.2615, Training time: 20858.1262\n",
      "Epoch : 1800/2000 data_batch_2,  Train_loss : 4412.3979  Test_loss : 4793.4053, Time/batch_file : 2.2589, Training time: 20860.3853\n",
      "Epoch : 1800/2000 data_batch_3,  Train_loss : 4551.7178  Test_loss : 4467.2593, Time/batch_file : 2.2503, Training time: 20862.6357\n",
      "Epoch : 1800/2000 data_batch_4,  Train_loss : 4601.9854  Test_loss : 4488.8291, Time/batch_file : 2.2664, Training time: 20864.9023\n",
      "Epoch : 1800/2000 data_batch_5,  Train_loss : 4477.8657  Test_loss : 4919.7148, Time/batch_file : 2.2685, Training time: 20867.1710\n",
      "[./nets/net-1800.ckpt] SAVED\n",
      "Epoch : 1801/2000 data_batch_1,  Train_loss : 4403.3359  Test_loss : 4597.1626, Time/batch_file : 2.2902, Training time: 20870.7631\n",
      "Epoch : 1801/2000 data_batch_2,  Train_loss : 4434.6211  Test_loss : 4450.7119, Time/batch_file : 2.2778, Training time: 20873.0411\n",
      "Epoch : 1801/2000 data_batch_3,  Train_loss : 4397.4561  Test_loss : 4202.1226, Time/batch_file : 2.2791, Training time: 20875.3204\n",
      "Epoch : 1801/2000 data_batch_4,  Train_loss : 4367.6533  Test_loss : 4408.4307, Time/batch_file : 2.2809, Training time: 20877.6016\n",
      "Epoch : 1801/2000 data_batch_5,  Train_loss : 4240.6875  Test_loss : 4612.7607, Time/batch_file : 2.2715, Training time: 20879.8732\n",
      "Epoch : 1802/2000 data_batch_1,  Train_loss : 5082.5439  Test_loss : 5149.5200, Time/batch_file : 2.2864, Training time: 20882.1599\n",
      "Epoch : 1802/2000 data_batch_2,  Train_loss : 4801.6274  Test_loss : 5165.5996, Time/batch_file : 2.2818, Training time: 20884.4419\n",
      "Epoch : 1802/2000 data_batch_3,  Train_loss : 4924.6240  Test_loss : 4961.2896, Time/batch_file : 2.2935, Training time: 20886.7356\n",
      "Epoch : 1802/2000 data_batch_4,  Train_loss : 4817.7935  Test_loss : 5189.7446, Time/batch_file : 2.2788, Training time: 20889.0147\n",
      "Epoch : 1802/2000 data_batch_5,  Train_loss : 4882.0308  Test_loss : 5235.6865, Time/batch_file : 2.2916, Training time: 20891.3065\n",
      "Epoch : 1803/2000 data_batch_1,  Train_loss : 4509.8369  Test_loss : 4565.0591, Time/batch_file : 2.2654, Training time: 20893.5721\n",
      "Epoch : 1803/2000 data_batch_2,  Train_loss : 4510.7979  Test_loss : 4713.8291, Time/batch_file : 2.2698, Training time: 20895.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1803/2000 data_batch_3,  Train_loss : 4402.6758  Test_loss : 4749.1914, Time/batch_file : 2.2765, Training time: 20898.1189\n",
      "Epoch : 1803/2000 data_batch_4,  Train_loss : 4572.2222  Test_loss : 4664.6089, Time/batch_file : 2.2775, Training time: 20900.3966\n",
      "Epoch : 1803/2000 data_batch_5,  Train_loss : 4307.0898  Test_loss : 4795.5215, Time/batch_file : 2.2586, Training time: 20902.6554\n",
      "Epoch : 1804/2000 data_batch_1,  Train_loss : 4713.2412  Test_loss : 4239.6094, Time/batch_file : 2.2730, Training time: 20904.9287\n",
      "Epoch : 1804/2000 data_batch_2,  Train_loss : 4745.5635  Test_loss : 4697.2656, Time/batch_file : 2.2717, Training time: 20907.2006\n",
      "Epoch : 1804/2000 data_batch_3,  Train_loss : 4608.6763  Test_loss : 4440.6099, Time/batch_file : 2.2724, Training time: 20909.4732\n",
      "Epoch : 1804/2000 data_batch_4,  Train_loss : 4769.9648  Test_loss : 4590.7339, Time/batch_file : 2.2648, Training time: 20911.7383\n",
      "Epoch : 1804/2000 data_batch_5,  Train_loss : 4743.5615  Test_loss : 4645.4468, Time/batch_file : 2.2721, Training time: 20914.0106\n",
      "Epoch : 1805/2000 data_batch_1,  Train_loss : 5456.7710  Test_loss : 4843.2583, Time/batch_file : 2.2699, Training time: 20916.2808\n",
      "Epoch : 1805/2000 data_batch_2,  Train_loss : 5557.0757  Test_loss : 4715.7695, Time/batch_file : 2.2630, Training time: 20918.5440\n",
      "Epoch : 1805/2000 data_batch_3,  Train_loss : 5530.7910  Test_loss : 4709.3936, Time/batch_file : 2.2650, Training time: 20920.8092\n",
      "Epoch : 1805/2000 data_batch_4,  Train_loss : 5453.6504  Test_loss : 4650.5996, Time/batch_file : 2.2767, Training time: 20923.0862\n",
      "Epoch : 1805/2000 data_batch_5,  Train_loss : 5102.3770  Test_loss : 4876.6050, Time/batch_file : 2.2626, Training time: 20925.3490\n",
      "Epoch : 1806/2000 data_batch_1,  Train_loss : 4798.6611  Test_loss : 4842.8438, Time/batch_file : 2.2773, Training time: 20927.6265\n",
      "Epoch : 1806/2000 data_batch_2,  Train_loss : 4723.6919  Test_loss : 4802.6060, Time/batch_file : 2.2717, Training time: 20929.8985\n",
      "Epoch : 1806/2000 data_batch_3,  Train_loss : 4926.7544  Test_loss : 4870.8496, Time/batch_file : 2.2742, Training time: 20932.1729\n",
      "Epoch : 1806/2000 data_batch_4,  Train_loss : 5023.3818  Test_loss : 5063.1250, Time/batch_file : 2.2705, Training time: 20934.4436\n",
      "Epoch : 1806/2000 data_batch_5,  Train_loss : 4911.5278  Test_loss : 5158.4653, Time/batch_file : 2.2738, Training time: 20936.7177\n",
      "Epoch : 1807/2000 data_batch_1,  Train_loss : 4320.7856  Test_loss : 4607.0225, Time/batch_file : 2.2896, Training time: 20939.0074\n",
      "Epoch : 1807/2000 data_batch_2,  Train_loss : 4490.0825  Test_loss : 4558.4453, Time/batch_file : 2.2818, Training time: 20941.2894\n",
      "Epoch : 1807/2000 data_batch_3,  Train_loss : 4654.6719  Test_loss : 4629.5898, Time/batch_file : 2.2659, Training time: 20943.5555\n",
      "Epoch : 1807/2000 data_batch_4,  Train_loss : 4386.9106  Test_loss : 4616.6787, Time/batch_file : 2.2796, Training time: 20945.8353\n",
      "Epoch : 1807/2000 data_batch_5,  Train_loss : 4348.4116  Test_loss : 4485.7222, Time/batch_file : 2.2642, Training time: 20948.0997\n",
      "Epoch : 1808/2000 data_batch_1,  Train_loss : 3893.4124  Test_loss : 4708.4614, Time/batch_file : 2.2723, Training time: 20950.3723\n",
      "Epoch : 1808/2000 data_batch_2,  Train_loss : 4333.2324  Test_loss : 4702.2764, Time/batch_file : 2.2581, Training time: 20952.6306\n",
      "Epoch : 1808/2000 data_batch_3,  Train_loss : 4202.9878  Test_loss : 4534.2212, Time/batch_file : 2.2702, Training time: 20954.9010\n",
      "Epoch : 1808/2000 data_batch_4,  Train_loss : 4339.0596  Test_loss : 4689.3374, Time/batch_file : 2.2499, Training time: 20957.1511\n",
      "Epoch : 1808/2000 data_batch_5,  Train_loss : 4360.7139  Test_loss : 4776.0029, Time/batch_file : 2.2737, Training time: 20959.4250\n",
      "Epoch : 1809/2000 data_batch_1,  Train_loss : 4927.6753  Test_loss : 4540.9463, Time/batch_file : 2.2688, Training time: 20961.6940\n",
      "Epoch : 1809/2000 data_batch_2,  Train_loss : 4888.8154  Test_loss : 4429.6284, Time/batch_file : 2.2729, Training time: 20963.9671\n",
      "Epoch : 1809/2000 data_batch_3,  Train_loss : 4811.4824  Test_loss : 4643.3135, Time/batch_file : 2.2600, Training time: 20966.2274\n",
      "Epoch : 1809/2000 data_batch_4,  Train_loss : 4618.0376  Test_loss : 4428.0591, Time/batch_file : 2.2768, Training time: 20968.5044\n",
      "Epoch : 1809/2000 data_batch_5,  Train_loss : 4747.2207  Test_loss : 4480.4570, Time/batch_file : 2.2618, Training time: 20970.7665\n",
      "Epoch : 1810/2000 data_batch_1,  Train_loss : 4486.7407  Test_loss : 4935.3696, Time/batch_file : 2.2736, Training time: 20973.0404\n",
      "Epoch : 1810/2000 data_batch_2,  Train_loss : 4480.5068  Test_loss : 4692.0063, Time/batch_file : 2.2632, Training time: 20975.3038\n",
      "Epoch : 1810/2000 data_batch_3,  Train_loss : 4664.6763  Test_loss : 5019.1699, Time/batch_file : 2.2724, Training time: 20977.5764\n",
      "Epoch : 1810/2000 data_batch_4,  Train_loss : 4608.9746  Test_loss : 4976.6792, Time/batch_file : 2.2791, Training time: 20979.8556\n",
      "Epoch : 1810/2000 data_batch_5,  Train_loss : 4451.1577  Test_loss : 4559.8066, Time/batch_file : 2.2718, Training time: 20982.1276\n",
      "[./nets/net-1810.ckpt] SAVED\n",
      "Epoch : 1811/2000 data_batch_1,  Train_loss : 4025.0669  Test_loss : 4160.9102, Time/batch_file : 2.3714, Training time: 20985.7703\n",
      "Epoch : 1811/2000 data_batch_2,  Train_loss : 4081.3511  Test_loss : 4398.8638, Time/batch_file : 2.2971, Training time: 20988.0676\n",
      "Epoch : 1811/2000 data_batch_3,  Train_loss : 4333.0225  Test_loss : 4637.4565, Time/batch_file : 2.3039, Training time: 20990.3717\n",
      "Epoch : 1811/2000 data_batch_4,  Train_loss : 4397.9990  Test_loss : 4167.3301, Time/batch_file : 2.2873, Training time: 20992.6592\n",
      "Epoch : 1811/2000 data_batch_5,  Train_loss : 4331.6460  Test_loss : 4201.6118, Time/batch_file : 2.2703, Training time: 20994.9297\n",
      "Epoch : 1812/2000 data_batch_1,  Train_loss : 4205.5112  Test_loss : 4569.8564, Time/batch_file : 2.2833, Training time: 20997.2133\n",
      "Epoch : 1812/2000 data_batch_2,  Train_loss : 4250.1948  Test_loss : 4633.1597, Time/batch_file : 2.2616, Training time: 20999.4750\n",
      "Epoch : 1812/2000 data_batch_3,  Train_loss : 4219.6934  Test_loss : 4631.5420, Time/batch_file : 2.2840, Training time: 21001.7592\n",
      "Epoch : 1812/2000 data_batch_4,  Train_loss : 4306.4927  Test_loss : 4168.4014, Time/batch_file : 2.2552, Training time: 21004.0146\n",
      "Epoch : 1812/2000 data_batch_5,  Train_loss : 4174.6768  Test_loss : 4264.6606, Time/batch_file : 2.2873, Training time: 21006.3021\n",
      "Epoch : 1813/2000 data_batch_1,  Train_loss : 4218.6733  Test_loss : 5063.8081, Time/batch_file : 2.2749, Training time: 21008.5773\n",
      "Epoch : 1813/2000 data_batch_2,  Train_loss : 4434.6616  Test_loss : 5281.8154, Time/batch_file : 2.2998, Training time: 21010.8774\n",
      "Epoch : 1813/2000 data_batch_3,  Train_loss : 4529.0845  Test_loss : 5230.8013, Time/batch_file : 2.2723, Training time: 21013.1498\n",
      "Epoch : 1813/2000 data_batch_4,  Train_loss : 4408.4087  Test_loss : 5142.8120, Time/batch_file : 2.2929, Training time: 21015.4429\n",
      "Epoch : 1813/2000 data_batch_5,  Train_loss : 4428.7407  Test_loss : 5205.2417, Time/batch_file : 2.2786, Training time: 21017.7218\n",
      "Epoch : 1814/2000 data_batch_1,  Train_loss : 3958.0000  Test_loss : 4730.2812, Time/batch_file : 2.2877, Training time: 21020.0098\n",
      "Epoch : 1814/2000 data_batch_2,  Train_loss : 4143.7632  Test_loss : 4807.4136, Time/batch_file : 2.3057, Training time: 21022.3157\n",
      "Epoch : 1814/2000 data_batch_3,  Train_loss : 4096.3364  Test_loss : 4648.6479, Time/batch_file : 2.2785, Training time: 21024.5944\n",
      "Epoch : 1814/2000 data_batch_4,  Train_loss : 4089.6943  Test_loss : 4865.8833, Time/batch_file : 2.2521, Training time: 21026.8467\n",
      "Epoch : 1814/2000 data_batch_5,  Train_loss : 4208.3789  Test_loss : 4875.3008, Time/batch_file : 2.2847, Training time: 21029.1315\n",
      "Epoch : 1815/2000 data_batch_1,  Train_loss : 4274.5151  Test_loss : 4399.6143, Time/batch_file : 2.2779, Training time: 21031.4097\n",
      "Epoch : 1815/2000 data_batch_2,  Train_loss : 4505.9863  Test_loss : 4207.8955, Time/batch_file : 2.2899, Training time: 21033.6998\n",
      "Epoch : 1815/2000 data_batch_3,  Train_loss : 4362.8438  Test_loss : 4274.3999, Time/batch_file : 2.2763, Training time: 21035.9763\n",
      "Epoch : 1815/2000 data_batch_4,  Train_loss : 4332.6738  Test_loss : 4402.0757, Time/batch_file : 2.2999, Training time: 21038.2764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1815/2000 data_batch_5,  Train_loss : 4181.8828  Test_loss : 4439.7061, Time/batch_file : 2.2741, Training time: 21040.5506\n",
      "Epoch : 1816/2000 data_batch_1,  Train_loss : 4481.8906  Test_loss : 4851.0459, Time/batch_file : 2.2841, Training time: 21042.8351\n",
      "Epoch : 1816/2000 data_batch_2,  Train_loss : 4377.0244  Test_loss : 4829.7339, Time/batch_file : 2.2688, Training time: 21045.1041\n",
      "Epoch : 1816/2000 data_batch_3,  Train_loss : 4454.0884  Test_loss : 4995.0415, Time/batch_file : 2.2799, Training time: 21047.3842\n",
      "Epoch : 1816/2000 data_batch_4,  Train_loss : 4415.9229  Test_loss : 5015.0928, Time/batch_file : 2.2623, Training time: 21049.6467\n",
      "Epoch : 1816/2000 data_batch_5,  Train_loss : 4281.9185  Test_loss : 4841.0449, Time/batch_file : 2.2811, Training time: 21051.9280\n",
      "Epoch : 1817/2000 data_batch_1,  Train_loss : 4633.7148  Test_loss : 5194.7402, Time/batch_file : 2.2653, Training time: 21054.1935\n",
      "Epoch : 1817/2000 data_batch_2,  Train_loss : 4583.2388  Test_loss : 4890.1118, Time/batch_file : 2.2858, Training time: 21056.4794\n",
      "Epoch : 1817/2000 data_batch_3,  Train_loss : 4612.4497  Test_loss : 4844.9614, Time/batch_file : 2.2684, Training time: 21058.7480\n",
      "Epoch : 1817/2000 data_batch_4,  Train_loss : 4515.1826  Test_loss : 4932.1064, Time/batch_file : 2.2916, Training time: 21061.0398\n",
      "Epoch : 1817/2000 data_batch_5,  Train_loss : 4640.2041  Test_loss : 4887.4502, Time/batch_file : 2.2548, Training time: 21063.2948\n",
      "Epoch : 1818/2000 data_batch_1,  Train_loss : 4365.8413  Test_loss : 4903.3379, Time/batch_file : 2.2878, Training time: 21065.5830\n",
      "Epoch : 1818/2000 data_batch_2,  Train_loss : 4317.4268  Test_loss : 4810.8628, Time/batch_file : 2.2611, Training time: 21067.8443\n",
      "Epoch : 1818/2000 data_batch_3,  Train_loss : 4139.7290  Test_loss : 4701.0254, Time/batch_file : 2.2783, Training time: 21070.1228\n",
      "Epoch : 1818/2000 data_batch_4,  Train_loss : 4093.7903  Test_loss : 4855.7134, Time/batch_file : 2.2599, Training time: 21072.3831\n",
      "Epoch : 1818/2000 data_batch_5,  Train_loss : 4297.7764  Test_loss : 4880.7969, Time/batch_file : 2.2861, Training time: 21074.6694\n",
      "Epoch : 1819/2000 data_batch_1,  Train_loss : 4612.5903  Test_loss : 5138.5005, Time/batch_file : 2.2709, Training time: 21076.9404\n",
      "Epoch : 1819/2000 data_batch_2,  Train_loss : 4701.0908  Test_loss : 5338.8408, Time/batch_file : 2.2930, Training time: 21079.2335\n",
      "Epoch : 1819/2000 data_batch_3,  Train_loss : 4928.5347  Test_loss : 5305.9009, Time/batch_file : 2.2716, Training time: 21081.5053\n",
      "Epoch : 1819/2000 data_batch_4,  Train_loss : 4835.0439  Test_loss : 5248.6240, Time/batch_file : 2.2975, Training time: 21083.8032\n",
      "Epoch : 1819/2000 data_batch_5,  Train_loss : 4790.4956  Test_loss : 5308.3799, Time/batch_file : 2.2746, Training time: 21086.0780\n",
      "Epoch : 1820/2000 data_batch_1,  Train_loss : 4428.1055  Test_loss : 5606.2432, Time/batch_file : 2.2802, Training time: 21088.3585\n",
      "Epoch : 1820/2000 data_batch_2,  Train_loss : 4660.0654  Test_loss : 5544.1914, Time/batch_file : 2.2677, Training time: 21090.6264\n",
      "Epoch : 1820/2000 data_batch_3,  Train_loss : 4371.2764  Test_loss : 5330.5234, Time/batch_file : 2.2842, Training time: 21092.9108\n",
      "Epoch : 1820/2000 data_batch_4,  Train_loss : 4337.6284  Test_loss : 5390.5005, Time/batch_file : 2.2658, Training time: 21095.1768\n",
      "Epoch : 1820/2000 data_batch_5,  Train_loss : 4633.3936  Test_loss : 5561.5415, Time/batch_file : 2.2816, Training time: 21097.4585\n",
      "[./nets/net-1820.ckpt] SAVED\n",
      "Epoch : 1821/2000 data_batch_1,  Train_loss : 4553.0107  Test_loss : 4848.8384, Time/batch_file : 2.2919, Training time: 21101.0436\n",
      "Epoch : 1821/2000 data_batch_2,  Train_loss : 4660.7612  Test_loss : 5183.2319, Time/batch_file : 2.2896, Training time: 21103.3334\n",
      "Epoch : 1821/2000 data_batch_3,  Train_loss : 4742.1396  Test_loss : 5172.3438, Time/batch_file : 2.2783, Training time: 21105.6118\n",
      "Epoch : 1821/2000 data_batch_4,  Train_loss : 4893.0435  Test_loss : 5152.9023, Time/batch_file : 2.2920, Training time: 21107.9040\n",
      "Epoch : 1821/2000 data_batch_5,  Train_loss : 4845.0791  Test_loss : 5057.6318, Time/batch_file : 2.2707, Training time: 21110.1749\n",
      "Epoch : 1822/2000 data_batch_1,  Train_loss : 4853.2695  Test_loss : 5359.8037, Time/batch_file : 2.3025, Training time: 21112.4776\n",
      "Epoch : 1822/2000 data_batch_2,  Train_loss : 4607.4429  Test_loss : 5595.6646, Time/batch_file : 2.2883, Training time: 21114.7661\n",
      "Epoch : 1822/2000 data_batch_3,  Train_loss : 4936.2100  Test_loss : 4982.1958, Time/batch_file : 2.2991, Training time: 21117.0655\n",
      "Epoch : 1822/2000 data_batch_4,  Train_loss : 4822.8076  Test_loss : 5300.1289, Time/batch_file : 2.2767, Training time: 21119.3423\n",
      "Epoch : 1822/2000 data_batch_5,  Train_loss : 4923.4678  Test_loss : 5318.5361, Time/batch_file : 2.3066, Training time: 21121.6490\n",
      "Epoch : 1823/2000 data_batch_1,  Train_loss : 5101.3638  Test_loss : 5534.9756, Time/batch_file : 2.2735, Training time: 21123.9227\n",
      "Epoch : 1823/2000 data_batch_2,  Train_loss : 5132.0483  Test_loss : 4985.8594, Time/batch_file : 2.3069, Training time: 21126.2299\n",
      "Epoch : 1823/2000 data_batch_3,  Train_loss : 4677.4907  Test_loss : 5358.3799, Time/batch_file : 2.2694, Training time: 21128.4995\n",
      "Epoch : 1823/2000 data_batch_4,  Train_loss : 4923.4512  Test_loss : 5330.2686, Time/batch_file : 2.3081, Training time: 21130.8078\n",
      "Epoch : 1823/2000 data_batch_5,  Train_loss : 4860.2529  Test_loss : 4901.7539, Time/batch_file : 2.2798, Training time: 21133.0879\n",
      "Epoch : 1824/2000 data_batch_1,  Train_loss : 5093.9668  Test_loss : 4953.4590, Time/batch_file : 2.3033, Training time: 21135.3914\n",
      "Epoch : 1824/2000 data_batch_2,  Train_loss : 4955.9976  Test_loss : 5294.2295, Time/batch_file : 2.2651, Training time: 21137.6567\n",
      "Epoch : 1824/2000 data_batch_3,  Train_loss : 4833.9888  Test_loss : 5100.8525, Time/batch_file : 2.3002, Training time: 21139.9571\n",
      "Epoch : 1824/2000 data_batch_4,  Train_loss : 4916.6558  Test_loss : 5142.4756, Time/batch_file : 2.2750, Training time: 21142.2323\n",
      "Epoch : 1824/2000 data_batch_5,  Train_loss : 4886.7793  Test_loss : 5288.4780, Time/batch_file : 2.2917, Training time: 21144.5242\n",
      "Epoch : 1825/2000 data_batch_1,  Train_loss : 4813.5356  Test_loss : 4888.5010, Time/batch_file : 2.2849, Training time: 21146.8093\n",
      "Epoch : 1825/2000 data_batch_2,  Train_loss : 4852.1875  Test_loss : 4577.0132, Time/batch_file : 2.3030, Training time: 21149.1126\n",
      "Epoch : 1825/2000 data_batch_3,  Train_loss : 4673.9429  Test_loss : 4830.3159, Time/batch_file : 2.2744, Training time: 21151.3872\n",
      "Epoch : 1825/2000 data_batch_4,  Train_loss : 4694.9878  Test_loss : 4706.6514, Time/batch_file : 2.3047, Training time: 21153.6922\n",
      "Epoch : 1825/2000 data_batch_5,  Train_loss : 4966.0127  Test_loss : 4729.0723, Time/batch_file : 2.2710, Training time: 21155.9635\n",
      "Epoch : 1826/2000 data_batch_1,  Train_loss : 3699.9055  Test_loss : 4648.8276, Time/batch_file : 2.2968, Training time: 21158.2604\n",
      "Epoch : 1826/2000 data_batch_2,  Train_loss : 4095.1462  Test_loss : 4767.5234, Time/batch_file : 2.2782, Training time: 21160.5387\n",
      "Epoch : 1826/2000 data_batch_3,  Train_loss : 4079.0686  Test_loss : 4757.3682, Time/batch_file : 2.3034, Training time: 21162.8423\n",
      "Epoch : 1826/2000 data_batch_4,  Train_loss : 4073.5012  Test_loss : 4889.4531, Time/batch_file : 2.2640, Training time: 21165.1064\n",
      "Epoch : 1826/2000 data_batch_5,  Train_loss : 3994.0728  Test_loss : 4666.9341, Time/batch_file : 2.2952, Training time: 21167.4019\n",
      "Epoch : 1827/2000 data_batch_1,  Train_loss : 4996.6738  Test_loss : 4548.8569, Time/batch_file : 2.2752, Training time: 21169.6774\n",
      "Epoch : 1827/2000 data_batch_2,  Train_loss : 4675.8042  Test_loss : 4486.6099, Time/batch_file : 2.2978, Training time: 21171.9754\n",
      "Epoch : 1827/2000 data_batch_3,  Train_loss : 4962.3145  Test_loss : 4603.2417, Time/batch_file : 2.2644, Training time: 21174.2400\n",
      "Epoch : 1827/2000 data_batch_4,  Train_loss : 4756.2866  Test_loss : 4555.1309, Time/batch_file : 2.2920, Training time: 21176.5322\n",
      "Epoch : 1827/2000 data_batch_5,  Train_loss : 4860.1509  Test_loss : 4511.5420, Time/batch_file : 2.3101, Training time: 21178.8424\n",
      "Epoch : 1828/2000 data_batch_1,  Train_loss : 4339.9834  Test_loss : 4814.6675, Time/batch_file : 2.2956, Training time: 21181.1383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1828/2000 data_batch_2,  Train_loss : 4127.7163  Test_loss : 4998.4731, Time/batch_file : 2.2598, Training time: 21183.3983\n",
      "Epoch : 1828/2000 data_batch_3,  Train_loss : 4054.9570  Test_loss : 4846.7393, Time/batch_file : 2.2907, Training time: 21185.6892\n",
      "Epoch : 1828/2000 data_batch_4,  Train_loss : 4052.3877  Test_loss : 4933.8560, Time/batch_file : 2.2802, Training time: 21187.9695\n",
      "Epoch : 1828/2000 data_batch_5,  Train_loss : 4116.2412  Test_loss : 4915.4736, Time/batch_file : 2.3060, Training time: 21190.2758\n",
      "Epoch : 1829/2000 data_batch_1,  Train_loss : 4893.3564  Test_loss : 4951.2451, Time/batch_file : 2.2763, Training time: 21192.5523\n",
      "Epoch : 1829/2000 data_batch_2,  Train_loss : 4758.0015  Test_loss : 4830.7393, Time/batch_file : 2.3062, Training time: 21194.8586\n",
      "Epoch : 1829/2000 data_batch_3,  Train_loss : 4690.1572  Test_loss : 4430.5200, Time/batch_file : 2.2890, Training time: 21197.1477\n",
      "Epoch : 1829/2000 data_batch_4,  Train_loss : 5080.6631  Test_loss : 4849.3286, Time/batch_file : 2.3047, Training time: 21199.4526\n",
      "Epoch : 1829/2000 data_batch_5,  Train_loss : 5024.5635  Test_loss : 4789.0864, Time/batch_file : 2.2678, Training time: 21201.7206\n",
      "Epoch : 1830/2000 data_batch_1,  Train_loss : 4607.5117  Test_loss : 4863.0894, Time/batch_file : 2.2924, Training time: 21204.0132\n",
      "Epoch : 1830/2000 data_batch_2,  Train_loss : 4581.4834  Test_loss : 5216.8677, Time/batch_file : 2.2759, Training time: 21206.2892\n",
      "Epoch : 1830/2000 data_batch_3,  Train_loss : 4394.1973  Test_loss : 5137.4517, Time/batch_file : 2.2962, Training time: 21208.5856\n",
      "Epoch : 1830/2000 data_batch_4,  Train_loss : 4580.8994  Test_loss : 5203.8501, Time/batch_file : 2.2752, Training time: 21210.8610\n",
      "Epoch : 1830/2000 data_batch_5,  Train_loss : 4424.2725  Test_loss : 5351.8599, Time/batch_file : 2.3002, Training time: 21213.1614\n",
      "[./nets/net-1830.ckpt] SAVED\n",
      "Epoch : 1831/2000 data_batch_1,  Train_loss : 4350.7041  Test_loss : 4744.6768, Time/batch_file : 2.4642, Training time: 21216.9071\n",
      "Epoch : 1831/2000 data_batch_2,  Train_loss : 4317.7510  Test_loss : 5093.4092, Time/batch_file : 2.2805, Training time: 21219.1878\n",
      "Epoch : 1831/2000 data_batch_3,  Train_loss : 4359.3936  Test_loss : 4900.4492, Time/batch_file : 2.2897, Training time: 21221.4778\n",
      "Epoch : 1831/2000 data_batch_4,  Train_loss : 4193.7646  Test_loss : 4711.2178, Time/batch_file : 2.2692, Training time: 21223.7471\n",
      "Epoch : 1831/2000 data_batch_5,  Train_loss : 4142.9507  Test_loss : 4863.4243, Time/batch_file : 2.2865, Training time: 21226.0339\n",
      "Epoch : 1832/2000 data_batch_1,  Train_loss : 4616.8965  Test_loss : 4823.9336, Time/batch_file : 2.3050, Training time: 21228.3391\n",
      "Epoch : 1832/2000 data_batch_2,  Train_loss : 4775.7383  Test_loss : 4838.4795, Time/batch_file : 2.2799, Training time: 21230.6192\n",
      "Epoch : 1832/2000 data_batch_3,  Train_loss : 4882.6470  Test_loss : 4816.9429, Time/batch_file : 2.2773, Training time: 21232.8966\n",
      "Epoch : 1832/2000 data_batch_4,  Train_loss : 4758.7910  Test_loss : 4954.7461, Time/batch_file : 2.3079, Training time: 21235.2047\n",
      "Epoch : 1832/2000 data_batch_5,  Train_loss : 4560.9150  Test_loss : 4958.7500, Time/batch_file : 2.2819, Training time: 21237.4867\n",
      "Epoch : 1833/2000 data_batch_1,  Train_loss : 4018.8105  Test_loss : 5482.5552, Time/batch_file : 2.2803, Training time: 21239.7673\n",
      "Epoch : 1833/2000 data_batch_2,  Train_loss : 4207.2256  Test_loss : 5386.4214, Time/batch_file : 2.2888, Training time: 21242.0563\n",
      "Epoch : 1833/2000 data_batch_3,  Train_loss : 3871.5139  Test_loss : 5501.5317, Time/batch_file : 2.2778, Training time: 21244.3343\n",
      "Epoch : 1833/2000 data_batch_4,  Train_loss : 4270.7100  Test_loss : 5402.0713, Time/batch_file : 2.2701, Training time: 21246.6046\n",
      "Epoch : 1833/2000 data_batch_5,  Train_loss : 3974.7539  Test_loss : 5626.6416, Time/batch_file : 2.2885, Training time: 21248.8933\n",
      "Epoch : 1834/2000 data_batch_1,  Train_loss : 4428.5879  Test_loss : 5282.6738, Time/batch_file : 2.2846, Training time: 21251.1781\n",
      "Epoch : 1834/2000 data_batch_2,  Train_loss : 4089.0723  Test_loss : 5241.8228, Time/batch_file : 2.2851, Training time: 21253.4634\n",
      "Epoch : 1834/2000 data_batch_3,  Train_loss : 4285.4214  Test_loss : 5028.0488, Time/batch_file : 2.2942, Training time: 21255.7577\n",
      "Epoch : 1834/2000 data_batch_4,  Train_loss : 4280.8696  Test_loss : 5226.7173, Time/batch_file : 2.2859, Training time: 21258.0437\n",
      "Epoch : 1834/2000 data_batch_5,  Train_loss : 4342.6411  Test_loss : 5217.6001, Time/batch_file : 2.2871, Training time: 21260.3311\n",
      "Epoch : 1835/2000 data_batch_1,  Train_loss : 4634.2715  Test_loss : 4383.7505, Time/batch_file : 2.2850, Training time: 21262.6162\n",
      "Epoch : 1835/2000 data_batch_2,  Train_loss : 4461.8843  Test_loss : 4613.4941, Time/batch_file : 2.3097, Training time: 21264.9262\n",
      "Epoch : 1835/2000 data_batch_3,  Train_loss : 4686.7305  Test_loss : 4655.8784, Time/batch_file : 2.2785, Training time: 21267.2050\n",
      "Epoch : 1835/2000 data_batch_4,  Train_loss : 4331.6738  Test_loss : 4312.1343, Time/batch_file : 2.2708, Training time: 21269.4760\n",
      "Epoch : 1835/2000 data_batch_5,  Train_loss : 4565.4043  Test_loss : 4530.3110, Time/batch_file : 2.2781, Training time: 21271.7543\n",
      "Epoch : 1836/2000 data_batch_1,  Train_loss : 4708.1172  Test_loss : 4795.8638, Time/batch_file : 2.2742, Training time: 21274.0288\n",
      "Epoch : 1836/2000 data_batch_2,  Train_loss : 4639.7822  Test_loss : 4797.6367, Time/batch_file : 2.2737, Training time: 21276.3027\n",
      "Epoch : 1836/2000 data_batch_3,  Train_loss : 4629.3276  Test_loss : 4877.2764, Time/batch_file : 2.2746, Training time: 21278.5775\n",
      "Epoch : 1836/2000 data_batch_4,  Train_loss : 4571.5962  Test_loss : 4784.8979, Time/batch_file : 2.2775, Training time: 21280.8552\n",
      "Epoch : 1836/2000 data_batch_5,  Train_loss : 4825.8779  Test_loss : 4700.3882, Time/batch_file : 2.2882, Training time: 21283.1435\n",
      "Epoch : 1837/2000 data_batch_1,  Train_loss : 5030.8003  Test_loss : 4458.4595, Time/batch_file : 2.2861, Training time: 21285.4299\n",
      "Epoch : 1837/2000 data_batch_2,  Train_loss : 5184.3760  Test_loss : 4550.8008, Time/batch_file : 2.2548, Training time: 21287.6848\n",
      "Epoch : 1837/2000 data_batch_3,  Train_loss : 5066.9512  Test_loss : 4476.9429, Time/batch_file : 2.2683, Training time: 21289.9533\n",
      "Epoch : 1837/2000 data_batch_4,  Train_loss : 4962.3394  Test_loss : 4507.6982, Time/batch_file : 2.2530, Training time: 21292.2065\n",
      "Epoch : 1837/2000 data_batch_5,  Train_loss : 5234.3486  Test_loss : 4552.2959, Time/batch_file : 2.2803, Training time: 21294.4869\n",
      "Epoch : 1838/2000 data_batch_1,  Train_loss : 4100.2197  Test_loss : 4256.1978, Time/batch_file : 2.2707, Training time: 21296.7577\n",
      "Epoch : 1838/2000 data_batch_2,  Train_loss : 4246.3135  Test_loss : 4394.1362, Time/batch_file : 2.3140, Training time: 21299.0720\n",
      "Epoch : 1838/2000 data_batch_3,  Train_loss : 3961.9458  Test_loss : 4369.0166, Time/batch_file : 2.2739, Training time: 21301.3461\n",
      "Epoch : 1838/2000 data_batch_4,  Train_loss : 3914.1865  Test_loss : 4348.4072, Time/batch_file : 2.3004, Training time: 21303.6466\n",
      "Epoch : 1838/2000 data_batch_5,  Train_loss : 4087.2812  Test_loss : 4453.8672, Time/batch_file : 2.2602, Training time: 21305.9071\n",
      "Epoch : 1839/2000 data_batch_1,  Train_loss : 4268.6064  Test_loss : 4386.1240, Time/batch_file : 2.3000, Training time: 21308.2073\n",
      "Epoch : 1839/2000 data_batch_2,  Train_loss : 4332.9189  Test_loss : 4688.7959, Time/batch_file : 2.2595, Training time: 21310.4670\n",
      "Epoch : 1839/2000 data_batch_3,  Train_loss : 4284.3804  Test_loss : 4735.1514, Time/batch_file : 2.2850, Training time: 21312.7521\n",
      "Epoch : 1839/2000 data_batch_4,  Train_loss : 4219.7158  Test_loss : 4697.4644, Time/batch_file : 2.2866, Training time: 21315.0390\n",
      "Epoch : 1839/2000 data_batch_5,  Train_loss : 4247.9766  Test_loss : 4847.8853, Time/batch_file : 2.2952, Training time: 21317.3343\n",
      "Epoch : 1840/2000 data_batch_1,  Train_loss : 4807.6821  Test_loss : 4637.4316, Time/batch_file : 2.2806, Training time: 21319.6151\n",
      "Epoch : 1840/2000 data_batch_2,  Train_loss : 4744.0693  Test_loss : 4657.0532, Time/batch_file : 2.2944, Training time: 21321.9097\n",
      "Epoch : 1840/2000 data_batch_3,  Train_loss : 4855.5547  Test_loss : 4423.8252, Time/batch_file : 2.2706, Training time: 21324.1805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1840/2000 data_batch_4,  Train_loss : 5010.9854  Test_loss : 4810.7241, Time/batch_file : 2.2729, Training time: 21326.4535\n",
      "Epoch : 1840/2000 data_batch_5,  Train_loss : 5248.7358  Test_loss : 4648.1011, Time/batch_file : 2.2608, Training time: 21328.7145\n",
      "[./nets/net-1840.ckpt] SAVED\n",
      "Epoch : 1841/2000 data_batch_1,  Train_loss : 4210.8633  Test_loss : 4734.0088, Time/batch_file : 2.3136, Training time: 21332.3008\n",
      "Epoch : 1841/2000 data_batch_2,  Train_loss : 4075.8928  Test_loss : 4812.0591, Time/batch_file : 2.2844, Training time: 21334.5854\n",
      "Epoch : 1841/2000 data_batch_3,  Train_loss : 4330.4678  Test_loss : 5122.7627, Time/batch_file : 2.2746, Training time: 21336.8603\n",
      "Epoch : 1841/2000 data_batch_4,  Train_loss : 4140.3184  Test_loss : 4711.7651, Time/batch_file : 2.2610, Training time: 21339.1214\n",
      "Epoch : 1841/2000 data_batch_5,  Train_loss : 4303.8193  Test_loss : 4806.6064, Time/batch_file : 2.2615, Training time: 21341.3831\n",
      "Epoch : 1842/2000 data_batch_1,  Train_loss : 4479.1367  Test_loss : 5095.2539, Time/batch_file : 2.2684, Training time: 21343.6517\n",
      "Epoch : 1842/2000 data_batch_2,  Train_loss : 4458.4424  Test_loss : 4766.0938, Time/batch_file : 2.2577, Training time: 21345.9096\n",
      "Epoch : 1842/2000 data_batch_3,  Train_loss : 4528.7158  Test_loss : 4732.7676, Time/batch_file : 2.2744, Training time: 21348.1841\n",
      "Epoch : 1842/2000 data_batch_4,  Train_loss : 4368.4380  Test_loss : 4632.4858, Time/batch_file : 2.2710, Training time: 21350.4552\n",
      "Epoch : 1842/2000 data_batch_5,  Train_loss : 4314.8857  Test_loss : 4890.0854, Time/batch_file : 2.2728, Training time: 21352.7282\n",
      "Epoch : 1843/2000 data_batch_1,  Train_loss : 4793.6875  Test_loss : 4805.4282, Time/batch_file : 2.2909, Training time: 21355.0194\n",
      "Epoch : 1843/2000 data_batch_2,  Train_loss : 4650.4268  Test_loss : 4726.7490, Time/batch_file : 2.2928, Training time: 21357.3123\n",
      "Epoch : 1843/2000 data_batch_3,  Train_loss : 4736.8867  Test_loss : 4288.7915, Time/batch_file : 2.2876, Training time: 21359.6000\n",
      "Epoch : 1843/2000 data_batch_4,  Train_loss : 4812.1797  Test_loss : 4491.5605, Time/batch_file : 2.3238, Training time: 21361.9240\n",
      "Epoch : 1843/2000 data_batch_5,  Train_loss : 4673.4048  Test_loss : 4536.5361, Time/batch_file : 2.2959, Training time: 21364.2202\n",
      "Epoch : 1844/2000 data_batch_1,  Train_loss : 4728.8154  Test_loss : 5060.4707, Time/batch_file : 2.2893, Training time: 21366.5097\n",
      "Epoch : 1844/2000 data_batch_2,  Train_loss : 4554.3638  Test_loss : 5005.2549, Time/batch_file : 2.2586, Training time: 21368.7685\n",
      "Epoch : 1844/2000 data_batch_3,  Train_loss : 4580.0586  Test_loss : 4968.8306, Time/batch_file : 2.3021, Training time: 21371.0709\n",
      "Epoch : 1844/2000 data_batch_4,  Train_loss : 4539.6289  Test_loss : 4787.9033, Time/batch_file : 2.2580, Training time: 21373.3291\n",
      "Epoch : 1844/2000 data_batch_5,  Train_loss : 4415.5010  Test_loss : 5119.5146, Time/batch_file : 2.2683, Training time: 21375.5975\n",
      "Epoch : 1845/2000 data_batch_1,  Train_loss : 4635.9248  Test_loss : 4764.9258, Time/batch_file : 2.2774, Training time: 21377.8751\n",
      "Epoch : 1845/2000 data_batch_2,  Train_loss : 4614.6758  Test_loss : 4962.2402, Time/batch_file : 2.2730, Training time: 21380.1483\n",
      "Epoch : 1845/2000 data_batch_3,  Train_loss : 4545.3110  Test_loss : 5073.2139, Time/batch_file : 2.2692, Training time: 21382.4177\n",
      "Epoch : 1845/2000 data_batch_4,  Train_loss : 4645.9844  Test_loss : 5069.2212, Time/batch_file : 2.2888, Training time: 21384.7067\n",
      "Epoch : 1845/2000 data_batch_5,  Train_loss : 4641.3086  Test_loss : 4874.2661, Time/batch_file : 2.2746, Training time: 21386.9815\n",
      "Epoch : 1846/2000 data_batch_1,  Train_loss : 4636.6421  Test_loss : 4638.8438, Time/batch_file : 2.2768, Training time: 21389.2585\n",
      "Epoch : 1846/2000 data_batch_2,  Train_loss : 4529.2310  Test_loss : 4842.1929, Time/batch_file : 2.2824, Training time: 21391.5410\n",
      "Epoch : 1846/2000 data_batch_3,  Train_loss : 4814.9409  Test_loss : 4567.8989, Time/batch_file : 2.2757, Training time: 21393.8170\n",
      "Epoch : 1846/2000 data_batch_4,  Train_loss : 4361.1631  Test_loss : 4600.1426, Time/batch_file : 2.2734, Training time: 21396.0907\n",
      "Epoch : 1846/2000 data_batch_5,  Train_loss : 4770.0459  Test_loss : 4641.5117, Time/batch_file : 2.2686, Training time: 21398.3595\n",
      "Epoch : 1847/2000 data_batch_1,  Train_loss : 4350.7637  Test_loss : 4798.8682, Time/batch_file : 2.2830, Training time: 21400.6427\n",
      "Epoch : 1847/2000 data_batch_2,  Train_loss : 4538.8486  Test_loss : 5045.7983, Time/batch_file : 2.2564, Training time: 21402.8993\n",
      "Epoch : 1847/2000 data_batch_3,  Train_loss : 4489.2231  Test_loss : 4653.8184, Time/batch_file : 2.3033, Training time: 21405.2028\n",
      "Epoch : 1847/2000 data_batch_4,  Train_loss : 4345.9551  Test_loss : 4867.8027, Time/batch_file : 2.2621, Training time: 21407.4651\n",
      "Epoch : 1847/2000 data_batch_5,  Train_loss : 4457.2520  Test_loss : 4604.1084, Time/batch_file : 2.2858, Training time: 21409.7512\n",
      "Epoch : 1848/2000 data_batch_1,  Train_loss : 4713.3682  Test_loss : 5488.9746, Time/batch_file : 2.2660, Training time: 21412.0174\n",
      "Epoch : 1848/2000 data_batch_2,  Train_loss : 4224.6699  Test_loss : 5278.2271, Time/batch_file : 2.2754, Training time: 21414.2931\n",
      "Epoch : 1848/2000 data_batch_3,  Train_loss : 4687.7642  Test_loss : 5181.1880, Time/batch_file : 2.2757, Training time: 21416.5690\n",
      "Epoch : 1848/2000 data_batch_4,  Train_loss : 4682.2583  Test_loss : 5525.1167, Time/batch_file : 2.3015, Training time: 21418.8707\n",
      "Epoch : 1848/2000 data_batch_5,  Train_loss : 4611.9302  Test_loss : 5568.8701, Time/batch_file : 2.2702, Training time: 21421.1411\n",
      "Epoch : 1849/2000 data_batch_1,  Train_loss : 4807.8525  Test_loss : 4745.7607, Time/batch_file : 2.2502, Training time: 21423.3915\n",
      "Epoch : 1849/2000 data_batch_2,  Train_loss : 5127.6177  Test_loss : 4480.1528, Time/batch_file : 2.2667, Training time: 21425.6585\n",
      "Epoch : 1849/2000 data_batch_3,  Train_loss : 4906.9009  Test_loss : 4542.3530, Time/batch_file : 2.2658, Training time: 21427.9245\n",
      "Epoch : 1849/2000 data_batch_4,  Train_loss : 5025.5986  Test_loss : 4695.1450, Time/batch_file : 2.2669, Training time: 21430.1916\n",
      "Epoch : 1849/2000 data_batch_5,  Train_loss : 4878.2588  Test_loss : 4523.7832, Time/batch_file : 2.2505, Training time: 21432.4423\n",
      "Epoch : 1850/2000 data_batch_1,  Train_loss : 4471.0518  Test_loss : 4343.8066, Time/batch_file : 2.2723, Training time: 21434.7148\n",
      "Epoch : 1850/2000 data_batch_2,  Train_loss : 4438.9321  Test_loss : 4649.4961, Time/batch_file : 2.2723, Training time: 21436.9874\n",
      "Epoch : 1850/2000 data_batch_3,  Train_loss : 4484.3311  Test_loss : 4566.6074, Time/batch_file : 2.2739, Training time: 21439.2615\n",
      "Epoch : 1850/2000 data_batch_4,  Train_loss : 4452.4624  Test_loss : 4527.2920, Time/batch_file : 2.2601, Training time: 21441.5218\n",
      "Epoch : 1850/2000 data_batch_5,  Train_loss : 4668.1279  Test_loss : 4591.6289, Time/batch_file : 2.2710, Training time: 21443.7931\n",
      "[./nets/net-1850.ckpt] SAVED\n",
      "Epoch : 1851/2000 data_batch_1,  Train_loss : 4369.1143  Test_loss : 5068.3521, Time/batch_file : 2.4602, Training time: 21447.5723\n",
      "Epoch : 1851/2000 data_batch_2,  Train_loss : 4575.1147  Test_loss : 4904.0244, Time/batch_file : 2.2688, Training time: 21449.8414\n",
      "Epoch : 1851/2000 data_batch_3,  Train_loss : 4656.8809  Test_loss : 4964.9199, Time/batch_file : 2.2843, Training time: 21452.1259\n",
      "Epoch : 1851/2000 data_batch_4,  Train_loss : 4553.1118  Test_loss : 4907.6689, Time/batch_file : 2.2685, Training time: 21454.3945\n",
      "Epoch : 1851/2000 data_batch_5,  Train_loss : 4578.4800  Test_loss : 4568.2832, Time/batch_file : 2.2660, Training time: 21456.6608\n",
      "Epoch : 1852/2000 data_batch_1,  Train_loss : 4541.7275  Test_loss : 4862.9858, Time/batch_file : 2.2898, Training time: 21458.9508\n",
      "Epoch : 1852/2000 data_batch_2,  Train_loss : 4613.2432  Test_loss : 4682.4019, Time/batch_file : 2.2684, Training time: 21461.2194\n",
      "Epoch : 1852/2000 data_batch_3,  Train_loss : 4760.1973  Test_loss : 4729.2256, Time/batch_file : 2.2754, Training time: 21463.4951\n",
      "Epoch : 1852/2000 data_batch_4,  Train_loss : 5061.2168  Test_loss : 4511.8945, Time/batch_file : 2.2917, Training time: 21465.7870\n",
      "Epoch : 1852/2000 data_batch_5,  Train_loss : 4575.2593  Test_loss : 4772.7656, Time/batch_file : 2.2974, Training time: 21468.0846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1853/2000 data_batch_1,  Train_loss : 4549.0542  Test_loss : 4856.5244, Time/batch_file : 2.2965, Training time: 21470.3812\n",
      "Epoch : 1853/2000 data_batch_2,  Train_loss : 4815.7944  Test_loss : 4929.8711, Time/batch_file : 2.3014, Training time: 21472.6828\n",
      "Epoch : 1853/2000 data_batch_3,  Train_loss : 4478.8765  Test_loss : 5113.7368, Time/batch_file : 2.2972, Training time: 21474.9802\n",
      "Epoch : 1853/2000 data_batch_4,  Train_loss : 4586.8457  Test_loss : 4766.0234, Time/batch_file : 2.2909, Training time: 21477.2713\n",
      "Epoch : 1853/2000 data_batch_5,  Train_loss : 4846.7642  Test_loss : 4948.3813, Time/batch_file : 2.3035, Training time: 21479.5750\n",
      "Epoch : 1854/2000 data_batch_1,  Train_loss : 4589.9438  Test_loss : 4768.9141, Time/batch_file : 2.2871, Training time: 21481.8623\n",
      "Epoch : 1854/2000 data_batch_2,  Train_loss : 4494.4390  Test_loss : 4934.4995, Time/batch_file : 2.2830, Training time: 21484.1456\n",
      "Epoch : 1854/2000 data_batch_3,  Train_loss : 4257.7715  Test_loss : 4851.4629, Time/batch_file : 2.2972, Training time: 21486.4430\n",
      "Epoch : 1854/2000 data_batch_4,  Train_loss : 4435.4238  Test_loss : 4725.3457, Time/batch_file : 2.2889, Training time: 21488.7321\n",
      "Epoch : 1854/2000 data_batch_5,  Train_loss : 4562.2305  Test_loss : 5100.5049, Time/batch_file : 2.2924, Training time: 21491.0247\n",
      "Epoch : 1855/2000 data_batch_1,  Train_loss : 4161.5391  Test_loss : 4971.2861, Time/batch_file : 2.2950, Training time: 21493.3200\n",
      "Epoch : 1855/2000 data_batch_2,  Train_loss : 4290.6396  Test_loss : 5108.9868, Time/batch_file : 2.3058, Training time: 21495.6259\n",
      "Epoch : 1855/2000 data_batch_3,  Train_loss : 4095.0571  Test_loss : 5428.1953, Time/batch_file : 2.2975, Training time: 21497.9236\n",
      "Epoch : 1855/2000 data_batch_4,  Train_loss : 4031.4214  Test_loss : 5385.3003, Time/batch_file : 2.2955, Training time: 21500.2194\n",
      "Epoch : 1855/2000 data_batch_5,  Train_loss : 4383.7451  Test_loss : 5093.1060, Time/batch_file : 2.2932, Training time: 21502.5127\n",
      "Epoch : 1856/2000 data_batch_1,  Train_loss : 4255.4624  Test_loss : 4698.3745, Time/batch_file : 2.2869, Training time: 21504.7999\n",
      "Epoch : 1856/2000 data_batch_2,  Train_loss : 4451.5195  Test_loss : 4646.7280, Time/batch_file : 2.3094, Training time: 21507.1095\n",
      "Epoch : 1856/2000 data_batch_3,  Train_loss : 4437.1841  Test_loss : 5046.2310, Time/batch_file : 2.2918, Training time: 21509.4014\n",
      "Epoch : 1856/2000 data_batch_4,  Train_loss : 4401.2925  Test_loss : 4345.3516, Time/batch_file : 2.2871, Training time: 21511.6886\n",
      "Epoch : 1856/2000 data_batch_5,  Train_loss : 4522.3633  Test_loss : 4493.0811, Time/batch_file : 2.2973, Training time: 21513.9860\n",
      "Epoch : 1857/2000 data_batch_1,  Train_loss : 4880.9814  Test_loss : 4403.1274, Time/batch_file : 2.2752, Training time: 21516.2615\n",
      "Epoch : 1857/2000 data_batch_2,  Train_loss : 4475.0420  Test_loss : 4089.7310, Time/batch_file : 2.2760, Training time: 21518.5378\n",
      "Epoch : 1857/2000 data_batch_3,  Train_loss : 4568.5005  Test_loss : 4337.3086, Time/batch_file : 2.2921, Training time: 21520.8300\n",
      "Epoch : 1857/2000 data_batch_4,  Train_loss : 4779.8394  Test_loss : 4589.6719, Time/batch_file : 2.2907, Training time: 21523.1210\n",
      "Epoch : 1857/2000 data_batch_5,  Train_loss : 4833.6392  Test_loss : 4343.7793, Time/batch_file : 2.2846, Training time: 21525.4057\n",
      "Epoch : 1858/2000 data_batch_1,  Train_loss : 4699.1553  Test_loss : 5079.7778, Time/batch_file : 2.2935, Training time: 21527.6994\n",
      "Epoch : 1858/2000 data_batch_2,  Train_loss : 4566.0845  Test_loss : 4898.8804, Time/batch_file : 2.3049, Training time: 21530.0046\n",
      "Epoch : 1858/2000 data_batch_3,  Train_loss : 4446.5215  Test_loss : 4781.4951, Time/batch_file : 2.2845, Training time: 21532.2893\n",
      "Epoch : 1858/2000 data_batch_4,  Train_loss : 4542.7847  Test_loss : 4909.2256, Time/batch_file : 2.3055, Training time: 21534.5950\n",
      "Epoch : 1858/2000 data_batch_5,  Train_loss : 4691.4800  Test_loss : 4589.8159, Time/batch_file : 2.2813, Training time: 21536.8765\n",
      "Epoch : 1859/2000 data_batch_1,  Train_loss : 4890.4966  Test_loss : 4661.5537, Time/batch_file : 2.3042, Training time: 21539.1809\n",
      "Epoch : 1859/2000 data_batch_2,  Train_loss : 4670.8628  Test_loss : 4906.7500, Time/batch_file : 2.2987, Training time: 21541.4798\n",
      "Epoch : 1859/2000 data_batch_3,  Train_loss : 4825.4951  Test_loss : 4552.7119, Time/batch_file : 2.2795, Training time: 21543.7595\n",
      "Epoch : 1859/2000 data_batch_4,  Train_loss : 4585.1025  Test_loss : 4670.1025, Time/batch_file : 2.2934, Training time: 21546.0530\n",
      "Epoch : 1859/2000 data_batch_5,  Train_loss : 4708.1963  Test_loss : 4950.4150, Time/batch_file : 2.3132, Training time: 21548.3664\n",
      "Epoch : 1860/2000 data_batch_1,  Train_loss : 4570.8101  Test_loss : 4573.4590, Time/batch_file : 2.2861, Training time: 21550.6528\n",
      "Epoch : 1860/2000 data_batch_2,  Train_loss : 4562.4717  Test_loss : 4606.3379, Time/batch_file : 2.2901, Training time: 21552.9431\n",
      "Epoch : 1860/2000 data_batch_3,  Train_loss : 4624.1743  Test_loss : 4840.2451, Time/batch_file : 2.2871, Training time: 21555.2303\n",
      "Epoch : 1860/2000 data_batch_4,  Train_loss : 4928.8223  Test_loss : 4413.8657, Time/batch_file : 2.2872, Training time: 21557.5178\n",
      "Epoch : 1860/2000 data_batch_5,  Train_loss : 4654.5444  Test_loss : 4456.5562, Time/batch_file : 2.2764, Training time: 21559.7943\n",
      "[./nets/net-1860.ckpt] SAVED\n",
      "Epoch : 1861/2000 data_batch_1,  Train_loss : 4774.2588  Test_loss : 5350.5542, Time/batch_file : 2.3250, Training time: 21563.3832\n",
      "Epoch : 1861/2000 data_batch_2,  Train_loss : 4693.8281  Test_loss : 5301.4536, Time/batch_file : 2.2930, Training time: 21565.6764\n",
      "Epoch : 1861/2000 data_batch_3,  Train_loss : 4760.3232  Test_loss : 5248.3643, Time/batch_file : 2.2756, Training time: 21567.9522\n",
      "Epoch : 1861/2000 data_batch_4,  Train_loss : 4472.5352  Test_loss : 4860.6484, Time/batch_file : 2.2928, Training time: 21570.2452\n",
      "Epoch : 1861/2000 data_batch_5,  Train_loss : 4432.6113  Test_loss : 5100.7476, Time/batch_file : 2.2700, Training time: 21572.5154\n",
      "Epoch : 1862/2000 data_batch_1,  Train_loss : 4586.8574  Test_loss : 4578.8218, Time/batch_file : 2.2867, Training time: 21574.8023\n",
      "Epoch : 1862/2000 data_batch_2,  Train_loss : 4340.5132  Test_loss : 4716.6147, Time/batch_file : 2.2986, Training time: 21577.1011\n",
      "Epoch : 1862/2000 data_batch_3,  Train_loss : 4649.1401  Test_loss : 4739.8394, Time/batch_file : 2.3102, Training time: 21579.4115\n",
      "Epoch : 1862/2000 data_batch_4,  Train_loss : 4450.2319  Test_loss : 4710.9385, Time/batch_file : 2.3024, Training time: 21581.7141\n",
      "Epoch : 1862/2000 data_batch_5,  Train_loss : 4506.7900  Test_loss : 4705.0986, Time/batch_file : 2.2974, Training time: 21584.0117\n",
      "Epoch : 1863/2000 data_batch_1,  Train_loss : 4415.6064  Test_loss : 4397.9370, Time/batch_file : 2.2896, Training time: 21586.3015\n",
      "Epoch : 1863/2000 data_batch_2,  Train_loss : 4683.6812  Test_loss : 4430.6836, Time/batch_file : 2.2767, Training time: 21588.5784\n",
      "Epoch : 1863/2000 data_batch_3,  Train_loss : 4580.0127  Test_loss : 4378.5635, Time/batch_file : 2.2977, Training time: 21590.8763\n",
      "Epoch : 1863/2000 data_batch_4,  Train_loss : 4694.0386  Test_loss : 4151.8599, Time/batch_file : 2.2734, Training time: 21593.1499\n",
      "Epoch : 1863/2000 data_batch_5,  Train_loss : 4529.2603  Test_loss : 4151.9688, Time/batch_file : 2.2733, Training time: 21595.4234\n",
      "Epoch : 1864/2000 data_batch_1,  Train_loss : 4480.7407  Test_loss : 4903.3779, Time/batch_file : 2.2967, Training time: 21597.7203\n",
      "Epoch : 1864/2000 data_batch_2,  Train_loss : 4460.0220  Test_loss : 4993.3770, Time/batch_file : 2.2846, Training time: 21600.0051\n",
      "Epoch : 1864/2000 data_batch_3,  Train_loss : 4531.8999  Test_loss : 5049.4199, Time/batch_file : 2.2810, Training time: 21602.2863\n",
      "Epoch : 1864/2000 data_batch_4,  Train_loss : 4626.7739  Test_loss : 5078.7227, Time/batch_file : 2.3001, Training time: 21604.5866\n",
      "Epoch : 1864/2000 data_batch_5,  Train_loss : 4400.9004  Test_loss : 5022.2246, Time/batch_file : 2.3069, Training time: 21606.8936\n",
      "Epoch : 1865/2000 data_batch_1,  Train_loss : 4256.5928  Test_loss : 4723.9268, Time/batch_file : 2.2966, Training time: 21609.1904\n",
      "Epoch : 1865/2000 data_batch_2,  Train_loss : 4328.2588  Test_loss : 4880.7886, Time/batch_file : 2.2882, Training time: 21611.4788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1865/2000 data_batch_3,  Train_loss : 4524.2432  Test_loss : 5276.5532, Time/batch_file : 2.2838, Training time: 21613.7629\n",
      "Epoch : 1865/2000 data_batch_4,  Train_loss : 4257.0625  Test_loss : 4889.9019, Time/batch_file : 2.2837, Training time: 21616.0468\n",
      "Epoch : 1865/2000 data_batch_5,  Train_loss : 4223.5962  Test_loss : 5066.4941, Time/batch_file : 2.3007, Training time: 21618.3477\n",
      "Epoch : 1866/2000 data_batch_1,  Train_loss : 3980.5854  Test_loss : 4892.5581, Time/batch_file : 2.3270, Training time: 21620.6749\n",
      "Epoch : 1866/2000 data_batch_2,  Train_loss : 4125.1357  Test_loss : 4808.2681, Time/batch_file : 2.2763, Training time: 21622.9515\n",
      "Epoch : 1866/2000 data_batch_3,  Train_loss : 3958.9849  Test_loss : 5244.3066, Time/batch_file : 2.2842, Training time: 21625.2358\n",
      "Epoch : 1866/2000 data_batch_4,  Train_loss : 4161.0391  Test_loss : 5063.8940, Time/batch_file : 2.2717, Training time: 21627.5077\n",
      "Epoch : 1866/2000 data_batch_5,  Train_loss : 3976.7573  Test_loss : 5183.8818, Time/batch_file : 2.2826, Training time: 21629.7905\n",
      "Epoch : 1867/2000 data_batch_1,  Train_loss : 4391.8633  Test_loss : 4803.5649, Time/batch_file : 2.2980, Training time: 21632.0886\n",
      "Epoch : 1867/2000 data_batch_2,  Train_loss : 4487.3306  Test_loss : 4785.8091, Time/batch_file : 2.3013, Training time: 21634.3901\n",
      "Epoch : 1867/2000 data_batch_3,  Train_loss : 4546.1436  Test_loss : 4537.1504, Time/batch_file : 2.2958, Training time: 21636.6862\n",
      "Epoch : 1867/2000 data_batch_4,  Train_loss : 4383.0293  Test_loss : 4726.3657, Time/batch_file : 2.2970, Training time: 21638.9835\n",
      "Epoch : 1867/2000 data_batch_5,  Train_loss : 4065.2251  Test_loss : 4611.2520, Time/batch_file : 2.3010, Training time: 21641.2847\n",
      "Epoch : 1868/2000 data_batch_1,  Train_loss : 4613.8696  Test_loss : 4592.4341, Time/batch_file : 2.3010, Training time: 21643.5859\n",
      "Epoch : 1868/2000 data_batch_2,  Train_loss : 4551.0278  Test_loss : 4382.1904, Time/batch_file : 2.3145, Training time: 21645.9006\n",
      "Epoch : 1868/2000 data_batch_3,  Train_loss : 4753.8423  Test_loss : 4474.0967, Time/batch_file : 2.2827, Training time: 21648.1835\n",
      "Epoch : 1868/2000 data_batch_4,  Train_loss : 4480.3203  Test_loss : 4704.8408, Time/batch_file : 2.2794, Training time: 21650.4631\n",
      "Epoch : 1868/2000 data_batch_5,  Train_loss : 4849.9683  Test_loss : 4472.5068, Time/batch_file : 2.2910, Training time: 21652.7542\n",
      "Epoch : 1869/2000 data_batch_1,  Train_loss : 4505.5020  Test_loss : 4695.6069, Time/batch_file : 2.2863, Training time: 21655.0407\n",
      "Epoch : 1869/2000 data_batch_2,  Train_loss : 4808.9326  Test_loss : 4866.9570, Time/batch_file : 2.2868, Training time: 21657.3278\n",
      "Epoch : 1869/2000 data_batch_3,  Train_loss : 4698.2539  Test_loss : 4713.6128, Time/batch_file : 2.3268, Training time: 21659.6547\n",
      "Epoch : 1869/2000 data_batch_4,  Train_loss : 4527.8076  Test_loss : 4480.3657, Time/batch_file : 2.3110, Training time: 21661.9659\n",
      "Epoch : 1869/2000 data_batch_5,  Train_loss : 4855.3438  Test_loss : 4959.6362, Time/batch_file : 2.3088, Training time: 21664.2749\n",
      "Epoch : 1870/2000 data_batch_1,  Train_loss : 4714.2939  Test_loss : 5182.9731, Time/batch_file : 2.2953, Training time: 21666.5704\n",
      "Epoch : 1870/2000 data_batch_2,  Train_loss : 4545.0234  Test_loss : 4895.5845, Time/batch_file : 2.2925, Training time: 21668.8631\n",
      "Epoch : 1870/2000 data_batch_3,  Train_loss : 4648.4590  Test_loss : 4898.8682, Time/batch_file : 2.2829, Training time: 21671.1462\n",
      "Epoch : 1870/2000 data_batch_4,  Train_loss : 4252.3662  Test_loss : 5132.7236, Time/batch_file : 2.3163, Training time: 21673.4626\n",
      "Epoch : 1870/2000 data_batch_5,  Train_loss : 4353.2578  Test_loss : 5045.9805, Time/batch_file : 2.2911, Training time: 21675.7540\n",
      "[./nets/net-1870.ckpt] SAVED\n",
      "Epoch : 1871/2000 data_batch_1,  Train_loss : 4882.1665  Test_loss : 4780.1650, Time/batch_file : 2.4266, Training time: 21679.4647\n",
      "Epoch : 1871/2000 data_batch_2,  Train_loss : 5106.3174  Test_loss : 4765.6162, Time/batch_file : 2.2684, Training time: 21681.7332\n",
      "Epoch : 1871/2000 data_batch_3,  Train_loss : 5474.5527  Test_loss : 4858.9448, Time/batch_file : 2.2593, Training time: 21683.9927\n",
      "Epoch : 1871/2000 data_batch_4,  Train_loss : 4732.9912  Test_loss : 5019.4536, Time/batch_file : 2.2680, Training time: 21686.2610\n",
      "Epoch : 1871/2000 data_batch_5,  Train_loss : 4947.9478  Test_loss : 4849.4209, Time/batch_file : 2.2691, Training time: 21688.5304\n",
      "Epoch : 1872/2000 data_batch_1,  Train_loss : 4179.1167  Test_loss : 4450.8701, Time/batch_file : 2.2491, Training time: 21690.7797\n",
      "Epoch : 1872/2000 data_batch_2,  Train_loss : 4239.2837  Test_loss : 4233.5635, Time/batch_file : 2.2708, Training time: 21693.0508\n",
      "Epoch : 1872/2000 data_batch_3,  Train_loss : 4478.5205  Test_loss : 4463.7539, Time/batch_file : 2.2501, Training time: 21695.3010\n",
      "Epoch : 1872/2000 data_batch_4,  Train_loss : 4467.6802  Test_loss : 4718.3770, Time/batch_file : 2.2571, Training time: 21697.5584\n",
      "Epoch : 1872/2000 data_batch_5,  Train_loss : 4342.7017  Test_loss : 4271.1592, Time/batch_file : 2.2542, Training time: 21699.8127\n",
      "Epoch : 1873/2000 data_batch_1,  Train_loss : 5424.1294  Test_loss : 4314.7100, Time/batch_file : 2.2503, Training time: 21702.0632\n",
      "Epoch : 1873/2000 data_batch_2,  Train_loss : 5088.9233  Test_loss : 4684.4443, Time/batch_file : 2.2549, Training time: 21704.3183\n",
      "Epoch : 1873/2000 data_batch_3,  Train_loss : 5331.4976  Test_loss : 4617.9536, Time/batch_file : 2.2616, Training time: 21706.5802\n",
      "Epoch : 1873/2000 data_batch_4,  Train_loss : 5319.6943  Test_loss : 4513.6982, Time/batch_file : 2.2540, Training time: 21708.8343\n",
      "Epoch : 1873/2000 data_batch_5,  Train_loss : 5200.1133  Test_loss : 4418.4102, Time/batch_file : 2.2723, Training time: 21711.1068\n",
      "Epoch : 1874/2000 data_batch_1,  Train_loss : 4462.5327  Test_loss : 4597.4648, Time/batch_file : 2.2652, Training time: 21713.3723\n",
      "Epoch : 1874/2000 data_batch_2,  Train_loss : 4411.9360  Test_loss : 4684.1904, Time/batch_file : 2.2840, Training time: 21715.6565\n",
      "Epoch : 1874/2000 data_batch_3,  Train_loss : 4485.3247  Test_loss : 4568.9937, Time/batch_file : 2.2717, Training time: 21717.9284\n",
      "Epoch : 1874/2000 data_batch_4,  Train_loss : 4662.9766  Test_loss : 4895.0977, Time/batch_file : 2.2803, Training time: 21720.2089\n",
      "Epoch : 1874/2000 data_batch_5,  Train_loss : 4727.5586  Test_loss : 4573.1665, Time/batch_file : 2.2608, Training time: 21722.4699\n",
      "Epoch : 1875/2000 data_batch_1,  Train_loss : 4765.5898  Test_loss : 4997.4785, Time/batch_file : 2.2871, Training time: 21724.7572\n",
      "Epoch : 1875/2000 data_batch_2,  Train_loss : 4522.7266  Test_loss : 4715.0425, Time/batch_file : 2.2643, Training time: 21727.0217\n",
      "Epoch : 1875/2000 data_batch_3,  Train_loss : 4188.2256  Test_loss : 5005.0586, Time/batch_file : 2.2837, Training time: 21729.3056\n",
      "Epoch : 1875/2000 data_batch_4,  Train_loss : 4616.5605  Test_loss : 4859.5708, Time/batch_file : 2.2610, Training time: 21731.5669\n",
      "Epoch : 1875/2000 data_batch_5,  Train_loss : 4687.5552  Test_loss : 4996.8262, Time/batch_file : 2.2729, Training time: 21733.8400\n",
      "Epoch : 1876/2000 data_batch_1,  Train_loss : 4608.1851  Test_loss : 4761.4580, Time/batch_file : 2.2803, Training time: 21736.1204\n",
      "Epoch : 1876/2000 data_batch_2,  Train_loss : 4466.8442  Test_loss : 4510.3994, Time/batch_file : 2.2845, Training time: 21738.4051\n",
      "Epoch : 1876/2000 data_batch_3,  Train_loss : 4662.4014  Test_loss : 4849.0845, Time/batch_file : 2.2795, Training time: 21740.6848\n",
      "Epoch : 1876/2000 data_batch_4,  Train_loss : 4489.5122  Test_loss : 4809.8105, Time/batch_file : 2.2866, Training time: 21742.9717\n",
      "Epoch : 1876/2000 data_batch_5,  Train_loss : 4422.1851  Test_loss : 4883.7441, Time/batch_file : 2.2813, Training time: 21745.2531\n",
      "Epoch : 1877/2000 data_batch_1,  Train_loss : 4604.4409  Test_loss : 4521.8691, Time/batch_file : 2.2759, Training time: 21747.5293\n",
      "Epoch : 1877/2000 data_batch_2,  Train_loss : 4334.3096  Test_loss : 4439.8921, Time/batch_file : 2.2637, Training time: 21749.7931\n",
      "Epoch : 1877/2000 data_batch_3,  Train_loss : 4489.1611  Test_loss : 4635.5674, Time/batch_file : 2.2794, Training time: 21752.0726\n",
      "Epoch : 1877/2000 data_batch_4,  Train_loss : 4643.7280  Test_loss : 4762.0630, Time/batch_file : 2.2671, Training time: 21754.3400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1877/2000 data_batch_5,  Train_loss : 4379.6021  Test_loss : 4607.1499, Time/batch_file : 2.2713, Training time: 21756.6115\n",
      "Epoch : 1878/2000 data_batch_1,  Train_loss : 4660.1753  Test_loss : 4778.4824, Time/batch_file : 2.2516, Training time: 21758.8633\n",
      "Epoch : 1878/2000 data_batch_2,  Train_loss : 4543.4004  Test_loss : 4468.7773, Time/batch_file : 2.2600, Training time: 21761.1235\n",
      "Epoch : 1878/2000 data_batch_3,  Train_loss : 4611.9702  Test_loss : 4478.4336, Time/batch_file : 2.2591, Training time: 21763.3829\n",
      "Epoch : 1878/2000 data_batch_4,  Train_loss : 4614.5615  Test_loss : 4638.7100, Time/batch_file : 2.2722, Training time: 21765.6554\n",
      "Epoch : 1878/2000 data_batch_5,  Train_loss : 4589.1885  Test_loss : 4468.0820, Time/batch_file : 2.2587, Training time: 21767.9142\n",
      "Epoch : 1879/2000 data_batch_1,  Train_loss : 4586.0405  Test_loss : 4746.0391, Time/batch_file : 2.2631, Training time: 21770.1775\n",
      "Epoch : 1879/2000 data_batch_2,  Train_loss : 4409.6450  Test_loss : 4775.8892, Time/batch_file : 2.2543, Training time: 21772.4320\n",
      "Epoch : 1879/2000 data_batch_3,  Train_loss : 4588.9487  Test_loss : 5046.4580, Time/batch_file : 2.2648, Training time: 21774.6970\n",
      "Epoch : 1879/2000 data_batch_4,  Train_loss : 4299.4595  Test_loss : 4879.7939, Time/batch_file : 2.2515, Training time: 21776.9487\n",
      "Epoch : 1879/2000 data_batch_5,  Train_loss : 4484.0713  Test_loss : 4863.4248, Time/batch_file : 2.2935, Training time: 21779.2423\n",
      "Epoch : 1880/2000 data_batch_1,  Train_loss : 4498.5093  Test_loss : 4791.9116, Time/batch_file : 2.2539, Training time: 21781.4964\n",
      "Epoch : 1880/2000 data_batch_2,  Train_loss : 4301.6113  Test_loss : 5105.4922, Time/batch_file : 2.2657, Training time: 21783.7623\n",
      "Epoch : 1880/2000 data_batch_3,  Train_loss : 4449.2773  Test_loss : 4921.2339, Time/batch_file : 2.2612, Training time: 21786.0237\n",
      "Epoch : 1880/2000 data_batch_4,  Train_loss : 4249.5000  Test_loss : 4877.9565, Time/batch_file : 2.2640, Training time: 21788.2879\n",
      "Epoch : 1880/2000 data_batch_5,  Train_loss : 4202.1152  Test_loss : 4815.5151, Time/batch_file : 2.2575, Training time: 21790.5456\n",
      "[./nets/net-1880.ckpt] SAVED\n",
      "Epoch : 1881/2000 data_batch_1,  Train_loss : 4641.7441  Test_loss : 4605.4258, Time/batch_file : 2.3091, Training time: 21794.1299\n",
      "Epoch : 1881/2000 data_batch_2,  Train_loss : 4553.4463  Test_loss : 4696.6665, Time/batch_file : 2.2800, Training time: 21796.4101\n",
      "Epoch : 1881/2000 data_batch_3,  Train_loss : 4678.0547  Test_loss : 4344.7090, Time/batch_file : 2.2962, Training time: 21798.7064\n",
      "Epoch : 1881/2000 data_batch_4,  Train_loss : 4692.0625  Test_loss : 4416.6489, Time/batch_file : 2.2630, Training time: 21800.9697\n",
      "Epoch : 1881/2000 data_batch_5,  Train_loss : 4625.3560  Test_loss : 4442.0283, Time/batch_file : 2.2667, Training time: 21803.2367\n",
      "Epoch : 1882/2000 data_batch_1,  Train_loss : 4256.5059  Test_loss : 4678.7480, Time/batch_file : 2.2702, Training time: 21805.5072\n",
      "Epoch : 1882/2000 data_batch_2,  Train_loss : 4107.1396  Test_loss : 4730.9785, Time/batch_file : 2.2743, Training time: 21807.7818\n",
      "Epoch : 1882/2000 data_batch_3,  Train_loss : 4093.6846  Test_loss : 4747.3486, Time/batch_file : 2.2606, Training time: 21810.0425\n",
      "Epoch : 1882/2000 data_batch_4,  Train_loss : 4234.8818  Test_loss : 4843.6035, Time/batch_file : 2.2591, Training time: 21812.3018\n",
      "Epoch : 1882/2000 data_batch_5,  Train_loss : 4081.9165  Test_loss : 4648.1426, Time/batch_file : 2.2872, Training time: 21814.5892\n",
      "Epoch : 1883/2000 data_batch_1,  Train_loss : 4805.4492  Test_loss : 4827.5762, Time/batch_file : 2.2682, Training time: 21816.8576\n",
      "Epoch : 1883/2000 data_batch_2,  Train_loss : 4625.3623  Test_loss : 4513.3398, Time/batch_file : 2.2661, Training time: 21819.1240\n",
      "Epoch : 1883/2000 data_batch_3,  Train_loss : 4835.3804  Test_loss : 4242.5498, Time/batch_file : 2.2676, Training time: 21821.3918\n",
      "Epoch : 1883/2000 data_batch_4,  Train_loss : 4588.9922  Test_loss : 4394.0205, Time/batch_file : 2.2466, Training time: 21823.6386\n",
      "Epoch : 1883/2000 data_batch_5,  Train_loss : 4656.0781  Test_loss : 4226.6499, Time/batch_file : 2.2792, Training time: 21825.9179\n",
      "Epoch : 1884/2000 data_batch_1,  Train_loss : 4575.0537  Test_loss : 4702.2939, Time/batch_file : 2.2797, Training time: 21828.1979\n",
      "Epoch : 1884/2000 data_batch_2,  Train_loss : 4675.4756  Test_loss : 4985.8584, Time/batch_file : 2.2884, Training time: 21830.4865\n",
      "Epoch : 1884/2000 data_batch_3,  Train_loss : 4570.7036  Test_loss : 4874.3750, Time/batch_file : 2.2924, Training time: 21832.7791\n",
      "Epoch : 1884/2000 data_batch_4,  Train_loss : 4499.3027  Test_loss : 4671.0576, Time/batch_file : 2.2837, Training time: 21835.0630\n",
      "Epoch : 1884/2000 data_batch_5,  Train_loss : 4363.3247  Test_loss : 4529.5566, Time/batch_file : 2.2793, Training time: 21837.3426\n",
      "Epoch : 1885/2000 data_batch_1,  Train_loss : 4855.9927  Test_loss : 5086.0571, Time/batch_file : 2.2546, Training time: 21839.5974\n",
      "Epoch : 1885/2000 data_batch_2,  Train_loss : 4608.0723  Test_loss : 4672.2202, Time/batch_file : 2.2601, Training time: 21841.8577\n",
      "Epoch : 1885/2000 data_batch_3,  Train_loss : 4572.7603  Test_loss : 4779.6895, Time/batch_file : 2.2732, Training time: 21844.1311\n",
      "Epoch : 1885/2000 data_batch_4,  Train_loss : 4747.0020  Test_loss : 4712.9238, Time/batch_file : 2.2544, Training time: 21846.3858\n",
      "Epoch : 1885/2000 data_batch_5,  Train_loss : 4707.0381  Test_loss : 4861.7178, Time/batch_file : 2.2753, Training time: 21848.6613\n",
      "Epoch : 1886/2000 data_batch_1,  Train_loss : 4604.2910  Test_loss : 4480.7739, Time/batch_file : 2.2637, Training time: 21850.9251\n",
      "Epoch : 1886/2000 data_batch_2,  Train_loss : 4539.8989  Test_loss : 4524.4263, Time/batch_file : 2.2838, Training time: 21853.2091\n",
      "Epoch : 1886/2000 data_batch_3,  Train_loss : 4644.6890  Test_loss : 4884.4536, Time/batch_file : 2.2847, Training time: 21855.4940\n",
      "Epoch : 1886/2000 data_batch_4,  Train_loss : 4491.1265  Test_loss : 4622.6787, Time/batch_file : 2.2797, Training time: 21857.7739\n",
      "Epoch : 1886/2000 data_batch_5,  Train_loss : 4467.4634  Test_loss : 5071.6250, Time/batch_file : 2.2696, Training time: 21860.0437\n",
      "Epoch : 1887/2000 data_batch_1,  Train_loss : 4691.6714  Test_loss : 4595.8779, Time/batch_file : 2.2768, Training time: 21862.3207\n",
      "Epoch : 1887/2000 data_batch_2,  Train_loss : 4235.8652  Test_loss : 4724.9487, Time/batch_file : 2.2587, Training time: 21864.5796\n",
      "Epoch : 1887/2000 data_batch_3,  Train_loss : 4382.8301  Test_loss : 4688.7734, Time/batch_file : 2.2859, Training time: 21866.8657\n",
      "Epoch : 1887/2000 data_batch_4,  Train_loss : 4282.8203  Test_loss : 4439.9893, Time/batch_file : 2.2759, Training time: 21869.1418\n",
      "Epoch : 1887/2000 data_batch_5,  Train_loss : 4176.6714  Test_loss : 4659.6533, Time/batch_file : 2.2647, Training time: 21871.4067\n",
      "Epoch : 1888/2000 data_batch_1,  Train_loss : 4735.4062  Test_loss : 4807.8467, Time/batch_file : 2.2664, Training time: 21873.6734\n",
      "Epoch : 1888/2000 data_batch_2,  Train_loss : 4646.4268  Test_loss : 4630.2354, Time/batch_file : 2.2719, Training time: 21875.9455\n",
      "Epoch : 1888/2000 data_batch_3,  Train_loss : 4956.7573  Test_loss : 4731.3311, Time/batch_file : 2.2591, Training time: 21878.2048\n",
      "Epoch : 1888/2000 data_batch_4,  Train_loss : 4853.7412  Test_loss : 5096.1362, Time/batch_file : 2.3008, Training time: 21880.5058\n",
      "Epoch : 1888/2000 data_batch_5,  Train_loss : 4554.8823  Test_loss : 4860.1108, Time/batch_file : 2.2551, Training time: 21882.7611\n",
      "Epoch : 1889/2000 data_batch_1,  Train_loss : 4131.6177  Test_loss : 4760.7021, Time/batch_file : 2.2737, Training time: 21885.0350\n",
      "Epoch : 1889/2000 data_batch_2,  Train_loss : 4312.1758  Test_loss : 4593.3999, Time/batch_file : 2.2678, Training time: 21887.3030\n",
      "Epoch : 1889/2000 data_batch_3,  Train_loss : 4296.8252  Test_loss : 4444.0605, Time/batch_file : 2.2899, Training time: 21889.5931\n",
      "Epoch : 1889/2000 data_batch_4,  Train_loss : 4227.8057  Test_loss : 4761.4214, Time/batch_file : 2.2762, Training time: 21891.8694\n",
      "Epoch : 1889/2000 data_batch_5,  Train_loss : 4143.5142  Test_loss : 4576.2080, Time/batch_file : 2.2838, Training time: 21894.1534\n",
      "Epoch : 1890/2000 data_batch_1,  Train_loss : 4216.3618  Test_loss : 4368.9727, Time/batch_file : 2.2478, Training time: 21896.4015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1890/2000 data_batch_2,  Train_loss : 4551.2549  Test_loss : 4281.5488, Time/batch_file : 2.2771, Training time: 21898.6788\n",
      "Epoch : 1890/2000 data_batch_3,  Train_loss : 4260.6035  Test_loss : 4553.8984, Time/batch_file : 2.2615, Training time: 21900.9406\n",
      "Epoch : 1890/2000 data_batch_4,  Train_loss : 4500.7622  Test_loss : 4281.6523, Time/batch_file : 2.2737, Training time: 21903.2144\n",
      "Epoch : 1890/2000 data_batch_5,  Train_loss : 4481.4863  Test_loss : 4414.8267, Time/batch_file : 2.2466, Training time: 21905.4612\n",
      "[./nets/net-1890.ckpt] SAVED\n",
      "Epoch : 1891/2000 data_batch_1,  Train_loss : 4568.0391  Test_loss : 4963.9438, Time/batch_file : 2.5651, Training time: 21909.3245\n",
      "Epoch : 1891/2000 data_batch_2,  Train_loss : 4252.2695  Test_loss : 4610.9004, Time/batch_file : 2.4837, Training time: 21911.8084\n",
      "Epoch : 1891/2000 data_batch_3,  Train_loss : 4317.2637  Test_loss : 4886.8037, Time/batch_file : 2.2728, Training time: 21914.0814\n",
      "Epoch : 1891/2000 data_batch_4,  Train_loss : 4399.8682  Test_loss : 4909.0688, Time/batch_file : 2.2908, Training time: 21916.3724\n",
      "Epoch : 1891/2000 data_batch_5,  Train_loss : 4619.6948  Test_loss : 4808.3267, Time/batch_file : 2.2931, Training time: 21918.6658\n",
      "Epoch : 1892/2000 data_batch_1,  Train_loss : 4394.9883  Test_loss : 5209.0391, Time/batch_file : 2.3213, Training time: 21920.9873\n",
      "Epoch : 1892/2000 data_batch_2,  Train_loss : 4403.7715  Test_loss : 5404.7827, Time/batch_file : 2.2642, Training time: 21923.2518\n",
      "Epoch : 1892/2000 data_batch_3,  Train_loss : 4468.4385  Test_loss : 5286.7275, Time/batch_file : 2.2739, Training time: 21925.5259\n",
      "Epoch : 1892/2000 data_batch_4,  Train_loss : 4178.3428  Test_loss : 5009.6465, Time/batch_file : 2.2619, Training time: 21927.7880\n",
      "Epoch : 1892/2000 data_batch_5,  Train_loss : 4281.1313  Test_loss : 5391.6333, Time/batch_file : 2.2774, Training time: 21930.0656\n",
      "Epoch : 1893/2000 data_batch_1,  Train_loss : 4233.1733  Test_loss : 4462.1577, Time/batch_file : 2.2822, Training time: 21932.3481\n",
      "Epoch : 1893/2000 data_batch_2,  Train_loss : 4675.7256  Test_loss : 4574.3320, Time/batch_file : 2.2739, Training time: 21934.6222\n",
      "Epoch : 1893/2000 data_batch_3,  Train_loss : 4545.1377  Test_loss : 4679.7485, Time/batch_file : 2.2677, Training time: 21936.8900\n",
      "Epoch : 1893/2000 data_batch_4,  Train_loss : 4356.7759  Test_loss : 4479.9282, Time/batch_file : 2.2843, Training time: 21939.1744\n",
      "Epoch : 1893/2000 data_batch_5,  Train_loss : 4381.4419  Test_loss : 4448.3013, Time/batch_file : 2.2735, Training time: 21941.4481\n",
      "Epoch : 1894/2000 data_batch_1,  Train_loss : 4452.1152  Test_loss : 4638.8428, Time/batch_file : 2.2804, Training time: 21943.7287\n",
      "Epoch : 1894/2000 data_batch_2,  Train_loss : 4486.5552  Test_loss : 4316.5713, Time/batch_file : 2.2705, Training time: 21945.9994\n",
      "Epoch : 1894/2000 data_batch_3,  Train_loss : 4476.8677  Test_loss : 4766.0181, Time/batch_file : 2.2777, Training time: 21948.2773\n",
      "Epoch : 1894/2000 data_batch_4,  Train_loss : 4396.4419  Test_loss : 4637.5674, Time/batch_file : 2.2718, Training time: 21950.5493\n",
      "Epoch : 1894/2000 data_batch_5,  Train_loss : 4369.5679  Test_loss : 4459.2964, Time/batch_file : 2.2753, Training time: 21952.8248\n",
      "Epoch : 1895/2000 data_batch_1,  Train_loss : 4709.3843  Test_loss : 4579.2847, Time/batch_file : 2.2741, Training time: 21955.0991\n",
      "Epoch : 1895/2000 data_batch_2,  Train_loss : 4911.6338  Test_loss : 4821.8770, Time/batch_file : 2.2688, Training time: 21957.3682\n",
      "Epoch : 1895/2000 data_batch_3,  Train_loss : 4724.1831  Test_loss : 4747.7754, Time/batch_file : 2.2634, Training time: 21959.6318\n",
      "Epoch : 1895/2000 data_batch_4,  Train_loss : 4690.4688  Test_loss : 4926.2026, Time/batch_file : 2.2717, Training time: 21961.9037\n",
      "Epoch : 1895/2000 data_batch_5,  Train_loss : 4702.2588  Test_loss : 4760.4639, Time/batch_file : 2.2573, Training time: 21964.1611\n",
      "Epoch : 1896/2000 data_batch_1,  Train_loss : 4927.7168  Test_loss : 4706.9160, Time/batch_file : 2.2841, Training time: 21966.4454\n",
      "Epoch : 1896/2000 data_batch_2,  Train_loss : 4449.3481  Test_loss : 4833.9194, Time/batch_file : 2.2815, Training time: 21968.7271\n",
      "Epoch : 1896/2000 data_batch_3,  Train_loss : 4504.2578  Test_loss : 4827.5645, Time/batch_file : 2.2867, Training time: 21971.0140\n",
      "Epoch : 1896/2000 data_batch_4,  Train_loss : 4353.4170  Test_loss : 4810.3364, Time/batch_file : 2.2729, Training time: 21973.2872\n",
      "Epoch : 1896/2000 data_batch_5,  Train_loss : 4647.9150  Test_loss : 4766.8506, Time/batch_file : 2.2868, Training time: 21975.5743\n",
      "Epoch : 1897/2000 data_batch_1,  Train_loss : 4481.4893  Test_loss : 4436.3066, Time/batch_file : 2.2677, Training time: 21977.8421\n",
      "Epoch : 1897/2000 data_batch_2,  Train_loss : 4597.4111  Test_loss : 4619.9365, Time/batch_file : 2.2749, Training time: 21980.1173\n",
      "Epoch : 1897/2000 data_batch_3,  Train_loss : 4550.6289  Test_loss : 4544.0811, Time/batch_file : 2.2665, Training time: 21982.3841\n",
      "Epoch : 1897/2000 data_batch_4,  Train_loss : 4364.5161  Test_loss : 4449.4473, Time/batch_file : 2.2819, Training time: 21984.6662\n",
      "Epoch : 1897/2000 data_batch_5,  Train_loss : 4398.4912  Test_loss : 4454.4775, Time/batch_file : 2.2745, Training time: 21986.9409\n",
      "Epoch : 1898/2000 data_batch_1,  Train_loss : 4846.4224  Test_loss : 4847.8535, Time/batch_file : 2.2726, Training time: 21989.2137\n",
      "Epoch : 1898/2000 data_batch_2,  Train_loss : 4825.3730  Test_loss : 4485.5293, Time/batch_file : 2.2642, Training time: 21991.4781\n",
      "Epoch : 1898/2000 data_batch_3,  Train_loss : 4858.5024  Test_loss : 4930.0679, Time/batch_file : 2.2685, Training time: 21993.7469\n",
      "Epoch : 1898/2000 data_batch_4,  Train_loss : 4792.2070  Test_loss : 4614.3936, Time/batch_file : 2.2749, Training time: 21996.0219\n",
      "Epoch : 1898/2000 data_batch_5,  Train_loss : 4592.5791  Test_loss : 4727.9053, Time/batch_file : 2.2716, Training time: 21998.2938\n",
      "Epoch : 1899/2000 data_batch_1,  Train_loss : 4553.5518  Test_loss : 5039.1758, Time/batch_file : 2.2828, Training time: 22000.5770\n",
      "Epoch : 1899/2000 data_batch_2,  Train_loss : 4519.4351  Test_loss : 4800.0454, Time/batch_file : 2.2812, Training time: 22002.8584\n",
      "Epoch : 1899/2000 data_batch_3,  Train_loss : 4590.2529  Test_loss : 4989.5088, Time/batch_file : 2.2780, Training time: 22005.1365\n",
      "Epoch : 1899/2000 data_batch_4,  Train_loss : 4526.8652  Test_loss : 5041.0039, Time/batch_file : 2.2757, Training time: 22007.4124\n",
      "Epoch : 1899/2000 data_batch_5,  Train_loss : 4543.3042  Test_loss : 4951.0747, Time/batch_file : 2.2718, Training time: 22009.6844\n",
      "Epoch : 1900/2000 data_batch_1,  Train_loss : 4721.5254  Test_loss : 4547.3447, Time/batch_file : 2.2659, Training time: 22011.9505\n",
      "Epoch : 1900/2000 data_batch_2,  Train_loss : 4718.4141  Test_loss : 4678.6299, Time/batch_file : 2.2799, Training time: 22014.2306\n",
      "Epoch : 1900/2000 data_batch_3,  Train_loss : 4586.8047  Test_loss : 4589.2007, Time/batch_file : 2.2662, Training time: 22016.4971\n",
      "Epoch : 1900/2000 data_batch_4,  Train_loss : 4358.1582  Test_loss : 4422.9966, Time/batch_file : 2.2830, Training time: 22018.7802\n",
      "Epoch : 1900/2000 data_batch_5,  Train_loss : 4389.1694  Test_loss : 4635.1104, Time/batch_file : 2.2691, Training time: 22021.0495\n",
      "[./nets/net-1900.ckpt] SAVED\n",
      "Epoch : 1901/2000 data_batch_1,  Train_loss : 4728.3257  Test_loss : 4942.3267, Time/batch_file : 2.3268, Training time: 22024.6667\n",
      "Epoch : 1901/2000 data_batch_2,  Train_loss : 4797.6816  Test_loss : 5034.8682, Time/batch_file : 2.2596, Training time: 22026.9263\n",
      "Epoch : 1901/2000 data_batch_3,  Train_loss : 4737.7192  Test_loss : 4875.9512, Time/batch_file : 2.2986, Training time: 22029.2252\n",
      "Epoch : 1901/2000 data_batch_4,  Train_loss : 4808.4976  Test_loss : 5231.8037, Time/batch_file : 2.2682, Training time: 22031.4935\n",
      "Epoch : 1901/2000 data_batch_5,  Train_loss : 4810.1777  Test_loss : 5354.1592, Time/batch_file : 2.2664, Training time: 22033.7602\n",
      "Epoch : 1902/2000 data_batch_1,  Train_loss : 4450.8975  Test_loss : 4388.1963, Time/batch_file : 2.2797, Training time: 22036.0400\n",
      "Epoch : 1902/2000 data_batch_2,  Train_loss : 4352.4375  Test_loss : 4551.1895, Time/batch_file : 2.3004, Training time: 22038.3407\n",
      "Epoch : 1902/2000 data_batch_3,  Train_loss : 4496.9717  Test_loss : 4411.9614, Time/batch_file : 2.2841, Training time: 22040.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1902/2000 data_batch_4,  Train_loss : 4285.7749  Test_loss : 4383.6152, Time/batch_file : 2.3095, Training time: 22042.9347\n",
      "Epoch : 1902/2000 data_batch_5,  Train_loss : 4332.5020  Test_loss : 4682.6763, Time/batch_file : 2.2825, Training time: 22045.2176\n",
      "Epoch : 1903/2000 data_batch_1,  Train_loss : 4753.6621  Test_loss : 4961.4517, Time/batch_file : 2.2769, Training time: 22047.4946\n",
      "Epoch : 1903/2000 data_batch_2,  Train_loss : 4533.8438  Test_loss : 4996.3833, Time/batch_file : 2.3035, Training time: 22049.7983\n",
      "Epoch : 1903/2000 data_batch_3,  Train_loss : 4538.5874  Test_loss : 4938.6475, Time/batch_file : 2.2654, Training time: 22052.0640\n",
      "Epoch : 1903/2000 data_batch_4,  Train_loss : 4575.2622  Test_loss : 4822.9570, Time/batch_file : 2.2832, Training time: 22054.3474\n",
      "Epoch : 1903/2000 data_batch_5,  Train_loss : 4814.1299  Test_loss : 4864.9893, Time/batch_file : 2.2784, Training time: 22056.6259\n",
      "Epoch : 1904/2000 data_batch_1,  Train_loss : 4407.9282  Test_loss : 4622.5068, Time/batch_file : 2.2778, Training time: 22058.9039\n",
      "Epoch : 1904/2000 data_batch_2,  Train_loss : 4452.6465  Test_loss : 4682.2939, Time/batch_file : 2.2762, Training time: 22061.1803\n",
      "Epoch : 1904/2000 data_batch_3,  Train_loss : 4318.5312  Test_loss : 4543.0264, Time/batch_file : 2.2806, Training time: 22063.4611\n",
      "Epoch : 1904/2000 data_batch_4,  Train_loss : 4395.8574  Test_loss : 4616.3389, Time/batch_file : 2.2890, Training time: 22065.7503\n",
      "Epoch : 1904/2000 data_batch_5,  Train_loss : 4598.6953  Test_loss : 4539.2578, Time/batch_file : 2.2706, Training time: 22068.0211\n",
      "Epoch : 1905/2000 data_batch_1,  Train_loss : 4694.0308  Test_loss : 4364.0576, Time/batch_file : 2.2738, Training time: 22070.2951\n",
      "Epoch : 1905/2000 data_batch_2,  Train_loss : 4686.1562  Test_loss : 4400.7212, Time/batch_file : 2.2733, Training time: 22072.5686\n",
      "Epoch : 1905/2000 data_batch_3,  Train_loss : 4527.7979  Test_loss : 4492.0879, Time/batch_file : 2.3066, Training time: 22074.8754\n",
      "Epoch : 1905/2000 data_batch_4,  Train_loss : 4805.0249  Test_loss : 4279.1787, Time/batch_file : 2.2728, Training time: 22077.1483\n",
      "Epoch : 1905/2000 data_batch_5,  Train_loss : 4601.6655  Test_loss : 4291.0254, Time/batch_file : 2.2798, Training time: 22079.4282\n",
      "Epoch : 1906/2000 data_batch_1,  Train_loss : 4502.5566  Test_loss : 4319.9453, Time/batch_file : 2.3021, Training time: 22081.7305\n",
      "Epoch : 1906/2000 data_batch_2,  Train_loss : 4468.7007  Test_loss : 4530.4150, Time/batch_file : 2.2704, Training time: 22084.0011\n",
      "Epoch : 1906/2000 data_batch_3,  Train_loss : 4394.7139  Test_loss : 4355.0312, Time/batch_file : 2.2921, Training time: 22086.2934\n",
      "Epoch : 1906/2000 data_batch_4,  Train_loss : 4530.1851  Test_loss : 4329.1865, Time/batch_file : 2.2777, Training time: 22088.5713\n",
      "Epoch : 1906/2000 data_batch_5,  Train_loss : 4613.3843  Test_loss : 4496.0576, Time/batch_file : 2.2866, Training time: 22090.8581\n",
      "Epoch : 1907/2000 data_batch_1,  Train_loss : 4294.5859  Test_loss : 4917.4727, Time/batch_file : 2.2871, Training time: 22093.1454\n",
      "Epoch : 1907/2000 data_batch_2,  Train_loss : 4296.7871  Test_loss : 5094.3271, Time/batch_file : 2.2785, Training time: 22095.4241\n",
      "Epoch : 1907/2000 data_batch_3,  Train_loss : 4393.3267  Test_loss : 5213.5835, Time/batch_file : 2.2822, Training time: 22097.7066\n",
      "Epoch : 1907/2000 data_batch_4,  Train_loss : 4275.9502  Test_loss : 5211.5015, Time/batch_file : 2.2740, Training time: 22099.9807\n",
      "Epoch : 1907/2000 data_batch_5,  Train_loss : 4319.7124  Test_loss : 5206.9409, Time/batch_file : 2.3101, Training time: 22102.2911\n",
      "Epoch : 1908/2000 data_batch_1,  Train_loss : 4512.1152  Test_loss : 5342.8364, Time/batch_file : 2.2860, Training time: 22104.5774\n",
      "Epoch : 1908/2000 data_batch_2,  Train_loss : 4356.2695  Test_loss : 5140.7329, Time/batch_file : 2.2802, Training time: 22106.8577\n",
      "Epoch : 1908/2000 data_batch_3,  Train_loss : 4461.0073  Test_loss : 5375.8765, Time/batch_file : 2.2957, Training time: 22109.1536\n",
      "Epoch : 1908/2000 data_batch_4,  Train_loss : 4666.7578  Test_loss : 5146.1821, Time/batch_file : 2.2756, Training time: 22111.4294\n",
      "Epoch : 1908/2000 data_batch_5,  Train_loss : 4356.5244  Test_loss : 5442.9531, Time/batch_file : 2.2943, Training time: 22113.7239\n",
      "Epoch : 1909/2000 data_batch_1,  Train_loss : 4149.3438  Test_loss : 4651.2822, Time/batch_file : 2.2841, Training time: 22116.0082\n",
      "Epoch : 1909/2000 data_batch_2,  Train_loss : 4252.1035  Test_loss : 4762.8247, Time/batch_file : 2.2801, Training time: 22118.2885\n",
      "Epoch : 1909/2000 data_batch_3,  Train_loss : 4161.1855  Test_loss : 4589.1553, Time/batch_file : 2.2928, Training time: 22120.5816\n",
      "Epoch : 1909/2000 data_batch_4,  Train_loss : 4098.7139  Test_loss : 4728.9209, Time/batch_file : 2.2666, Training time: 22122.8484\n",
      "Epoch : 1909/2000 data_batch_5,  Train_loss : 4434.9868  Test_loss : 4599.8130, Time/batch_file : 2.2793, Training time: 22125.1279\n",
      "Epoch : 1910/2000 data_batch_1,  Train_loss : 4918.0605  Test_loss : 4961.8315, Time/batch_file : 2.2958, Training time: 22127.4240\n",
      "Epoch : 1910/2000 data_batch_2,  Train_loss : 4701.0972  Test_loss : 4887.3628, Time/batch_file : 2.3189, Training time: 22129.7431\n",
      "Epoch : 1910/2000 data_batch_3,  Train_loss : 4796.7461  Test_loss : 4729.9082, Time/batch_file : 2.2762, Training time: 22132.0196\n",
      "Epoch : 1910/2000 data_batch_4,  Train_loss : 4552.3457  Test_loss : 4877.7793, Time/batch_file : 2.2905, Training time: 22134.3102\n",
      "Epoch : 1910/2000 data_batch_5,  Train_loss : 4782.0898  Test_loss : 5164.6641, Time/batch_file : 2.3048, Training time: 22136.6152\n",
      "[./nets/net-1910.ckpt] SAVED\n",
      "Epoch : 1911/2000 data_batch_1,  Train_loss : 4479.8252  Test_loss : 4676.5513, Time/batch_file : 2.3902, Training time: 22140.3463\n",
      "Epoch : 1911/2000 data_batch_2,  Train_loss : 4665.5830  Test_loss : 4525.4497, Time/batch_file : 2.2843, Training time: 22142.6308\n",
      "Epoch : 1911/2000 data_batch_3,  Train_loss : 4766.5220  Test_loss : 4603.8208, Time/batch_file : 2.2862, Training time: 22144.9173\n",
      "Epoch : 1911/2000 data_batch_4,  Train_loss : 4511.7012  Test_loss : 4515.5840, Time/batch_file : 2.2763, Training time: 22147.1938\n",
      "Epoch : 1911/2000 data_batch_5,  Train_loss : 4600.2061  Test_loss : 4873.8779, Time/batch_file : 2.3041, Training time: 22149.4981\n",
      "Epoch : 1912/2000 data_batch_1,  Train_loss : 4834.6914  Test_loss : 4749.0527, Time/batch_file : 2.2599, Training time: 22151.7582\n",
      "Epoch : 1912/2000 data_batch_2,  Train_loss : 4370.9229  Test_loss : 5059.9775, Time/batch_file : 2.2743, Training time: 22154.0328\n",
      "Epoch : 1912/2000 data_batch_3,  Train_loss : 4592.2461  Test_loss : 4790.1465, Time/batch_file : 2.2561, Training time: 22156.2891\n",
      "Epoch : 1912/2000 data_batch_4,  Train_loss : 4658.6509  Test_loss : 4943.5444, Time/batch_file : 2.2716, Training time: 22158.5609\n",
      "Epoch : 1912/2000 data_batch_5,  Train_loss : 4561.2510  Test_loss : 4774.6670, Time/batch_file : 2.2657, Training time: 22160.8268\n",
      "Epoch : 1913/2000 data_batch_1,  Train_loss : 4712.1875  Test_loss : 4897.1543, Time/batch_file : 2.2861, Training time: 22163.1131\n",
      "Epoch : 1913/2000 data_batch_2,  Train_loss : 4811.2319  Test_loss : 4800.9141, Time/batch_file : 2.2676, Training time: 22165.3810\n",
      "Epoch : 1913/2000 data_batch_3,  Train_loss : 4554.7666  Test_loss : 4685.9941, Time/batch_file : 2.2765, Training time: 22167.6577\n",
      "Epoch : 1913/2000 data_batch_4,  Train_loss : 4797.7803  Test_loss : 4720.7070, Time/batch_file : 2.3114, Training time: 22169.9693\n",
      "Epoch : 1913/2000 data_batch_5,  Train_loss : 4311.1865  Test_loss : 4615.4272, Time/batch_file : 2.2617, Training time: 22172.2312\n",
      "Epoch : 1914/2000 data_batch_1,  Train_loss : 4778.7095  Test_loss : 4848.4219, Time/batch_file : 2.2757, Training time: 22174.5072\n",
      "Epoch : 1914/2000 data_batch_2,  Train_loss : 4988.3716  Test_loss : 4929.4976, Time/batch_file : 2.2760, Training time: 22176.7834\n",
      "Epoch : 1914/2000 data_batch_3,  Train_loss : 4830.3564  Test_loss : 4778.7871, Time/batch_file : 2.2927, Training time: 22179.0762\n",
      "Epoch : 1914/2000 data_batch_4,  Train_loss : 5029.5312  Test_loss : 4763.9990, Time/batch_file : 2.2674, Training time: 22181.3437\n",
      "Epoch : 1914/2000 data_batch_5,  Train_loss : 5005.7314  Test_loss : 4850.2979, Time/batch_file : 2.2838, Training time: 22183.6278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1915/2000 data_batch_1,  Train_loss : 4069.1284  Test_loss : 4983.8140, Time/batch_file : 2.2871, Training time: 22185.9151\n",
      "Epoch : 1915/2000 data_batch_2,  Train_loss : 4336.3755  Test_loss : 5048.5381, Time/batch_file : 2.2578, Training time: 22188.1732\n",
      "Epoch : 1915/2000 data_batch_3,  Train_loss : 4139.1997  Test_loss : 4823.9888, Time/batch_file : 2.2910, Training time: 22190.4644\n",
      "Epoch : 1915/2000 data_batch_4,  Train_loss : 4094.3193  Test_loss : 4896.8140, Time/batch_file : 2.2747, Training time: 22192.7394\n",
      "Epoch : 1915/2000 data_batch_5,  Train_loss : 3859.4736  Test_loss : 4830.2002, Time/batch_file : 2.2673, Training time: 22195.0068\n",
      "Epoch : 1916/2000 data_batch_1,  Train_loss : 4646.9502  Test_loss : 4756.5449, Time/batch_file : 2.2875, Training time: 22197.2945\n",
      "Epoch : 1916/2000 data_batch_2,  Train_loss : 4507.0669  Test_loss : 4875.9790, Time/batch_file : 2.2833, Training time: 22199.5780\n",
      "Epoch : 1916/2000 data_batch_3,  Train_loss : 4490.7109  Test_loss : 4875.3252, Time/batch_file : 2.2867, Training time: 22201.8649\n",
      "Epoch : 1916/2000 data_batch_4,  Train_loss : 4551.8740  Test_loss : 4732.2617, Time/batch_file : 2.2820, Training time: 22204.1471\n",
      "Epoch : 1916/2000 data_batch_5,  Train_loss : 4796.3857  Test_loss : 4753.7319, Time/batch_file : 2.2899, Training time: 22206.4372\n",
      "Epoch : 1917/2000 data_batch_1,  Train_loss : 4955.4399  Test_loss : 4320.9731, Time/batch_file : 2.2777, Training time: 22208.7151\n",
      "Epoch : 1917/2000 data_batch_2,  Train_loss : 5045.0840  Test_loss : 4237.8501, Time/batch_file : 2.2871, Training time: 22211.0024\n",
      "Epoch : 1917/2000 data_batch_3,  Train_loss : 5215.9419  Test_loss : 4814.9253, Time/batch_file : 2.2731, Training time: 22213.2758\n",
      "Epoch : 1917/2000 data_batch_4,  Train_loss : 5066.5444  Test_loss : 4515.5645, Time/batch_file : 2.2925, Training time: 22215.5685\n",
      "Epoch : 1917/2000 data_batch_5,  Train_loss : 4904.3032  Test_loss : 4789.2666, Time/batch_file : 2.2752, Training time: 22217.8439\n",
      "Epoch : 1918/2000 data_batch_1,  Train_loss : 4542.4307  Test_loss : 4937.0176, Time/batch_file : 2.3244, Training time: 22220.1685\n",
      "Epoch : 1918/2000 data_batch_2,  Train_loss : 4410.3862  Test_loss : 4975.0664, Time/batch_file : 2.2829, Training time: 22222.4516\n",
      "Epoch : 1918/2000 data_batch_3,  Train_loss : 4179.1367  Test_loss : 4814.6479, Time/batch_file : 2.2923, Training time: 22224.7441\n",
      "Epoch : 1918/2000 data_batch_4,  Train_loss : 4554.6045  Test_loss : 4995.7207, Time/batch_file : 2.2855, Training time: 22227.0298\n",
      "Epoch : 1918/2000 data_batch_5,  Train_loss : 4523.5415  Test_loss : 4996.4131, Time/batch_file : 2.2955, Training time: 22229.3255\n",
      "Epoch : 1919/2000 data_batch_1,  Train_loss : 4543.7407  Test_loss : 5261.0620, Time/batch_file : 2.2680, Training time: 22231.5937\n",
      "Epoch : 1919/2000 data_batch_2,  Train_loss : 4557.5859  Test_loss : 5376.8232, Time/batch_file : 2.2882, Training time: 22233.8821\n",
      "Epoch : 1919/2000 data_batch_3,  Train_loss : 4640.1782  Test_loss : 5492.1924, Time/batch_file : 2.2695, Training time: 22236.1518\n",
      "Epoch : 1919/2000 data_batch_4,  Train_loss : 4703.2070  Test_loss : 5359.6138, Time/batch_file : 2.2764, Training time: 22238.4284\n",
      "Epoch : 1919/2000 data_batch_5,  Train_loss : 4509.2534  Test_loss : 5294.8730, Time/batch_file : 2.2684, Training time: 22240.6970\n",
      "Epoch : 1920/2000 data_batch_1,  Train_loss : 4543.9541  Test_loss : 4535.2832, Time/batch_file : 2.2980, Training time: 22242.9952\n",
      "Epoch : 1920/2000 data_batch_2,  Train_loss : 4432.4116  Test_loss : 4259.1182, Time/batch_file : 2.2805, Training time: 22245.2760\n",
      "Epoch : 1920/2000 data_batch_3,  Train_loss : 4464.3350  Test_loss : 4728.8374, Time/batch_file : 2.2948, Training time: 22247.5711\n",
      "Epoch : 1920/2000 data_batch_4,  Train_loss : 4657.0771  Test_loss : 4410.1074, Time/batch_file : 2.2776, Training time: 22249.8489\n",
      "Epoch : 1920/2000 data_batch_5,  Train_loss : 4469.6011  Test_loss : 4445.7256, Time/batch_file : 2.2984, Training time: 22252.1475\n",
      "[./nets/net-1920.ckpt] SAVED\n",
      "Epoch : 1921/2000 data_batch_1,  Train_loss : 4566.3643  Test_loss : 4564.9019, Time/batch_file : 2.3157, Training time: 22255.7489\n",
      "Epoch : 1921/2000 data_batch_2,  Train_loss : 4603.5176  Test_loss : 4519.0391, Time/batch_file : 2.3260, Training time: 22258.0752\n",
      "Epoch : 1921/2000 data_batch_3,  Train_loss : 4774.3735  Test_loss : 4668.7090, Time/batch_file : 2.2927, Training time: 22260.3680\n",
      "Epoch : 1921/2000 data_batch_4,  Train_loss : 4971.6475  Test_loss : 4699.6885, Time/batch_file : 2.3347, Training time: 22262.7029\n",
      "Epoch : 1921/2000 data_batch_5,  Train_loss : 4549.1455  Test_loss : 4782.6406, Time/batch_file : 2.3193, Training time: 22265.0223\n",
      "Epoch : 1922/2000 data_batch_1,  Train_loss : 4750.4512  Test_loss : 5132.9673, Time/batch_file : 2.2960, Training time: 22267.3185\n",
      "Epoch : 1922/2000 data_batch_2,  Train_loss : 4704.0303  Test_loss : 4692.1943, Time/batch_file : 2.3074, Training time: 22269.6262\n",
      "Epoch : 1922/2000 data_batch_3,  Train_loss : 4970.7324  Test_loss : 4714.0518, Time/batch_file : 2.2989, Training time: 22271.9253\n",
      "Epoch : 1922/2000 data_batch_4,  Train_loss : 5012.9614  Test_loss : 4697.3394, Time/batch_file : 2.3050, Training time: 22274.2305\n",
      "Epoch : 1922/2000 data_batch_5,  Train_loss : 4736.4922  Test_loss : 4676.2031, Time/batch_file : 2.2793, Training time: 22276.5100\n",
      "Epoch : 1923/2000 data_batch_1,  Train_loss : 4346.4995  Test_loss : 4167.7329, Time/batch_file : 2.3097, Training time: 22278.8199\n",
      "Epoch : 1923/2000 data_batch_2,  Train_loss : 4565.2070  Test_loss : 4142.3174, Time/batch_file : 2.2775, Training time: 22281.0977\n",
      "Epoch : 1923/2000 data_batch_3,  Train_loss : 4338.9556  Test_loss : 4584.6509, Time/batch_file : 2.2822, Training time: 22283.3801\n",
      "Epoch : 1923/2000 data_batch_4,  Train_loss : 4373.4512  Test_loss : 4356.6558, Time/batch_file : 2.2998, Training time: 22285.6801\n",
      "Epoch : 1923/2000 data_batch_5,  Train_loss : 4362.9917  Test_loss : 4215.9370, Time/batch_file : 2.3307, Training time: 22288.0110\n",
      "Epoch : 1924/2000 data_batch_1,  Train_loss : 4393.7480  Test_loss : 4925.6992, Time/batch_file : 2.2978, Training time: 22290.3090\n",
      "Epoch : 1924/2000 data_batch_2,  Train_loss : 4488.7197  Test_loss : 4609.6831, Time/batch_file : 2.3107, Training time: 22292.6199\n",
      "Epoch : 1924/2000 data_batch_3,  Train_loss : 4354.8472  Test_loss : 4626.6885, Time/batch_file : 2.2944, Training time: 22294.9146\n",
      "Epoch : 1924/2000 data_batch_4,  Train_loss : 4427.1523  Test_loss : 4758.7480, Time/batch_file : 2.2817, Training time: 22297.1966\n",
      "Epoch : 1924/2000 data_batch_5,  Train_loss : 4298.6670  Test_loss : 4608.0723, Time/batch_file : 2.3093, Training time: 22299.5060\n",
      "Epoch : 1925/2000 data_batch_1,  Train_loss : 4707.5142  Test_loss : 4766.2930, Time/batch_file : 2.3034, Training time: 22301.8096\n",
      "Epoch : 1925/2000 data_batch_2,  Train_loss : 4582.8901  Test_loss : 4739.1533, Time/batch_file : 2.2653, Training time: 22304.0750\n",
      "Epoch : 1925/2000 data_batch_3,  Train_loss : 4580.7651  Test_loss : 4899.4736, Time/batch_file : 2.2860, Training time: 22306.3613\n",
      "Epoch : 1925/2000 data_batch_4,  Train_loss : 4423.0698  Test_loss : 4989.7695, Time/batch_file : 2.2946, Training time: 22308.6562\n",
      "Epoch : 1925/2000 data_batch_5,  Train_loss : 4508.1875  Test_loss : 4988.6387, Time/batch_file : 2.2618, Training time: 22310.9182\n",
      "Epoch : 1926/2000 data_batch_1,  Train_loss : 4899.1846  Test_loss : 4573.5850, Time/batch_file : 2.3196, Training time: 22313.2380\n",
      "Epoch : 1926/2000 data_batch_2,  Train_loss : 5057.8076  Test_loss : 4787.0522, Time/batch_file : 2.3076, Training time: 22315.5458\n",
      "Epoch : 1926/2000 data_batch_3,  Train_loss : 4865.3013  Test_loss : 4585.2988, Time/batch_file : 2.2831, Training time: 22317.8291\n",
      "Epoch : 1926/2000 data_batch_4,  Train_loss : 4668.9268  Test_loss : 4449.2773, Time/batch_file : 2.3047, Training time: 22320.1340\n",
      "Epoch : 1926/2000 data_batch_5,  Train_loss : 4903.2500  Test_loss : 4301.5029, Time/batch_file : 2.3213, Training time: 22322.4555\n",
      "Epoch : 1927/2000 data_batch_1,  Train_loss : 4717.6963  Test_loss : 4742.1328, Time/batch_file : 2.2759, Training time: 22324.7316\n",
      "Epoch : 1927/2000 data_batch_2,  Train_loss : 5188.2119  Test_loss : 4705.9678, Time/batch_file : 2.2943, Training time: 22327.0260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1927/2000 data_batch_3,  Train_loss : 4532.9531  Test_loss : 4790.6499, Time/batch_file : 2.2984, Training time: 22329.3245\n",
      "Epoch : 1927/2000 data_batch_4,  Train_loss : 4845.8105  Test_loss : 4636.3789, Time/batch_file : 2.3002, Training time: 22331.6248\n",
      "Epoch : 1927/2000 data_batch_5,  Train_loss : 4908.6646  Test_loss : 4606.4023, Time/batch_file : 2.2657, Training time: 22333.8907\n",
      "Epoch : 1928/2000 data_batch_1,  Train_loss : 4527.1411  Test_loss : 4446.3965, Time/batch_file : 2.2832, Training time: 22336.1740\n",
      "Epoch : 1928/2000 data_batch_2,  Train_loss : 4805.1235  Test_loss : 4339.6011, Time/batch_file : 2.2786, Training time: 22338.4529\n",
      "Epoch : 1928/2000 data_batch_3,  Train_loss : 4626.5020  Test_loss : 4264.6860, Time/batch_file : 2.2787, Training time: 22340.7318\n",
      "Epoch : 1928/2000 data_batch_4,  Train_loss : 4557.4541  Test_loss : 4482.1865, Time/batch_file : 2.2957, Training time: 22343.0278\n",
      "Epoch : 1928/2000 data_batch_5,  Train_loss : 4589.7637  Test_loss : 4399.0420, Time/batch_file : 2.2904, Training time: 22345.3184\n",
      "Epoch : 1929/2000 data_batch_1,  Train_loss : 4699.6392  Test_loss : 4842.9248, Time/batch_file : 2.3200, Training time: 22347.6386\n",
      "Epoch : 1929/2000 data_batch_2,  Train_loss : 4653.8711  Test_loss : 4702.9644, Time/batch_file : 2.3410, Training time: 22349.9799\n",
      "Epoch : 1929/2000 data_batch_3,  Train_loss : 4546.4893  Test_loss : 4894.3862, Time/batch_file : 2.2971, Training time: 22352.2772\n",
      "Epoch : 1929/2000 data_batch_4,  Train_loss : 4588.2900  Test_loss : 4617.9404, Time/batch_file : 2.3387, Training time: 22354.6160\n",
      "Epoch : 1929/2000 data_batch_5,  Train_loss : 4381.6855  Test_loss : 4709.6997, Time/batch_file : 2.3232, Training time: 22356.9395\n",
      "Epoch : 1930/2000 data_batch_1,  Train_loss : 4290.1396  Test_loss : 4711.0771, Time/batch_file : 2.3054, Training time: 22359.2451\n",
      "Epoch : 1930/2000 data_batch_2,  Train_loss : 4699.6948  Test_loss : 4952.8320, Time/batch_file : 2.3315, Training time: 22361.5769\n",
      "Epoch : 1930/2000 data_batch_3,  Train_loss : 4770.6411  Test_loss : 4647.4678, Time/batch_file : 2.2968, Training time: 22363.8739\n",
      "Epoch : 1930/2000 data_batch_4,  Train_loss : 4616.3301  Test_loss : 4660.9292, Time/batch_file : 2.2941, Training time: 22366.1682\n",
      "Epoch : 1930/2000 data_batch_5,  Train_loss : 4538.2021  Test_loss : 4808.3857, Time/batch_file : 2.3003, Training time: 22368.4687\n",
      "[./nets/net-1930.ckpt] SAVED\n",
      "Epoch : 1931/2000 data_batch_1,  Train_loss : 4944.6089  Test_loss : 4156.6626, Time/batch_file : 2.4619, Training time: 22372.2485\n",
      "Epoch : 1931/2000 data_batch_2,  Train_loss : 4802.8188  Test_loss : 3819.9175, Time/batch_file : 2.2852, Training time: 22374.5339\n",
      "Epoch : 1931/2000 data_batch_3,  Train_loss : 4750.2036  Test_loss : 4127.4238, Time/batch_file : 2.2958, Training time: 22376.8299\n",
      "Epoch : 1931/2000 data_batch_4,  Train_loss : 4827.8096  Test_loss : 4027.5283, Time/batch_file : 2.3196, Training time: 22379.1498\n",
      "Epoch : 1931/2000 data_batch_5,  Train_loss : 4851.9521  Test_loss : 4160.8555, Time/batch_file : 2.2911, Training time: 22381.4409\n",
      "Epoch : 1932/2000 data_batch_1,  Train_loss : 4232.9229  Test_loss : 4766.7715, Time/batch_file : 2.2819, Training time: 22383.7231\n",
      "Epoch : 1932/2000 data_batch_2,  Train_loss : 4171.0107  Test_loss : 4444.2827, Time/batch_file : 2.3096, Training time: 22386.0329\n",
      "Epoch : 1932/2000 data_batch_3,  Train_loss : 4115.1641  Test_loss : 4281.7686, Time/batch_file : 2.2884, Training time: 22388.3214\n",
      "Epoch : 1932/2000 data_batch_4,  Train_loss : 4181.6128  Test_loss : 4221.7651, Time/batch_file : 2.2970, Training time: 22390.6187\n",
      "Epoch : 1932/2000 data_batch_5,  Train_loss : 4058.1414  Test_loss : 4617.8979, Time/batch_file : 2.2945, Training time: 22392.9134\n",
      "Epoch : 1933/2000 data_batch_1,  Train_loss : 4758.5225  Test_loss : 4692.6602, Time/batch_file : 2.3100, Training time: 22395.2237\n",
      "Epoch : 1933/2000 data_batch_2,  Train_loss : 4830.8384  Test_loss : 4977.5972, Time/batch_file : 2.2587, Training time: 22397.4826\n",
      "Epoch : 1933/2000 data_batch_3,  Train_loss : 4872.0757  Test_loss : 4838.0630, Time/batch_file : 2.2676, Training time: 22399.7504\n",
      "Epoch : 1933/2000 data_batch_4,  Train_loss : 4890.2466  Test_loss : 5222.5029, Time/batch_file : 2.2826, Training time: 22402.0333\n",
      "Epoch : 1933/2000 data_batch_5,  Train_loss : 4872.3369  Test_loss : 4928.3389, Time/batch_file : 2.2871, Training time: 22404.3206\n",
      "Epoch : 1934/2000 data_batch_1,  Train_loss : 3987.9846  Test_loss : 5122.6558, Time/batch_file : 2.3170, Training time: 22406.6379\n",
      "Epoch : 1934/2000 data_batch_2,  Train_loss : 3968.2537  Test_loss : 5075.7080, Time/batch_file : 2.2598, Training time: 22408.8980\n",
      "Epoch : 1934/2000 data_batch_3,  Train_loss : 4145.5728  Test_loss : 5021.3057, Time/batch_file : 2.2891, Training time: 22411.1873\n",
      "Epoch : 1934/2000 data_batch_4,  Train_loss : 4000.2959  Test_loss : 5184.9663, Time/batch_file : 2.2802, Training time: 22413.4677\n",
      "Epoch : 1934/2000 data_batch_5,  Train_loss : 4170.4199  Test_loss : 5323.0527, Time/batch_file : 2.2697, Training time: 22415.7376\n",
      "Epoch : 1935/2000 data_batch_1,  Train_loss : 4930.8062  Test_loss : 4681.1885, Time/batch_file : 2.2970, Training time: 22418.0348\n",
      "Epoch : 1935/2000 data_batch_2,  Train_loss : 4932.1704  Test_loss : 4689.7847, Time/batch_file : 2.3023, Training time: 22420.3373\n",
      "Epoch : 1935/2000 data_batch_3,  Train_loss : 5079.5142  Test_loss : 4454.8809, Time/batch_file : 2.2912, Training time: 22422.6286\n",
      "Epoch : 1935/2000 data_batch_4,  Train_loss : 5019.9561  Test_loss : 4551.9121, Time/batch_file : 2.3034, Training time: 22424.9323\n",
      "Epoch : 1935/2000 data_batch_5,  Train_loss : 4797.5586  Test_loss : 4803.1143, Time/batch_file : 2.2938, Training time: 22427.2263\n",
      "Epoch : 1936/2000 data_batch_1,  Train_loss : 4530.3027  Test_loss : 4857.1914, Time/batch_file : 2.2807, Training time: 22429.5072\n",
      "Epoch : 1936/2000 data_batch_2,  Train_loss : 4322.3701  Test_loss : 4976.1201, Time/batch_file : 2.2818, Training time: 22431.7893\n",
      "Epoch : 1936/2000 data_batch_3,  Train_loss : 4595.6074  Test_loss : 4711.6343, Time/batch_file : 2.2799, Training time: 22434.0693\n",
      "Epoch : 1936/2000 data_batch_4,  Train_loss : 4488.2808  Test_loss : 4753.9663, Time/batch_file : 2.2755, Training time: 22436.3452\n",
      "Epoch : 1936/2000 data_batch_5,  Train_loss : 4538.1816  Test_loss : 4768.5586, Time/batch_file : 2.2901, Training time: 22438.6354\n",
      "Epoch : 1937/2000 data_batch_1,  Train_loss : 5034.1855  Test_loss : 5316.4727, Time/batch_file : 2.2782, Training time: 22440.9138\n",
      "Epoch : 1937/2000 data_batch_2,  Train_loss : 4802.3350  Test_loss : 5421.7266, Time/batch_file : 2.2844, Training time: 22443.1984\n",
      "Epoch : 1937/2000 data_batch_3,  Train_loss : 5132.8257  Test_loss : 5408.5752, Time/batch_file : 2.2767, Training time: 22445.4753\n",
      "Epoch : 1937/2000 data_batch_4,  Train_loss : 5071.9634  Test_loss : 5228.6191, Time/batch_file : 2.2848, Training time: 22447.7602\n",
      "Epoch : 1937/2000 data_batch_5,  Train_loss : 5105.5376  Test_loss : 5394.4209, Time/batch_file : 2.2752, Training time: 22450.0356\n",
      "Epoch : 1938/2000 data_batch_1,  Train_loss : 4946.7061  Test_loss : 4715.1167, Time/batch_file : 2.2903, Training time: 22452.3261\n",
      "Epoch : 1938/2000 data_batch_2,  Train_loss : 4810.3711  Test_loss : 4821.1860, Time/batch_file : 2.2809, Training time: 22454.6073\n",
      "Epoch : 1938/2000 data_batch_3,  Train_loss : 4942.1582  Test_loss : 4830.1909, Time/batch_file : 2.2821, Training time: 22456.8895\n",
      "Epoch : 1938/2000 data_batch_4,  Train_loss : 4696.2261  Test_loss : 4566.6846, Time/batch_file : 2.2830, Training time: 22459.1727\n",
      "Epoch : 1938/2000 data_batch_5,  Train_loss : 4892.6133  Test_loss : 4956.1890, Time/batch_file : 2.2811, Training time: 22461.4540\n",
      "Epoch : 1939/2000 data_batch_1,  Train_loss : 4873.1113  Test_loss : 4801.2700, Time/batch_file : 2.2737, Training time: 22463.7278\n",
      "Epoch : 1939/2000 data_batch_2,  Train_loss : 4666.3237  Test_loss : 4379.2178, Time/batch_file : 2.2792, Training time: 22466.0071\n",
      "Epoch : 1939/2000 data_batch_3,  Train_loss : 4677.6685  Test_loss : 4732.3252, Time/batch_file : 2.2766, Training time: 22468.2839\n",
      "Epoch : 1939/2000 data_batch_4,  Train_loss : 4751.6387  Test_loss : 4572.9590, Time/batch_file : 2.2916, Training time: 22470.5756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1939/2000 data_batch_5,  Train_loss : 4758.7446  Test_loss : 4911.9380, Time/batch_file : 2.2689, Training time: 22472.8448\n",
      "Epoch : 1940/2000 data_batch_1,  Train_loss : 5002.1318  Test_loss : 4679.2212, Time/batch_file : 2.2606, Training time: 22475.1057\n",
      "Epoch : 1940/2000 data_batch_2,  Train_loss : 4969.3652  Test_loss : 4791.1772, Time/batch_file : 2.2592, Training time: 22477.3651\n",
      "Epoch : 1940/2000 data_batch_3,  Train_loss : 4969.4971  Test_loss : 4494.8604, Time/batch_file : 2.2734, Training time: 22479.6387\n",
      "Epoch : 1940/2000 data_batch_4,  Train_loss : 4855.2236  Test_loss : 4556.5664, Time/batch_file : 2.2543, Training time: 22481.8934\n",
      "Epoch : 1940/2000 data_batch_5,  Train_loss : 5033.1572  Test_loss : 4316.0698, Time/batch_file : 2.2734, Training time: 22484.1670\n",
      "[./nets/net-1940.ckpt] SAVED\n",
      "Epoch : 1941/2000 data_batch_1,  Train_loss : 4780.5771  Test_loss : 4649.6230, Time/batch_file : 2.3128, Training time: 22487.7435\n",
      "Epoch : 1941/2000 data_batch_2,  Train_loss : 4589.6260  Test_loss : 4720.8525, Time/batch_file : 2.3019, Training time: 22490.0456\n",
      "Epoch : 1941/2000 data_batch_3,  Train_loss : 4740.2686  Test_loss : 4889.4551, Time/batch_file : 2.2734, Training time: 22492.3193\n",
      "Epoch : 1941/2000 data_batch_4,  Train_loss : 4656.8730  Test_loss : 4788.0181, Time/batch_file : 2.3013, Training time: 22494.6207\n",
      "Epoch : 1941/2000 data_batch_5,  Train_loss : 4612.4170  Test_loss : 4620.2183, Time/batch_file : 2.2995, Training time: 22496.9205\n",
      "Epoch : 1942/2000 data_batch_1,  Train_loss : 4373.9146  Test_loss : 5013.4580, Time/batch_file : 2.3296, Training time: 22499.2503\n",
      "Epoch : 1942/2000 data_batch_2,  Train_loss : 4428.0791  Test_loss : 4731.6123, Time/batch_file : 2.3037, Training time: 22501.5541\n",
      "Epoch : 1942/2000 data_batch_3,  Train_loss : 4367.5605  Test_loss : 4855.3018, Time/batch_file : 2.2765, Training time: 22503.8308\n",
      "Epoch : 1942/2000 data_batch_4,  Train_loss : 4432.3657  Test_loss : 4763.2690, Time/batch_file : 2.3137, Training time: 22506.1446\n",
      "Epoch : 1942/2000 data_batch_5,  Train_loss : 4411.3281  Test_loss : 4736.6938, Time/batch_file : 2.2714, Training time: 22508.4162\n",
      "Epoch : 1943/2000 data_batch_1,  Train_loss : 4515.8555  Test_loss : 4658.3096, Time/batch_file : 2.3163, Training time: 22510.7328\n",
      "Epoch : 1943/2000 data_batch_2,  Train_loss : 4495.1812  Test_loss : 4506.7305, Time/batch_file : 2.2793, Training time: 22513.0123\n",
      "Epoch : 1943/2000 data_batch_3,  Train_loss : 4519.4844  Test_loss : 4778.5762, Time/batch_file : 2.2779, Training time: 22515.2905\n",
      "Epoch : 1943/2000 data_batch_4,  Train_loss : 4297.7300  Test_loss : 4736.6304, Time/batch_file : 2.3004, Training time: 22517.5911\n",
      "Epoch : 1943/2000 data_batch_5,  Train_loss : 4370.4463  Test_loss : 4667.4761, Time/batch_file : 2.2862, Training time: 22519.8775\n",
      "Epoch : 1944/2000 data_batch_1,  Train_loss : 4785.8604  Test_loss : 4435.0762, Time/batch_file : 2.3204, Training time: 22522.1982\n",
      "Epoch : 1944/2000 data_batch_2,  Train_loss : 4788.8389  Test_loss : 4663.1577, Time/batch_file : 2.3127, Training time: 22524.5112\n",
      "Epoch : 1944/2000 data_batch_3,  Train_loss : 4700.6748  Test_loss : 4405.8857, Time/batch_file : 2.2956, Training time: 22526.8069\n",
      "Epoch : 1944/2000 data_batch_4,  Train_loss : 4874.8408  Test_loss : 4398.6807, Time/batch_file : 2.2944, Training time: 22529.1014\n",
      "Epoch : 1944/2000 data_batch_5,  Train_loss : 4747.0415  Test_loss : 4383.4844, Time/batch_file : 2.2931, Training time: 22531.3948\n",
      "Epoch : 1945/2000 data_batch_1,  Train_loss : 4283.6353  Test_loss : 4710.4131, Time/batch_file : 2.2810, Training time: 22533.6761\n",
      "Epoch : 1945/2000 data_batch_2,  Train_loss : 4027.3145  Test_loss : 4840.5625, Time/batch_file : 2.2917, Training time: 22535.9678\n",
      "Epoch : 1945/2000 data_batch_3,  Train_loss : 4168.7959  Test_loss : 4884.5918, Time/batch_file : 2.2611, Training time: 22538.2291\n",
      "Epoch : 1945/2000 data_batch_4,  Train_loss : 4186.7642  Test_loss : 4818.6401, Time/batch_file : 2.2931, Training time: 22540.5224\n",
      "Epoch : 1945/2000 data_batch_5,  Train_loss : 4293.3999  Test_loss : 4836.5347, Time/batch_file : 2.2763, Training time: 22542.7989\n",
      "Epoch : 1946/2000 data_batch_1,  Train_loss : 4038.7129  Test_loss : 4829.0684, Time/batch_file : 2.2810, Training time: 22545.0800\n",
      "Epoch : 1946/2000 data_batch_2,  Train_loss : 4289.1953  Test_loss : 4540.8853, Time/batch_file : 2.2865, Training time: 22547.3666\n",
      "Epoch : 1946/2000 data_batch_3,  Train_loss : 4280.0938  Test_loss : 4737.4380, Time/batch_file : 2.2778, Training time: 22549.6446\n",
      "Epoch : 1946/2000 data_batch_4,  Train_loss : 4512.0312  Test_loss : 4613.6084, Time/batch_file : 2.2727, Training time: 22551.9175\n",
      "Epoch : 1946/2000 data_batch_5,  Train_loss : 3949.1777  Test_loss : 4643.8965, Time/batch_file : 2.2940, Training time: 22554.2116\n",
      "Epoch : 1947/2000 data_batch_1,  Train_loss : 4893.9512  Test_loss : 4593.9199, Time/batch_file : 2.2760, Training time: 22556.4880\n",
      "Epoch : 1947/2000 data_batch_2,  Train_loss : 4647.6348  Test_loss : 4490.0566, Time/batch_file : 2.2884, Training time: 22558.7765\n",
      "Epoch : 1947/2000 data_batch_3,  Train_loss : 4923.4238  Test_loss : 4441.5342, Time/batch_file : 2.2804, Training time: 22561.0570\n",
      "Epoch : 1947/2000 data_batch_4,  Train_loss : 4844.8193  Test_loss : 4452.5771, Time/batch_file : 2.2919, Training time: 22563.3492\n",
      "Epoch : 1947/2000 data_batch_5,  Train_loss : 4825.8140  Test_loss : 4500.2207, Time/batch_file : 2.2852, Training time: 22565.6346\n",
      "Epoch : 1948/2000 data_batch_1,  Train_loss : 4363.2207  Test_loss : 5073.5869, Time/batch_file : 2.2816, Training time: 22567.9163\n",
      "Epoch : 1948/2000 data_batch_2,  Train_loss : 4207.3169  Test_loss : 5063.9653, Time/batch_file : 2.2879, Training time: 22570.2044\n",
      "Epoch : 1948/2000 data_batch_3,  Train_loss : 4160.7480  Test_loss : 4943.3770, Time/batch_file : 2.3034, Training time: 22572.5080\n",
      "Epoch : 1948/2000 data_batch_4,  Train_loss : 4277.2085  Test_loss : 5275.2949, Time/batch_file : 2.2710, Training time: 22574.7793\n",
      "Epoch : 1948/2000 data_batch_5,  Train_loss : 4178.4980  Test_loss : 5065.3496, Time/batch_file : 2.2906, Training time: 22577.0700\n",
      "Epoch : 1949/2000 data_batch_1,  Train_loss : 4926.7808  Test_loss : 5247.4717, Time/batch_file : 2.2640, Training time: 22579.3342\n",
      "Epoch : 1949/2000 data_batch_2,  Train_loss : 5038.5669  Test_loss : 5299.0962, Time/batch_file : 2.2810, Training time: 22581.6154\n",
      "Epoch : 1949/2000 data_batch_3,  Train_loss : 4710.0586  Test_loss : 5272.6396, Time/batch_file : 2.2758, Training time: 22583.8914\n",
      "Epoch : 1949/2000 data_batch_4,  Train_loss : 4728.9629  Test_loss : 5346.6064, Time/batch_file : 2.2704, Training time: 22586.1621\n",
      "Epoch : 1949/2000 data_batch_5,  Train_loss : 4851.1084  Test_loss : 5360.9526, Time/batch_file : 2.2620, Training time: 22588.4244\n",
      "Epoch : 1950/2000 data_batch_1,  Train_loss : 3908.0796  Test_loss : 5087.6343, Time/batch_file : 2.3019, Training time: 22590.7266\n",
      "Epoch : 1950/2000 data_batch_2,  Train_loss : 3650.3508  Test_loss : 4782.8433, Time/batch_file : 2.2777, Training time: 22593.0045\n",
      "Epoch : 1950/2000 data_batch_3,  Train_loss : 3889.0322  Test_loss : 5135.0938, Time/batch_file : 2.2840, Training time: 22595.2887\n",
      "Epoch : 1950/2000 data_batch_4,  Train_loss : 3777.6680  Test_loss : 4931.8467, Time/batch_file : 2.2828, Training time: 22597.5717\n",
      "Epoch : 1950/2000 data_batch_5,  Train_loss : 3657.6270  Test_loss : 5125.2754, Time/batch_file : 2.2915, Training time: 22599.8634\n",
      "[./nets/net-1950.ckpt] SAVED\n",
      "Epoch : 1951/2000 data_batch_1,  Train_loss : 4281.1260  Test_loss : 5040.8374, Time/batch_file : 2.3663, Training time: 22603.5105\n",
      "Epoch : 1951/2000 data_batch_2,  Train_loss : 4299.9229  Test_loss : 4963.5894, Time/batch_file : 2.2752, Training time: 22605.7859\n",
      "Epoch : 1951/2000 data_batch_3,  Train_loss : 4086.8147  Test_loss : 5099.8525, Time/batch_file : 2.2855, Training time: 22608.0716\n",
      "Epoch : 1951/2000 data_batch_4,  Train_loss : 4207.4111  Test_loss : 4893.8984, Time/batch_file : 2.2689, Training time: 22610.3408\n",
      "Epoch : 1951/2000 data_batch_5,  Train_loss : 4390.1914  Test_loss : 4899.8530, Time/batch_file : 2.2908, Training time: 22612.6318\n",
      "Epoch : 1952/2000 data_batch_1,  Train_loss : 4678.8740  Test_loss : 4959.2759, Time/batch_file : 2.2798, Training time: 22614.9118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1952/2000 data_batch_2,  Train_loss : 4545.1846  Test_loss : 5093.4238, Time/batch_file : 2.2950, Training time: 22617.2071\n",
      "Epoch : 1952/2000 data_batch_3,  Train_loss : 4605.8823  Test_loss : 4714.2129, Time/batch_file : 2.3088, Training time: 22619.5161\n",
      "Epoch : 1952/2000 data_batch_4,  Train_loss : 4775.1514  Test_loss : 4795.5386, Time/batch_file : 2.2911, Training time: 22621.8075\n",
      "Epoch : 1952/2000 data_batch_5,  Train_loss : 4509.6172  Test_loss : 4792.5986, Time/batch_file : 2.2739, Training time: 22624.0816\n",
      "Epoch : 1953/2000 data_batch_1,  Train_loss : 4834.3760  Test_loss : 4590.8369, Time/batch_file : 2.2960, Training time: 22626.3779\n",
      "Epoch : 1953/2000 data_batch_2,  Train_loss : 4550.7271  Test_loss : 4521.7222, Time/batch_file : 2.2743, Training time: 22628.6524\n",
      "Epoch : 1953/2000 data_batch_3,  Train_loss : 4880.3809  Test_loss : 4738.2871, Time/batch_file : 2.2973, Training time: 22630.9498\n",
      "Epoch : 1953/2000 data_batch_4,  Train_loss : 4781.4111  Test_loss : 4758.6211, Time/batch_file : 2.2779, Training time: 22633.2279\n",
      "Epoch : 1953/2000 data_batch_5,  Train_loss : 4927.4805  Test_loss : 4495.6108, Time/batch_file : 2.3093, Training time: 22635.5375\n",
      "Epoch : 1954/2000 data_batch_1,  Train_loss : 4465.8340  Test_loss : 4786.4141, Time/batch_file : 2.2788, Training time: 22637.8165\n",
      "Epoch : 1954/2000 data_batch_2,  Train_loss : 4339.3257  Test_loss : 4892.7456, Time/batch_file : 2.2985, Training time: 22640.1152\n",
      "Epoch : 1954/2000 data_batch_3,  Train_loss : 4642.8896  Test_loss : 4601.9253, Time/batch_file : 2.2836, Training time: 22642.3990\n",
      "Epoch : 1954/2000 data_batch_4,  Train_loss : 4437.0703  Test_loss : 4689.5996, Time/batch_file : 2.2960, Training time: 22644.6952\n",
      "Epoch : 1954/2000 data_batch_5,  Train_loss : 4122.5640  Test_loss : 4791.0400, Time/batch_file : 2.2794, Training time: 22646.9747\n",
      "Epoch : 1955/2000 data_batch_1,  Train_loss : 4590.9023  Test_loss : 4716.4653, Time/batch_file : 2.3093, Training time: 22649.2841\n",
      "Epoch : 1955/2000 data_batch_2,  Train_loss : 4630.9648  Test_loss : 4937.4253, Time/batch_file : 2.2853, Training time: 22651.5696\n",
      "Epoch : 1955/2000 data_batch_3,  Train_loss : 4575.4209  Test_loss : 4681.9814, Time/batch_file : 2.3085, Training time: 22653.8783\n",
      "Epoch : 1955/2000 data_batch_4,  Train_loss : 4547.3296  Test_loss : 4556.8887, Time/batch_file : 2.2767, Training time: 22656.1552\n",
      "Epoch : 1955/2000 data_batch_5,  Train_loss : 4456.9990  Test_loss : 4754.5088, Time/batch_file : 2.2931, Training time: 22658.4486\n",
      "Epoch : 1956/2000 data_batch_1,  Train_loss : 4924.9326  Test_loss : 4575.7358, Time/batch_file : 2.2720, Training time: 22660.7208\n",
      "Epoch : 1956/2000 data_batch_2,  Train_loss : 4879.3198  Test_loss : 4683.1440, Time/batch_file : 2.3114, Training time: 22663.0324\n",
      "Epoch : 1956/2000 data_batch_3,  Train_loss : 4689.4541  Test_loss : 4576.9575, Time/batch_file : 2.2728, Training time: 22665.3054\n",
      "Epoch : 1956/2000 data_batch_4,  Train_loss : 4696.4570  Test_loss : 4664.9438, Time/batch_file : 2.2918, Training time: 22667.5974\n",
      "Epoch : 1956/2000 data_batch_5,  Train_loss : 4848.0293  Test_loss : 4460.6821, Time/batch_file : 2.2704, Training time: 22669.8680\n",
      "Epoch : 1957/2000 data_batch_1,  Train_loss : 4467.6040  Test_loss : 4533.3970, Time/batch_file : 2.2887, Training time: 22672.1570\n",
      "Epoch : 1957/2000 data_batch_2,  Train_loss : 4599.7944  Test_loss : 4663.7837, Time/batch_file : 2.2616, Training time: 22674.4188\n",
      "Epoch : 1957/2000 data_batch_3,  Train_loss : 4428.8379  Test_loss : 4597.8564, Time/batch_file : 2.2842, Training time: 22676.7033\n",
      "Epoch : 1957/2000 data_batch_4,  Train_loss : 4443.5884  Test_loss : 4845.0522, Time/batch_file : 2.2602, Training time: 22678.9635\n",
      "Epoch : 1957/2000 data_batch_5,  Train_loss : 4326.6748  Test_loss : 4493.9736, Time/batch_file : 2.2880, Training time: 22681.2517\n",
      "Epoch : 1958/2000 data_batch_1,  Train_loss : 4098.7705  Test_loss : 5129.8149, Time/batch_file : 2.2797, Training time: 22683.5316\n",
      "Epoch : 1958/2000 data_batch_2,  Train_loss : 4540.6001  Test_loss : 4974.1460, Time/batch_file : 2.3162, Training time: 22685.8481\n",
      "Epoch : 1958/2000 data_batch_3,  Train_loss : 4288.8716  Test_loss : 5161.8584, Time/batch_file : 2.2757, Training time: 22688.1240\n",
      "Epoch : 1958/2000 data_batch_4,  Train_loss : 3931.2534  Test_loss : 5146.5132, Time/batch_file : 2.2916, Training time: 22690.4158\n",
      "Epoch : 1958/2000 data_batch_5,  Train_loss : 4302.3535  Test_loss : 5154.5269, Time/batch_file : 2.2789, Training time: 22692.6949\n",
      "Epoch : 1959/2000 data_batch_1,  Train_loss : 4595.6924  Test_loss : 4959.7524, Time/batch_file : 2.2908, Training time: 22694.9858\n",
      "Epoch : 1959/2000 data_batch_2,  Train_loss : 4677.6729  Test_loss : 5175.9604, Time/batch_file : 2.2730, Training time: 22697.2590\n",
      "Epoch : 1959/2000 data_batch_3,  Train_loss : 4692.3662  Test_loss : 5255.8936, Time/batch_file : 2.2910, Training time: 22699.5503\n",
      "Epoch : 1959/2000 data_batch_4,  Train_loss : 4541.9087  Test_loss : 5127.9741, Time/batch_file : 2.2726, Training time: 22701.8231\n",
      "Epoch : 1959/2000 data_batch_5,  Train_loss : 4454.2471  Test_loss : 5219.3525, Time/batch_file : 2.2901, Training time: 22704.1134\n",
      "Epoch : 1960/2000 data_batch_1,  Train_loss : 4619.5010  Test_loss : 4408.0581, Time/batch_file : 2.2669, Training time: 22706.3805\n",
      "Epoch : 1960/2000 data_batch_2,  Train_loss : 4557.6958  Test_loss : 4456.2471, Time/batch_file : 2.2971, Training time: 22708.6778\n",
      "Epoch : 1960/2000 data_batch_3,  Train_loss : 4731.8833  Test_loss : 4437.8086, Time/batch_file : 2.2776, Training time: 22710.9556\n",
      "Epoch : 1960/2000 data_batch_4,  Train_loss : 4724.1558  Test_loss : 4506.2651, Time/batch_file : 2.2887, Training time: 22713.2445\n",
      "Epoch : 1960/2000 data_batch_5,  Train_loss : 4843.7783  Test_loss : 4390.0923, Time/batch_file : 2.2669, Training time: 22715.5115\n",
      "[./nets/net-1960.ckpt] SAVED\n",
      "Epoch : 1961/2000 data_batch_1,  Train_loss : 4149.5122  Test_loss : 4508.5010, Time/batch_file : 2.6487, Training time: 22719.4698\n",
      "Epoch : 1961/2000 data_batch_2,  Train_loss : 4190.9907  Test_loss : 4880.8955, Time/batch_file : 2.2940, Training time: 22721.7640\n",
      "Epoch : 1961/2000 data_batch_3,  Train_loss : 4269.7227  Test_loss : 5117.8525, Time/batch_file : 2.2888, Training time: 22724.0531\n",
      "Epoch : 1961/2000 data_batch_4,  Train_loss : 4222.3755  Test_loss : 4891.4058, Time/batch_file : 2.2826, Training time: 22726.3359\n",
      "Epoch : 1961/2000 data_batch_5,  Train_loss : 4278.3330  Test_loss : 4864.9570, Time/batch_file : 2.2789, Training time: 22728.6152\n",
      "Epoch : 1962/2000 data_batch_1,  Train_loss : 4841.8247  Test_loss : 4355.2793, Time/batch_file : 2.2829, Training time: 22730.8983\n",
      "Epoch : 1962/2000 data_batch_2,  Train_loss : 4856.1436  Test_loss : 4182.8970, Time/batch_file : 2.2880, Training time: 22733.1866\n",
      "Epoch : 1962/2000 data_batch_3,  Train_loss : 4703.9175  Test_loss : 4275.5977, Time/batch_file : 2.2678, Training time: 22735.4546\n",
      "Epoch : 1962/2000 data_batch_4,  Train_loss : 4685.3936  Test_loss : 4366.1514, Time/batch_file : 2.2697, Training time: 22737.7245\n",
      "Epoch : 1962/2000 data_batch_5,  Train_loss : 5023.4697  Test_loss : 4331.6504, Time/batch_file : 2.3154, Training time: 22740.0401\n",
      "Epoch : 1963/2000 data_batch_1,  Train_loss : 4485.1465  Test_loss : 4819.4956, Time/batch_file : 2.2770, Training time: 22742.3173\n",
      "Epoch : 1963/2000 data_batch_2,  Train_loss : 4512.4268  Test_loss : 5009.8545, Time/batch_file : 2.2903, Training time: 22744.6079\n",
      "Epoch : 1963/2000 data_batch_3,  Train_loss : 4646.1465  Test_loss : 5164.7241, Time/batch_file : 2.2887, Training time: 22746.8968\n",
      "Epoch : 1963/2000 data_batch_4,  Train_loss : 4310.6094  Test_loss : 4999.3511, Time/batch_file : 2.2632, Training time: 22749.1603\n",
      "Epoch : 1963/2000 data_batch_5,  Train_loss : 4384.9917  Test_loss : 5165.5957, Time/batch_file : 2.2859, Training time: 22751.4465\n",
      "Epoch : 1964/2000 data_batch_1,  Train_loss : 4486.5088  Test_loss : 4706.2993, Time/batch_file : 2.2818, Training time: 22753.7285\n",
      "Epoch : 1964/2000 data_batch_2,  Train_loss : 4512.5791  Test_loss : 4639.1387, Time/batch_file : 2.2888, Training time: 22756.0174\n",
      "Epoch : 1964/2000 data_batch_3,  Train_loss : 4610.8066  Test_loss : 4588.0186, Time/batch_file : 2.2961, Training time: 22758.3137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1964/2000 data_batch_4,  Train_loss : 4382.6255  Test_loss : 4679.1816, Time/batch_file : 2.2874, Training time: 22760.6013\n",
      "Epoch : 1964/2000 data_batch_5,  Train_loss : 4570.2036  Test_loss : 4711.0220, Time/batch_file : 2.3000, Training time: 22762.9015\n",
      "Epoch : 1965/2000 data_batch_1,  Train_loss : 4665.5190  Test_loss : 4869.8257, Time/batch_file : 2.2729, Training time: 22765.1746\n",
      "Epoch : 1965/2000 data_batch_2,  Train_loss : 4454.2734  Test_loss : 4890.3423, Time/batch_file : 2.2649, Training time: 22767.4397\n",
      "Epoch : 1965/2000 data_batch_3,  Train_loss : 4655.3037  Test_loss : 4796.9717, Time/batch_file : 2.3003, Training time: 22769.7402\n",
      "Epoch : 1965/2000 data_batch_4,  Train_loss : 4442.8188  Test_loss : 4957.5601, Time/batch_file : 2.2709, Training time: 22772.0115\n",
      "Epoch : 1965/2000 data_batch_5,  Train_loss : 4643.7891  Test_loss : 4736.1162, Time/batch_file : 2.2921, Training time: 22774.3038\n",
      "Epoch : 1966/2000 data_batch_1,  Train_loss : 4557.5142  Test_loss : 5359.4771, Time/batch_file : 2.2752, Training time: 22776.5792\n",
      "Epoch : 1966/2000 data_batch_2,  Train_loss : 4480.2007  Test_loss : 5097.3442, Time/batch_file : 2.2940, Training time: 22778.8734\n",
      "Epoch : 1966/2000 data_batch_3,  Train_loss : 4321.4463  Test_loss : 5006.7632, Time/batch_file : 2.2837, Training time: 22781.1573\n",
      "Epoch : 1966/2000 data_batch_4,  Train_loss : 4426.4507  Test_loss : 5043.7402, Time/batch_file : 2.2813, Training time: 22783.4387\n",
      "Epoch : 1966/2000 data_batch_5,  Train_loss : 4335.7983  Test_loss : 4874.6035, Time/batch_file : 2.2685, Training time: 22785.7074\n",
      "Epoch : 1967/2000 data_batch_1,  Train_loss : 4709.8823  Test_loss : 4774.9717, Time/batch_file : 2.2906, Training time: 22787.9983\n",
      "Epoch : 1967/2000 data_batch_2,  Train_loss : 4828.8794  Test_loss : 4918.3184, Time/batch_file : 2.2921, Training time: 22790.2906\n",
      "Epoch : 1967/2000 data_batch_3,  Train_loss : 4566.8096  Test_loss : 4754.7754, Time/batch_file : 2.2897, Training time: 22792.5804\n",
      "Epoch : 1967/2000 data_batch_4,  Train_loss : 4546.3462  Test_loss : 4808.0596, Time/batch_file : 2.2852, Training time: 22794.8658\n",
      "Epoch : 1967/2000 data_batch_5,  Train_loss : 4537.2217  Test_loss : 4781.9019, Time/batch_file : 2.2825, Training time: 22797.1485\n",
      "Epoch : 1968/2000 data_batch_1,  Train_loss : 5058.7007  Test_loss : 5037.5415, Time/batch_file : 2.2959, Training time: 22799.4446\n",
      "Epoch : 1968/2000 data_batch_2,  Train_loss : 4904.2393  Test_loss : 5403.9844, Time/batch_file : 2.2870, Training time: 22801.7318\n",
      "Epoch : 1968/2000 data_batch_3,  Train_loss : 5080.4854  Test_loss : 5474.3765, Time/batch_file : 2.2748, Training time: 22804.0067\n",
      "Epoch : 1968/2000 data_batch_4,  Train_loss : 4811.3657  Test_loss : 5098.1377, Time/batch_file : 2.3014, Training time: 22806.3084\n",
      "Epoch : 1968/2000 data_batch_5,  Train_loss : 4769.0166  Test_loss : 5022.3340, Time/batch_file : 2.2806, Training time: 22808.5892\n",
      "Epoch : 1969/2000 data_batch_1,  Train_loss : 4463.0928  Test_loss : 4650.7119, Time/batch_file : 2.2824, Training time: 22810.8719\n",
      "Epoch : 1969/2000 data_batch_2,  Train_loss : 4548.6826  Test_loss : 4747.5293, Time/batch_file : 2.2726, Training time: 22813.1447\n",
      "Epoch : 1969/2000 data_batch_3,  Train_loss : 4242.0132  Test_loss : 4523.1953, Time/batch_file : 2.2811, Training time: 22815.4260\n",
      "Epoch : 1969/2000 data_batch_4,  Train_loss : 4203.0151  Test_loss : 4734.9775, Time/batch_file : 2.2613, Training time: 22817.6875\n",
      "Epoch : 1969/2000 data_batch_5,  Train_loss : 4483.5273  Test_loss : 4683.3076, Time/batch_file : 2.3095, Training time: 22819.9971\n",
      "Epoch : 1970/2000 data_batch_1,  Train_loss : 4279.2417  Test_loss : 4185.6338, Time/batch_file : 2.3044, Training time: 22822.3017\n",
      "Epoch : 1970/2000 data_batch_2,  Train_loss : 4351.5371  Test_loss : 4426.7368, Time/batch_file : 2.2649, Training time: 22824.5668\n",
      "Epoch : 1970/2000 data_batch_3,  Train_loss : 4463.2471  Test_loss : 4457.1416, Time/batch_file : 2.2886, Training time: 22826.8555\n",
      "Epoch : 1970/2000 data_batch_4,  Train_loss : 4347.1992  Test_loss : 4186.5479, Time/batch_file : 2.2857, Training time: 22829.1414\n",
      "Epoch : 1970/2000 data_batch_5,  Train_loss : 4292.1201  Test_loss : 4469.2495, Time/batch_file : 2.2697, Training time: 22831.4112\n",
      "[./nets/net-1970.ckpt] SAVED\n",
      "Epoch : 1971/2000 data_batch_1,  Train_loss : 4877.8257  Test_loss : 4707.1328, Time/batch_file : 2.3139, Training time: 22835.0462\n",
      "Epoch : 1971/2000 data_batch_2,  Train_loss : 4958.9810  Test_loss : 4898.7725, Time/batch_file : 2.3007, Training time: 22837.3471\n",
      "Epoch : 1971/2000 data_batch_3,  Train_loss : 4936.0723  Test_loss : 4562.9409, Time/batch_file : 2.3329, Training time: 22839.6803\n",
      "Epoch : 1971/2000 data_batch_4,  Train_loss : 5112.7451  Test_loss : 4564.0464, Time/batch_file : 2.2971, Training time: 22841.9776\n",
      "Epoch : 1971/2000 data_batch_5,  Train_loss : 4934.4829  Test_loss : 4799.2212, Time/batch_file : 2.2822, Training time: 22844.2600\n",
      "Epoch : 1972/2000 data_batch_1,  Train_loss : 5195.8926  Test_loss : 4961.6260, Time/batch_file : 2.2958, Training time: 22846.5561\n",
      "Epoch : 1972/2000 data_batch_2,  Train_loss : 5285.7324  Test_loss : 4866.7632, Time/batch_file : 2.2720, Training time: 22848.8283\n",
      "Epoch : 1972/2000 data_batch_3,  Train_loss : 5054.3906  Test_loss : 5182.0747, Time/batch_file : 2.3019, Training time: 22851.1304\n",
      "Epoch : 1972/2000 data_batch_4,  Train_loss : 5209.2549  Test_loss : 4986.4487, Time/batch_file : 2.3037, Training time: 22853.4343\n",
      "Epoch : 1972/2000 data_batch_5,  Train_loss : 5242.1304  Test_loss : 4823.6899, Time/batch_file : 2.2669, Training time: 22855.7015\n",
      "Epoch : 1973/2000 data_batch_1,  Train_loss : 4709.2261  Test_loss : 4750.6689, Time/batch_file : 2.3033, Training time: 22858.0050\n",
      "Epoch : 1973/2000 data_batch_2,  Train_loss : 4747.2891  Test_loss : 4853.0161, Time/batch_file : 2.3004, Training time: 22860.3056\n",
      "Epoch : 1973/2000 data_batch_3,  Train_loss : 4568.3213  Test_loss : 4754.0137, Time/batch_file : 2.2995, Training time: 22862.6053\n",
      "Epoch : 1973/2000 data_batch_4,  Train_loss : 4551.9863  Test_loss : 4586.5879, Time/batch_file : 2.3048, Training time: 22864.9103\n",
      "Epoch : 1973/2000 data_batch_5,  Train_loss : 4723.2891  Test_loss : 4527.0801, Time/batch_file : 2.2829, Training time: 22867.1934\n",
      "Epoch : 1974/2000 data_batch_1,  Train_loss : 4443.2998  Test_loss : 4931.0400, Time/batch_file : 2.2878, Training time: 22869.4815\n",
      "Epoch : 1974/2000 data_batch_2,  Train_loss : 4393.0576  Test_loss : 4971.7549, Time/batch_file : 2.2843, Training time: 22871.7660\n",
      "Epoch : 1974/2000 data_batch_3,  Train_loss : 4343.1475  Test_loss : 4730.4062, Time/batch_file : 2.3124, Training time: 22874.0786\n",
      "Epoch : 1974/2000 data_batch_4,  Train_loss : 4172.5176  Test_loss : 5107.2671, Time/batch_file : 2.3084, Training time: 22876.4071\n",
      "Epoch : 1974/2000 data_batch_5,  Train_loss : 4246.1621  Test_loss : 5004.6895, Time/batch_file : 2.2838, Training time: 22878.6911\n",
      "Epoch : 1975/2000 data_batch_1,  Train_loss : 3922.3823  Test_loss : 4272.7012, Time/batch_file : 2.3087, Training time: 22880.9999\n",
      "Epoch : 1975/2000 data_batch_2,  Train_loss : 4130.9697  Test_loss : 4418.7466, Time/batch_file : 2.2707, Training time: 22883.2707\n",
      "Epoch : 1975/2000 data_batch_3,  Train_loss : 4295.8223  Test_loss : 4362.4102, Time/batch_file : 2.2944, Training time: 22885.5653\n",
      "Epoch : 1975/2000 data_batch_4,  Train_loss : 4040.2090  Test_loss : 4349.0371, Time/batch_file : 2.2822, Training time: 22887.8477\n",
      "Epoch : 1975/2000 data_batch_5,  Train_loss : 3975.4761  Test_loss : 4226.6562, Time/batch_file : 2.2704, Training time: 22890.1183\n",
      "Epoch : 1976/2000 data_batch_1,  Train_loss : 4794.3594  Test_loss : 4875.1226, Time/batch_file : 2.2902, Training time: 22892.4086\n",
      "Epoch : 1976/2000 data_batch_2,  Train_loss : 4777.8164  Test_loss : 4776.8716, Time/batch_file : 2.2877, Training time: 22894.6965\n",
      "Epoch : 1976/2000 data_batch_3,  Train_loss : 4774.5137  Test_loss : 4958.4302, Time/batch_file : 2.3099, Training time: 22897.0066\n",
      "Epoch : 1976/2000 data_batch_4,  Train_loss : 4729.5371  Test_loss : 5141.3911, Time/batch_file : 2.3081, Training time: 22899.3150\n",
      "Epoch : 1976/2000 data_batch_5,  Train_loss : 5066.6113  Test_loss : 5124.0352, Time/batch_file : 2.2940, Training time: 22901.6091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1977/2000 data_batch_1,  Train_loss : 4139.3369  Test_loss : 4843.0415, Time/batch_file : 2.3007, Training time: 22903.9100\n",
      "Epoch : 1977/2000 data_batch_2,  Train_loss : 4351.5664  Test_loss : 4907.6582, Time/batch_file : 2.2546, Training time: 22906.1649\n",
      "Epoch : 1977/2000 data_batch_3,  Train_loss : 4313.5308  Test_loss : 4695.6177, Time/batch_file : 2.2916, Training time: 22908.4567\n",
      "Epoch : 1977/2000 data_batch_4,  Train_loss : 4400.3101  Test_loss : 4658.8447, Time/batch_file : 2.2909, Training time: 22910.7478\n",
      "Epoch : 1977/2000 data_batch_5,  Train_loss : 4386.0049  Test_loss : 4788.7402, Time/batch_file : 2.2657, Training time: 22913.0136\n",
      "Epoch : 1978/2000 data_batch_1,  Train_loss : 4678.4941  Test_loss : 4604.2490, Time/batch_file : 2.2930, Training time: 22915.3068\n",
      "Epoch : 1978/2000 data_batch_2,  Train_loss : 4832.2974  Test_loss : 4641.9316, Time/batch_file : 2.2888, Training time: 22917.5957\n",
      "Epoch : 1978/2000 data_batch_3,  Train_loss : 4658.5742  Test_loss : 4970.6167, Time/batch_file : 2.3071, Training time: 22919.9031\n",
      "Epoch : 1978/2000 data_batch_4,  Train_loss : 4736.5938  Test_loss : 4712.6406, Time/batch_file : 2.2858, Training time: 22922.1891\n",
      "Epoch : 1978/2000 data_batch_5,  Train_loss : 4310.1812  Test_loss : 4985.8428, Time/batch_file : 2.2928, Training time: 22924.4820\n",
      "Epoch : 1979/2000 data_batch_1,  Train_loss : 4571.2148  Test_loss : 4840.2549, Time/batch_file : 2.3005, Training time: 22926.7829\n",
      "Epoch : 1979/2000 data_batch_2,  Train_loss : 4410.8643  Test_loss : 4829.9497, Time/batch_file : 2.2703, Training time: 22929.0534\n",
      "Epoch : 1979/2000 data_batch_3,  Train_loss : 4720.0615  Test_loss : 4978.1470, Time/batch_file : 2.3008, Training time: 22931.3545\n",
      "Epoch : 1979/2000 data_batch_4,  Train_loss : 4865.1812  Test_loss : 4745.1826, Time/batch_file : 2.3093, Training time: 22933.6639\n",
      "Epoch : 1979/2000 data_batch_5,  Train_loss : 4630.8794  Test_loss : 4704.6572, Time/batch_file : 2.2965, Training time: 22935.9606\n",
      "Epoch : 1980/2000 data_batch_1,  Train_loss : 4061.8154  Test_loss : 4698.9614, Time/batch_file : 2.2683, Training time: 22938.2291\n",
      "Epoch : 1980/2000 data_batch_2,  Train_loss : 4535.1606  Test_loss : 4520.1807, Time/batch_file : 2.2850, Training time: 22940.5144\n",
      "Epoch : 1980/2000 data_batch_3,  Train_loss : 4552.1299  Test_loss : 4502.9248, Time/batch_file : 2.2910, Training time: 22942.8056\n",
      "Epoch : 1980/2000 data_batch_4,  Train_loss : 4250.2056  Test_loss : 4672.9658, Time/batch_file : 2.2927, Training time: 22945.0985\n",
      "Epoch : 1980/2000 data_batch_5,  Train_loss : 4431.0234  Test_loss : 4741.6953, Time/batch_file : 2.2761, Training time: 22947.3747\n",
      "[./nets/net-1980.ckpt] SAVED\n",
      "Epoch : 1981/2000 data_batch_1,  Train_loss : 4649.5137  Test_loss : 5263.5068, Time/batch_file : 2.3974, Training time: 22951.0412\n",
      "Epoch : 1981/2000 data_batch_2,  Train_loss : 4781.7588  Test_loss : 4755.1704, Time/batch_file : 2.2731, Training time: 22953.3144\n",
      "Epoch : 1981/2000 data_batch_3,  Train_loss : 4897.9497  Test_loss : 4996.4893, Time/batch_file : 2.2944, Training time: 22955.6090\n",
      "Epoch : 1981/2000 data_batch_4,  Train_loss : 4443.5005  Test_loss : 5056.1895, Time/batch_file : 2.2777, Training time: 22957.8869\n",
      "Epoch : 1981/2000 data_batch_5,  Train_loss : 4538.3940  Test_loss : 4872.2915, Time/batch_file : 2.2770, Training time: 22960.1641\n",
      "Epoch : 1982/2000 data_batch_1,  Train_loss : 5030.2500  Test_loss : 4460.1172, Time/batch_file : 2.3095, Training time: 22962.4738\n",
      "Epoch : 1982/2000 data_batch_2,  Train_loss : 4721.3203  Test_loss : 4665.1230, Time/batch_file : 2.2714, Training time: 22964.7455\n",
      "Epoch : 1982/2000 data_batch_3,  Train_loss : 4728.9604  Test_loss : 4347.0708, Time/batch_file : 2.2843, Training time: 22967.0299\n",
      "Epoch : 1982/2000 data_batch_4,  Train_loss : 4852.5869  Test_loss : 4196.6289, Time/batch_file : 2.2871, Training time: 22969.3172\n",
      "Epoch : 1982/2000 data_batch_5,  Train_loss : 4720.2075  Test_loss : 4110.0962, Time/batch_file : 2.2788, Training time: 22971.5963\n",
      "Epoch : 1983/2000 data_batch_1,  Train_loss : 4554.4619  Test_loss : 4236.9482, Time/batch_file : 2.2671, Training time: 22973.8636\n",
      "Epoch : 1983/2000 data_batch_2,  Train_loss : 4491.2446  Test_loss : 4273.5127, Time/batch_file : 2.2840, Training time: 22976.1477\n",
      "Epoch : 1983/2000 data_batch_3,  Train_loss : 4586.6582  Test_loss : 4463.7124, Time/batch_file : 2.3036, Training time: 22978.4516\n",
      "Epoch : 1983/2000 data_batch_4,  Train_loss : 4440.4541  Test_loss : 4249.2178, Time/batch_file : 2.2782, Training time: 22980.7299\n",
      "Epoch : 1983/2000 data_batch_5,  Train_loss : 4465.4316  Test_loss : 4011.7480, Time/batch_file : 2.2557, Training time: 22982.9859\n",
      "Epoch : 1984/2000 data_batch_1,  Train_loss : 4827.5845  Test_loss : 4950.1050, Time/batch_file : 2.2715, Training time: 22985.2576\n",
      "Epoch : 1984/2000 data_batch_2,  Train_loss : 4509.2178  Test_loss : 5120.3774, Time/batch_file : 2.2792, Training time: 22987.5369\n",
      "Epoch : 1984/2000 data_batch_3,  Train_loss : 4526.7344  Test_loss : 4876.3516, Time/batch_file : 2.2895, Training time: 22989.8266\n",
      "Epoch : 1984/2000 data_batch_4,  Train_loss : 4454.2168  Test_loss : 4951.0933, Time/batch_file : 2.2578, Training time: 22992.0846\n",
      "Epoch : 1984/2000 data_batch_5,  Train_loss : 4401.1846  Test_loss : 5014.2432, Time/batch_file : 2.2662, Training time: 22994.3509\n",
      "Epoch : 1985/2000 data_batch_1,  Train_loss : 4280.0732  Test_loss : 4550.9146, Time/batch_file : 2.2721, Training time: 22996.6232\n",
      "Epoch : 1985/2000 data_batch_2,  Train_loss : 4326.8877  Test_loss : 4835.4512, Time/batch_file : 2.2753, Training time: 22998.8987\n",
      "Epoch : 1985/2000 data_batch_3,  Train_loss : 4498.9448  Test_loss : 4907.6377, Time/batch_file : 2.2645, Training time: 23001.1634\n",
      "Epoch : 1985/2000 data_batch_4,  Train_loss : 4412.6870  Test_loss : 5097.6064, Time/batch_file : 2.2747, Training time: 23003.4383\n",
      "Epoch : 1985/2000 data_batch_5,  Train_loss : 4416.5317  Test_loss : 4757.3730, Time/batch_file : 2.2948, Training time: 23005.7334\n",
      "Epoch : 1986/2000 data_batch_1,  Train_loss : 4468.9658  Test_loss : 4993.0332, Time/batch_file : 2.2695, Training time: 23008.0032\n",
      "Epoch : 1986/2000 data_batch_2,  Train_loss : 4447.1587  Test_loss : 4931.2891, Time/batch_file : 2.2618, Training time: 23010.2652\n",
      "Epoch : 1986/2000 data_batch_3,  Train_loss : 4534.4971  Test_loss : 4959.5522, Time/batch_file : 2.2613, Training time: 23012.5267\n",
      "Epoch : 1986/2000 data_batch_4,  Train_loss : 4618.5737  Test_loss : 5095.4043, Time/batch_file : 2.2744, Training time: 23014.8013\n",
      "Epoch : 1986/2000 data_batch_5,  Train_loss : 4508.9878  Test_loss : 4798.3848, Time/batch_file : 2.2792, Training time: 23017.0807\n",
      "Epoch : 1987/2000 data_batch_1,  Train_loss : 4800.8779  Test_loss : 4911.7637, Time/batch_file : 2.2706, Training time: 23019.3515\n",
      "Epoch : 1987/2000 data_batch_2,  Train_loss : 4899.3418  Test_loss : 4863.0752, Time/batch_file : 2.2677, Training time: 23021.6194\n",
      "Epoch : 1987/2000 data_batch_3,  Train_loss : 4785.6050  Test_loss : 4812.7280, Time/batch_file : 2.2610, Training time: 23023.8806\n",
      "Epoch : 1987/2000 data_batch_4,  Train_loss : 4761.6597  Test_loss : 4904.7280, Time/batch_file : 2.2729, Training time: 23026.1537\n",
      "Epoch : 1987/2000 data_batch_5,  Train_loss : 4744.9766  Test_loss : 4833.3945, Time/batch_file : 2.2626, Training time: 23028.4166\n",
      "Epoch : 1988/2000 data_batch_1,  Train_loss : 4101.9668  Test_loss : 4865.0459, Time/batch_file : 2.2796, Training time: 23030.6965\n",
      "Epoch : 1988/2000 data_batch_2,  Train_loss : 4171.1680  Test_loss : 4926.2412, Time/batch_file : 2.2982, Training time: 23032.9949\n",
      "Epoch : 1988/2000 data_batch_3,  Train_loss : 4442.0908  Test_loss : 4897.4912, Time/batch_file : 2.2863, Training time: 23035.2814\n",
      "Epoch : 1988/2000 data_batch_4,  Train_loss : 4199.0195  Test_loss : 4942.2656, Time/batch_file : 2.2888, Training time: 23037.5703\n",
      "Epoch : 1988/2000 data_batch_5,  Train_loss : 4204.6704  Test_loss : 5168.3115, Time/batch_file : 2.2841, Training time: 23039.8546\n",
      "Epoch : 1989/2000 data_batch_1,  Train_loss : 4700.5000  Test_loss : 4910.2217, Time/batch_file : 2.2834, Training time: 23042.1382\n",
      "Epoch : 1989/2000 data_batch_2,  Train_loss : 4843.6724  Test_loss : 4897.7021, Time/batch_file : 2.2892, Training time: 23044.4277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1989/2000 data_batch_3,  Train_loss : 4630.0259  Test_loss : 4778.1011, Time/batch_file : 2.2742, Training time: 23046.7021\n",
      "Epoch : 1989/2000 data_batch_4,  Train_loss : 4663.5933  Test_loss : 5026.6460, Time/batch_file : 2.2800, Training time: 23048.9822\n",
      "Epoch : 1989/2000 data_batch_5,  Train_loss : 4849.1709  Test_loss : 5106.2314, Time/batch_file : 2.2740, Training time: 23051.2565\n",
      "Epoch : 1990/2000 data_batch_1,  Train_loss : 4290.1372  Test_loss : 4711.9043, Time/batch_file : 2.2704, Training time: 23053.5271\n",
      "Epoch : 1990/2000 data_batch_2,  Train_loss : 4511.8813  Test_loss : 4798.8076, Time/batch_file : 2.2537, Training time: 23055.7809\n",
      "Epoch : 1990/2000 data_batch_3,  Train_loss : 4661.7651  Test_loss : 4780.9922, Time/batch_file : 2.2671, Training time: 23058.0482\n",
      "Epoch : 1990/2000 data_batch_4,  Train_loss : 4453.1533  Test_loss : 4625.6592, Time/batch_file : 2.2766, Training time: 23060.3250\n",
      "Epoch : 1990/2000 data_batch_5,  Train_loss : 4541.4731  Test_loss : 5090.1250, Time/batch_file : 2.2621, Training time: 23062.5874\n",
      "[./nets/net-1990.ckpt] SAVED\n",
      "Epoch : 1991/2000 data_batch_1,  Train_loss : 3819.1108  Test_loss : 4646.5146, Time/batch_file : 2.2819, Training time: 23066.1466\n",
      "Epoch : 1991/2000 data_batch_2,  Train_loss : 3808.0315  Test_loss : 4419.0264, Time/batch_file : 2.2667, Training time: 23068.4136\n",
      "Epoch : 1991/2000 data_batch_3,  Train_loss : 4002.9980  Test_loss : 4165.4736, Time/batch_file : 2.2807, Training time: 23070.6945\n",
      "Epoch : 1991/2000 data_batch_4,  Train_loss : 3877.7808  Test_loss : 4699.0132, Time/batch_file : 2.2653, Training time: 23072.9600\n",
      "Epoch : 1991/2000 data_batch_5,  Train_loss : 3906.8835  Test_loss : 4188.7100, Time/batch_file : 2.2881, Training time: 23075.2482\n",
      "Epoch : 1992/2000 data_batch_1,  Train_loss : 4536.2051  Test_loss : 5084.5132, Time/batch_file : 2.2681, Training time: 23077.5164\n",
      "Epoch : 1992/2000 data_batch_2,  Train_loss : 4464.4902  Test_loss : 4997.2427, Time/batch_file : 2.3043, Training time: 23079.8210\n",
      "Epoch : 1992/2000 data_batch_3,  Train_loss : 4444.8257  Test_loss : 4852.6997, Time/batch_file : 2.2792, Training time: 23082.1003\n",
      "Epoch : 1992/2000 data_batch_4,  Train_loss : 4523.8511  Test_loss : 4567.5820, Time/batch_file : 2.2820, Training time: 23084.3826\n",
      "Epoch : 1992/2000 data_batch_5,  Train_loss : 4961.7881  Test_loss : 4774.1318, Time/batch_file : 2.2819, Training time: 23086.6648\n",
      "Epoch : 1993/2000 data_batch_1,  Train_loss : 4742.1484  Test_loss : 4931.2119, Time/batch_file : 2.3066, Training time: 23088.9716\n",
      "Epoch : 1993/2000 data_batch_2,  Train_loss : 4761.7183  Test_loss : 4909.4941, Time/batch_file : 2.2945, Training time: 23091.2662\n",
      "Epoch : 1993/2000 data_batch_3,  Train_loss : 4636.2290  Test_loss : 4818.1099, Time/batch_file : 2.3100, Training time: 23093.5765\n",
      "Epoch : 1993/2000 data_batch_4,  Train_loss : 4654.6025  Test_loss : 4824.9595, Time/batch_file : 2.2858, Training time: 23095.8625\n",
      "Epoch : 1993/2000 data_batch_5,  Train_loss : 4528.9556  Test_loss : 4854.7324, Time/batch_file : 2.3387, Training time: 23098.2013\n",
      "Epoch : 1994/2000 data_batch_1,  Train_loss : 4651.0156  Test_loss : 4874.3237, Time/batch_file : 2.2767, Training time: 23100.4783\n",
      "Epoch : 1994/2000 data_batch_2,  Train_loss : 4573.2393  Test_loss : 4840.3467, Time/batch_file : 2.2843, Training time: 23102.7628\n",
      "Epoch : 1994/2000 data_batch_3,  Train_loss : 4499.1865  Test_loss : 4669.7305, Time/batch_file : 2.2820, Training time: 23105.0450\n",
      "Epoch : 1994/2000 data_batch_4,  Train_loss : 4826.4092  Test_loss : 5022.7021, Time/batch_file : 2.2982, Training time: 23107.3435\n",
      "Epoch : 1994/2000 data_batch_5,  Train_loss : 4642.1973  Test_loss : 5056.8530, Time/batch_file : 2.2801, Training time: 23109.6239\n",
      "Epoch : 1995/2000 data_batch_1,  Train_loss : 4199.6777  Test_loss : 4712.2993, Time/batch_file : 2.2884, Training time: 23111.9124\n",
      "Epoch : 1995/2000 data_batch_2,  Train_loss : 4264.4004  Test_loss : 4452.1982, Time/batch_file : 2.2908, Training time: 23114.2034\n",
      "Epoch : 1995/2000 data_batch_3,  Train_loss : 4078.2441  Test_loss : 4748.2617, Time/batch_file : 2.2881, Training time: 23116.4918\n",
      "Epoch : 1995/2000 data_batch_4,  Train_loss : 4122.7139  Test_loss : 4442.1719, Time/batch_file : 2.3123, Training time: 23118.8044\n",
      "Epoch : 1995/2000 data_batch_5,  Train_loss : 4170.7017  Test_loss : 4498.5659, Time/batch_file : 2.2867, Training time: 23121.0913\n",
      "Epoch : 1996/2000 data_batch_1,  Train_loss : 4162.6602  Test_loss : 4847.1997, Time/batch_file : 2.2925, Training time: 23123.3840\n",
      "Epoch : 1996/2000 data_batch_2,  Train_loss : 3949.0508  Test_loss : 5150.6904, Time/batch_file : 2.2837, Training time: 23125.6677\n",
      "Epoch : 1996/2000 data_batch_3,  Train_loss : 4153.7886  Test_loss : 5251.8535, Time/batch_file : 2.2668, Training time: 23127.9347\n",
      "Epoch : 1996/2000 data_batch_4,  Train_loss : 4031.0261  Test_loss : 5103.9111, Time/batch_file : 2.3016, Training time: 23130.2365\n",
      "Epoch : 1996/2000 data_batch_5,  Train_loss : 4019.8286  Test_loss : 5080.3828, Time/batch_file : 2.2637, Training time: 23132.5004\n",
      "Epoch : 1997/2000 data_batch_1,  Train_loss : 3845.4045  Test_loss : 4738.1846, Time/batch_file : 2.3028, Training time: 23134.8034\n",
      "Epoch : 1997/2000 data_batch_2,  Train_loss : 4151.2163  Test_loss : 4795.6523, Time/batch_file : 2.2697, Training time: 23137.0734\n",
      "Epoch : 1997/2000 data_batch_3,  Train_loss : 3911.9504  Test_loss : 4731.0229, Time/batch_file : 2.2841, Training time: 23139.3577\n",
      "Epoch : 1997/2000 data_batch_4,  Train_loss : 3898.3501  Test_loss : 4867.1631, Time/batch_file : 2.2963, Training time: 23141.6542\n",
      "Epoch : 1997/2000 data_batch_5,  Train_loss : 4077.8271  Test_loss : 5134.5542, Time/batch_file : 2.2680, Training time: 23143.9223\n",
      "Epoch : 1998/2000 data_batch_1,  Train_loss : 4231.0439  Test_loss : 5079.8320, Time/batch_file : 2.2751, Training time: 23146.1976\n",
      "Epoch : 1998/2000 data_batch_2,  Train_loss : 4173.7109  Test_loss : 4689.2197, Time/batch_file : 2.2757, Training time: 23148.4735\n",
      "Epoch : 1998/2000 data_batch_3,  Train_loss : 4482.1011  Test_loss : 4966.2334, Time/batch_file : 2.2854, Training time: 23150.7591\n",
      "Epoch : 1998/2000 data_batch_4,  Train_loss : 4291.4326  Test_loss : 4917.9873, Time/batch_file : 2.2718, Training time: 23153.0312\n",
      "Epoch : 1998/2000 data_batch_5,  Train_loss : 4346.6582  Test_loss : 5100.3643, Time/batch_file : 2.2856, Training time: 23155.3170\n",
      "Epoch : 1999/2000 data_batch_1,  Train_loss : 4787.9365  Test_loss : 4455.9102, Time/batch_file : 2.2950, Training time: 23157.6122\n",
      "Epoch : 1999/2000 data_batch_2,  Train_loss : 4649.6929  Test_loss : 4203.7207, Time/batch_file : 2.3003, Training time: 23159.9127\n",
      "Epoch : 1999/2000 data_batch_3,  Train_loss : 4975.6309  Test_loss : 4293.7524, Time/batch_file : 2.3149, Training time: 23162.2278\n",
      "Epoch : 1999/2000 data_batch_4,  Train_loss : 4918.0762  Test_loss : 4474.4263, Time/batch_file : 2.3004, Training time: 23164.5284\n",
      "Epoch : 1999/2000 data_batch_5,  Train_loss : 4786.4561  Test_loss : 4584.3335, Time/batch_file : 2.2999, Training time: 23166.8285\n",
      "Epoch : 2000/2000 data_batch_1,  Train_loss : 4699.3809  Test_loss : 4776.2896, Time/batch_file : 2.2934, Training time: 23169.1221\n",
      "Epoch : 2000/2000 data_batch_2,  Train_loss : 4721.2441  Test_loss : 4501.1768, Time/batch_file : 2.2856, Training time: 23171.4079\n",
      "Epoch : 2000/2000 data_batch_3,  Train_loss : 4455.2095  Test_loss : 4766.1719, Time/batch_file : 2.2861, Training time: 23173.6942\n",
      "Epoch : 2000/2000 data_batch_4,  Train_loss : 4615.6450  Test_loss : 4766.2314, Time/batch_file : 2.2946, Training time: 23175.9890\n",
      "Epoch : 2000/2000 data_batch_5,  Train_loss : 4623.3428  Test_loss : 4767.7236, Time/batch_file : 2.2896, Training time: 23178.2789\n",
      "[./nets/net-2000.ckpt] SAVED\n",
      "Optimization Finished\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "training_epochs = FLAGS.training_epochs\n",
    "batch_num = FLAGS.batch_num\n",
    "batch_size = FLAGS.batch_size\n",
    "n_total_batch = int(FLAGS.img_num/batch_size)\n",
    "display_step = FLAGS.display_step\n",
    "\n",
    "# Plot\n",
    "n_plot = 5    # plot 5 images\n",
    "cifar10_train_img = read_cifar(FLAGS.test_dir+'/data_batch_1')     # (10000, 3072)\n",
    "cifar10_test_img = read_cifar(FLAGS.test_dir+'/test_batch')     # (10000, 3072)\n",
    "train_disp_idx = np.random.randint(FLAGS.img_num, size=n_plot)    # fixed during train time\n",
    "train_gt_pure = np.copy(np.take(cifar10_train_img, train_disp_idx, axis=0))    # (n_plot, 3072) fixed\n",
    "test_disp_idx = np.random.randint(FLAGS.img_num, size=n_plot)\n",
    "test_gt_pure = np.copy(np.take(cifar10_test_img, test_disp_idx, axis=0))    # (n_plot, 3072) fixed\n",
    "\n",
    "rand_train_idx = np.arange(FLAGS.img_num)    # for display loss\n",
    "rand_test_idx = np.arange(FLAGS.img_num)    # for display loss\n",
    "# Initialize\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)\n",
    "\n",
    "cifar10_test_img = read_cifar(FLAGS.test_dir+'/test_batch')     # (10000, 3072)\n",
    "\n",
    "# Optimize\n",
    "start_optm = time.time()\n",
    "for epoch in range(training_epochs):\n",
    "    for cifar_batch_idx in range(FLAGS.batch_num):\n",
    "        with tf.device('/CPU:0'):\n",
    "            start_epoch = time.time()\n",
    "            cifar_batch_name = FLAGS.train_dir+'/data_batch_%d' %(cifar_batch_idx+1)\n",
    "            cifar10_img = read_cifar(cifar_batch_name)     # (10000, 3072)\n",
    "             \n",
    "            np.random.seed(epoch)\n",
    "            np.random.shuffle(rand_train_idx)\n",
    "            np.random.shuffle(rand_test_idx)\n",
    "\n",
    "        # Iteration\n",
    "        for batch_idx in range(n_total_batch):\n",
    "            with tf.device('/CPU:0'):\n",
    "                batch_pure = np.take(cifar10_img, rand_train_idx[batch_size*batch_idx:batch_size*(batch_idx+1)], axis=0)   # pure image\n",
    "                noise = noise_batch(batch_size)    # random noise\n",
    "                batch_crpt = occl(batch_pure, noise)   # corrupted image \n",
    "                train_feeds = {ph_pure: batch_pure, ph_noise: noise, ph_crpt: batch_crpt}\n",
    "            sess.run(optm, feed_dict=train_feeds)\n",
    "\n",
    "        with tf.device('/CPU:0'):\n",
    "#             train_pure = np.take(cifar10_img,[rand_train_idx], axis=0)    # pure image\n",
    "#             train_noise = noise_batch(batch_size)    # random noise\n",
    "#             train_crpt = occl(train_pure,train_noise)   # corrupted image\n",
    "#             train_feeds = {ph_pure: train_pure, ph_noise: train_noise, ph_crpt: train_crpt}\n",
    "            train_loss, tb_train_loss = sess.run([loss,_train_loss], feed_dict=train_feeds)\n",
    "\n",
    "            test_pure = np.take(cifar10_test_img,rand_test_idx[:batch_size], axis=0)    # pure image\n",
    "            test_noise = noise_batch(batch_size)    # random noise\n",
    "            test_crpt = occl(test_pure,test_noise)   # corrupted image\n",
    "            test_feeds = {ph_pure: test_pure, ph_noise: test_noise, ph_crpt: test_crpt}\n",
    "            test_loss, tb_test_loss = sess.run([loss,_test_loss], feed_dict=test_feeds)\n",
    "\n",
    "        writer.add_summary(tb_train_loss, epoch)\n",
    "        writer.add_summary(tb_test_loss, epoch)\n",
    "        \n",
    "        epoch_time = time.time() - start_epoch\n",
    "        current_time = time.time() - start_optm\n",
    "        print(\"Epoch : %03d/%03d data_batch_%d,  Train_loss : %.4f  Test_loss : %.4f, Time/batch_file : %.4f, Training time: %.4f\" \n",
    "              % (epoch+1, training_epochs, cifar_batch_idx+1, train_loss, test_loss, epoch_time, current_time))   \n",
    "        \n",
    "    # Display\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        # train_gt_pure  # pure image\n",
    "        train_gt_noise = noise_batch(n_plot)    # random noise\n",
    "        train_gt_crpt = occl(train_gt_pure,train_gt_noise)   # corrupted image\n",
    "        train_gt_feeds = {ph_pure: train_gt_pure, ph_noise: train_gt_noise, ph_crpt: train_gt_crpt}\n",
    "        \n",
    "        # test_gt_pure   # pure image\n",
    "        test_gt_noise = noise_batch(n_plot)    # random noise\n",
    "        test_gt_crpt = occl(test_gt_pure,test_gt_noise)   # corrupted image\n",
    "        test_gt_feeds = {ph_pure: test_gt_pure, ph_noise: test_gt_noise, ph_crpt: test_gt_crpt}\n",
    "        \n",
    "        # generated images\n",
    "        train_gen_pure, train_gen_noise, train_gen_crpt = sess.run([core_gen, shell2_gen, full_gen], \\\n",
    "                                        feed_dict=train_gt_feeds)  # 3072-d vector\n",
    "        test_gen_pure, test_gen_noise, test_gen_crpt = sess.run([core_gen, shell2_gen, full_gen], \\\n",
    "                                        feed_dict=test_gt_feeds)  # 3072-d vector\n",
    "        \n",
    "        # plotting results from training data\n",
    "        with tf.device('/CPU:0'):\n",
    "            fig, axes = plt.subplots(nrows=4, ncols=n_plot, figsize=(10,2*n_plot))   # displaying 4*n_plot images\n",
    "            plt.setp(axes, xticks=np.arange(0,31,8), yticks=np.arange(0,31,8)) \n",
    "            for j in range(n_plot):\n",
    "                train_disp_gt_crpt = np.reshape(train_gt_crpt[j], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "                axes[0, j].imshow(train_disp_gt_crpt, cmap='gray')   \n",
    "                axes[0, j].set(ylabel='gt_crpt')\n",
    "                axes[0, j].label_outer()\n",
    "\n",
    "                train_disp_gen_pure = np.reshape(train_gen_pure[j], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "                axes[1, j].imshow(train_disp_gen_pure, cmap='gray')   \n",
    "                axes[1, j].set(ylabel='gen_pure')\n",
    "                axes[1, j].label_outer()\n",
    "\n",
    "                train_disp_gen_noise = np.reshape(train_gen_noise[j], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "                axes[2, j].imshow(train_disp_gen_noise, cmap='gray')   \n",
    "                axes[2, j].set(ylabel='gen_noise')\n",
    "                axes[2, j].label_outer()\n",
    "\n",
    "                train_disp_gen_crpt = np.reshape(train_gen_crpt[j], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "                axes[3, j].imshow(train_disp_gen_crpt, cmap='gray')   \n",
    "                axes[3, j].set(ylabel='gen_crpt')\n",
    "                axes[3, j].label_outer()\n",
    "\n",
    "            plt.savefig(outputdir+'/train/epoch %03d' %(epoch+1))    \n",
    "            plt.close(fig)\n",
    "\n",
    "            # plotting results from testing data\n",
    "            fig, axes = plt.subplots(nrows=4, ncols=n_plot, figsize=(10,2*n_plot))   # displaying 4*n_plot images\n",
    "            plt.setp(axes, xticks=np.arange(0,31,8), yticks=np.arange(0,31,8)) \n",
    "            for k in range(n_plot):\n",
    "                test_disp_gt_crpt = np.reshape(test_gt_crpt[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "                axes[0, k].imshow(test_disp_gt_crpt)   \n",
    "                axes[0, k].set(ylabel='gt_crpt')\n",
    "                axes[0, k].label_outer()\n",
    "\n",
    "                test_disp_gen_pure = np.reshape(test_gen_pure[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "                axes[1, k].imshow(test_disp_gen_pure)   \n",
    "                axes[1, k].set(ylabel='gen_pure')\n",
    "                axes[1, k].label_outer()           \n",
    "\n",
    "                test_disp_gen_noise = np.reshape(test_gen_noise[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "                axes[2, k].imshow(test_disp_gen_noise)   \n",
    "                axes[2, k].set(ylabel='gen_noise')\n",
    "                axes[2, k].label_outer()\n",
    "\n",
    "                test_disp_gen_crpt = np.reshape(test_gen_crpt[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "                axes[3, k].imshow(test_disp_gen_crpt)   \n",
    "                axes[3, k].set(ylabel='gen_crpt')\n",
    "                axes[3, k].label_outer()\n",
    "\n",
    "\n",
    "            plt.savefig(outputdir+'/test/epoch %03d' %(epoch+1))    \n",
    "            plt.close(fig)\n",
    "\n",
    "            # Save\n",
    "            if (epoch+1) % FLAGS.save_step ==0:\n",
    "                savename = savedir+\"/net-\"+str(epoch+1)+\".ckpt\"\n",
    "                saver.save(sess, savename)\n",
    "                print(\"[%s] SAVED\" % (savename))\n",
    "\n",
    "print(\"Optimization Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./nets/net-2000.ckpt\n",
      "NETWORK RESTORED\n"
     ]
    }
   ],
   "source": [
    "do_restore = 1\n",
    "if do_restore == 1:\n",
    "    sess = tf.Session()\n",
    "    epoch = FLAGS.training_epochs\n",
    "    savename = savedir+\"/net-\"+str(epoch)+\".ckpt\"\n",
    "    saver.restore(sess, savename)\n",
    "    print (\"NETWORK RESTORED\")\n",
    "else:\n",
    "    print (\"DO NOTHING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAIsCAYAAABRBMX6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOBwOxzXh/wd8qQHtsl11NQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fceb48bdfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_disp_idx = np.random.randint(FLAGS.img_num, size=n_plot)\n",
    "test_gt_pure = np.copy(np.take(cifar10_test_img, test_disp_idx, axis=0))    # (n_plot, 3072) fixed\n",
    "test_gt_noise = noise_batch(5)    # random noise\n",
    "test_gt_crpt = occl(test_gt_pure,test_gt_noise)   # corrupted image\n",
    "test_gt_feeds = {ph_crpt: test_gt_crpt}\n",
    "test_gen_pure, test_gen_noise, test_gen_crpt = sess.run([core_gen, shell2_gen, full_gen], \\\n",
    "                                                        feed_dict=test_gt_feeds)\n",
    "\n",
    "# plotting results from testing data\n",
    "fig, axes = plt.subplots(nrows=4, ncols=n_plot, figsize=(10,2*n_plot))   # displaying 4*n_plot images\n",
    "plt.setp(axes, xticks=np.arange(0,31,8), yticks=np.arange(0,31,8)) \n",
    "for k in range(n_plot):\n",
    "    test_disp_gt_crpt = np.reshape(test_gt_crpt[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "    axes[0, k].imshow(test_disp_gt_crpt)   \n",
    "    axes[0, k].set(ylabel='gt_crpt')\n",
    "    axes[0, k].label_outer()\n",
    "\n",
    "    test_disp_gen_pure = np.reshape(test_gen_pure[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "    axes[1, k].imshow(test_disp_gen_pure)   \n",
    "    axes[1, k].set(ylabel='gen_pure')\n",
    "    axes[1, k].label_outer()           \n",
    "\n",
    "    test_disp_gen_noise = np.reshape(test_gen_noise[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "    axes[2, k].imshow(test_disp_gen_noise)   \n",
    "    axes[2, k].set(ylabel='gen_noise')\n",
    "    axes[2, k].label_outer()\n",
    "\n",
    "    test_disp_gen_crpt = np.reshape(test_gen_crpt[k], [FLAGS.img_size,FLAGS.img_size, 3])    # 28x28\n",
    "    axes[3, k].imshow(test_disp_gen_crpt)   \n",
    "    axes[3, k].set(ylabel='gen_crpt')\n",
    "    axes[3, k].label_outer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
