{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current version [1.3.1]\n",
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  ## just for ignore DeprcationWarning message\n",
    "print(\"Current version [%s]\" %(tf.__version__))\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../data/t10k-labels-idx1-ubyte.gz\n",
      "MNIST ready\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../../data/', one_hot=True)\n",
    "train_img = mnist.train.images\n",
    "train_label = mnist.train.labels\n",
    "test_img = mnist.test.images\n",
    "test_label = mnist.test.labels\n",
    "print(\"MNIST ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random noise mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_mask():\n",
    "    mask = np.zeros([28,28])\n",
    "    # threshold of the size of masks\n",
    "    uthd = 28    \n",
    "    lthd = 0     \n",
    "    # mask size should be beween 14x14, 5x5\n",
    "    while(uthd>14 or lthd<5):\n",
    "        ver1 = np.random.random_integers(0, 27, size= 2)   # vertex1\n",
    "        ver2 = np.random.random_integers(0, 27, size= 2)    # vertex2\n",
    "        uthd = np.maximum(np.abs(ver1[0]-ver2[0]), np.abs(ver1[1]-ver2[1]))    # upperbound\n",
    "        lthd = np.minimum(np.abs(ver1[0]-ver2[0]), np.abs(ver1[1]-ver2[1]))    # lowerbound\n",
    "    xmin = np.minimum(ver1[0], ver2[0])    # left x value\n",
    "    xmax = np.maximum(ver1[0], ver2[0])    # right x value\n",
    "    ymin = np.minimum(ver1[1], ver2[1])    # top y value\n",
    "    ymax = np.maximum(ver1[1], ver2[1])    # bottom y value\n",
    "    noise = np.random.random((xmax-xmin+1, ymax-ymin+1))    # random sample in [0,1]\n",
    "    mask[xmin:xmax+1, ymin:ymax+1] = noise    # noise mask with location\n",
    "    mask_meta = [xmin, xmax, ymin, ymax, noise, mask]\n",
    "    return mask_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready\n"
     ]
    }
   ],
   "source": [
    "# Network Topology\n",
    "n_input = 784\n",
    "n_enc1 = 512/2\n",
    "n_enc2 = 256/2\n",
    "n_enc3 = 128/2\n",
    "n_dec1 = 256/2\n",
    "n_dec2 = 512/2\n",
    "n_out = 784\n",
    "\n",
    "# Inputs and Outputs\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "# Nework Parameters\n",
    "stddev = 0.1\n",
    "weights = {\n",
    "    'enc1' : tf.Variable(tf.random_normal([n_input, n_enc1], stddev=stddev)),\n",
    "    'enc2' : tf.Variable(tf.random_normal([n_enc1, n_enc2], stddev=stddev)),\n",
    "    'enc3' : tf.Variable(tf.random_normal([n_enc2, n_enc3], stddev=stddev)),\n",
    "    'dec1' : tf.Variable(tf.random_normal([n_enc3, n_dec1], stddev=stddev)),\n",
    "    'dec2' : tf.Variable(tf.random_normal([n_dec1, n_dec2], stddev=stddev)),\n",
    "    'out' : tf.Variable(tf.random_normal([n_dec2, n_out], stddev=stddev))\n",
    "}\n",
    "biases = {\n",
    "    'enc1' : tf.Variable(tf.random_normal([n_enc1], stddev=stddev)),\n",
    "    'enc2' : tf.Variable(tf.random_normal([n_enc2], stddev=stddev)),\n",
    "    'enc3' : tf.Variable(tf.random_normal([n_enc3], stddev=stddev)),\n",
    "    'dec1' : tf.Variable(tf.random_normal([n_dec1], stddev=stddev)),\n",
    "    'dec2' : tf.Variable(tf.random_normal([n_dec2], stddev=stddev)),\n",
    "    'out' : tf.Variable(tf.random_normal([n_out], stddev=stddev))\n",
    "}\n",
    "\n",
    "print(\"Network Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs Ready\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "def ae(_X, _weights, _biases):\n",
    "    enc1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights['enc1']),_biases['enc1']))\n",
    "    enc2 = tf.nn.sigmoid(tf.add(tf.matmul(enc1, _weights['enc2']),_biases['enc2']))\n",
    "    enc3 = tf.nn.sigmoid(tf.add(tf.matmul(enc2, _weights['enc3']),_biases['enc3']))\n",
    "    dec1 = tf.nn.sigmoid(tf.add(tf.matmul(enc3, _weights['dec1']),_biases['dec1']))\n",
    "    dec2 = tf.nn.sigmoid(tf.add(tf.matmul(dec1, _weights['dec2']),_biases['dec2']))\n",
    "    out = tf.nn.sigmoid(tf.add(tf.matmul(dec2, _weights['out']),_biases['out']))\n",
    "    _out = {\n",
    "        'enc1' : enc1,\n",
    "        'enc2' : enc2,\n",
    "        'enc3' : enc3,\n",
    "        'dec1' : dec1,\n",
    "        'dec2' : dec2,\n",
    "        'out' : out\n",
    "    }\n",
    "    return _out\n",
    "\n",
    "# Generation\n",
    "gen = ae(x, weights, biases)['out']    # [None, n_input]\n",
    "\n",
    "# Loss & Optimizer\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    cost = tf.reduce_mean(tf.nn.l2_loss(gen-x))\n",
    "    train_loss = tf.summary.scalar(\"train_loss\", cost)\n",
    "    test_loss = tf.summary.scalar(\"test_loss\", cost)\n",
    "counter = 0\n",
    "\n",
    "optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "\n",
    "print(\"Graphs Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Ready\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "tensorboard_path = \"tensorboard\"\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path)\n",
    "writer = tf.summary.FileWriter(tensorboard_path)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "print(\"Initialize Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saver ready\n"
     ]
    }
   ],
   "source": [
    "outputdir = \"output\"\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "    \n",
    "savedir = \"nets\"\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "    \n",
    "saver = tf.train.Saver(max_to_keep=3)\n",
    "save_step = 5\n",
    "\n",
    "print(\"Saver ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 001/005  Train_loss : 2191.1909180  Test_loss : 2031.0305176\n",
      "Epoch : 002/005  Train_loss : 1538.0623779  Test_loss : 1548.2508545\n",
      "Epoch : 003/005  Train_loss : 1283.3503418  Test_loss : 1341.6989746\n",
      "Epoch : 004/005  Train_loss : 1283.6140137  Test_loss : 1227.9260254\n",
      "Epoch : 005/005  Train_loss : 1132.1136475  Test_loss : 1104.1437988\n",
      "[nets/net-5.ckpt] SAVED\n",
      "Optimization Finished\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "training_epochs = 5\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "# Plot\n",
    "n_plot = 5    # plot 5 images\n",
    "train_disp_idx = np.random.randint(mnist.train.num_examples, size=n_plot)    # fixed during train time\n",
    "test_disp_idx = np.random.randint(mnist.test.num_examples, size=n_plot)\n",
    "\n",
    "# Initialize\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)\n",
    "\n",
    "# Optimize\n",
    "for epoch in range(training_epochs):\n",
    "    total_cost = 0.\n",
    "    n_total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    rand_train_idx = np.random.randint(mnist.train.num_examples, size=batch_size)\n",
    "    rand_test_idx = np.random.randint(mnist.test.num_examples, size=batch_size)\n",
    "    \n",
    "    # Iteration\n",
    "    for i in range(n_total_batch):\n",
    "        batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "        feeds = {x: batch_xs}\n",
    "        sess.run(optm, feed_dict=feeds)\n",
    "        total_cost += sess.run(cost, feed_dict=feeds)\n",
    "    total_cost = total_cost / mnist.train.num_examples\n",
    "    \n",
    "    train_feed = {x: mnist.train.images[rand_train_idx]}\n",
    "    train_cost, tb_train_loss = sess.run([cost,train_loss], feed_dict=train_feed)\n",
    "    test_feed = {x: mnist.test.images[rand_test_idx]}\n",
    "    test_cost, tb_test_loss = sess.run([cost,test_loss], feed_dict=test_feed)\n",
    "\n",
    "    writer.add_summary(tb_train_loss, epoch)\n",
    "    writer.add_summary(tb_test_loss, epoch)\n",
    "    print(\"Epoch : %03d/%03d  Train_loss : %.7f  Test_loss : %.7f\" \n",
    "          % (epoch+1, training_epochs, train_cost, test_cost))   \n",
    "        \n",
    "    # Display\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        train_disp_feed = {x:mnist.train.images[train_disp_idx]}\n",
    "        test_disp_feed = {x:mnist.test.images[test_disp_idx]}\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=4, ncols=n_plot, figsize=(10,2*n_plot))   # displaying 4*n_plot images\n",
    "        plt.setp(axes, xticks=np.arange(0,27,7), yticks=np.arange(0,27,7))\n",
    "        train_gens = sess.run(gen, feed_dict={x: train_img[train_disp_idx,:]})    # 784-d vector\n",
    "        test_gens = sess.run(gen, feed_dict={x: test_img[test_disp_idx,:]})    # 784-d vector\n",
    "        for j in range(n_plot):\n",
    "            train_gt = np.reshape(train_img[train_disp_idx[j]], [28,28])\n",
    "            axes[0, j].imshow(train_gt, cmap='gray')\n",
    "            axes[0, j].set(ylabel='train_gt')\n",
    "            axes[0, j].label_outer()\n",
    "            \n",
    "            train_gen = np.reshape(train_gens[j,:], [28,28])    # 28x28\n",
    "            axes[1, j].imshow(train_gen, cmap='gray')   \n",
    "            axes[1, j].set(ylabel='train_gen')\n",
    "            axes[1, j].label_outer()\n",
    "            \n",
    "            test_gt = np.reshape(test_img[test_disp_idx[j]], [28,28])\n",
    "            axes[2, j].imshow(test_gt, cmap='gray')     \n",
    "            axes[2, j].set(ylabel='test_gt')\n",
    "            axes[2, j].label_outer()\n",
    "            \n",
    "            test_gen = np.reshape(test_gens[j,:], [28,28])    # 28x28\n",
    "            axes[3, j].imshow(test_gen, cmap='gray')     \n",
    "            axes[3, j].set(ylabel='test_gen')\n",
    "            axes[3, j].label_outer()\n",
    "            \n",
    "        plt.savefig(outputdir+'/epoch %03d' %(epoch))    \n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Save\n",
    "        if (epoch+1) % save_step ==0:\n",
    "            savename = savedir+\"/net-\"+str(epoch+1)+\".ckpt\"\n",
    "            saver.save(sess, savename)\n",
    "            print(\"[%s] SAVED\" % (savename))\n",
    "\n",
    "print(\"Optimization Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.reshape(train_img[np.random.random_integers(0,55000)], [28,28])     # inputdata : 55000\n",
    "mask = noise_mask()\n",
    "masked_ex = np.copy(example)\n",
    "masked_ex[mask[0]:mask[1]+1, mask[2]:mask[3]+1] = mask[4]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(12,9))\n",
    "plt.setp(ax, xticks=np.arange(0,27,7), yticks=np.arange(0,27,7))\n",
    "for k in range(4):\n",
    "    ax[0, k].imshow(mask[5])\n",
    "    ax[0, k].set(xlabel='xlabel', ylabel='ylabel')\n",
    "    ax[0, k].label_outer()\n",
    "    ax[1, k].imshow(example)\n",
    "    ax[1, k].set(xlabel='xlabel', ylabel='ylabel')\n",
    "    ax[1, k].label_outer()\n",
    "    ax[2, k].imshow(masked_ex)\n",
    "    ax[2, k].set(xlabel='xlabel', ylabel='ylabel')\n",
    "    ax[2, k].label_outer()\n",
    "\n",
    "# fig.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "# plt.figure(figsize=(12,9))\n",
    "# for p in range(4):\n",
    "#     aa = plt.subplot(3, 4, p+1)\n",
    "#     aa.imshow(mask[5])\n",
    "#     aa.set(xlabel='xlabel', ylabel='ylabel')\n",
    "#     plt.xticks(np.arange(0,27,7))\n",
    "#     plt.yticks(np.arange(0,27,7))\n",
    "#     aa.label_outer()\n",
    "    \n",
    "#     bb = plt.subplot(3, 4, p+5)\n",
    "#     bb.imshow(example)\n",
    "#     bb.set(xlabel='xlabel', ylabel='ylabel')\n",
    "#     plt.xticks(np.arange(0,27,7))\n",
    "#     plt.yticks(np.arange(0,27,7))\n",
    "#     bb.label_outer()\n",
    "    \n",
    "#     cc = plt.subplot(3, 4, p+9)\n",
    "#     cc.imshow(masked_ex)\n",
    "#     cc.set(xlabel='xlabel', ylabel='ylabel')\n",
    "#     plt.xticks(np.arange(0,27,7))\n",
    "#     plt.yticks(np.arange(0,27,7))\n",
    "#     cc.label_outer()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "#plt.imshow(mask[5], cmap='gray')\n",
    "#plt.show()\n",
    "#plt.imshow(example, cmap='gray')\n",
    "#plt.show()\n",
    "#plt.imshow(masked_ex, cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2], [10, 20]]\n",
    "b = np.zeros([3,5])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[2,3],[4,5]]\n",
    "a[1:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
